"""
ğŸ¯ Kë¦¬ê·¸ 2024 ì‹œì¦Œ - ì´ˆí˜„ëŒ€ì  ë°ì´í„° ë¶„ì„ íŒŒì´í”„ë¼ì¸
========================================================

âœ¨ ìµœì‹  Pandas/Seaborn/SciPy íŒ¨í„´ ì™„ì „ ì ìš©:
- Pandas: Timedelta operations, efficient filtering, advanced indexing
- Seaborn: Figure-level functions, FacetGrid, modern objects interface  
- SciPy: Advanced optimization, statistical sampling, signal processing
- Scikit-learn: Latest pipeline patterns, quantile regression

ğŸš€ íŠ¹ì§•:
- ë©”ëª¨ë¦¬ íš¨ìœ¨ì ì¸ ë°ì´í„° ì²˜ë¦¬
- í˜„ëŒ€ì  ì‹œê°í™” íŒ¨í„´
- ê³ ê¸‰ í†µê³„/ìµœì í™” ê¸°ë²•
- ì¬í˜„ì„± ìˆëŠ” íŒŒì´í”„ë¼ì¸
- ì‹¤ì‹œê°„ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§

ì‘ì„±ì: Claude (Ultra Modern Data Scientist)
ë‚œì´ë„: â­â­â­â­â­ (ê³ ê¸‰ì)
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats, optimize, signal
from scipy.stats import sampling
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.impute import SimpleImputer
from sklearn.model_selection import (
    train_test_split, StratifiedKFold, cross_validate, 
    RandomizedSearchCV, learning_curve
)
from sklearn.linear_model import LogisticRegression, TweedieRegressor
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.experimental import enable_hist_gradient_boosting
from sklearn.ensemble import HistGradientBoostingRegressor
from sklearn.metrics import (
    classification_report, accuracy_score, roc_auc_score, 
    confusion_matrix, precision_recall_curve
)

# ìµœì‹  ìŠ¤íƒ€ì¼ ì„¤ì •
plt.style.use('seaborn-v0_8-whitegrid')
sns.set_palette("husl")
RANDOM_STATE = 42
np.random.seed(RANDOM_STATE)

print("ğŸ¯ Kë¦¬ê·¸ ì´ˆí˜„ëŒ€ì  ë°ì´í„° ë¶„ì„ íŒŒì´í”„ë¼ì¸ ì‹œì‘!")
print("=" * 80)

# ============================================================
# ğŸ“Š ìµœì‹  Pandas íŒ¨í„´ ì ìš© ë°ì´í„° ì²˜ë¦¬
# ============================================================

class ModernKLeagueDataProcessor:
    """ìµœì‹  Pandas íŒ¨í„´ì„ ì ìš©í•œ Kë¦¬ê·¸ ë°ì´í„° ì²˜ë¦¬ í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.raw_data = None
        self.match_info = None
        self.processed_data = None
        
    def load_data(self, raw_path='data/raw/raw_data.csv', match_path='data/raw/match_info.csv'):
        """ë©”ëª¨ë¦¬ íš¨ìœ¨ì ì¸ ë°ì´í„° ë¡œë“œ (ìµœì‹  Pandas íŒ¨í„´)"""
        try:
            # dtype ì§€ì •ìœ¼ë¡œ ë©”ëª¨ë¦¬ ìµœì í™”
            dtypes = {
                'team_id': 'int32',
                'game_id': 'int32', 
                'player_id': 'int32',
                'total_passes': 'int16',
                'pass_success_rate': 'float32',
                'total_shots': 'int16',
                'tackles': 'int16',
                'interceptions': 'int16',
                'fouls': 'int16',
                'attack_zone_actions': 'int16',
                'take_ons': 'int16',
                'goals': 'int8',
                'goals_against': 'int8'
            }
            
            self.raw_data = pd.read_csv(raw_path, dtype=dtypes, encoding='utf-8')
            self.match_info = pd.read_csv(match_path, encoding='utf-8')
            
            # ìµœì‹  Timedelta íŒ¨í„´ìœ¼ë¡œ ë‚ ì§œ ì²˜ë¦¬
            self.match_info['game_date'] = pd.to_datetime(self.match_info['game_date'])
            
            # ê²°ì¸¡ì¹˜ íš¨ìœ¨ì  ì²˜ë¦¬
            self.raw_data['result_name'] = self.raw_data['result_name'].fillna('Unknown')
            
            print(f"âœ“ ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {self.raw_data.shape}, {self.match_info.shape}")
            print(f"âœ“ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ìµœì í™”ë¨")
            
        except FileNotFoundError:
            print("âŒ ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            exit(1)
    
    def create_advanced_features(self):
        """ê³ ê¸‰ í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§ (ìµœì‹  Pandas íŒ¨í„´)"""
        
        # 1. íš¨ìœ¨ì ì¸ í•„í„°ë§ê³¼ ê·¸ë£¹í™” (ìµœì‹  íŒ¨í„´)
        attack_events = (
            self.raw_data[self.raw_data['start_x'] > 70]
            .groupby(['game_id', 'team_name_ko'], observed=True)
            .size()
            .rename('attack_zone_actions')
        )
        
        shot_events = (
            self.raw_data[self.raw_data['type_name'].str.contains('Shot', case=False, na=False)]
            .groupby(['game_id', 'team_name_ko'], observed=True)
            .size()
            .rename('total_shots')
        )
        
        pass_events = (
            self.raw_data
            .groupby(['game_id', 'team_name_ko'], observed=True)
            .agg({
                'total_passes': 'sum',
                'pass_success_rate': 'mean',
                'tackles': 'sum',
                'interceptions': 'sum',
                'fouls': 'sum',
                'take_ons': 'sum',
                'goals': 'sum',
                'goals_against': 'sum'
            })
        )
        
        # 2. íš¨ìœ¨ì ì¸ ì¡°ì¸ (ìµœì‹  íŒ¨í„´)
        game_stats = pd.concat([pass_events, attack_events, shot_events], axis=1).fillna(0)
        
        # 3. í™ˆ/ì–´ì›¨ì´ ì •ë³´ ë³‘í•©
        game_stats = game_stats.reset_index()
        game_stats = game_stats.merge(
            self.match_info[['game_id', 'home_team_id', 'away_team_id', 'game_date']],
            on='game_id',
            how='left'
        )
        
        # 4. í™ˆ/ì–´ì›¨ì´ í”Œë˜ê·¸ ìƒì„± (íš¨ìœ¨ì  ë¹„êµ)
        game_stats['is_home'] = (
            game_stats['team_name_ko'].map(
                self.match_info.set_index('team_id')['team_name_ko'].to_dict()
            ) == game_stats['home_team_id']
        ).fillna(0).astype('int8')
        
        # 5. ì‹œê°„ ê¸°ë°˜ í”¼ì²˜ (Timedelta íŒ¨í„´)
        game_stats['days_since_season_start'] = (
            game_stats['game_date'] - game_stats['game_date'].min()
        ).dt.days
        
        # 6. ê³ ê¸‰ ìƒí˜¸ì‘ìš© í”¼ì²˜
        game_stats['home_shot_advantage'] = game_stats['is_home'] * game_stats['total_shots']
        game_stats['home_pass_advantage'] = game_stats['is_home'] * game_stats['total_passes']
        
        # 7. íš¨ìœ¨ì„± í”¼ì²˜ (ì•ˆì „í•œ ë‚˜ëˆ—ì…ˆ)
        game_stats['shot_conversion_rate'] = np.where(
            game_stats['total_shots'] > 0,
            game_stats['goals'] / game_stats['total_shots'],
            0
        )
        
        game_stats['pass_efficiency'] = np.where(
            game_stats['total_passes'] > 0,
            game_stats['attack_zone_actions'] / game_stats['total_passes'],
            0
        )
        
        # 8. ë°©ì–´ ê°•ë„ í”¼ì²˜
        game_stats['defensive_intensity'] = game_stats['tackles'] + game_stats['interceptions']
        
        # 9. ë¡¤ë§ í†µê³„ (ì‹œê³„ì—´ íŒ¨í„´)
        game_stats = game_stats.sort_values(['team_name_ko', 'game_date'])
        
        rolling_features = ['goals', 'total_shots', 'pass_success_rate']
        for feature in rolling_features:
            game_stats[f'{feature}_rolling_3'] = (
                game_stats.groupby('team_name_ko')[feature]
                .rolling(window=3, min_periods=1)
                .mean()
                .reset_index(0, drop=True)
            )
        
        self.processed_data = game_stats
        print(f"âœ“ ê³ ê¸‰ í”¼ì²˜ ìƒì„± ì™„ë£Œ: {game_stats.shape}")
        
        return game_stats
    
    def create_target_variables(self):
        """íƒ€ê²Ÿ ë³€ìˆ˜ ìƒì„± (ìµœì‹  íŒ¨í„´)"""
        
        # ìŠ¹ë¦¬/ë¬´ìŠ¹ë¶€ íƒ€ê²Ÿ
        self.processed_data['win_or_draw'] = (
            self.processed_data['goals'] >= self.processed_data['goals_against']
        ).astype('int8')
        
        # ê³¨ ë“ì‹¤ íƒ€ê²Ÿ (íšŒê·€ìš©)
        self.processed_data['goal_difference'] = (
            self.processed_data['goals'] - self.processed_data['goals_against']
        )
        
        # ë“ì  ì—¬ë¶€ íƒ€ê²Ÿ
        self.processed_data['scored_goal'] = (self.processed_data['goals'] > 0).astype('int8')
        
        print("âœ“ íƒ€ê²Ÿ ë³€ìˆ˜ ìƒì„± ì™„ë£Œ")
        return self.processed_data

# ============================================================
# ğŸ¨ ìµœì‹  Seaborn íŒ¨í„´ ì ìš© ì‹œê°í™”
# ============================================================

class ModernKLeagueVisualizer:
    """ìµœì‹  Seaborn íŒ¨í„´ì„ ì ìš©í•œ ì‹œê°í™” í´ë˜ìŠ¤"""
    
    def __init__(self, data):
        self.data = data
        
    def create_comprehensive_dashboard(self):
        """ì¢…í•© ëŒ€ì‹œë³´ë“œ (Figure-level functions í™œìš©)"""
        
        # Figure-level í•¨ìˆ˜ë¡œ ë‹¤ì¤‘ í”Œë¡¯ ìƒì„±
        g = sns.FacetGrid(
            self.data, 
            col='is_home', 
            hue='win_or_draw',
            height=6, 
            aspect=1.2,
            palette={0: 'lightcoral', 1: 'lightblue'}
        )
        
        # ë‹¤ì–‘í•œ í”Œë¡¯ ì¡°í•©
        g.map_dataframe(
            sns.scatterplot, 
            x='total_shots', 
            y='pass_success_rate',
            size='goals',
            alpha=0.7
        )
        
        g.map_dataframe(
            sns.regplot, 
            x='total_shots', 
            y='goals',
            scatter=False,
            line_kws={'color': 'red', 'linestyle': '--'}
        )
        
        g.set_axis_labels('ì´ ìŠˆíŒ… ìˆ˜', 'íŒ¨ìŠ¤ ì„±ê³µë¥ ')
        g.set_titles('í™ˆ/ì–´ì›¨ì´ë³„ ìŠ¹ë¦¬ ì˜ˆì¸¡')
        g.add_legend()
        
        plt.tight_layout()
        plt.show()
    
    def create_distribution_analysis(self):
        """ë¶„í¬ ë¶„ì„ (ìµœì‹  Seaborn íŒ¨í„´)"""
        
        # Figure-level í•¨ìˆ˜ë¡œ ë‹¤ì¤‘ ë¶„í¬ í”Œë¡¯
        fig, axes = plt.subplots(2, 3, figsize=(18, 12))
        
        # 1. íˆìŠ¤í† ê·¸ë¨ + KDE (displot ìŠ¤íƒ€ì¼)
        sns.histplot(
            data=self.data, 
            x='goal_difference', 
            hue='win_or_draw',
            multiple='stack',
            kde=True,
            ax=axes[0, 0]
        )
        axes[0, 0].set_title('ê³¨ ë“ì‹¤ ë¶„í¬')
        
        # 2. ë°•ìŠ¤í”Œë¡¯ (catplot ìŠ¤íƒ€ì¼)
        sns.boxplot(
            data=self.data,
            x='is_home',
            y='total_shots',
            hue='win_or_draw',
            ax=axes[0, 1]
        )
        axes[0, 1].set_title('í™ˆ/ì–´ì›¨ì´ë³„ ìŠˆíŒ… ìˆ˜')
        
        # 3. ë°”ì´ì˜¬ë¦° í”Œë¡¯
        sns.violinplot(
            data=self.data,
            x='win_or_draw',
            y='pass_success_rate',
            ax=axes[0, 2]
        )
        axes[0, 2].set_title('ìŠ¹ë¦¬ ì—¬ë¶€ë³„ íŒ¨ìŠ¤ ì„±ê³µë¥ ')
        
        # 4. íˆíŠ¸ë§µ (ìƒê´€ê´€ê³„)
        numeric_cols = [
            'goals', 'total_shots', 'pass_success_rate', 
            'tackles', 'interceptions', 'goal_difference'
        ]
        correlation_matrix = self.data[numeric_cols].corr()
        
        sns.heatmap(
            correlation_matrix,
            annot=True,
            cmap='coolwarm',
            center=0,
            ax=axes[1, 0]
        )
        axes[1, 0].set_title('ìƒê´€ê´€ê³„ íˆíŠ¸ë§µ')
        
        # 5. í˜ì–´í”Œë¡¯ (ì¼ë¶€ ë³€ìˆ˜ë§Œ)
        sample_vars = ['goals', 'total_shots', 'pass_success_rate', 'win_or_draw']
        sample_data = self.data[sample_vars].sample(min(500, len(self.data)))
        
        # í˜ì–´í”Œë¡¯ì„ ê°œë³„ì ìœ¼ë¡œ ê·¸ë¦¬ê¸° (ë©”ëª¨ë¦¬ íš¨ìœ¨)
        sns.scatterplot(
            data=sample_data,
            x='total_shots',
            y='pass_success_rate',
            hue='win_or_draw',
            ax=axes[1, 1]
        )
        axes[1, 1].set_title('ìŠˆíŒ… vs íŒ¨ìŠ¤ ì„±ê³µë¥ ')
        
        # 6. ì‹œê³„ì—´ íŒ¨í„´
        time_data = self.data.groupby('days_since_season_start')['goal_difference'].mean().reset_index()
        sns.lineplot(
            data=time_data,
            x='days_since_season_start',
            y='goal_difference',
            ax=axes[1, 2]
        )
        axes[1, 2].set_title('ì‹œì¦Œ ê²½ê³¼ë³„ ê³¨ ë“ì‹¤')
        
        plt.tight_layout()
        plt.show()
    
    def create_advanced_visualizations(self):
        """ê³ ê¸‰ ì‹œê°í™” (ìµœì‹  Seaborn objects interface)"""
        
        # 1. Jointplot (ìƒì„¸ ë¶„í¬)
        sns.jointplot(
            data=self.data,
            x='total_shots',
            y='goals',
            hue='is_home',
            kind='scatter',
            height=8,
            alpha=0.6
        )
        plt.suptitle('ìŠˆíŒ…-ë“ì  ê´€ê³„ (í™ˆ/ì–´ì›¨ì´ë³„)', y=1.02)
        plt.show()
        
        # 2. Pairplot (í•µì‹¬ ë³€ìˆ˜ë“¤)
        core_features = ['goals', 'total_shots', 'pass_success_rate', 'defensive_intensity']
        pair_data = self.data[core_features + ['win_or_draw']].sample(min(300, len(self.data)))
        
        sns.pairplot(
            pair_data,
            hue='win_or_draw',
            diag_kind='kde',
            plot_kws={'alpha': 0.6},
            diag_kws={'fill': True}
        )
        plt.suptitle('í•µì‹¬ ë³€ìˆ˜ ê°„ ê´€ê³„', y=1.02)
        plt.show()

# ============================================================
# ğŸ”¬ ìµœì‹  SciPy íŒ¨í„´ ì ìš© í†µê³„ ë¶„ì„
# ============================================================

class ModernKLeagueStatisticalAnalyzer:
    """ìµœì‹  SciPy íŒ¨í„´ì„ ì ìš©í•œ í†µê³„ ë¶„ì„ í´ë˜ìŠ¤"""
    
    def __init__(self, data):
        self.data = data
        
    def advanced_hypothesis_testing(self):
        """ê³ ê¸‰ ê°€ì„¤ ê²€ì • (ìµœì‹  SciPy íŒ¨í„´)"""
        
        print("\nğŸ”¬ ê³ ê¸‰ í†µê³„ ë¶„ì„")
        print("-" * 60)
        
        # 1. ë…ë¦½í‘œë³¸ t-ê²€ì • (í™ˆ vs ì–´ì›¨ì´)
        home_goals = self.data[self.data['is_home'] == 1]['goals']
        away_goals = self.data[self.data['is_home'] == 0]['goals']
        
        t_stat, p_value = stats.ttest_ind(home_goals, away_goals)
        
        print(f"í™ˆ/ì–´ì›¨ì´ ë“ì  t-ê²€ì •:")
        print(f"  t-í†µê³„ëŸ‰: {t_stat:.4f}")
        print(f"  p-value: {p_value:.4f}")
        
        if p_value < 0.05:
            home_advantage = (home_goals.mean() - away_goals.mean()) / away_goals.mean() * 100
            print(f"  âœ“ í™ˆ ì–´ë“œë°´í‹°ì§€ í™•ì¸: {home_advantage:.1f}%")
        
        # 2. ë¶„ì‚° ë¶„ì„ (ANOVA) - íŒ€ë³„ ë“ì  ì°¨ì´
        team_goals = [
            group['goals'].values for name, group in self.data.groupby('team_name_ko')
        ]
        
        f_stat, p_anova = stats.f_oneway(*team_goals)
        
        print(f"\níŒ€ë³„ ë“ì  ANOVA:")
        print(f"  F-í†µê³„ëŸ‰: {f_stat:.4f}")
        print(f"  p-value: {p_anova:.4f}")
        
        # 3. ìƒê´€ê´€ê³„ ê²€ì •
        shot_goal_corr, p_corr = stats.pearsonr(
            self.data['total_shots'], 
            self.data['goals']
        )
        
        print(f"\nìŠˆíŒ…-ë“ì  ìƒê´€ê´€ê³„:")
        print(f"  ìƒê´€ê³„ìˆ˜: {shot_goal_corr:.4f}")
        print(f"  p-value: {p_corr:.4f}")
        
        return {
            'home_advantage_test': {'t_stat': t_stat, 'p_value': p_value},
            'team_anova': {'f_stat': f_stat, 'p_value': p_anova},
            'shot_goal_correlation': {'corr': shot_goal_corr, 'p_value': p_corr}
        }
    
    def advanced_optimization_analysis(self):
        """ê³ ê¸‰ ìµœì í™” ë¶„ì„ (ìµœì‹  SciPy íŒ¨í„´)"""
        
        print("\nâš¡ ê³ ê¸‰ ìµœì í™” ë¶„ì„")
        print("-" * 60)
        
        # 1. ìµœì  ìŠˆíŒ…ë¥  ì°¾ê¸° (minimize_scalar)
        def shot_efficiency_model(x):
            """ìŠˆíŒ… íš¨ìœ¨ ëª¨ë¸"""
            return -np.exp(-0.1 * x) * (1 - np.exp(-0.05 * x))
        
        result = optimize.minimize_scalar(
            shot_efficiency_model,
            bounds=(0, 50),
            method='bounded'
        )
        
        optimal_shots = result.x
        max_efficiency = -result.fun
        
        print(f"ìµœì  ìŠˆíŒ… ìˆ˜: {optimal_shots:.1f}")
        print(f"ìµœëŒ€ íš¨ìœ¨: {max_efficiency:.3f}")
        
        # 2. ì‹ í˜¸ ì²˜ë¦¬ - ê²½ê¸° íŒ¨í„´ ë¶„ì„
        team_performance = self.data.groupby('team_name_ko')['goal_difference'].mean()
        
        # ì‹ í˜¸ smoothing (convolution í™œìš©)
        smoothed_performance = signal.convolve(
            team_performance.values, 
            np.ones(3)/3, 
            mode='same'
        )
        
        print(f"\níŒ€ ì„±ì  smoothing ì™„ë£Œ")
        print(f"ì›ë³¸ í‰ê· : {team_performance.mean():.3f}")
        print(f"Smoothing í›„ í‰ê· : {smoothed_performance.mean():.3f}")
        
        return {
            'optimal_shots': optimal_shots,
            'max_efficiency': max_efficiency,
            'smoothed_performance': smoothed_performance
        }
    
    def statistical_sampling_analysis(self):
        """í†µê³„ì  ìƒ˜í”Œë§ ë¶„ì„ (ìµœì‹  SciPy íŒ¨í„´)"""
        
        print("\nğŸ² í†µê³„ì  ìƒ˜í”Œë§ ë¶„ì„")
        print("-" * 60)
        
        # 1. ë“ì  ë¶„í¬ ëª¨ë¸ë§
        goals = self.data['goals']
        
        # í¬ì•„ì†¡ ë¶„ìˆ˜ fitting
        poisson_lambda = goals.mean()
        
        # 2. Monte Carlo ì‹œë®¬ë ˆì´ì…˜
        n_simulations = 10000
        simulated_goals = np.random.poisson(poisson_lambda, n_simulations)
        
        # 3. ì‹ ë¢° êµ¬ê°„ ê³„ì‚°
        confidence_interval = np.percentile(simulated_goals, [2.5, 97.5])
        
        print(f"ë“ì  ë¶„í¬ ë¶„ì„:")
        print(f"  í‰ê·  ë“ì : {poisson_lambda:.2f}")
        print(f"  95% ì‹ ë¢°êµ¬ê°„: {confidence_interval}")
        
        # 4. í™•ë¥  ê³„ì‚°
        prob_2_plus_goals = np.mean(simulated_goals >= 2)
        prob_clean_sheet = np.mean(simulated_goals == 0)
        
        print(f"  2ê³¨ ì´ìƒ ë“ì  í™•ë¥ : {prob_2_plus_goals:.1%}")
        print(f"  ë¬´ì‹¤ì  í™•ë¥ : {prob_clean_sheet:.1%}")
        
        return {
            'poisson_lambda': poisson_lambda,
            'confidence_interval': confidence_interval,
            'prob_2_plus_goals': prob_2_plus_goals,
            'prob_clean_sheet': prob_clean_sheet
        }

# ============================================================
# ğŸ¤– ìµœì‹  Scikit-learn íŒ¨í„´ ì ìš© ë¨¸ì‹ ëŸ¬ë‹
# ============================================================

class ModernKLeagueMLPipeline:
    """ìµœì‹  Scikit-learn íŒ¨í„´ì„ ì ìš©í•œ ë¨¸ì‹ ëŸ¬ë‹ íŒŒì´í”„ë¼ì¸"""
    
    def __init__(self, data):
        self.data = data
        self.models = {}
        self.results = {}
        
    def prepare_features(self):
        """í”¼ì²˜ ì¤€ë¹„ (ìµœì‹  íŒ¨í„´)"""
        
        # í”¼ì²˜ ì„ íƒ
        numeric_features = [
            'total_passes', 'pass_success_rate', 'total_shots',
            'tackles', 'interceptions', 'fouls', 
            'attack_zone_actions', 'take_ons',
            'defensive_intensity', 'shot_conversion_rate',
            'home_shot_advantage', 'home_pass_advantage',
            'goals_rolling_3', 'total_shots_rolling_3'
        ]
        
        categorical_features = ['team_name_ko']
        binary_features = ['is_home']
        
        # ê²°ì¸¡ì¹˜ ì²˜ë¦¬
        X = self.data[numeric_features + categorical_features + binary_features].fillna(0)
        y_classification = self.data['win_or_draw']
        y_regression = self.data['goal_difference']
        
        return X, y_classification, y_regression, numeric_features, categorical_features, binary_features
    
    def build_modern_pipeline(self, numeric_features, categorical_features, binary_features):
        """í˜„ëŒ€ì  íŒŒì´í”„ë¼ì¸ êµ¬ì¶•"""
        
        # ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸
        preprocessor = ColumnTransformer(
            transformers=[
                ('num', Pipeline([
                    ('imputer', SimpleImputer(strategy='median')),
                    ('scaler', StandardScaler())
                ]), numeric_features),
                ('cat', Pipeline([
                    ('imputer', SimpleImputer(strategy='most_frequent')),
                    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))
                ]), categorical_features),
                ('bin', Pipeline([
                    ('imputer', SimpleImputer(strategy='most_frequent'))
                ]), binary_features)
            ]
        )
        
        # ë¶„ë¥˜ ëª¨ë¸ íŒŒì´í”„ë¼ì¸
        classification_models = {
            'Logistic Regression': Pipeline([
                ('preprocessor', preprocessor),
                ('classifier', LogisticRegression(
                    max_iter=1000,
                    random_state=RANDOM_STATE,
                    penalty='l2',
                    C=1.0,
                    solver='lbfgs'
                ))
            ]),
            'Random Forest': Pipeline([
                ('preprocessor', preprocessor),
                ('classifier', RandomForestClassifier(
                    n_estimators=200,
                    max_depth=10,
                    min_samples_split=5,
                    random_state=RANDOM_STATE,
                    n_jobs=-1,
                    oob_score=True
                ))
            ]),
            'Gradient Boosting': Pipeline([
                ('preprocessor', preprocessor),
                ('classifier', GradientBoostingClassifier(
                    n_estimators=200,
                    learning_rate=0.05,
                    max_depth=6,
                    subsample=0.8,
                    random_state=RANDOM_STATE
                ))
            ])
        }
        
        # íšŒê·€ ëª¨ë¸ íŒŒì´í”„ë¼ì¸ (TweedieRegressor - ìµœì‹  íŒ¨í„´)
        regression_models = {
            'Tweedie Regression': Pipeline([
                ('preprocessor', preprocessor),
                ('regressor', TweedieRegressor(
                    power=1.5,  # Compound Poisson-Gamma
                    alpha=0.1,
                    link='log',
                    max_iter=1000
                ))
            ]),
            'Quantile Regression': Pipeline([
                ('preprocessor', preprocessor),
                ('regressor', HistGradientBoostingRegressor(
                    loss="quantile",
                    quantile=0.9,
                    max_iter=200,
                    random_state=RANDOM_STATE
                ))
            ])
        }
        
        return classification_models, regression_models
    
    def comprehensive_evaluation(self, models, X, y, task_type='classification'):
        """ì¢…í•© í‰ê°€ (ìµœì‹  íŒ¨í„´)"""
        
        cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)
        
        if task_type == 'classification':
            scoring = ['accuracy', 'roc_auc', 'precision', 'recall', 'f1']
        else:
            scoring = ['neg_mean_squared_error', 'neg_mean_absolute_error', 'r2']
        
        results = {}
        
        for name, model in models.items():
            print(f"\nğŸ” {name} í‰ê°€ ì¤‘...")
            
            cv_results = cross_validate(
                model, X, y,
                cv=cv,
                scoring=scoring,
                return_train_score=True,
                n_jobs=-1
            )
            
            # ê²°ê³¼ ì €ì¥
            results[name] = {}
            for metric in scoring:
                test_key = f'test_{metric}'
                if test_key in cv_results:
                    results[name][metric] = {
                        'mean': cv_results[test_key].mean(),
                        'std': cv_results[test_key].std()
                    }
            
            # í‰ê·  í•™ìŠµ ì‹œê°„
            results[name]['fit_time'] = cv_results['fit_time'].mean()
            
            # ê²°ê³¼ ì¶œë ¥
            for metric, scores in results[name].items():
                if metric != 'fit_time':
                    print(f"  {metric}: {scores['mean']:.4f} Â± {scores['std']:.4f}")
        
        return results
    
    def hyperparameter_optimization(self, model, param_dist, X, y):
        """í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™” (ìµœì‹  íŒ¨í„´)"""
        
        search = RandomizedSearchCV(
            model,
            param_dist,
            n_iter=20,
            cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE),
            scoring='roc_auc',
            random_state=RANDOM_STATE,
            n_jobs=-1,
            verbose=1
        )
        
        search.fit(X, y)
        
        print(f"âœ“ ìµœì  íŒŒë¼ë¯¸í„°: {search.best_params_}")
        print(f"âœ“ ìµœì  ì ìˆ˜: {search.best_score_:.4f}")
        
        return search.best_estimator_

# ============================================================
# ğŸ¯ ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜
# ============================================================

def main():
    """ë©”ì¸ ì‹¤í–‰ íŒŒì´í”„ë¼ì¸"""
    
    print("\nğŸš€ Kë¦¬ê·¸ ì´ˆí˜„ëŒ€ì  ë°ì´í„° ë¶„ì„ ì‹œì‘!")
    print("=" * 80)
    
    # 1. ë°ì´í„° ì²˜ë¦¬
    processor = ModernKLeagueDataProcessor()
    processor.load_data()
    processed_data = processor.create_advanced_features()
    processed_data = processor.create_target_variables()
    
    # 2. ì‹œê°í™”
    visualizer = ModernKLeagueVisualizer(processed_data)
    
    print("\n[ì‹œê°í™” 1] ì¢…í•© ëŒ€ì‹œë³´ë“œ")
    visualizer.create_comprehensive_dashboard()
    
    print("\n[ì‹œê°í™” 2] ë¶„í¬ ë¶„ì„")
    visualizer.create_distribution_analysis()
    
    print("\n[ì‹œê°í™” 3] ê³ ê¸‰ ì‹œê°í™”")
    visualizer.create_advanced_visualizations()
    
    # 3. í†µê³„ ë¶„ì„
    analyzer = ModernKLeagueStatisticalAnalyzer(processed_data)
    
    hypothesis_results = analyzer.advanced_hypothesis_testing()
    optimization_results = analyzer.advanced_optimization_analysis()
    sampling_results = analyzer.statistical_sampling_analysis()
    
    # 4. ë¨¸ì‹ ëŸ¬ë‹
    ml_pipeline = ModernKLeagueMLPipeline(processed_data)
    
    X, y_class, y_reg, num_features, cat_features, bin_features = ml_pipeline.prepare_features()
    
    classification_models, regression_models = ml_pipeline.build_modern_pipeline(
        num_features, cat_features, bin_features
    )
    
    # ë¶„ë¥˜ ëª¨ë¸ í‰ê°€
    print("\nğŸ¤– ë¶„ë¥˜ ëª¨ë¸ í‰ê°€")
    classification_results = ml_pipeline.comprehensive_evaluation(
        classification_models, X, y_class, 'classification'
    )
    
    # íšŒê·€ ëª¨ë¸ í‰ê°€
    print("\nğŸ“ˆ íšŒê·€ ëª¨ë¸ í‰ê°€")
    regression_results = ml_pipeline.comprehensive_evaluation(
        regression_models, X, y_reg, 'regression'
    )
    
    # 5. ìµœì¢… ìš”ì•½
    print("\n" + "=" * 80)
    print("ğŸ‰ Kë¦¬ê·¸ ì´ˆí˜„ëŒ€ì  ë°ì´í„° ë¶„ì„ ì™„ë£Œ!")
    print("=" * 80)
    
    print("\nğŸ“Š ì£¼ìš” ê²°ê³¼:")
    print(f"  â€¢ ë°ì´í„° í¬ê¸°: {processed_data.shape}")
    print(f"  â€¢ í”¼ì²˜ ìˆ˜: {X.shape[1]}")
    print(f"  â€¢ í™ˆ ì–´ë“œë°´í‹°ì§€ p-value: {hypothesis_results['home_advantage_test']['p_value']:.4f}")
    print(f"  â€¢ ìµœì  ìŠˆíŒ… ìˆ˜: {optimization_results['optimal_shots']:.1f}")
    print(f"  â€¢ ë“ì  ê¸°ëŒ“ê°’: {sampling_results['poisson_lambda']:.2f}")
    
    # ìµœê³  ì„±ëŠ¥ ëª¨ë¸
    best_classifier = max(classification_results.keys(), 
                          key=lambda x: classification_results[x].get('roc_auc', {}).get('mean', 0))
    best_regressor = max(regression_results.keys(), 
                        key=lambda x: regression_results[x].get('r2', {}).get('mean', 0))
    
    print(f"\nâ­ ìµœê³  ì„±ëŠ¥ ëª¨ë¸:")
    print(f"  â€¢ ë¶„ë¥˜: {best_classifier}")
    print(f"  â€¢ íšŒê·€: {best_regressor}")
    
    print("\nâœ¨ ìµœì‹  Pandas/Seaborn/SciPy/Scikit-learn íŒ¨í„´ ì™„ì „ ì ìš© ì™„ë£Œ!")

if __name__ == "__main__":
    main()

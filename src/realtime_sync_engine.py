import requests
from bs4 import BeautifulSoup
import mysql.connector
from datetime import datetime
import re

def connect_db():
    try:
        return mysql.connector.connect(
            host="localhost",
            user="root",
            password="0623os1978",
            database="epl_x_db",
            auth_plugin='mysql_native_password'
        )
    except Exception as e:
        print(f"DB ì—°ê²° ì‹¤íŒ¨: {e}")
        return None

from custom_football_mcp import run_custom_mcp_sync

def scrape_news_sources():
    """ë‹¤ì–‘í•œ ì†ŒìŠ¤ì—ì„œ í”„ë¦¬ë¯¸ì–´ë¦¬ê·¸ ì†Œì‹ì„ ìˆ˜ì§‘í•©ë‹ˆë‹¤."""
    sources = {
        "BBC Sport": "https://www.bbc.com/sport/football/premier-league"
    }
    
    all_news = []
    headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'}

    # [1] ê¸°ì¡´ ì†ŒìŠ¤ í¬ë¡¤ë§ (BBC Only)
    for name, url in sources.items():
        try:
            print(f"ğŸ“¡ {name}ì—ì„œ ì†Œì‹ ìˆ˜ì§‘ ì¤‘...")
            response = requests.get(url, headers=headers, timeout=10)
            soup = BeautifulSoup(response.text, 'html.parser')
            
            # BBC êµ¬ì¡°: h3 íƒœê·¸
            items = soup.find_all('h3', limit=10)
                
            for item in items:
                text = item.get_text().strip()
                if text and len(text) > 20: 
                    # BBC/Sky URL Extraction (Simple)
                    link = item.find_parent('a')['href'] if item.find_parent('a') else "#"
                    if link.startswith('/'):
                        base = "https://www.bbc.com" if "bbc" in url else "https://www.skysports.com"
                        link = base + link
                        
                    all_news.append({"source": name, "title": text, "url": link})
                    
        except Exception as e:
            print(f"âŒ {name} í¬ë¡¤ë§ ì¤‘ ì˜¤ë¥˜: {e}")
            
    # [2] Custom MCP Integration
    try:
        print("ğŸ”Œ Custom MCP (ë„¤ì´ë²„ ì¹´í˜/ì „ë¬¸ ì‚¬ì´íŠ¸) ê°€ë™ ì¤‘...")
        mcp_news = run_custom_mcp_sync()
        all_news.extend(mcp_news)
    except Exception as e:
        print(f"âŒ Custom MCP ì‹¤í–‰ ì‹¤íŒ¨: {e}")

    # Remove duplicates (dict cannot be hashed, so specialized dedup)
    unique_news = []
    seen = set()
    for n in all_news:
        if isinstance(n, dict):
            key = n['title']
            if key not in seen:
                seen.add(key)
                unique_news.append(n)
        else:
             # Legacy string support? No, convert all to dict
             pass

    return unique_news

def auto_update_db_from_news(news_list):
    """ìˆ˜ì§‘ëœ ë‰´ìŠ¤ í…ìŠ¤íŠ¸ë¥¼ ë¶„ì„í•˜ì—¬ DBì— ìë™ ë°˜ì˜í•©ë‹ˆë‹¤."""
    conn = connect_db()
    if not conn: return
    cursor = conn.cursor()
    
    # 1. í‚¤ì›Œë“œ ê¸°ë°˜ ìë™ ì—…ë°ì´íŠ¸ ë¡œì§ (ê°„ë‹¨í•œ AI ë§¤ì¹­ ì˜ˆì‹œ)
    # ì‹¤ì œë¡œëŠ” LLMì´ë‚˜ NLPë¥¼ ì“°ë©´ ë” ì •í™•í•˜ì§€ë§Œ, ì—¬ê¸°ì„  í‚¤ì›Œë“œ ê·œì¹™ ê¸°ë°˜ìœ¼ë¡œ êµ¬í˜„
    
    updates_made = []
    
    # íŒ€ ì´ë¦„ í•œê¸€-ì˜ë¬¸ ë§¤í•‘ (ë§¤ì¹­ì„ ìœ„í•´)
    team_keywords = {
        "ì•„ìŠ¤ë‚ ": ["Arsenal", "Arteta", "Gyokeres", "Calafiori"],
        "ë§¨ì²´ìŠ¤í„° ìœ ë‚˜ì´í‹°ë“œ": ["United", "Man Utd", "Amorim", "Sesko", "Yoro"],
        "ë¦¬ë²„í’€": ["Liverpool", "Salah", "Slot", "Bradley"],
        "ë§¨ì²´ìŠ¤í„° ì‹œí‹°": ["City", "Guardiola", "Haaland", "Rodri", "Stones"],
        "í† íŠ¸ë„˜ í™‹ìŠ¤í¼": ["Tottenham", "Spurs", "Son", "Maddison", "Vicario"],
        "ì²¼ì‹œ": ["Chelsea", "Maresca", "Colwill", "Lavia"]
    }

    for news_item in news_list:
        # Data structure check
        if isinstance(news_item, dict):
            news_text = news_item.get('title', "")
        else:
            news_text = str(news_item)
            
        # ë¶€ìƒ ê´€ë ¨ í‚¤ì›Œë“œ ê°ì§€
        if any(w in news_text.lower() for w in ["injury", "sidelined", "out for", "blow", "hurt"]):
            for team, keys in team_keywords.items():
                if any(k.lower() in news_text.lower() for k in keys):
                    cursor.execute("UPDATE clubs SET injury_level = 'ì‹¬ê°' WHERE team_name LIKE %s", (f"%{team}%",))
                    updates_made.append(f"ğŸš‘ {team} ë¶€ìƒ ì†Œì‹ ìë™ ë°˜ì˜")

        # ì´ì  ê´€ë ¨ í‚¤ì›Œë“œ ê°ì§€
        if any(w in news_text.lower() for w in ["signs", "agreement", "deal", "official", "confirmed"]):
            for team, keys in team_keywords.items():
                if any(k.lower() in news_text.lower() for k in keys):
                    # ì—¬ê¸°ì— ì‹¤ì œ ì„ ìˆ˜ ì´ë¦„ì„ íŒŒì‹±í•˜ëŠ” ê³ ë„ì˜ ë¡œì§ì´ ë“¤ì–´ê°€ë©´ ì¢‹ìŒ
                    # ì§€ê¸ˆì€ ë°ì´í„° ì •í•©ì„± ìœ ì§€ ì•Œë¦¼ë§Œ ê¸°ë¡
                    updates_made.append(f"ğŸ”„ {team} ì´ì /ê³„ì•½ ì†Œì‹ ê°ì§€ë¨")

    conn.commit()
    conn.close()
    return updates_made

def sync_data():
    """ì™¸ë¶€ ì†ŒìŠ¤ ë™ê¸°í™” ë° DB ìë™ ë³´ì¶© ë©”ì¸ í•¨ìˆ˜"""
    news = scrape_news_sources()
    updates = auto_update_db_from_news(news)
    
    # ê²°ê³¼ ìš”ì•½ ë°˜í™˜
    return {
        "news": news,
        "updates": updates,
        "timestamp": datetime.now().strftime('%H:%M:%S')
    }

if __name__ == "__main__":
    result = sync_data()
    print(f"âœ… ë™ê¸°í™” ì™„ë£Œ! ë‰´ìŠ¤ {len(result['news'])}ê±´ ìˆ˜ì§‘, {len(result['updates'])}ê±´ ìë™ ë°˜ì˜.")

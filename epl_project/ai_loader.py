import os

# [Stability Patch] Mac Mì‹œë¦¬ì¦ˆ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì¶©ëŒ ë° ë©”ëª¨ë¦¬ ì—ëŸ¬ ì™„ì „ ë°©ì§€
os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'
os.environ['OMP_NUM_THREADS'] = '1' # ë©€í‹°ìŠ¤ë ˆë”© ì¶©ëŒ ë°©ì§€ (ì•ˆì •ì„± ìµœìš°ì„ )

def get_ensemble_engine():
    # ë¬´ê±°ìš´ ë¼ì´ë¸ŒëŸ¬ë¦¬ëŠ” ë¶„ì„ ì§ì „ì—ë§Œ ë¡œë“œ (Lazy Loading)
    try:
        import torch
        import torch.nn as nn
        import joblib
        import numpy as np
        # LightGBM ëŒ€ì‹  ë” ê°€ë³ê³  í‘œì¤€ì ì¸ RandomForest ì‚¬ìš© (Mac ì•ˆì •ì„± ëíŒì™•)
        from sklearn.ensemble import RandomForestClassifier
    except ImportError:
        return None, None, None

    class EPLDeepNet(nn.Module):
        def __init__(self, input_size):
            super(EPLDeepNet, self).__init__()
            self.net = nn.Sequential(
                nn.Linear(input_size, 64), # ë ˆì´ì–´ ë‹¨ìˆœí™”ë¡œ ë¶€í•˜ ê°ì†Œ
                nn.ReLU(),
                nn.Linear(64, 32),
                nn.Linear(32, 1),
                nn.Sigmoid()
            )
        def forward(self, x):
            self.eval()
            with torch.no_grad():
                return self.net(x)

    BASE_DIR = os.path.dirname(__file__)
    torch_path = os.path.join(BASE_DIR, "models/epl_pytorch.pth")
    rf_path = os.path.join(BASE_DIR, "models/epl_rf.pkl")
    scaler_path = os.path.join(BASE_DIR, "models/scaler.pkl")
    
    try:
        if all(os.path.exists(p) for p in [torch_path, rf_path, scaler_path]):
            model_torch = EPLDeepNet(input_size=4)
            model_torch.load_state_dict(torch.load(torch_path, map_location=torch.device('cpu')))
            
            # [Lottery Ticket Hypothesis] Magnitude Pruning ì ìš© (Hyper-Sparse Mode)
            # 8GB RAM í™˜ê²½ ìµœì í™”ë¥¼ ìœ„í•´ ê°€ì¤‘ì¹˜ì˜ 75%ë¥¼ ì³ë‚´ê³  'Winning Ticket'ë§Œ ë‚¨ê¹ë‹ˆë‹¤.
            import torch.nn.utils.prune as prune
            for name, module in model_torch.named_modules():
                if isinstance(module, nn.Linear):
                    prune.l1_unstructured(module, name='weight', amount=0.75)
                    prune.remove(module, 'weight') # Maskë¥¼ ì‹¤ì œ ê°€ì¤‘ì¹˜ì— ì ìš©í•˜ì—¬ ì˜êµ¬ ê²½ëŸ‰í™”
            
            model_torch.eval()
            
            model_rf = joblib.load(rf_path)
            scaler = joblib.load(scaler_path)
            
            # [UX] ìµœì í™” ì„±ê³µ ì•Œë¦¼ (ë‚´ë¶€ ë¡œê·¸ìš©)
            print("ğŸ’ [Sparse Intelligence] Hyper-Sparse Ticket Identified: 75% Weights Pruned.")
            
            return model_torch, model_rf, scaler
    except:
        pass
    
    return None, None, None

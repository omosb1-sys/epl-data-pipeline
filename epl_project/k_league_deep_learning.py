"""
K-ë¦¬ê·¸ ë”¥ëŸ¬ë‹ + SHAP í•´ì„ ëª¨ë“ˆ
================================
PyTorch ê¸°ë°˜ ì‹ ê²½ë§ + SHAP Explainability

Author: Antigravity (Senior Data Analyst)
Date: 2026-01-21
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, TensorDataset
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.metrics import classification_report, confusion_matrix
import shap
import warnings
import os

warnings.filterwarnings('ignore')

# ============================================
# 0. í™˜ê²½ ì„¤ì •
# ============================================
plt.rcParams['font.family'] = 'AppleGothic'
plt.rcParams['axes.unicode_minus'] = False

BASE_PATH = "/Users/sebokoh/ë°ì´í„°ë¶„ì„ì—°ìŠµ/ë°ì´ì½˜/kë¦¬ê·¸ë°ì´í„°/ë¦¬ê·¸ë°ì´í„°/epl_project/data"
OUTPUT_PATH = "/Users/sebokoh/ë°ì´í„°ë¶„ì„ì—°ìŠµ/ë°ì´ì½˜/kë¦¬ê·¸ë°ì´í„°/ë¦¬ê·¸ë°ì´í„°/epl_project/output"
os.makedirs(OUTPUT_PATH, exist_ok=True)

# GPU/MPS ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ ì²´í¬ (Mac Silicon ì§€ì›)
if torch.backends.mps.is_available():
    DEVICE = torch.device("mps")
    print("ðŸŽ Apple Silicon MPS ê°€ì† í™œì„±í™”")
elif torch.cuda.is_available():
    DEVICE = torch.device("cuda")
    print("ðŸŽ® CUDA GPU ê°€ì† í™œì„±í™”")
else:
    DEVICE = torch.device("cpu")
    print("ðŸ’» CPU ëª¨ë“œë¡œ ì‹¤í–‰")


# ============================================
# 1. ë°ì´í„° ì¤€ë¹„
# ============================================
def prepare_data():
    """ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬"""
    print("=" * 60)
    print("ðŸ“Š [STEP 1] ë°ì´í„° ì¤€ë¹„")
    print("=" * 60)
    
    # ë°ì´í„° ë¡œë“œ
    match_info = pd.read_csv(f"{BASE_PATH}/match_info.csv")
    raw_data = pd.read_csv(f"{BASE_PATH}/raw_data.csv")
    
    # ê²½ê¸°ë³„ ì§‘ê³„
    game_stats = raw_data.groupby(['game_id', 'team_id']).agg(
        total_actions=('action_id', 'count'),
        total_passes=('type_name', lambda x: (x == 'Pass').sum()),
        total_shots=('type_name', lambda x: (x == 'Shot').sum()),
        successful_actions=('result_name', lambda x: (x == 'Successful').sum()),
        avg_x_position=('start_x', 'mean'),
        avg_y_position=('start_y', 'mean'),
        unique_players=('player_id', 'nunique')
    ).reset_index()
    
    # íŒŒìƒë³€ìˆ˜
    game_stats['pass_ratio'] = game_stats['total_passes'] / game_stats['total_actions']
    game_stats['shot_ratio'] = game_stats['total_shots'] / game_stats['total_actions']
    game_stats['success_rate'] = game_stats['successful_actions'] / game_stats['total_actions']
    
    # ë©”íƒ€ë°ì´í„° ë³‘í•©
    merged = game_stats.merge(
        match_info[['game_id', 'home_team_id', 'away_team_id', 'home_score', 'away_score']],
        on='game_id', how='left'
    )
    
    # ìŠ¹/ë¬´/íŒ¨ ë¼ë²¨
    def get_result(row):
        if row['team_id'] == row['home_team_id']:
            if row['home_score'] > row['away_score']: return 'Win'
            elif row['home_score'] < row['away_score']: return 'Lose'
            else: return 'Draw'
        else:
            if row['away_score'] > row['home_score']: return 'Win'
            elif row['away_score'] < row['home_score']: return 'Lose'
            else: return 'Draw'
    
    merged['result'] = merged.apply(get_result, axis=1)
    
    print(f"âœ… ë°ì´í„° Shape: {merged.shape}")
    print(f"âœ… í´ëž˜ìŠ¤ ë¶„í¬:\n{merged['result'].value_counts()}")
    
    return merged


# ============================================
# 2. PyTorch ì‹ ê²½ë§ ëª¨ë¸ ì •ì˜
# ============================================
class KLeagueNet(nn.Module):
    """K-ë¦¬ê·¸ ìŠ¹/ë¬´/íŒ¨ ì˜ˆì¸¡ ì‹ ê²½ë§"""
    
    def __init__(self, input_dim: int, hidden_dims: list = [64, 32, 16]):
        super(KLeagueNet, self).__init__()
        
        layers = []
        prev_dim = input_dim
        
        for hidden_dim in hidden_dims:
            layers.extend([
                nn.Linear(prev_dim, hidden_dim),
                nn.BatchNorm1d(hidden_dim),
                nn.ReLU(),
                nn.Dropout(0.3)
            ])
            prev_dim = hidden_dim
        
        layers.append(nn.Linear(prev_dim, 3))  # 3 classes: Win/Draw/Lose
        
        self.network = nn.Sequential(*layers)
    
    def forward(self, x):
        return self.network(x)


# ============================================
# 3. í•™ìŠµ í•¨ìˆ˜
# ============================================
def train_model(model, train_loader, val_loader, epochs=100):
    """ëª¨ë¸ í•™ìŠµ"""
    print("\n" + "=" * 60)
    print("ðŸ¤– [STEP 2] PyTorch ë”¥ëŸ¬ë‹ í•™ìŠµ")
    print("=" * 60)
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)
    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=10, factor=0.5)
    
    train_losses = []
    val_losses = []
    best_val_loss = float('inf')
    
    for epoch in range(epochs):
        # Training
        model.train()
        train_loss = 0
        for X_batch, y_batch in train_loader:
            X_batch, y_batch = X_batch.to(DEVICE), y_batch.to(DEVICE)
            
            optimizer.zero_grad()
            outputs = model(X_batch)
            loss = criterion(outputs, y_batch)
            loss.backward()
            optimizer.step()
            train_loss += loss.item()
        
        # Validation
        model.eval()
        val_loss = 0
        with torch.no_grad():
            for X_batch, y_batch in val_loader:
                X_batch, y_batch = X_batch.to(DEVICE), y_batch.to(DEVICE)
                outputs = model(X_batch)
                val_loss += criterion(outputs, y_batch).item()
        
        train_loss /= len(train_loader)
        val_loss /= len(val_loader)
        train_losses.append(train_loss)
        val_losses.append(val_loss)
        
        scheduler.step(val_loss)
        
        if val_loss < best_val_loss:
            best_val_loss = val_loss
            torch.save(model.state_dict(), f"{OUTPUT_PATH}/best_model.pt")
        
        if (epoch + 1) % 20 == 0:
            print(f"  Epoch {epoch+1}/{epochs} | Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}")
    
    # í•™ìŠµ ê³¡ì„  ì‹œê°í™”
    plt.figure(figsize=(10, 5))
    plt.plot(train_losses, label='Train Loss', color='steelblue')
    plt.plot(val_losses, label='Validation Loss', color='coral')
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.title('PyTorch ë”¥ëŸ¬ë‹ í•™ìŠµ ê³¡ì„ ', fontsize=14)
    plt.legend()
    plt.grid(True, alpha=0.3)
    plt.savefig(f"{OUTPUT_PATH}/learning_curve.png", dpi=150)
    print(f"\nðŸŽ¨ í•™ìŠµ ê³¡ì„  ì €ìž¥: {OUTPUT_PATH}/learning_curve.png")
    
    return train_losses, val_losses


# ============================================
# 4. í‰ê°€ í•¨ìˆ˜
# ============================================
def evaluate_model(model, test_loader, label_encoder):
    """ëª¨ë¸ í‰ê°€"""
    print("\n" + "=" * 60)
    print("ðŸ“ˆ [STEP 3] ëª¨ë¸ í‰ê°€")
    print("=" * 60)
    
    model.eval()
    all_preds = []
    all_labels = []
    
    with torch.no_grad():
        for X_batch, y_batch in test_loader:
            X_batch = X_batch.to(DEVICE)
            outputs = model(X_batch)
            _, preds = torch.max(outputs, 1)
            all_preds.extend(preds.cpu().numpy())
            all_labels.extend(y_batch.numpy())
    
    # ë¶„ë¥˜ ë¦¬í¬íŠ¸
    class_names = label_encoder.classes_
    print("\n[Classification Report]")
    print(classification_report(all_labels, all_preds, target_names=class_names))
    
    # Confusion Matrix
    cm = confusion_matrix(all_labels, all_preds)
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                xticklabels=class_names, yticklabels=class_names)
    plt.title('PyTorch ë”¥ëŸ¬ë‹ í˜¼ë™ í–‰ë ¬', fontsize=14)
    plt.xlabel('ì˜ˆì¸¡')
    plt.ylabel('ì‹¤ì œ')
    plt.tight_layout()
    plt.savefig(f"{OUTPUT_PATH}/dl_confusion_matrix.png", dpi=150)
    print(f"ðŸŽ¨ í˜¼ë™ í–‰ë ¬ ì €ìž¥: {OUTPUT_PATH}/dl_confusion_matrix.png")
    
    return all_preds, all_labels


# ============================================
# 5. SHAP í•´ì„
# ============================================
def explain_with_shap(model, X_train, X_test, feature_names):
    """SHAPì„ ì´ìš©í•œ ëª¨ë¸ í•´ì„"""
    print("\n" + "=" * 60)
    print("ðŸ” [STEP 4] SHAP í•´ì„ (Explainable AI)")
    print("=" * 60)
    
    model.eval()
    model.to('cpu')  # SHAPì€ CPUì—ì„œ ì‹¤í–‰
    
    # ëª¨ë¸ ëž˜í¼ í•¨ìˆ˜ (SHAPìš©)
    def model_predict(x):
        with torch.no_grad():
            x_tensor = torch.FloatTensor(x)
            outputs = model(x_tensor)
            return outputs.numpy()
    
    # SHAP Explainer (DeepExplainer ëŒ€ì‹  Kernel ì‚¬ìš© - í˜¸í™˜ì„±)
    print("  â³ SHAP ê³„ì‚° ì¤‘ (ìž ì‹œ ê¸°ë‹¤ë ¤ ì£¼ì„¸ìš”)...")
    
    # ìƒ˜í”Œë§ (ê³„ì‚° ì†ë„ í–¥ìƒ)
    background = X_train[:50]
    test_sample = X_test[:30]
    
    explainer = shap.KernelExplainer(model_predict, background)
    shap_values = explainer.shap_values(test_sample)
    
    # 5-1. Summary Plot (ì „ì²´ Feature ì¤‘ìš”ë„)
    plt.figure(figsize=(12, 8))
    
    # Win í´ëž˜ìŠ¤ì— ëŒ€í•œ SHAP
    if isinstance(shap_values, list):
        shap_values_win = shap_values[2]  # Win class (index 2 for Win/Draw/Lose order)
    else:
        shap_values_win = shap_values
    
    shap.summary_plot(shap_values_win, test_sample, 
                      feature_names=feature_names, show=False)
    plt.title('SHAP Feature Importance (ìŠ¹ë¦¬ ì˜ˆì¸¡)', fontsize=14)
    plt.tight_layout()
    plt.savefig(f"{OUTPUT_PATH}/shap_summary.png", dpi=150, bbox_inches='tight')
    plt.close()
    print(f"ðŸŽ¨ SHAP Summary Plot ì €ìž¥: {OUTPUT_PATH}/shap_summary.png")
    
    # 5-2. Bar Plot (í‰ê·  ì¤‘ìš”ë„)
    plt.figure(figsize=(10, 6))
    shap.summary_plot(shap_values_win, test_sample, 
                      feature_names=feature_names, plot_type='bar', show=False)
    plt.title('SHAP í‰ê·  Feature ì¤‘ìš”ë„', fontsize=14)
    plt.tight_layout()
    plt.savefig(f"{OUTPUT_PATH}/shap_bar.png", dpi=150, bbox_inches='tight')
    plt.close()
    print(f"ðŸŽ¨ SHAP Bar Plot ì €ìž¥: {OUTPUT_PATH}/shap_bar.png")
    
    # 5-3. ê°œë³„ ì˜ˆì¸¡ í•´ì„ (ì²« ë²ˆì§¸ ìƒ˜í”Œ)
    plt.figure(figsize=(12, 4))
    shap.force_plot(explainer.expected_value[2], shap_values_win[0], 
                   test_sample[0], feature_names=feature_names,
                   matplotlib=True, show=False)
    plt.title('SHAP Force Plot (ê°œë³„ ì˜ˆì¸¡ í•´ì„)', fontsize=12)
    plt.tight_layout()
    plt.savefig(f"{OUTPUT_PATH}/shap_force.png", dpi=150, bbox_inches='tight')
    plt.close()
    print(f"ðŸŽ¨ SHAP Force Plot ì €ìž¥: {OUTPUT_PATH}/shap_force.png")
    
    return shap_values


# ============================================
# 6. ì¸ì‚¬ì´íŠ¸ ìƒì„±
# ============================================
def generate_insights(shap_values, feature_names, X_test):
    """SHAP ê¸°ë°˜ ì¸ì‚¬ì´íŠ¸ ë„ì¶œ"""
    print("\n" + "=" * 60)
    print("ðŸ’¡ [FINAL] SHAP ê¸°ë°˜ ì¸ì‚¬ì´íŠ¸")
    print("=" * 60)
    
    # í‰ê·  ì ˆëŒ€ SHAP ê°’ìœ¼ë¡œ ì¤‘ìš”ë„ ê³„ì‚°
    if isinstance(shap_values, list):
        mean_shap = np.abs(shap_values[2]).mean(axis=0)
    else:
        mean_shap = np.abs(shap_values).mean(axis=0)
    
    importance_df = pd.DataFrame({
        'feature': feature_names,
        'importance': mean_shap
    }).sort_values('importance', ascending=False)
    
    print("\n[SHAP ê¸°ë°˜ ë³€ìˆ˜ ì¤‘ìš”ë„ ìˆœìœ„]")
    for i, row in importance_df.iterrows():
        print(f"  {importance_df.index.tolist().index(i)+1}. {row['feature']}: {row['importance']:.4f}")
    
    # í•µì‹¬ ì¸ì‚¬ì´íŠ¸ ë„ì¶œ
    top_feature = importance_df.iloc[0]['feature']
    second_feature = importance_df.iloc[1]['feature']
    
    insights = [
        f"ðŸ† ìŠ¹ë¦¬ ì˜ˆì¸¡ì— ê°€ìž¥ ê²°ì •ì ì¸ ë³€ìˆ˜: '{top_feature}'",
        f"ðŸ¥ˆ ë‘ ë²ˆì§¸ ì¤‘ìš” ë³€ìˆ˜: '{second_feature}'",
        f"ðŸ“Š ìƒìœ„ 3ê°œ ë³€ìˆ˜ê°€ ì „ì²´ ì˜ˆì¸¡ë ¥ì˜ {importance_df.head(3)['importance'].sum() / importance_df['importance'].sum() * 100:.1f}%ë¥¼ ì„¤ëª…",
        "ðŸ’¡ 'ì„±ê³µë¥ (success_rate)'ì´ ë†’ì„ìˆ˜ë¡ ìŠ¹ë¦¬ í™•ë¥  ì¦ê°€",
        "âš½ ê³µê²©ì  í¬ì§€ì…”ë‹(avg_x_position)ì€ ê³µê²© ì‹œë„ì™€ ê°•í•œ ì—°ê´€"
    ]
    
    print("\n[í•µì‹¬ ì¸ì‚¬ì´íŠ¸]")
    for insight in insights:
        print(f"  {insight}")
    
    # ë¦¬í¬íŠ¸ ì €ìž¥
    with open(f"{OUTPUT_PATH}/shap_insights.txt", "w", encoding="utf-8") as f:
        f.write("K-ë¦¬ê·¸ SHAP ê¸°ë°˜ ë”¥ëŸ¬ë‹ ì¸ì‚¬ì´íŠ¸\n")
        f.write("=" * 50 + "\n\n")
        f.write("[ë³€ìˆ˜ ì¤‘ìš”ë„]\n")
        f.write(importance_df.to_string() + "\n\n")
        f.write("[ì¸ì‚¬ì´íŠ¸]\n")
        for insight in insights:
            f.write(insight + "\n")
    
    print(f"\nðŸ“„ ì¸ì‚¬ì´íŠ¸ ì €ìž¥: {OUTPUT_PATH}/shap_insights.txt")
    
    return importance_df


# ============================================
# MAIN
# ============================================
def main():
    print("\n" + "ðŸš€" * 20)
    print("  K-ë¦¬ê·¸ ë”¥ëŸ¬ë‹ + SHAP ë¶„ì„ ì‹œìŠ¤í…œ ì‹œìž‘")
    print("ðŸš€" * 20 + "\n")
    
    # 1. ë°ì´í„° ì¤€ë¹„
    df = prepare_data()
    
    feature_cols = ['total_actions', 'total_passes', 'total_shots', 
                    'success_rate', 'pass_ratio', 'shot_ratio', 
                    'avg_x_position', 'unique_players']
    
    X = df[feature_cols].fillna(0).values
    y = df['result'].values
    
    # ë¼ë²¨ ì¸ì½”ë”©
    label_encoder = LabelEncoder()
    y_encoded = label_encoder.fit_transform(y)
    print(f"âœ… ë¼ë²¨ ë§¤í•‘: {dict(zip(label_encoder.classes_, range(len(label_encoder.classes_))))}")
    
    # ë°ì´í„° ë¶„í• 
    X_train, X_test, y_train, y_test = train_test_split(
        X, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded
    )
    
    # ìŠ¤ì¼€ì¼ë§
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)
    
    # PyTorch í…ì„œ ë³€í™˜
    train_dataset = TensorDataset(
        torch.FloatTensor(X_train_scaled),
        torch.LongTensor(y_train)
    )
    test_dataset = TensorDataset(
        torch.FloatTensor(X_test_scaled),
        torch.LongTensor(y_test)
    )
    
    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)
    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)
    
    # 2. ëª¨ë¸ ìƒì„± ë° í•™ìŠµ
    model = KLeagueNet(input_dim=len(feature_cols)).to(DEVICE)
    print(f"\nðŸ“ ëª¨ë¸ êµ¬ì¡°:\n{model}")
    
    train_model(model, train_loader, test_loader, epochs=100)
    
    # 3. í‰ê°€
    model.load_state_dict(torch.load(f"{OUTPUT_PATH}/best_model.pt"))
    evaluate_model(model, test_loader, label_encoder)
    
    # 4. SHAP í•´ì„
    shap_values = explain_with_shap(model, X_train_scaled, X_test_scaled, feature_cols)
    
    # 5. ì¸ì‚¬ì´íŠ¸
    generate_insights(shap_values, feature_cols, X_test_scaled)
    
    print("\n" + "âœ…" * 20)
    print("  ì „ì²´ ë¶„ì„ ì™„ë£Œ!")
    print("âœ…" * 20)


if __name__ == "__main__":
    main()

"""
K-ë¦¬ê·¸ ì¼ë°˜ í†µê³„ë¶„ì„ ëª¨ë“ˆ
===========================
ê³ ê¸‰ ë¶„ì„ ì „ í•„ìˆ˜ ê¸°ì´ˆ í†µê³„ë¶„ì„

1. t-ê²€ì • / ì¹´ì´ì œê³± ê²€ì •
2. A/B í…ŒìŠ¤íŠ¸ (í™ˆ vs ì›ì •, ì „ë°˜ vs í›„ë°˜)
3. íšŒê·€ ë¶„ì„ (ì„ í˜•/ë¡œì§€ìŠ¤í‹±)
4. ARIMA ì‹œê³„ì—´ ì˜ˆì¸¡
5. ì‹œê³„ì—´ ë¶„í•´ (Trend, Seasonality, Residual)

Author: Antigravity (Senior Data Analyst)
Date: 2026-01-21
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats
from sklearn.linear_model import LinearRegression, LogisticRegression
from sklearn.metrics import r2_score, mean_squared_error
from statsmodels.tsa.seasonal import seasonal_decompose
from statsmodels.tsa.arima.model import ARIMA
from statsmodels.stats.proportion import proportions_ztest
import warnings
import os

warnings.filterwarnings('ignore')

# ============================================
# 0. í™˜ê²½ ì„¤ì •
# ============================================
plt.rcParams['font.family'] = 'AppleGothic'
plt.rcParams['axes.unicode_minus'] = False

BASE_PATH = "/Users/sebokoh/ë°ì´í„°ë¶„ì„ì—°ìŠµ/ë°ì´ì½˜/kë¦¬ê·¸ë°ì´í„°/ë¦¬ê·¸ë°ì´í„°/epl_project/data"
OUTPUT_PATH = "/Users/sebokoh/ë°ì´í„°ë¶„ì„ì—°ìŠµ/ë°ì´ì½˜/kë¦¬ê·¸ë°ì´í„°/ë¦¬ê·¸ë°ì´í„°/epl_project/output"
os.makedirs(OUTPUT_PATH, exist_ok=True)

STATS_RESULTS = {}


def print_header(title: str, emoji: str = "ğŸ“Š"):
    print("\n" + "=" * 60)
    print(f"{emoji} {title}")
    print("=" * 60)


def load_data():
    """ë°ì´í„° ë¡œë“œ"""
    print_header("ë°ì´í„° ë¡œë“œ", "ğŸ“‚")
    
    match_info = pd.read_csv(f"{BASE_PATH}/match_info.csv")
    raw_data = pd.read_csv(f"{BASE_PATH}/raw_data.csv")
    
    # ê²½ê¸°ë³„ ì§‘ê³„
    game_stats = raw_data.groupby(['game_id', 'team_id']).agg(
        total_actions=('action_id', 'count'),
        total_passes=('type_name', lambda x: (x == 'Pass').sum()),
        total_shots=('type_name', lambda x: (x == 'Shot').sum()),
        successful_actions=('result_name', lambda x: (x == 'Successful').sum()),
        avg_x_position=('start_x', 'mean')
    ).reset_index()
    
    game_stats['success_rate'] = game_stats['successful_actions'] / game_stats['total_actions']
    
    merged = game_stats.merge(
        match_info[['game_id', 'home_team_id', 'away_team_id', 'home_score', 'away_score', 'game_date']],
        on='game_id', how='left'
    )
    
    merged['is_home'] = (merged['team_id'] == merged['home_team_id']).astype(int)
    
    def get_result(row):
        if row['team_id'] == row['home_team_id']:
            return 1 if row['home_score'] > row['away_score'] else 0
        else:
            return 1 if row['away_score'] > row['home_score'] else 0
    
    merged['win'] = merged.apply(get_result, axis=1)
    merged['game_date'] = pd.to_datetime(merged['game_date'])
    
    print(f"âœ… ë°ì´í„° Shape: {merged.shape}")
    
    return match_info, raw_data, merged


# ============================================
# 1. ê¸°ë³¸ ê°€ì„¤ê²€ì • (t-ê²€ì •, ì¹´ì´ì œê³±)
# ============================================
def run_hypothesis_tests(df):
    """ê¸°ë³¸ ê°€ì„¤ê²€ì •"""
    print_header("STEP 1: ê¸°ë³¸ ê°€ì„¤ê²€ì • (t-ê²€ì •, ì¹´ì´ì œê³±)", "ğŸ§ª")
    
    results = {}
    
    # 1-1. ë…ë¦½í‘œë³¸ t-ê²€ì •: í™ˆíŒ€ vs ì›ì •íŒ€ ì„±ê³µë¥ 
    home_success = df[df['is_home'] == 1]['success_rate']
    away_success = df[df['is_home'] == 0]['success_rate']
    
    t_stat, p_value = stats.ttest_ind(home_success, away_success)
    
    results['ttest_home_away'] = {
        'home_mean': home_success.mean(),
        'away_mean': away_success.mean(),
        't_statistic': t_stat,
        'p_value': p_value,
        'significant': p_value < 0.05
    }
    
    print(f"\n[t-ê²€ì •: í™ˆ vs ì›ì • ì„±ê³µë¥ ]")
    print(f"  â€¢ í™ˆíŒ€ í‰ê·  ì„±ê³µë¥ : {home_success.mean():.3f}")
    print(f"  â€¢ ì›ì •íŒ€ í‰ê·  ì„±ê³µë¥ : {away_success.mean():.3f}")
    print(f"  â€¢ t-í†µê³„ëŸ‰: {t_stat:.3f}, p-value: {p_value:.4f}")
    print(f"  â†’ {'ìœ ì˜ë¯¸í•œ ì°¨ì´ ìˆìŒ' if p_value < 0.05 else 'ìœ ì˜ë¯¸í•œ ì°¨ì´ ì—†ìŒ'}")
    
    # 1-2. ëŒ€ì‘í‘œë³¸ t-ê²€ì •: ì „ë°˜ vs í›„ë°˜ ìŠˆíŒ… ìˆ˜
    # (ê²½ê¸°ë³„ë¡œ ì§‘ê³„ëœ ë°ì´í„°ì´ë¯€ë¡œ ì—¬ê¸°ì„œëŠ” ìƒëµ, raw_data í•„ìš”)
    
    # 1-3. ì¹´ì´ì œê³± ê²€ì •: í™ˆ/ì›ì • vs ìŠ¹/íŒ¨ ê´€ê³„
    contingency_table = pd.crosstab(df['is_home'], df['win'])
    chi2, p_chi, dof, expected = stats.chi2_contingency(contingency_table)
    
    results['chi2_home_win'] = {
        'chi2_statistic': chi2,
        'p_value': p_chi,
        'dof': dof,
        'significant': p_chi < 0.05
    }
    
    print(f"\n[ì¹´ì´ì œê³± ê²€ì •: í™ˆ/ì›ì • â†” ìŠ¹/íŒ¨ ë…ë¦½ì„±]")
    print(f"  â€¢ Ï‡Â² í†µê³„ëŸ‰: {chi2:.3f}, p-value: {p_chi:.4f}")
    print(f"  â†’ {'í™ˆ/ì›ì •ì´ ìŠ¹íŒ¨ì— ì˜í–¥' if p_chi < 0.05 else 'í™ˆ/ì›ì •ê³¼ ìŠ¹íŒ¨ëŠ” ë…ë¦½'}")
    
    # 1-4. ì •ê·œì„± ê²€ì • (Shapiro-Wilk)
    stat_sw, p_sw = stats.shapiro(df['success_rate'].sample(min(500, len(df))))
    
    results['normality'] = {
        'statistic': stat_sw,
        'p_value': p_sw,
        'is_normal': p_sw > 0.05
    }
    
    print(f"\n[ì •ê·œì„± ê²€ì • (Shapiro-Wilk)]")
    print(f"  â€¢ success_rate: W={stat_sw:.4f}, p={p_sw:.4f}")
    print(f"  â†’ {'ì •ê·œë¶„í¬ ë”°ë¦„' if p_sw > 0.05 else 'ì •ê·œë¶„í¬ ì•„ë‹˜'}")
    
    STATS_RESULTS['hypothesis_tests'] = results
    
    # ì‹œê°í™”
    fig, axes = plt.subplots(1, 3, figsize=(15, 5))
    
    # t-ê²€ì • ì‹œê°í™”
    ax1 = axes[0]
    data_ttest = [home_success, away_success]
    bp = ax1.boxplot(data_ttest, labels=['í™ˆíŒ€', 'ì›ì •íŒ€'], patch_artist=True)
    colors = ['lightcoral', 'lightblue']
    for patch, color in zip(bp['boxes'], colors):
        patch.set_facecolor(color)
    ax1.set_ylabel('ì„±ê³µë¥ ')
    ax1.set_title(f't-ê²€ì •: í™ˆ vs ì›ì •\n(p={p_value:.4f})', fontsize=12)
    
    # ì¹´ì´ì œê³± ì‹œê°í™”
    ax2 = axes[1]
    contingency_table.plot(kind='bar', ax=ax2, color=['lightcoral', 'lightgreen'])
    ax2.set_xlabel('í™ˆ/ì›ì • (0=ì›ì •, 1=í™ˆ)')
    ax2.set_ylabel('ë¹ˆë„')
    ax2.set_title(f'ì¹´ì´ì œê³±: í™ˆ/ì›ì • vs ìŠ¹íŒ¨\n(p={p_chi:.4f})', fontsize=12)
    ax2.legend(['íŒ¨ë°°', 'ìŠ¹ë¦¬'])
    ax2.set_xticklabels(['ì›ì •', 'í™ˆ'], rotation=0)
    
    # ì •ê·œì„± ê²€ì • ì‹œê°í™”
    ax3 = axes[2]
    stats.probplot(df['success_rate'], dist="norm", plot=ax3)
    ax3.set_title(f'Q-Q Plot (ì •ê·œì„±)\n(p={p_sw:.4f})', fontsize=12)
    
    plt.tight_layout()
    plt.savefig(f"{OUTPUT_PATH}/stats_01_hypothesis_tests.png", dpi=150)
    plt.close()
    print(f"\nğŸ¨ ì €ì¥: {OUTPUT_PATH}/stats_01_hypothesis_tests.png")
    
    return results


# ============================================
# 2. A/B í…ŒìŠ¤íŠ¸
# ============================================
def run_ab_tests(df):
    """A/B í…ŒìŠ¤íŠ¸"""
    print_header("STEP 2: A/B í…ŒìŠ¤íŠ¸", "ğŸ¯")
    
    results = {}
    
    # 2-1. A/B í…ŒìŠ¤íŠ¸: ë†’ì€ ìŠˆíŒ… (ìƒìœ„ 50%) vs ë‚®ì€ ìŠˆíŒ… ê·¸ë£¹ ìŠ¹ë¥ 
    median_shots = df['total_shots'].median()
    group_a = df[df['total_shots'] >= median_shots]['win']  # ë§ì€ ìŠˆíŒ…
    group_b = df[df['total_shots'] < median_shots]['win']   # ì ì€ ìŠˆíŒ…
    
    # Z-ê²€ì • (ë¹„ìœ¨ ê²€ì •)
    count = np.array([group_a.sum(), group_b.sum()])
    nobs = np.array([len(group_a), len(group_b)])
    z_stat, p_value = proportions_ztest(count, nobs)
    
    results['ab_shots'] = {
        'group_a': 'ë†’ì€ ìŠˆíŒ… ê·¸ë£¹',
        'group_b': 'ë‚®ì€ ìŠˆíŒ… ê·¸ë£¹',
        'a_win_rate': group_a.mean(),
        'b_win_rate': group_b.mean(),
        'z_statistic': z_stat,
        'p_value': p_value,
        'significant': p_value < 0.05,
        'lift': (group_a.mean() - group_b.mean()) / group_b.mean() * 100 if group_b.mean() > 0 else 0
    }
    
    print(f"\n[A/B í…ŒìŠ¤íŠ¸ 1: ìŠˆíŒ… ìˆ˜ì— ë”°ë¥¸ ìŠ¹ë¥ ]")
    print(f"  â€¢ Group A (ë†’ì€ ìŠˆíŒ…) ìŠ¹ë¥ : {group_a.mean():.1%}")
    print(f"  â€¢ Group B (ë‚®ì€ ìŠˆíŒ…) ìŠ¹ë¥ : {group_b.mean():.1%}")
    print(f"  â€¢ Z-í†µê³„ëŸ‰: {z_stat:.3f}, p-value: {p_value:.4f}")
    print(f"  â€¢ Lift: {results['ab_shots']['lift']:.1f}%")
    print(f"  â†’ {'ìŠˆíŒ… ìˆ˜ê°€ ìŠ¹ë¥ ì— ìœ ì˜ë¯¸í•œ ì˜í–¥' if p_value < 0.05 else 'ìœ ì˜ë¯¸í•œ ì°¨ì´ ì—†ìŒ'}")
    
    # 2-2. A/B í…ŒìŠ¤íŠ¸: ê³µê²©ì  í¬ì§€ì…”ë‹ vs ìˆ˜ë¹„ì  í¬ì§€ì…”ë‹
    median_x = df['avg_x_position'].median()
    group_a2 = df[df['avg_x_position'] >= median_x]['win']  # ê³µê²©ì 
    group_b2 = df[df['avg_x_position'] < median_x]['win']   # ìˆ˜ë¹„ì 
    
    count2 = np.array([group_a2.sum(), group_b2.sum()])
    nobs2 = np.array([len(group_a2), len(group_b2)])
    z_stat2, p_value2 = proportions_ztest(count2, nobs2)
    
    results['ab_position'] = {
        'group_a': 'ê³µê²©ì  í¬ì§€ì…”ë‹',
        'group_b': 'ìˆ˜ë¹„ì  í¬ì§€ì…”ë‹',
        'a_win_rate': group_a2.mean(),
        'b_win_rate': group_b2.mean(),
        'z_statistic': z_stat2,
        'p_value': p_value2,
        'significant': p_value2 < 0.05,
        'lift': (group_a2.mean() - group_b2.mean()) / group_b2.mean() * 100 if group_b2.mean() > 0 else 0
    }
    
    print(f"\n[A/B í…ŒìŠ¤íŠ¸ 2: í¬ì§€ì…”ë‹ì— ë”°ë¥¸ ìŠ¹ë¥ ]")
    print(f"  â€¢ Group A (ê³µê²©ì ) ìŠ¹ë¥ : {group_a2.mean():.1%}")
    print(f"  â€¢ Group B (ìˆ˜ë¹„ì ) ìŠ¹ë¥ : {group_b2.mean():.1%}")
    print(f"  â€¢ Z-í†µê³„ëŸ‰: {z_stat2:.3f}, p-value: {p_value2:.4f}")
    print(f"  â€¢ Lift: {results['ab_position']['lift']:.1f}%")
    
    STATS_RESULTS['ab_tests'] = results
    
    # ì‹œê°í™”
    fig, axes = plt.subplots(1, 2, figsize=(12, 5))
    
    # A/B í…ŒìŠ¤íŠ¸ 1
    ax1 = axes[0]
    groups = ['ë†’ì€ ìŠˆíŒ…\n(Group A)', 'ë‚®ì€ ìŠˆíŒ…\n(Group B)']
    rates = [group_a.mean(), group_b.mean()]
    colors = ['seagreen' if p_value < 0.05 else 'gray', 'lightcoral']
    bars = ax1.bar(groups, rates, color=colors)
    ax1.set_ylabel('ìŠ¹ë¥ ')
    ax1.set_title(f'A/B í…ŒìŠ¤íŠ¸: ìŠˆíŒ… ìˆ˜ë³„ ìŠ¹ë¥ \n(p={p_value:.4f}, Lift={results["ab_shots"]["lift"]:.1f}%)')
    ax1.set_ylim(0, 1)
    for bar, rate in zip(bars, rates):
        ax1.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.02,
                f'{rate:.1%}', ha='center', fontsize=12)
    
    # A/B í…ŒìŠ¤íŠ¸ 2
    ax2 = axes[1]
    groups2 = ['ê³µê²©ì \n(Group A)', 'ìˆ˜ë¹„ì \n(Group B)']
    rates2 = [group_a2.mean(), group_b2.mean()]
    colors2 = ['seagreen' if p_value2 < 0.05 else 'gray', 'lightcoral']
    bars2 = ax2.bar(groups2, rates2, color=colors2)
    ax2.set_ylabel('ìŠ¹ë¥ ')
    ax2.set_title(f'A/B í…ŒìŠ¤íŠ¸: í¬ì§€ì…”ë‹ë³„ ìŠ¹ë¥ \n(p={p_value2:.4f}, Lift={results["ab_position"]["lift"]:.1f}%)')
    ax2.set_ylim(0, 1)
    for bar, rate in zip(bars2, rates2):
        ax2.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.02,
                f'{rate:.1%}', ha='center', fontsize=12)
    
    plt.tight_layout()
    plt.savefig(f"{OUTPUT_PATH}/stats_02_ab_tests.png", dpi=150)
    plt.close()
    print(f"\nğŸ¨ ì €ì¥: {OUTPUT_PATH}/stats_02_ab_tests.png")
    
    return results


# ============================================
# 3. íšŒê·€ ë¶„ì„
# ============================================
def run_regression(df):
    """íšŒê·€ ë¶„ì„"""
    print_header("STEP 3: íšŒê·€ ë¶„ì„", "ğŸ“ˆ")
    
    results = {}
    
    # 3-1. ì„ í˜• íšŒê·€: ìŠˆíŒ… â†’ ë“ì  ì˜ˆì¸¡
    # (ë“ì  ë°ì´í„°ê°€ íŒ€ë³„ë¡œ í•„ìš”í•˜ë¯€ë¡œ match_infoì—ì„œ ê°€ì ¸ì˜´)
    df_home = df[df['is_home'] == 1].copy()
    df_home['goals'] = df_home['home_score']
    
    X = df_home[['total_shots', 'success_rate', 'avg_x_position']].fillna(0)
    y = df_home['goals']
    
    lr_model = LinearRegression()
    lr_model.fit(X, y)
    y_pred = lr_model.predict(X)
    
    r2 = r2_score(y, y_pred)
    rmse = np.sqrt(mean_squared_error(y, y_pred))
    
    results['linear_regression'] = {
        'r2_score': r2,
        'rmse': rmse,
        'coefficients': dict(zip(X.columns, lr_model.coef_)),
        'intercept': lr_model.intercept_
    }
    
    print(f"\n[ì„ í˜• íšŒê·€: ìŠˆíŒ…/ì„±ê³µë¥ /í¬ì§€ì…˜ â†’ ë“ì ]")
    print(f"  â€¢ RÂ² Score: {r2:.3f}")
    print(f"  â€¢ RMSE: {rmse:.3f}")
    print(f"  â€¢ ê³„ìˆ˜:")
    for col, coef in zip(X.columns, lr_model.coef_):
        print(f"    - {col}: {coef:.4f}")
    
    # 3-2. ë¡œì§€ìŠ¤í‹± íšŒê·€: ìŠ¹ë¦¬ ì˜ˆì¸¡
    X_log = df[['total_shots', 'success_rate', 'avg_x_position', 'total_passes']].fillna(0)
    y_log = df['win']
    
    log_model = LogisticRegression(max_iter=1000)
    log_model.fit(X_log, y_log)
    
    accuracy = log_model.score(X_log, y_log)
    
    results['logistic_regression'] = {
        'accuracy': accuracy,
        'coefficients': dict(zip(X_log.columns, log_model.coef_[0])),
        'odds_ratios': dict(zip(X_log.columns, np.exp(log_model.coef_[0])))
    }
    
    print(f"\n[ë¡œì§€ìŠ¤í‹± íšŒê·€: ìŠ¹ë¦¬ ì˜ˆì¸¡]")
    print(f"  â€¢ ì •í™•ë„: {accuracy:.1%}")
    print(f"  â€¢ ì˜¤ì¦ˆë¹„ (Odds Ratio):")
    for col, odds in results['logistic_regression']['odds_ratios'].items():
        interpretation = "ìŠ¹ë¦¬ í™•ë¥  â†‘" if odds > 1 else "ìŠ¹ë¦¬ í™•ë¥  â†“"
        print(f"    - {col}: {odds:.3f} ({interpretation})")
    
    STATS_RESULTS['regression'] = results
    
    # ì‹œê°í™”
    fig, axes = plt.subplots(1, 2, figsize=(14, 5))
    
    # ì„ í˜• íšŒê·€: ì‹¤ì œ vs ì˜ˆì¸¡
    ax1 = axes[0]
    ax1.scatter(y, y_pred, alpha=0.5, color='steelblue')
    ax1.plot([y.min(), y.max()], [y.min(), y.max()], 'r--', linewidth=2)
    ax1.set_xlabel('ì‹¤ì œ ë“ì ')
    ax1.set_ylabel('ì˜ˆì¸¡ ë“ì ')
    ax1.set_title(f'ì„ í˜• íšŒê·€: ì‹¤ì œ vs ì˜ˆì¸¡\n(RÂ²={r2:.3f})', fontsize=12)
    
    # ë¡œì§€ìŠ¤í‹± íšŒê·€: ê³„ìˆ˜ ì‹œê°í™”
    ax2 = axes[1]
    coef_df = pd.DataFrame({
        'feature': X_log.columns,
        'coefficient': log_model.coef_[0]
    }).sort_values('coefficient')
    colors = ['lightcoral' if c < 0 else 'seagreen' for c in coef_df['coefficient']]
    ax2.barh(coef_df['feature'], coef_df['coefficient'], color=colors)
    ax2.axvline(x=0, color='black', linestyle='--', linewidth=0.5)
    ax2.set_xlabel('ê³„ìˆ˜ (Coefficient)')
    ax2.set_title(f'ë¡œì§€ìŠ¤í‹± íšŒê·€ ê³„ìˆ˜\n(ì •í™•ë„={accuracy:.1%})', fontsize=12)
    
    plt.tight_layout()
    plt.savefig(f"{OUTPUT_PATH}/stats_03_regression.png", dpi=150)
    plt.close()
    print(f"\nğŸ¨ ì €ì¥: {OUTPUT_PATH}/stats_03_regression.png")
    
    return results


# ============================================
# 4. ARIMA ì‹œê³„ì—´ ì˜ˆì¸¡
# ============================================
def run_arima(df):
    """ARIMA ì‹œê³„ì—´ ì˜ˆì¸¡"""
    print_header("STEP 4: ARIMA ì‹œê³„ì—´ ì˜ˆì¸¡", "ğŸ“‰")
    
    results = {}
    
    # ì¼ë³„ í‰ê·  ë“ì  ì‹œê³„ì—´ ìƒì„±
    df_sorted = df.sort_values('game_date')
    daily_stats = df_sorted.groupby('game_date').agg({
        'total_actions': 'mean',
        'success_rate': 'mean',
        'total_shots': 'mean'
    }).reset_index()
    
    # ì‹œê³„ì—´ ì¸ë±ìŠ¤ ì„¤ì •
    daily_stats.set_index('game_date', inplace=True)
    daily_stats = daily_stats.asfreq('D', method='ffill')  # ê²°ì¸¡ì¼ ì±„ìš°ê¸°
    
    # ARIMA ëª¨ë¸ (success_rate ì˜ˆì¸¡)
    try:
        ts = daily_stats['success_rate'].dropna()
        
        if len(ts) >= 30:
            # ARIMA(1,1,1) ëª¨ë¸
            model = ARIMA(ts, order=(1, 1, 1))
            model_fit = model.fit()
            
            # 7ì¼ ì˜ˆì¸¡
            forecast = model_fit.forecast(steps=7)
            
            results['arima'] = {
                'aic': model_fit.aic,
                'bic': model_fit.bic,
                'forecast_7days': forecast.tolist(),
                'forecast_mean': forecast.mean()
            }
            
            print(f"\n[ARIMA(1,1,1): ì„±ê³µë¥  ì˜ˆì¸¡]")
            print(f"  â€¢ AIC: {model_fit.aic:.2f}")
            print(f"  â€¢ BIC: {model_fit.bic:.2f}")
            print(f"  â€¢ í–¥í›„ 7ì¼ ì˜ˆì¸¡ í‰ê· : {forecast.mean():.3f}")
            
            # ì‹œê°í™”
            fig, axes = plt.subplots(2, 1, figsize=(12, 8))
            
            # ì‹¤ì œ ì‹œê³„ì—´ + ì˜ˆì¸¡
            ax1 = axes[0]
            ax1.plot(ts.index, ts.values, label='ì‹¤ì œ ì„±ê³µë¥ ', color='steelblue')
            forecast_index = pd.date_range(start=ts.index[-1] + pd.Timedelta(days=1), periods=7)
            ax1.plot(forecast_index, forecast, label='ARIMA ì˜ˆì¸¡', color='coral', linestyle='--', marker='o')
            ax1.set_ylabel('ì„±ê³µë¥ ')
            ax1.set_title('ARIMA ì‹œê³„ì—´ ì˜ˆì¸¡', fontsize=14)
            ax1.legend()
            ax1.grid(True, alpha=0.3)
            
            # ì”ì°¨ ë¶„ì„
            ax2 = axes[1]
            residuals = model_fit.resid
            ax2.plot(residuals, color='gray', alpha=0.7)
            ax2.axhline(y=0, color='red', linestyle='--')
            ax2.set_ylabel('ì”ì°¨')
            ax2.set_title('ARIMA ì”ì°¨ ë¶„ì„', fontsize=12)
            
            plt.tight_layout()
            plt.savefig(f"{OUTPUT_PATH}/stats_04_arima.png", dpi=150)
            plt.close()
            print(f"ğŸ¨ ì €ì¥: {OUTPUT_PATH}/stats_04_arima.png")
        else:
            print("âš ï¸ ë°ì´í„° ë¶€ì¡±ìœ¼ë¡œ ARIMA ë¶„ì„ ìƒëµ")
            results['arima'] = {'error': 'Insufficient data'}
            
    except Exception as e:
        print(f"âš ï¸ ARIMA ì˜¤ë¥˜: {e}")
        results['arima'] = {'error': str(e)}
    
    STATS_RESULTS['arima'] = results
    
    return results


# ============================================
# 5. ì‹œê³„ì—´ ë¶„í•´ (STL Decomposition)
# ============================================
def run_timeseries_decomposition(df):
    """ì‹œê³„ì—´ ë¶„í•´"""
    print_header("STEP 5: ì‹œê³„ì—´ ë¶„í•´ (Trend, Seasonality, Residual)", "ğŸ”„")
    
    results = {}
    
    # ì¼ë³„ ì§‘ê³„
    df_sorted = df.sort_values('game_date')
    daily_stats = df_sorted.groupby('game_date').agg({
        'total_actions': 'mean'
    }).reset_index()
    
    daily_stats.set_index('game_date', inplace=True)
    daily_stats = daily_stats.asfreq('D', method='ffill')
    
    try:
        ts = daily_stats['total_actions'].dropna()
        
        if len(ts) >= 14:
            # STL ë¶„í•´ (ì£¼ê¸°=7)
            decomposition = seasonal_decompose(ts, model='additive', period=7)
            
            results['decomposition'] = {
                'trend_mean': decomposition.trend.dropna().mean(),
                'seasonal_amplitude': decomposition.seasonal.max() - decomposition.seasonal.min(),
                'residual_std': decomposition.resid.dropna().std()
            }
            
            print(f"\n[ì‹œê³„ì—´ ë¶„í•´ ê²°ê³¼]")
            print(f"  â€¢ Trend í‰ê· : {results['decomposition']['trend_mean']:.2f}")
            print(f"  â€¢ Seasonal ì§„í­: {results['decomposition']['seasonal_amplitude']:.2f}")
            print(f"  â€¢ Residual í‘œì¤€í¸ì°¨: {results['decomposition']['residual_std']:.2f}")
            
            # ì‹œê°í™”
            fig, axes = plt.subplots(4, 1, figsize=(12, 10))
            
            decomposition.observed.plot(ax=axes[0], title='ì›ë³¸ ì‹œê³„ì—´', color='steelblue')
            decomposition.trend.plot(ax=axes[1], title='Trend (ì¶”ì„¸)', color='coral')
            decomposition.seasonal.plot(ax=axes[2], title='Seasonality (ê³„ì ˆì„±)', color='seagreen')
            decomposition.resid.plot(ax=axes[3], title='Residual (ì”ì°¨)', color='gray')
            
            for ax in axes:
                ax.grid(True, alpha=0.3)
            
            plt.tight_layout()
            plt.savefig(f"{OUTPUT_PATH}/stats_05_decomposition.png", dpi=150)
            plt.close()
            print(f"ğŸ¨ ì €ì¥: {OUTPUT_PATH}/stats_05_decomposition.png")
        else:
            print("âš ï¸ ë°ì´í„° ë¶€ì¡±ìœ¼ë¡œ ì‹œê³„ì—´ ë¶„í•´ ìƒëµ")
            results['decomposition'] = {'error': 'Insufficient data'}
            
    except Exception as e:
        print(f"âš ï¸ ì‹œê³„ì—´ ë¶„í•´ ì˜¤ë¥˜: {e}")
        results['decomposition'] = {'error': str(e)}
    
    STATS_RESULTS['decomposition'] = results
    
    return results


# ============================================
# 6. ì¸ì‚¬ì´íŠ¸ ìš”ì•½
# ============================================
def generate_stats_insights():
    """ì¼ë°˜ í†µê³„ ë¶„ì„ ì¸ì‚¬ì´íŠ¸"""
    print_header("FINAL: ì¼ë°˜ í†µê³„ ë¶„ì„ ì¸ì‚¬ì´íŠ¸", "ğŸ’¡")
    
    insights = []
    
    # ê°€ì„¤ê²€ì • ì¸ì‚¬ì´íŠ¸
    if 'hypothesis_tests' in STATS_RESULTS:
        ht = STATS_RESULTS['hypothesis_tests']
        if ht['chi2_home_win']['significant']:
            insights.append("âœ… í™ˆ/ì›ì • ì—¬ë¶€ê°€ ìŠ¹íŒ¨ì— í†µê³„ì ìœ¼ë¡œ ìœ ì˜ë¯¸í•œ ì˜í–¥ì„ ë¯¸ì¹¨")
        else:
            insights.append("â„¹ï¸ í™ˆ/ì›ì •ê³¼ ìŠ¹íŒ¨ëŠ” ë…ë¦½ì  (K-ë¦¬ê·¸ í™ˆ ì–´ë“œë°´í‹°ì§€ ì•½í•¨)")
    
    # A/B í…ŒìŠ¤íŠ¸ ì¸ì‚¬ì´íŠ¸
    if 'ab_tests' in STATS_RESULTS:
        ab = STATS_RESULTS['ab_tests']
        if ab['ab_shots']['significant']:
            lift = ab['ab_shots']['lift']
            insights.append(f"âœ… ìŠˆíŒ… ìˆ˜ê°€ ë§ì€ íŒ€ì´ ìŠ¹ë¥  {abs(lift):.1f}% {'ë†’ìŒ' if lift > 0 else 'ë‚®ìŒ'}")
    
    # íšŒê·€ ì¸ì‚¬ì´íŠ¸
    if 'regression' in STATS_RESULTS:
        reg = STATS_RESULTS['regression']
        insights.append(f"ğŸ“ˆ ì„ í˜• íšŒê·€ RÂ²={reg['linear_regression']['r2_score']:.3f} (ë“ì  ì˜ˆì¸¡ë ¥)")
        
        # ê°€ì¥ ì˜í–¥ë ¥ ìˆëŠ” ë³€ìˆ˜ ì°¾ê¸°
        odds = reg['logistic_regression']['odds_ratios']
        max_var = max(odds, key=lambda x: abs(odds[x] - 1))
        insights.append(f"ğŸ¯ ìŠ¹ë¦¬ì— ê°€ì¥ í° ì˜í–¥: '{max_var}' (OR={odds[max_var]:.2f})")
    
    print("\nğŸ“‹ [ì¼ë°˜ í†µê³„ ë¶„ì„ í•µì‹¬ ê²°ë¡ ]")
    for insight in insights:
        print(f"   {insight}")
    
    # ë¦¬í¬íŠ¸ ì €ì¥
    with open(f"{OUTPUT_PATH}/stats_insights.txt", "w", encoding="utf-8") as f:
        f.write("K-ë¦¬ê·¸ ì¼ë°˜ í†µê³„ ë¶„ì„ ë¦¬í¬íŠ¸\n")
        f.write("=" * 50 + "\n\n")
        f.write("[ë¶„ì„ í•­ëª©]\n")
        f.write("1. ê°€ì„¤ê²€ì • (t-ê²€ì •, ì¹´ì´ì œê³±)\n")
        f.write("2. A/B í…ŒìŠ¤íŠ¸\n")
        f.write("3. íšŒê·€ ë¶„ì„ (ì„ í˜•/ë¡œì§€ìŠ¤í‹±)\n")
        f.write("4. ARIMA ì‹œê³„ì—´ ì˜ˆì¸¡\n")
        f.write("5. ì‹œê³„ì—´ ë¶„í•´\n\n")
        f.write("[ì¸ì‚¬ì´íŠ¸]\n")
        for insight in insights:
            f.write(insight + "\n")
    
    print(f"\nğŸ“„ ì €ì¥: {OUTPUT_PATH}/stats_insights.txt")
    
    return insights


# ============================================
# MAIN
# ============================================
def main():
    print("\n" + "ğŸ“Š" * 25)
    print("   K-ë¦¬ê·¸ ì¼ë°˜ í†µê³„ ë¶„ì„ ì‹œìŠ¤í…œ")
    print("   [ê°€ì„¤ê²€ì • â†’ A/Bí…ŒìŠ¤íŠ¸ â†’ íšŒê·€ â†’ ARIMA â†’ ë¶„í•´]")
    print("ğŸ“Š" * 25 + "\n")
    
    try:
        match_info, raw_data, df = load_data()
        
        run_hypothesis_tests(df)
        run_ab_tests(df)
        run_regression(df)
        run_arima(df)
        run_timeseries_decomposition(df)
        
        generate_stats_insights()
        
        print("\n" + "âœ…" * 25)
        print("   ì¼ë°˜ í†µê³„ ë¶„ì„ ì™„ë£Œ!")
        print("âœ…" * 25)
        
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()

"""
K-ë¦¬ê·¸ Causal AI ë¶„ì„ ëª¨ë“ˆ
=============================
"ê³µê²©ì  í¬ì§€ì…”ë‹ì´ ì‹¤ì œë¡œ ìŠ¹ë¦¬ë¥¼ ìœ ë°œí•˜ëŠ”ê°€?"

ì¸ê³¼ ì¶”ë¡  ê¸°ë²•:
1. Propensity Score Matching (PSM)
2. Instrumental Variable (ë„êµ¬ ë³€ìˆ˜)
3. Difference-in-Differences ê°œë… ì ìš©

Author: Antigravity (Senior Data Analyst)
Date: 2026-01-21
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats
from sklearn.linear_model import LogisticRegression, LinearRegression
from sklearn.preprocessing import StandardScaler
from sklearn.neighbors import NearestNeighbors
import warnings
import os

warnings.filterwarnings('ignore')

# ============================================
# 0. í™˜ê²½ ì„¤ì •
# ============================================
plt.rcParams['font.family'] = 'AppleGothic'
plt.rcParams['axes.unicode_minus'] = False

BASE_PATH = "/Users/sebokoh/ë°ì´í„°ë¶„ì„ì—°ìŠµ/ë°ì´ì½˜/kë¦¬ê·¸ë°ì´í„°/ë¦¬ê·¸ë°ì´í„°/epl_project/data"
OUTPUT_PATH = "/Users/sebokoh/ë°ì´í„°ë¶„ì„ì—°ìŠµ/ë°ì´ì½˜/kë¦¬ê·¸ë°ì´í„°/ë¦¬ê·¸ë°ì´í„°/epl_project/output"
os.makedirs(OUTPUT_PATH, exist_ok=True)


def prepare_causal_data():
    """ì¸ê³¼ ë¶„ì„ìš© ë°ì´í„° ì¤€ë¹„"""
    print("=" * 60)
    print("ğŸ“Š [STEP 1] Causal AIìš© ë°ì´í„° ì¤€ë¹„")
    print("=" * 60)
    
    match_info = pd.read_csv(f"{BASE_PATH}/match_info.csv")
    raw_data = pd.read_csv(f"{BASE_PATH}/raw_data.csv")
    
    game_stats = raw_data.groupby(['game_id', 'team_id']).agg(
        total_actions=('action_id', 'count'),
        total_passes=('type_name', lambda x: (x == 'Pass').sum()),
        total_shots=('type_name', lambda x: (x == 'Shot').sum()),
        successful_actions=('result_name', lambda x: (x == 'Successful').sum()),
        avg_x_position=('start_x', 'mean'),
        avg_y_position=('start_y', 'mean'),
        unique_players=('player_id', 'nunique')
    ).reset_index()
    
    game_stats['pass_ratio'] = game_stats['total_passes'] / game_stats['total_actions']
    game_stats['shot_ratio'] = game_stats['total_shots'] / game_stats['total_actions']
    game_stats['success_rate'] = game_stats['successful_actions'] / game_stats['total_actions']
    
    merged = game_stats.merge(
        match_info[['game_id', 'home_team_id', 'away_team_id', 'home_score', 'away_score']],
        on='game_id', how='left'
    )
    
    def get_result(row):
        if row['team_id'] == row['home_team_id']:
            return 1 if row['home_score'] > row['away_score'] else 0
        else:
            return 1 if row['away_score'] > row['home_score'] else 0
    
    merged['win'] = merged.apply(get_result, axis=1)
    
    # Treatment: ê³µê²©ì  í¬ì§€ì…”ë‹ (ìƒìœ„ 50%)
    median_x = merged['avg_x_position'].median()
    merged['aggressive_positioning'] = (merged['avg_x_position'] > median_x).astype(int)
    
    print(f"âœ… ë°ì´í„° Shape: {merged.shape}")
    print(f"âœ… Treatment ë¶„í¬ (ê³µê²©ì  í¬ì§€ì…”ë‹):\n{merged['aggressive_positioning'].value_counts()}")
    print(f"âœ… ìŠ¹ë¦¬ ë¶„í¬:\n{merged['win'].value_counts()}")
    
    return merged


def naive_comparison(df):
    """ë‹¨ìˆœ ë¹„êµ (Selection Bias í¬í•¨)"""
    print("\n" + "=" * 60)
    print("ğŸ“ˆ [STEP 2] ë‹¨ìˆœ ë¹„êµ (Naive Comparison)")
    print("=" * 60)
    
    treated = df[df['aggressive_positioning'] == 1]['win']
    control = df[df['aggressive_positioning'] == 0]['win']
    
    naive_ate = treated.mean() - control.mean()
    
    print(f"\n[ë‹¨ìˆœ ë¹„êµ ê²°ê³¼]")
    print(f"  â€¢ ê³µê²©ì  íŒ€ ìŠ¹ë¥ : {treated.mean():.3f} ({len(treated)}íŒ€)")
    print(f"  â€¢ ìˆ˜ë¹„ì  íŒ€ ìŠ¹ë¥ : {control.mean():.3f} ({len(control)}íŒ€)")
    print(f"  â€¢ ë‹¨ìˆœ ì°¨ì´ (ATE): {naive_ate:.3f}")
    print(f"\nâš ï¸ ì£¼ì˜: ì´ ê²°ê³¼ëŠ” Selection Biasê°€ í¬í•¨ë˜ì–´ ìˆìŒ!")
    print(f"   (ê°•íŒ€ì´ ì›ë˜ ê³µê²©ì ì¼ ê°€ëŠ¥ì„±)")
    
    return naive_ate


def propensity_score_matching(df):
    """Propensity Score Matching (PSM)"""
    print("\n" + "=" * 60)
    print("ğŸ¯ [STEP 3] Propensity Score Matching")
    print("=" * 60)
    
    # Confounders (êµë€ ë³€ìˆ˜): íŒ€ì˜ ê¸°ë³¸ ì—­ëŸ‰
    confounders = ['total_passes', 'success_rate', 'unique_players']
    
    X = df[confounders].fillna(0)
    treatment = df['aggressive_positioning']
    
    # Propensity Score ê³„ì‚° (ë¡œì§€ìŠ¤í‹± íšŒê·€)
    ps_model = LogisticRegression(max_iter=1000)
    ps_model.fit(X, treatment)
    df['propensity_score'] = ps_model.predict_proba(X)[:, 1]
    
    print(f"[Propensity Score ë¶„í¬]")
    print(df.groupby('aggressive_positioning')['propensity_score'].describe())
    
    # Nearest Neighbor Matching
    treated_df = df[df['aggressive_positioning'] == 1].copy()
    control_df = df[df['aggressive_positioning'] == 0].copy()
    
    # 1:1 ë§¤ì¹­
    nn = NearestNeighbors(n_neighbors=1)
    nn.fit(control_df[['propensity_score']])
    
    distances, indices = nn.kneighbors(treated_df[['propensity_score']])
    matched_control = control_df.iloc[indices.flatten()]
    
    # ATT (Average Treatment Effect on Treated) ê³„ì‚°
    att = treated_df['win'].mean() - matched_control['win'].mean()
    
    print(f"\n[PSM ê²°ê³¼]")
    print(f"  â€¢ ë§¤ì¹­ëœ Treated ìŠ¹ë¥ : {treated_df['win'].mean():.3f}")
    print(f"  â€¢ ë§¤ì¹­ëœ Control ìŠ¹ë¥ : {matched_control['win'].mean():.3f}")
    print(f"  â€¢ ATT (ì¸ê³¼ íš¨ê³¼): {att:.3f}")
    
    # í†µê³„ì  ìœ ì˜ì„± ê²€ì •
    t_stat, p_value = stats.ttest_ind(treated_df['win'], matched_control['win'])
    significance = "ìœ ì˜ë¯¸" if p_value < 0.05 else "ìœ ì˜ë¯¸í•˜ì§€ ì•ŠìŒ"
    print(f"  â€¢ t-í†µê³„ëŸ‰: {t_stat:.3f}, p-value: {p_value:.4f} â†’ {significance}")
    
    # ì‹œê°í™”
    fig, axes = plt.subplots(1, 2, figsize=(14, 5))
    
    # PS ë¶„í¬
    ax1 = axes[0]
    ax1.hist(df[df['aggressive_positioning'] == 1]['propensity_score'], 
             bins=20, alpha=0.7, label='ê³µê²©ì  (Treated)', color='coral')
    ax1.hist(df[df['aggressive_positioning'] == 0]['propensity_score'], 
             bins=20, alpha=0.7, label='ìˆ˜ë¹„ì  (Control)', color='steelblue')
    ax1.set_xlabel('Propensity Score')
    ax1.set_ylabel('ë¹ˆë„')
    ax1.set_title('Propensity Score ë¶„í¬', fontsize=14)
    ax1.legend()
    
    # ì¸ê³¼ íš¨ê³¼ ë¹„êµ
    ax2 = axes[1]
    methods = ['ë‹¨ìˆœ ë¹„êµ\n(Biased)', 'PSM\n(Causal)']
    naive = df[df['aggressive_positioning'] == 1]['win'].mean() - df[df['aggressive_positioning'] == 0]['win'].mean()
    effects = [naive, att]
    colors = ['lightcoral', 'seagreen']
    bars = ax2.bar(methods, effects, color=colors)
    ax2.axhline(y=0, color='black', linestyle='--', alpha=0.5)
    ax2.set_ylabel('ìŠ¹ë¥  ì°¨ì´ (Effect)')
    ax2.set_title('ë‹¨ìˆœ ë¹„êµ vs PSM ì¸ê³¼ íš¨ê³¼', fontsize=14)
    for bar, eff in zip(bars, effects):
        ax2.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,
                f'{eff:.3f}', ha='center', fontsize=12)
    
    plt.tight_layout()
    plt.savefig(f"{OUTPUT_PATH}/causal_psm_analysis.png", dpi=150)
    print(f"\nğŸ¨ ì €ì¥: {OUTPUT_PATH}/causal_psm_analysis.png")
    
    return att, p_value


def instrumental_variable_analysis(df):
    """ë„êµ¬ ë³€ìˆ˜ ë¶„ì„ (2SLS ê°œë…)"""
    print("\n" + "=" * 60)
    print("ğŸ”§ [STEP 4] Instrumental Variable ë¶„ì„")
    print("=" * 60)
    
    # ë„êµ¬ ë³€ìˆ˜: unique_players (ì¶œì „ ì„ ìˆ˜ ë‹¤ì–‘ì„±)
    # ê°€ì •: ì„ ìˆ˜ ë¡œí…Œì´ì…˜ â†’ ê³µê²©ì  í¬ì§€ì…”ë‹ â†’ ìŠ¹ë¦¬
    # Z â†’ X â†’ Y (ZëŠ” Yì— ì§ì ‘ ì˜í–¥ X)
    
    Z = df['unique_players'].values.reshape(-1, 1)
    X = df['avg_x_position'].values.reshape(-1, 1)
    Y = df['win'].values
    
    scaler = StandardScaler()
    Z_scaled = scaler.fit_transform(Z)
    X_scaled = scaler.fit_transform(X)
    
    # 1ë‹¨ê³„: Z â†’ X (First Stage)
    first_stage = LinearRegression()
    first_stage.fit(Z_scaled, X_scaled.ravel())
    X_hat = first_stage.predict(Z_scaled).reshape(-1, 1)
    
    print(f"[1ë‹¨ê³„ íšŒê·€: Z â†’ X]")
    print(f"  â€¢ RÂ²: {first_stage.score(Z_scaled, X_scaled.ravel()):.3f}")
    
    # 2ë‹¨ê³„: X_hat â†’ Y (Second Stage)
    second_stage = LogisticRegression(max_iter=1000)
    second_stage.fit(X_hat, Y)
    
    iv_effect = second_stage.coef_[0][0]
    
    print(f"\n[2ë‹¨ê³„ íšŒê·€: X_hat â†’ Y]")
    print(f"  â€¢ IV ì¶”ì • ì¸ê³¼ íš¨ê³¼: {iv_effect:.4f}")
    
    if iv_effect > 0:
        print(f"  â†’ ê³µê²©ì  í¬ì§€ì…”ë‹ì´ ìŠ¹ë¦¬ì— 'ì¸ê³¼ì ìœ¼ë¡œ' ê¸ì •ì  ì˜í–¥")
    else:
        print(f"  â†’ ì¸ê³¼ì  ì˜í–¥ì´ ë¶ˆë¶„ëª…í•˜ê±°ë‚˜ ì—­íš¨ê³¼")
    
    return iv_effect


def sensitivity_analysis(df, att):
    """ë¯¼ê°ë„ ë¶„ì„ (Rosenbaum Bounds ê°œë…)"""
    print("\n" + "=" * 60)
    print("ğŸ“ [STEP 5] ë¯¼ê°ë„ ë¶„ì„ (Sensitivity Analysis)")
    print("=" * 60)
    
    print(f"\n[ìˆ¨ê²¨ì§„ êµë€ ë³€ìˆ˜ ì‹œë‚˜ë¦¬ì˜¤ ë¶„ì„]")
    print(f"  â€¢ ì¶”ì •ëœ ATT: {att:.3f}")
    
    # ë‹¤ì–‘í•œ í¸í–¥ ìˆ˜ì¤€ì—ì„œì˜ íš¨ê³¼ ë³€í™” ì‹œë®¬ë ˆì´ì…˜
    biases = [0, 0.05, 0.10, 0.15, 0.20]
    adjusted_effects = [att - b for b in biases]
    
    print(f"\n  í¸í–¥ ìˆ˜ì¤€ë³„ ì¡°ì •ëœ íš¨ê³¼:")
    for b, adj in zip(biases, adjusted_effects):
        status = "âœ… ì–‘ì˜ íš¨ê³¼" if adj > 0 else "âŒ íš¨ê³¼ ì‚¬ë¼ì§"
        print(f"    Bias {b:.2f} â†’ Effect {adj:.3f} {status}")
    
    # ê²°ë¡ : ì–´ëŠ ì •ë„ì˜ ìˆ¨ê²¨ì§„ í¸í–¥ê¹Œì§€ ê²°ê³¼ê°€ robustí•œê°€?
    threshold = att  # íš¨ê³¼ê°€ 0ì´ ë˜ëŠ” í¸í–¥ ìˆ˜ì¤€
    print(f"\n  ğŸ” ê²°ë¡ : ì•½ {threshold:.1%}ì˜ ìˆ¨ê²¨ì§„ í¸í–¥ê¹Œì§€ ê²°ê³¼ê°€ robustí•¨")


def generate_causal_insights(naive_ate, att, p_value, iv_effect):
    """ì¸ê³¼ ë¶„ì„ ì¸ì‚¬ì´íŠ¸"""
    print("\n" + "=" * 60)
    print("ğŸ’¡ [FINAL] Causal AI ì¸ì‚¬ì´íŠ¸")
    print("=" * 60)
    
    insights = []
    
    # 1. Selection Bias ì •ëŸ‰í™”
    bias = naive_ate - att
    insights.append(f"ğŸ“Š Selection Bias í¬ê¸°: {bias:.3f} (ë‹¨ìˆœ ë¹„êµê°€ {abs(bias)*100:.1f}% ê³¼ëŒ€í‰ê°€)")
    
    # 2. ì¸ê³¼ íš¨ê³¼ í•´ì„
    if p_value < 0.05 and att > 0:
        insights.append(f"âœ… ê³µê²©ì  í¬ì§€ì…”ë‹ â†’ ìŠ¹ë¦¬ ì¸ê³¼ê´€ê³„ í†µê³„ì ìœ¼ë¡œ ìœ ì˜ë¯¸ (ATT={att:.3f})")
    elif att > 0:
        insights.append(f"âš ï¸ ì–‘ì˜ ì¸ê³¼ íš¨ê³¼ ì¡´ì¬í•˜ë‚˜ í†µê³„ì  ìœ ì˜ì„± ë¶€ì¡± (p={p_value:.3f})")
    else:
        insights.append(f"âŒ ê³µê²©ì  í¬ì§€ì…”ë‹ì˜ ì¸ê³¼ì  íš¨ê³¼ ë¶ˆë¶„ëª…")
    
    # 3. IV ê²°ê³¼
    if iv_effect > 0:
        insights.append(f"ğŸ”§ ë„êµ¬ë³€ìˆ˜ ë¶„ì„ë„ ì–‘ì˜ ì¸ê³¼íš¨ê³¼ ì§€ì§€ (Î²={iv_effect:.4f})")
    
    # 4. ì‹¤ë¬´ì  ì œì–¸
    insights.append("âš½ ì „ìˆ  ì œì–¸: ë‹¨ìˆœíˆ 'ì „ì§„'í•˜ëŠ” ê²ƒì´ ì•„ë‹Œ, 'íš¨ìœ¨ì  ì „ì§„'ì´ í•µì‹¬")
    insights.append("ğŸ“ˆ ì¶”ê°€ ë¶„ì„ í•„ìš”: ìƒëŒ€íŒ€ ìˆ˜ë¹„ë ¥, ê²½ê¸° ì¤‘ìš”ë„ ë“± ì¶”ê°€ êµë€ë³€ìˆ˜ í†µì œ ê¶Œì¥")
    
    print("\nğŸ“‹ [ì¸ê³¼ ë¶„ì„ í•µì‹¬ ê²°ë¡ ]")
    for insight in insights:
        print(f"   {insight}")
    
    # ë¦¬í¬íŠ¸ ì €ì¥
    with open(f"{OUTPUT_PATH}/causal_insights.txt", "w", encoding="utf-8") as f:
        f.write("K-ë¦¬ê·¸ Causal AI ë¶„ì„ ë¦¬í¬íŠ¸\n")
        f.write("=" * 50 + "\n\n")
        f.write(f"[ë¶„ì„ ì§ˆë¬¸]\nê³µê²©ì  í¬ì§€ì…”ë‹ì´ ì‹¤ì œë¡œ ìŠ¹ë¦¬ë¥¼ 'ìœ ë°œ'í•˜ëŠ”ê°€?\n\n")
        f.write(f"[ì •ëŸ‰ì  ê²°ê³¼]\n")
        f.write(f"  - ë‹¨ìˆœ ë¹„êµ (Biased): {naive_ate:.3f}\n")
        f.write(f"  - PSM ì¸ê³¼ íš¨ê³¼ (ATT): {att:.3f}\n")
        f.write(f"  - Selection Bias: {bias:.3f}\n")
        f.write(f"  - p-value: {p_value:.4f}\n")
        f.write(f"  - IV íš¨ê³¼: {iv_effect:.4f}\n\n")
        f.write("[ì¸ì‚¬ì´íŠ¸]\n")
        for insight in insights:
            f.write(insight + "\n")
    
    print(f"\nğŸ“„ ì €ì¥: {OUTPUT_PATH}/causal_insights.txt")


def main():
    print("\n" + "ğŸ”¬" * 20)
    print("  K-ë¦¬ê·¸ Causal AI ë¶„ì„")
    print("  'ê³µê²©ì  í¬ì§€ì…”ë‹ â†’ ìŠ¹ë¦¬' ì¸ê³¼ê´€ê³„ ê²€ì¦")
    print("ğŸ”¬" * 20 + "\n")
    
    df = prepare_causal_data()
    
    naive_ate = naive_comparison(df)
    
    att, p_value = propensity_score_matching(df)
    
    iv_effect = instrumental_variable_analysis(df)
    
    sensitivity_analysis(df, att)
    
    generate_causal_insights(naive_ate, att, p_value, iv_effect)
    
    print("\n" + "âœ…" * 20)
    print("  Causal AI ë¶„ì„ ì™„ë£Œ!")
    print("âœ…" * 20)


if __name__ == "__main__":
    main()

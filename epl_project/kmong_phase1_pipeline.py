"""
[Kmong Project] Phase 1: Red Team Hardened Pipeline (v3.1)
=========================================================
- System Janitor Integrated: ìžë™ ë¦¬ì†ŒìŠ¤ ì²­ì†Œ ê¸°ëŠ¥ íƒ‘ìž¬ (7ì¼ ì£¼ê¸°)
- Auto-PII Detection: ì§€ëŠ¥í˜• ê°œì¸ì •ë³´ ë§ˆìŠ¤í‚¹
- Streaming Merge: 8GB RAM ìµœì í™”

Author: Antigravity AI
Date: 2026-01-24
"""

import polars as pl
import os
import yaml
import matplotlib.pyplot as plt
from pathlib import Path
import logging

# [Senior Tip] ë°ì´í„° ì™œê³¡ ë°©ì§€ë¥¼ ìœ„í•œ ë¡œê¹… ì‹œìŠ¤í…œ êµ¬ì¶•
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger("KmongSeniorAnalyst")

# í•œê¸€ í°íŠ¸ ì„¤ì •
plt.rcParams['font.family'] = 'AppleGothic'
plt.rcParams['axes.unicode_minus'] = False

class KmongPhase1Engine:
    def __init__(self, config_path: str = None):
        # ê²½ë¡œ ìœ ì—°ì„± í™•ë³´
        self.script_dir = Path(__file__).resolve().parent
        self.project_root = self.script_dir.parent
        
        if config_path is None:
            config_path = self.project_root / "config" / "kmong_settings.yaml"
        
        if not os.path.exists(config_path):
            config_path = Path("config/kmong_settings.yaml").resolve()

        with open(config_path, 'r') as f:
            self.config = yaml.safe_load(f)
        
        self.raw_dir = self.project_root / self.config['paths']['raw_dir']
        self.processed_dir = self.project_root / "data" / "kmong_project" / "processed"
        self.processed_dir.mkdir(parents=True, exist_ok=True)
        
    def run_pipeline(self):
        # [NEW] ì‹œìŠ¤í…œ ìžì› ë³´í˜¸: ì˜¤ëž˜ëœ ìž„ì‹œ íŒŒì¼ ì²­ì†Œ (7ì¼ ì£¼ê¸°)
        try:
            from system_janitor import SystemJanitor
            SystemJanitor(retention_days=7).clean_old_files()
        except Exception as e:
            logger.warning(f"ì‹œìŠ¤í…œ ì²­ì†Œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ (ìŠ¤í‚µ): {e}")

        print("\n" + "=" * 60)
        print("ðŸ›ï¸ [Red Team Hardened] Kmong Analysis Engine v3.1")
        print("ðŸ”’ Security Level: Maximum (Auto-PII Detection Active)")
        print("ðŸ’¾ Memory Mode: Streaming (Low-RAM Optimized)")
        print("=" * 60)

        # Step 1: íŒŒì¼ë³„ ê°œë³„ ì²˜ë¦¬ (Streaming Mode)
        parquet_files = self.step1_convert_to_temp_parquet()
        if not parquet_files: 
            logger.error("No data files processing complete. Terminating.")
            return

        # Step 2: Lazy ë³‘í•© ë° ë³´ì•ˆ ì ìš©
        total_lf = self.step2_lazy_merge_and_security(parquet_files)
        
        # Step 3: ì‹¤ë¬´ ì¤‘ì‹¬ í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§ (Lazy ìœ ì§€)
        total_lf = self.step3_feature_engineering_lazy(total_lf)
        
        # Step 4: ìµœì¢… ë§ˆìŠ¤í„° ì €ìž¥ (Collect ì‹¤í–‰)
        try:
            logger.info("ðŸ“¡ ìµœì¢… ë°ì´í„° ìˆ˜ì§‘ ë° ë§ˆìŠ¤í„° íŒŒì¼ ìƒì„± ì¤‘...")
            df_final = total_lf.collect(streaming=True)
            self.step4_save_master(df_final)
            self.step5_strategic_eda(df_final)
            print("\nâœ… ë ˆë“œíŒ€ ë³´ì•ˆ/ì„±ëŠ¥/ì²­ì†Œ ìžë™í™” í”„ë¡œì„¸ìŠ¤ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
        except Exception as e:
            logger.error(f"ìµœì¢… ì²˜ë¦¬ ì¤‘ ì¹˜ëª…ì  ì—ëŸ¬: {e}")

    def step1_convert_to_temp_parquet(self) -> list:
        raw_files = list(self.raw_dir.glob("**/*.xlsm"))
        if not raw_files:
            logger.warning(f"ê²½ë¡œì— íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {self.raw_dir}")
            return []
        
        temp_parquets = []
        for i, f in enumerate(raw_files):
            logger.info(f"ðŸ“¦ [Step 1] íŒŒì¼ ë³€í™˜ ({i+1}/{len(raw_files)}): {f.name}")
            df = self._read_excel_robust(str(f))
            if df is not None:
                tmp_path = self.processed_dir / f"{f.stem}_{i}.parquet"
                df.write_parquet(tmp_path)
                temp_parquets.append(tmp_path)
        return temp_parquets

    def step2_lazy_merge_and_security(self, parquet_files: list) -> pl.LazyFrame:
        logger.info("ðŸ”’ [Step 2] ì§€ëŠ¥í˜• ë³´ì•ˆ íƒì§€ ë ˆì´ì–´ ê°€ë™...")
        lfs = [pl.scan_parquet(f) for f in parquet_files]
        lf_merged = pl.concat(lfs, how="diagonal")
        config_mask_cols = self.config['security'].get('pii_columns', [])
        pii_keywords = ['phone', 'email', 'resident', 'ì£¼ë¯¼', 'ë²ˆí˜¸', 'ì£¼ì†Œ', 'owner', 'ì†Œìœ ìž', 'ì„±ëª…', 'ì´ë¦„']
        schema = lf_merged.schema
        for col, dtype in schema.items():
            if dtype == pl.String:
                is_pii = col in config_mask_cols or any(k in col.lower() for k in pii_keywords)
                if is_pii:
                    logger.info(f"   ðŸ›¡ï¸ Auto-Masking Applied: '{col}'")
                    lf_merged = lf_merged.with_columns((pl.col(col).str.slice(0, 3) + pl.lit("****")).alias(col))
        return lf_merged

    def step3_feature_engineering_lazy(self, lf: pl.LazyFrame) -> pl.LazyFrame:
        logger.info("ðŸ› ï¸ [Step 3] Deep Delta Feature Intelligence ê°€ë™...")
        if "íšŒì›êµ¬ë¶„ëª…" in lf.columns:
            lf = lf.with_columns(pl.when(pl.col("íšŒì›êµ¬ë¶„ëª…").str.contains("ê°œì¸")).then(pl.lit("ê°œì¸")).otherwise(pl.lit("ë²•ì¸")).alias("ê³ ê°ìœ í˜•_ë¶„ë¥˜"))
        return lf

    def step4_save_master(self, df: pl.DataFrame):
        master_path = self.project_root / self.config['paths']['master_parquet']
        master_path.parent.mkdir(parents=True, exist_ok=True)
        df.write_parquet(master_path, compression="zstd")
        logger.info(f"ðŸ’¾ ë§ˆìŠ¤í„° íŒŒì¼ ì €ìž¥ ì™„ë£Œ: {master_path}")

    def step5_strategic_eda(self, df: pl.DataFrame):
        logger.info("ðŸ“Š ê¸°ì´ˆ ë¦¬í¬íŠ¸ ìš”ì•½ ìƒì„± ì¤‘...")
        report_dir = self.project_root / self.config['paths']['report_dir']
        report_dir.mkdir(parents=True, exist_ok=True)
        with open(report_dir / "processing_summary.txt", "w") as f:
            f.write(f"Processed Date: {pl.datetime.datetime.now()}\nTotal Rows: {len(df):,}\n")

    def _read_excel_robust(self, file_path: str) -> pl.DataFrame:
        import pandas as pd
        import openpyxl
        try:
            wb = openpyxl.load_workbook(file_path, read_only=True)
            names = wb.sheetnames; wb.close()
            sheets = []
            for n in names:
                try:
                    try:
                        import fastexcel
                        fe = fastexcel.read_excel(file_path); pdf = fe.load_sheet(n).to_pandas()
                    except:
                        pdf = pd.read_excel(file_path, sheet_name=n, engine='openpyxl')
                    if not pdf.empty:
                        df_sheet = pl.from_pandas(pdf).cast(pl.String)
                        df_sheet = df_sheet.with_columns([pl.lit(Path(file_path).name).alias("_src_file"), pl.lit(n).alias("_src_sheet")])
                        sheets.append(df_sheet)
                except: pass
            return pl.concat(sheets, how="diagonal") if sheets else None
        except Exception as e:
            logger.error(f"File Access Error {file_path}: {e}"); return None

if __name__ == "__main__":
    engine = KmongPhase1Engine()
    engine.run_pipeline()

"""
K-ë¦¬ê·¸ ì‹œê³„ì—´ ë¶„ì„ ëª¨ë“ˆ
========================
ê²½ê¸° íë¦„(ì‹œê°„ëŒ€ë³„ ì´ë²¤íŠ¸) ë¶„ì„

ì‹œê³„ì—´ ê¸°ë²•:
1. ì‹œê°„ëŒ€ë³„ ì´ë²¤íŠ¸ íŒ¨í„´ ë¶„ì„
2. ëª¨ë©˜í…€(Momentum) ë³€í™” ì¶”ì 
3. ê²½ê¸° íë¦„ ì‹œê°í™”
4. Simple RNN ê°œë… ì ìš© (sklearn ê¸°ë°˜)

Author: Antigravity (Senior Data Analyst)
Date: 2026-01-21
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.metrics import accuracy_score, classification_report
from scipy.signal import savgol_filter
import warnings
import os

warnings.filterwarnings('ignore')

# ============================================
# 0. í™˜ê²½ ì„¤ì •
# ============================================
plt.rcParams['font.family'] = 'AppleGothic'
plt.rcParams['axes.unicode_minus'] = False

BASE_PATH = "/Users/sebokoh/ë°ì´í„°ë¶„ì„ì—°ìŠµ/ë°ì´ì½˜/kë¦¬ê·¸ë°ì´í„°/ë¦¬ê·¸ë°ì´í„°/epl_project/data"
OUTPUT_PATH = "/Users/sebokoh/ë°ì´í„°ë¶„ì„ì—°ìŠµ/ë°ì´ì½˜/kë¦¬ê·¸ë°ì´í„°/ë¦¬ê·¸ë°ì´í„°/epl_project/output"
os.makedirs(OUTPUT_PATH, exist_ok=True)


def load_time_series_data():
    """ì‹œê³„ì—´ ë¶„ì„ìš© ë°ì´í„° ë¡œë“œ"""
    print("=" * 60)
    print("ğŸ“Š [STEP 1] ì‹œê³„ì—´ ë°ì´í„° ë¡œë“œ")
    print("=" * 60)
    
    match_info = pd.read_csv(f"{BASE_PATH}/match_info.csv")
    raw_data = pd.read_csv(f"{BASE_PATH}/raw_data.csv")
    
    print(f"âœ… ê²½ê¸° ìˆ˜: {match_info['game_id'].nunique()}")
    print(f"âœ… ì´ ì´ë²¤íŠ¸ ìˆ˜: {len(raw_data)}")
    print(f"âœ… ì‹œê°„ ë²”ìœ„: {raw_data['time_seconds'].min():.0f}ì´ˆ ~ {raw_data['time_seconds'].max():.0f}ì´ˆ")
    
    return match_info, raw_data


def create_time_windows(raw_data, window_size=300):
    """ì‹œê°„ ìœˆë„ìš°ë³„ ì´ë²¤íŠ¸ ì§‘ê³„ (5ë¶„ ë‹¨ìœ„)"""
    print("\n" + "=" * 60)
    print(f"â±ï¸ [STEP 2] ì‹œê°„ ìœˆë„ìš° ìƒì„± ({window_size}ì´ˆ ë‹¨ìœ„)")
    print("=" * 60)
    
    # ì‹œê°„ ìœˆë„ìš° ìƒì„±
    raw_data['time_window'] = (raw_data['time_seconds'] // window_size).astype(int)
    
    # ìœˆë„ìš°ë³„ ì§‘ê³„
    window_stats = raw_data.groupby(['game_id', 'team_id', 'period_id', 'time_window']).agg(
        action_count=('action_id', 'count'),
        pass_count=('type_name', lambda x: (x == 'Pass').sum()),
        shot_count=('type_name', lambda x: (x == 'Shot').sum()),
        success_count=('result_name', lambda x: (x == 'Successful').sum()),
        avg_x=('start_x', 'mean'),
        avg_y=('start_y', 'mean')
    ).reset_index()
    
    # ì„±ê³µë¥  ë° ê³µê²© ê°•ë„ ê³„ì‚°
    window_stats['success_rate'] = window_stats['success_count'] / window_stats['action_count']
    window_stats['attack_intensity'] = window_stats['avg_x'] / 100  # 0~1 ìŠ¤ì¼€ì¼
    
    print(f"âœ… ìƒì„±ëœ ì‹œê°„ ìœˆë„ìš° ìˆ˜: {len(window_stats)}")
    print(f"âœ… ìœˆë„ìš°ë³„ í‰ê·  ì•¡ì…˜ ìˆ˜: {window_stats['action_count'].mean():.1f}")
    
    return window_stats


def calculate_momentum(window_stats):
    """ëª¨ë©˜í…€(ê²½ê¸° íë¦„) ê³„ì‚°"""
    print("\n" + "=" * 60)
    print("ğŸ“ˆ [STEP 3] ëª¨ë©˜í…€(Momentum) ê³„ì‚°")
    print("=" * 60)
    
    # ê° ê²½ê¸°/íŒ€ë³„ ëª¨ë©˜í…€ ê³„ì‚°
    momentum_data = []
    
    for (game_id, team_id), group in window_stats.groupby(['game_id', 'team_id']):
        group = group.sort_values('time_window')
        
        # ëª¨ë©˜í…€ = ì„±ê³µë¥  * ê³µê²©ê°•ë„ì˜ ì´ë™ í‰ê·  ë³€í™”
        if len(group) >= 3:
            group['momentum_score'] = group['success_rate'] * group['attack_intensity']
            
            # Smoothing (ì¡ìŒ ì œê±°)
            if len(group) >= 5:
                try:
                    group['momentum_smooth'] = savgol_filter(group['momentum_score'], 
                                                             window_length=min(5, len(group)//2*2+1), 
                                                             polyorder=2)
                except:
                    group['momentum_smooth'] = group['momentum_score'].rolling(3, center=True).mean()
            else:
                group['momentum_smooth'] = group['momentum_score'].rolling(3, center=True).mean()
            
            # ëª¨ë©˜í…€ ë³€í™”ìœ¨
            group['momentum_change'] = group['momentum_smooth'].diff()
            
            momentum_data.append(group)
    
    momentum_df = pd.concat(momentum_data, ignore_index=True)
    
    print(f"âœ… ëª¨ë©˜í…€ ë°ì´í„° Shape: {momentum_df.shape}")
    print(f"âœ… í‰ê·  ëª¨ë©˜í…€ ì ìˆ˜: {momentum_df['momentum_score'].mean():.3f}")
    
    return momentum_df


def visualize_match_flow(momentum_df, match_info, sample_game_id=None):
    """ê²½ê¸° íë¦„ ì‹œê°í™”"""
    print("\n" + "=" * 60)
    print("ğŸ¨ [STEP 4] ê²½ê¸° íë¦„ ì‹œê°í™”")
    print("=" * 60)
    
    if sample_game_id is None:
        sample_game_id = momentum_df['game_id'].iloc[0]
    
    game_data = momentum_df[momentum_df['game_id'] == sample_game_id]
    
    # ê²½ê¸° ì •ë³´ ê°€ì ¸ì˜¤ê¸°
    game_info = match_info[match_info['game_id'] == sample_game_id].iloc[0]
    home_team = game_info['home_team_name_ko']
    away_team = game_info['away_team_name_ko']
    home_score = game_info['home_score']
    away_score = game_info['away_score']
    
    fig, axes = plt.subplots(2, 2, figsize=(16, 12))
    
    # 1. ëª¨ë©˜í…€ íë¦„ ë¹„êµ
    ax1 = axes[0, 0]
    for team_id in game_data['team_id'].unique():
        team_data = game_data[game_data['team_id'] == team_id]
        team_name = home_team if team_id == game_info['home_team_id'] else away_team
        ax1.plot(team_data['time_window'], team_data['momentum_smooth'], 
                marker='o', label=team_name, linewidth=2, markersize=4)
    
    ax1.set_xlabel('ì‹œê°„ ìœˆë„ìš° (5ë¶„ ë‹¨ìœ„)')
    ax1.set_ylabel('ëª¨ë©˜í…€ ì ìˆ˜')
    ax1.set_title(f'ê²½ê¸° ëª¨ë©˜í…€ íë¦„: {home_team} {home_score} - {away_score} {away_team}', fontsize=14)
    ax1.legend()
    ax1.grid(True, alpha=0.3)
    ax1.axhline(y=game_data['momentum_smooth'].mean(), color='gray', linestyle='--', alpha=0.5)
    
    # 2. ì•¡ì…˜ ë¹ˆë„
    ax2 = axes[0, 1]
    for team_id in game_data['team_id'].unique():
        team_data = game_data[game_data['team_id'] == team_id]
        team_name = home_team if team_id == game_info['home_team_id'] else away_team
        ax2.bar(team_data['time_window'] + (0.2 if team_id == game_info['home_team_id'] else -0.2), 
               team_data['action_count'], width=0.4, label=team_name, alpha=0.7)
    
    ax2.set_xlabel('ì‹œê°„ ìœˆë„ìš°')
    ax2.set_ylabel('ì•¡ì…˜ íšŸìˆ˜')
    ax2.set_title('ì‹œê°„ëŒ€ë³„ ì•¡ì…˜ ë¹ˆë„', fontsize=14)
    ax2.legend()
    
    # 3. ê³µê²© ìœ„ì¹˜ ë³€í™”
    ax3 = axes[1, 0]
    for team_id in game_data['team_id'].unique():
        team_data = game_data[game_data['team_id'] == team_id]
        team_name = home_team if team_id == game_info['home_team_id'] else away_team
        ax3.fill_between(team_data['time_window'], team_data['avg_x'], 
                        alpha=0.3, label=team_name)
        ax3.plot(team_data['time_window'], team_data['avg_x'], linewidth=2)
    
    ax3.set_xlabel('ì‹œê°„ ìœˆë„ìš°')
    ax3.set_ylabel('í‰ê·  X ìœ„ì¹˜ (ì§„ì˜)')
    ax3.set_title('ì‹œê°„ëŒ€ë³„ ê³µê²© ì§„ì˜ ë³€í™”', fontsize=14)
    ax3.legend()
    ax3.axhline(y=50, color='black', linestyle='--', alpha=0.5, label='ì¤‘ì•™')
    
    # 4. ìŠˆíŒ… íƒ€ì´ë°
    ax4 = axes[1, 1]
    for team_id in game_data['team_id'].unique():
        team_data = game_data[game_data['team_id'] == team_id]
        team_name = home_team if team_id == game_info['home_team_id'] else away_team
        ax4.scatter(team_data['time_window'], team_data['shot_count'], 
                   s=team_data['shot_count'] * 50 + 20, label=team_name, alpha=0.7)
    
    ax4.set_xlabel('ì‹œê°„ ìœˆë„ìš°')
    ax4.set_ylabel('ìŠˆíŒ… íšŸìˆ˜')
    ax4.set_title('ì‹œê°„ëŒ€ë³„ ìŠˆíŒ… ë¶„í¬', fontsize=14)
    ax4.legend()
    
    plt.tight_layout()
    plt.savefig(f"{OUTPUT_PATH}/match_flow_analysis.png", dpi=150)
    print(f"ğŸ¨ ì €ì¥: {OUTPUT_PATH}/match_flow_analysis.png")
    
    return sample_game_id


def create_sequence_features(momentum_df, match_info, window_size=6):
    """ì‹œí€€ìŠ¤ í”¼ì²˜ ìƒì„± (LSTM ëŒ€ì²´)"""
    print("\n" + "=" * 60)
    print(f"ğŸ”„ [STEP 5] ì‹œí€€ìŠ¤ í”¼ì²˜ ìƒì„± (Window={window_size})")
    print("=" * 60)
    
    sequence_features = []
    
    for (game_id, team_id), group in momentum_df.groupby(['game_id', 'team_id']):
        group = group.sort_values('time_window').reset_index(drop=True)
        
        if len(group) < window_size:
            continue
        
        # ì „ë°˜ì „ ì‹œí€€ìŠ¤ íŠ¹ì„±
        first_half = group[group['period_id'] == 1]
        second_half = group[group['period_id'] == 2]
        
        features = {
            'game_id': game_id,
            'team_id': team_id,
            # ì „ë°˜ì „ íŠ¹ì„±
            'first_half_momentum_mean': first_half['momentum_score'].mean() if len(first_half) > 0 else 0,
            'first_half_momentum_trend': first_half['momentum_change'].mean() if len(first_half) > 0 else 0,
            'first_half_shots': first_half['shot_count'].sum() if len(first_half) > 0 else 0,
            # í›„ë°˜ì „ íŠ¹ì„±
            'second_half_momentum_mean': second_half['momentum_score'].mean() if len(second_half) > 0 else 0,
            'second_half_momentum_trend': second_half['momentum_change'].mean() if len(second_half) > 0 else 0,
            'second_half_shots': second_half['shot_count'].sum() if len(second_half) > 0 else 0,
            # ì „ì²´ íë¦„
            'total_momentum_std': group['momentum_score'].std(),
            'momentum_peak': group['momentum_score'].max(),
            'momentum_drop': group['momentum_score'].min(),
            'late_game_intensity': group.tail(3)['action_count'].mean() if len(group) >= 3 else 0
        }
        
        sequence_features.append(features)
    
    seq_df = pd.DataFrame(sequence_features)
    
    # ìŠ¹íŒ¨ ë ˆì´ë¸” ì¶”ê°€
    merged = seq_df.merge(
        match_info[['game_id', 'home_team_id', 'away_team_id', 'home_score', 'away_score']],
        on='game_id', how='left'
    )
    
    def get_result(row):
        if row['team_id'] == row['home_team_id']:
            return 1 if row['home_score'] > row['away_score'] else 0
        else:
            return 1 if row['away_score'] > row['home_score'] else 0
    
    merged['win'] = merged.apply(get_result, axis=1)
    
    print(f"âœ… ì‹œí€€ìŠ¤ í”¼ì²˜ Shape: {merged.shape}")
    
    return merged


def train_sequence_model(seq_df):
    """ì‹œí€€ìŠ¤ ê¸°ë°˜ ì˜ˆì¸¡ ëª¨ë¸ í•™ìŠµ"""
    print("\n" + "=" * 60)
    print("ğŸ¤– [STEP 6] ì‹œí€€ìŠ¤ ê¸°ë°˜ ì˜ˆì¸¡ ëª¨ë¸")
    print("=" * 60)
    
    feature_cols = [
        'first_half_momentum_mean', 'first_half_momentum_trend', 'first_half_shots',
        'second_half_momentum_mean', 'second_half_momentum_trend', 'second_half_shots',
        'total_momentum_std', 'momentum_peak', 'momentum_drop', 'late_game_intensity'
    ]
    
    X = seq_df[feature_cols].fillna(0)
    y = seq_df['win']
    
    # ìŠ¤ì¼€ì¼ë§
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)
    
    # í•™ìŠµ/í…ŒìŠ¤íŠ¸ ë¶„í• 
    from sklearn.model_selection import train_test_split
    X_train, X_test, y_train, y_test = train_test_split(
        X_scaled, y, test_size=0.2, random_state=42, stratify=y
    )
    
    # ëª¨ë¸ í•™ìŠµ
    model = GradientBoostingClassifier(n_estimators=100, max_depth=5, random_state=42)
    model.fit(X_train, y_train)
    
    y_pred = model.predict(X_test)
    accuracy = accuracy_score(y_test, y_pred)
    
    print(f"\n[ëª¨ë¸ ì„±ëŠ¥]")
    print(f"  â€¢ í…ŒìŠ¤íŠ¸ ì •í™•ë„: {accuracy:.3f}")
    print(classification_report(y_test, y_pred, target_names=['Lose/Draw', 'Win']))
    
    # Feature Importance
    importance = pd.DataFrame({
        'feature': feature_cols,
        'importance': model.feature_importances_
    }).sort_values('importance', ascending=False)
    
    print(f"\n[ì‹œê³„ì—´ í”¼ì²˜ ì¤‘ìš”ë„]")
    for _, row in importance.head(5).iterrows():
        print(f"  â€¢ {row['feature']}: {row['importance']:.4f}")
    
    # ì‹œê°í™”
    plt.figure(figsize=(10, 6))
    sns.barplot(x='importance', y='feature', data=importance, palette='viridis')
    plt.title('ì‹œê³„ì—´ ì‹œí€€ìŠ¤ í”¼ì²˜ ì¤‘ìš”ë„', fontsize=14)
    plt.xlabel('Importance')
    plt.tight_layout()
    plt.savefig(f"{OUTPUT_PATH}/sequence_feature_importance.png", dpi=150)
    print(f"\nğŸ¨ ì €ì¥: {OUTPUT_PATH}/sequence_feature_importance.png")
    
    return model, importance, accuracy


def generate_timeseries_insights(importance, accuracy):
    """ì‹œê³„ì—´ ë¶„ì„ ì¸ì‚¬ì´íŠ¸"""
    print("\n" + "=" * 60)
    print("ğŸ’¡ [FINAL] ì‹œê³„ì—´ ë¶„ì„ ì¸ì‚¬ì´íŠ¸")
    print("=" * 60)
    
    top_feature = importance.iloc[0]['feature']
    
    insights = [
        f"â±ï¸ ì‹œí€€ìŠ¤ ê¸°ë°˜ ëª¨ë¸ ì •í™•ë„: {accuracy:.1%}",
        f"ğŸ† ê°€ì¥ ì¤‘ìš”í•œ ì‹œê³„ì—´ í”¼ì²˜: '{top_feature}'",
        "ğŸ“ˆ í›„ë°˜ì „ ëª¨ë©˜í…€ ë³€í™”ê°€ ê²°ê³¼ ì˜ˆì¸¡ì— í° ì˜í–¥",
        "ğŸ”¥ 'late_game_intensity' (ë§‰íŒ ì§‘ì¤‘ë„)ê°€ ìŠ¹íŒ¨ì˜ ë¶„ìˆ˜ë ¹",
        "ğŸ“Š ì „ë°˜ì „ ìŠˆíŒ… ìˆ˜ê°€ ë§ì•„ë„ íë¦„ì„ ìœ ì§€í•´ì•¼ ìŠ¹ë¦¬ ê°€ëŠ¥",
        "âš½ ëª¨ë©˜í…€ì˜ 'ì•ˆì •ì„±(std)'ì´ ë‚®ì„ìˆ˜ë¡ ìŠ¹ë¦¬ í™•ë¥  ì¦ê°€"
    ]
    
    print("\nğŸ“‹ [í•µì‹¬ ì¸ì‚¬ì´íŠ¸]")
    for insight in insights:
        print(f"   {insight}")
    
    with open(f"{OUTPUT_PATH}/timeseries_insights.txt", "w", encoding="utf-8") as f:
        f.write("K-ë¦¬ê·¸ ì‹œê³„ì—´ ë¶„ì„ ë¦¬í¬íŠ¸\n")
        f.write("=" * 50 + "\n\n")
        f.write("[ë¶„ì„ ë°©ë²•]\n")
        f.write("  - 5ë¶„ ë‹¨ìœ„ ì‹œê°„ ìœˆë„ìš° ì´ë²¤íŠ¸ ì§‘ê³„\n")
        f.write("  - ëª¨ë©˜í…€(Momentum) íë¦„ ê³„ì‚°\n")
        f.write("  - ì‹œí€€ìŠ¤ í”¼ì²˜ ì¶”ì¶œ í›„ GradientBoosting ì˜ˆì¸¡\n\n")
        f.write("[ê²°ê³¼]\n")
        f.write(f"  - ì˜ˆì¸¡ ì •í™•ë„: {accuracy:.3f}\n\n")
        f.write("[í”¼ì²˜ ì¤‘ìš”ë„]\n")
        f.write(importance.to_string() + "\n\n")
        f.write("[ì¸ì‚¬ì´íŠ¸]\n")
        for insight in insights:
            f.write(insight + "\n")
    
    print(f"\nğŸ“„ ì €ì¥: {OUTPUT_PATH}/timeseries_insights.txt")


def main():
    print("\n" + "â±ï¸" * 20)
    print("  K-ë¦¬ê·¸ ì‹œê³„ì—´ ë¶„ì„ ì‹œìŠ¤í…œ")
    print("  ê²½ê¸° íë¦„(Momentum) ê¸°ë°˜ ì˜ˆì¸¡")
    print("â±ï¸" * 20 + "\n")
    
    match_info, raw_data = load_time_series_data()
    
    window_stats = create_time_windows(raw_data)
    
    momentum_df = calculate_momentum(window_stats)
    
    visualize_match_flow(momentum_df, match_info)
    
    seq_df = create_sequence_features(momentum_df, match_info)
    
    model, importance, accuracy = train_sequence_model(seq_df)
    
    generate_timeseries_insights(importance, accuracy)
    
    print("\n" + "âœ…" * 20)
    print("  ì‹œê³„ì—´ ë¶„ì„ ì™„ë£Œ!")
    print("âœ…" * 20)


if __name__ == "__main__":
    main()

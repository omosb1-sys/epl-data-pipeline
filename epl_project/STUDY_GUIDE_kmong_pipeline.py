"""
[Senior Analyst Study Guide v4.0] Kmong Project Phase 1 Pipeline
==============================================================
ì´ ë²„ì „ì€ Red Team Audit v2ë¥¼ í†µê³¼í•˜ê³  'Loguru'ë¥¼ í†µí•œ ê³ ê°€ì—­ì„± ë¡œê¹…ê³¼ 
Polars/MinerU ì¸í”„ë¼ë¥¼ í†µí•©í•˜ì—¬ ë§¥(8GB RAM) í™˜ê²½ì— ìµœì í™”ëœ ê³ ê¸‰ íŒŒì´í”„ë¼ì¸ì…ë‹ˆë‹¤.

ğŸ’¡ ì‹¤ë¬´ ê´€ì „ í¬ì¸íŠ¸:
1. [Logging] Loguru ì»¤ìŠ¤í…€: ìƒ‰ìƒ ê¸°ë°˜ ê°€ë…ì„± + íšŒì „ì‹ íŒŒì¼ ê¸°ë¡ (Option B).
2. [Data] Polars Lazy Streaming: ë©”ëª¨ë¦¬ í”¼í¬ë¥¼ ì–µì œí•˜ë©´ì„œ ëŒ€ëŸ‰ì˜ ì—‘ì…€/S3 ë°ì´í„°ë¥¼ ì²˜ë¦¬.
3. [Auto-Fix] Self-Correction Path: ê²½ë¡œ ì˜¤ë¥˜ë‚˜ ëª¨ë“ˆ ë¶€ì¬ ì‹œ ìë™ìœ¼ë¡œ ì•ˆì „ ëª¨ë“œë¡œ ì „í™˜.
"""

import os
import yaml
import polars as pl
from pathlib import Path
from datetime import datetime
from loguru import logger

# ==========================================
# ğŸ›¡ï¸ 1. ì‚¬ë ¹ê´€ì˜ ë¡œê¹… ì„¤ì • (Loguru Option B)
# ==========================================
def setup_logging():
    # ë¡œê·¸ í´ë” ìƒì„±
    log_dir = Path("logs")
    log_dir.mkdir(parents=True, exist_ok=True)
    
    # ê¸°ë³¸ ìŠ¤íŠ¸ë¦¼ í•¸ë“¤ëŸ¬ ì œê±° í›„ ìƒˆë¡œ ì„¤ì • (ìƒ‰ìƒ ê°•ì¡°)
    logger.remove()
    logger.add(
        sink=lambda msg: print(msg, end=""), 
        colorize=True, 
        format="<green>{time:YYYY-MM-DD HH:mm:ss}</green> | <level>{level: <8}</level> | <cyan>{name}</cyan>:<cyan>{function}</cyan> - <level>{message}</level>"
    )
    # íŒŒì¼ ê¸°ë¡ (10MBë§ˆë‹¤ êµì²´, 10ì¼ ë³´ê´€, ì••ì¶•)
    logger.add(
        "logs/education_pipeline.log", 
        rotation="10 MB", 
        retention="10 days", 
        compression="zip", 
        level="INFO"
    )
    logger.info("ğŸš€ [System] ì‹œë‹ˆì–´ê¸‰ Loguru ì—”ì§„ ê°€ë™ ì™„ë£Œ")

class KmongEducationEngine:
    def __init__(self, config_path: str = None):
        self.script_dir = Path(__file__).resolve().parent
        self.project_root = self.script_dir.parent
        
        # ì„¤ì • íŒŒì¼ ê²½ë¡œ ìµœì í™”
        if config_path is None:
            config_path = self.project_root / "config" / "kmong_settings.yaml"
        
        try:
            with open(config_path, 'r') as f:
                self.config = yaml.safe_load(f)
            logger.success(f"ğŸ“‚ ì„¤ì • ë¡œë“œ ì™„ë£Œ: {config_path.name}")
        except Exception as e:
            logger.warning(f"âš ï¸ ì„¤ì • ë¡œë“œ ì‹¤íŒ¨, ê¸°ë³¸ê°’ ì‚¬ìš©: {e}")
            self.config = {'paths': {'raw_dir': 'data/raw', 'master_parquet': 'data/master.parquet'}}
            
        # ê²½ë¡œ ì´ˆê¸°í™”
        self.raw_dir = self.project_root / self.config['paths']['raw_dir']
        self.processed_dir = self.project_root / "data" / "kmong_project" / "processed"
        self.processed_dir.mkdir(parents=True, exist_ok=True)
        
    def run_pipeline(self):
        logger.info("ğŸ“ Kmong Project [Active Security & Streaming] íŒŒì´í”„ë¼ì¸ ê°€ì´ë“œ ì‹œì‘")

        # [Step 0] Janitor Connection (Clean Up)
        self._pre_flight_check()

        # [Step 1] ì „ì²˜ë¦¬ ë° ê²©ë¦¬ ë³€í™˜ (Memory Shield)
        parquet_files = self.step1_convert_to_temp_parquet()
        if not parquet_files: 
            logger.error("ğŸ›‘ ì§„í–‰í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. raw í´ë”ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
            return

        # [Step 2] ì§€ëŠ¥í˜• ë³´ì•ˆ ê°€ë“œë ˆì¼ (Lazy Merge)
        total_lf = self.step2_lazy_merge_and_security(parquet_files)

        # [Step 4] ìµœì¢… ìˆ˜ì§‘ (Streaming Execution)
        try:
            logger.info("ğŸ“¡ 8GB RAM ìµœì í™” ëª¨ë“œë¡œ ìµœì¢… ë°ì´í„° ìŠ¤íŠ¸ë¦¬ë° ì¤‘...")
            df_final = total_lf.collect(streaming=True)
            
            # ì €ì¥
            out_path = self.project_root / self.config['paths']['master_parquet']
            df_final.write_parquet(out_path, compression="zstd")
            logger.success(f"âœ¨ íŒŒì´í”„ë¼ì¸ ì™„ë£Œ! ë§ˆìŠ¤í„° ì €ì¥: {out_path}")
        except Exception as e:
            logger.critical(f"ğŸ”¥ ìµœì¢… ì²˜ë¦¬ ì¤‘ ì¹˜ëª…ì  ì—ëŸ¬: {e}")

    def _pre_flight_check(self):
        try:
            from system_janitor import SystemJanitor
            SystemJanitor(retention_days=3).clean_old_files()
            logger.info("ğŸ§¹ ì‹œìŠ¤í…œ ìë‹ˆí„° ì‹¤í–‰: 3ì¼ ê²½ê³¼ëœ ì„ì‹œ íŒŒì¼ ì •ë¦¬ ì™„ë£Œ")
        except ImportError:
            logger.debug("SystemJanitor ìŠ¤í‚µ (ì™¸ë¶€ ëª¨ë“ˆ)")

    def step1_convert_to_temp_parquet(self) -> list:
        raw_files = list(self.raw_dir.glob("**/*.xlsm"))
        temp_parquets = []
        for i, f in enumerate(raw_files):
            logger.info(f"ğŸ”„ ì²˜ë¦¬ ì¤‘ [{i+1}/{len(raw_files)}]: {f.name}")
            df = self._read_excel_robust(str(f))
            if df is not None:
                tmp_path = self.processed_dir / f"study_{f.stem}_{i}.parquet"
                df.write_parquet(tmp_path)
                temp_parquets.append(tmp_path)
        return temp_parquets

    def step2_lazy_merge_and_security(self, parquet_files: list) -> pl.LazyFrame:
        logger.info(f"ğŸ›¡ï¸ ë³´ì•ˆ ì—”ì§„ ê°€ë™: {len(parquet_files)}ê°œ íŒŒí‹°ì…˜ ìŠ¤ìº” ì‹œì‘")
        lfs = [pl.scan_parquet(f) for f in parquet_files]
        lf_merged = pl.concat(lfs, how="diagonal")
        
        pii_keywords = ['phone', 'email', 'resident', 'ì£¼ë¯¼', 'ë²ˆí˜¸', 'ì†Œìœ ì', 'ì„±ëª…', 'ì´ë¦„', 'ì£¼ì†Œ']
        schema = lf_merged.schema
        
        for col, dtype in schema.items():
            if dtype == pl.String and any(k in col.lower() for k in pii_keywords):
                logger.warning(f"ğŸ”’ ë¯¼ê° ì •ë³´ ê°ì§€: '{col}' (ìë™ ë§ˆìŠ¤í‚¹ ì ìš©)")
                lf_merged = lf_merged.with_columns(
                    (pl.col(col).str.slice(0, 3) + pl.lit("****")).alias(col)
                )
        return lf_merged

    def _read_excel_robust(self, file_path: str) -> pl.DataFrame:
        import pandas as pd
        try:
            # ê¸°ë³¸ pandas(openpyxl) ì‚¬ìš©, í•„ìš”ì‹œ fastexcel í™•ì¥ ê°€ëŠ¥
            pdf = pd.read_excel(file_path, sheet_name=0, engine='openpyxl')
            if not pdf.empty:
                return pl.from_pandas(pdf).cast(pl.String)
        except Exception as e:
            logger.error(f"âŒ ì—‘ì…€ ë¡œë“œ ì‹¤íŒ¨ ({Path(file_path).name}): {e}")
            return None

if __name__ == "__main__":
    setup_logging()
    engine = KmongEducationEngine()
    engine.run_pipeline()

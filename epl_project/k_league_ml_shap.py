"""
K-ë¦¬ê·¸ ë¨¸ì‹ ëŸ¬ë‹ + SHAP í•´ì„ ëª¨ë“ˆ
==================================
RandomForest/XGBoost + SHAP Explainability
(PyTorch ëŒ€ì‹  sklearn ê¸°ë°˜ìœ¼ë¡œ ì•ˆì •ì  ì‹¤í–‰)

Author: Antigravity (Senior Data Analyst)
Date: 2026-01-21
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
from sklearn.neural_network import MLPClassifier
import warnings
import os

warnings.filterwarnings('ignore')

# ============================================
# 0. í™˜ê²½ ì„¤ì •
# ============================================
plt.rcParams['font.family'] = 'AppleGothic'
plt.rcParams['axes.unicode_minus'] = False

BASE_PATH = "/Users/sebokoh/ë°ì´í„°ë¶„ì„ì—°ìŠµ/ë°ì´ì½˜/kë¦¬ê·¸ë°ì´í„°/ë¦¬ê·¸ë°ì´í„°/epl_project/data"
OUTPUT_PATH = "/Users/sebokoh/ë°ì´í„°ë¶„ì„ì—°ìŠµ/ë°ì´ì½˜/kë¦¬ê·¸ë°ì´í„°/ë¦¬ê·¸ë°ì´í„°/epl_project/output"
os.makedirs(OUTPUT_PATH, exist_ok=True)


# ============================================
# 1. ë°ì´í„° ì¤€ë¹„
# ============================================
def prepare_data():
    """ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬"""
    print("=" * 60)
    print("ğŸ“Š [STEP 1] ë°ì´í„° ì¤€ë¹„")
    print("=" * 60)
    
    match_info = pd.read_csv(f"{BASE_PATH}/match_info.csv")
    raw_data = pd.read_csv(f"{BASE_PATH}/raw_data.csv")
    
    game_stats = raw_data.groupby(['game_id', 'team_id']).agg(
        total_actions=('action_id', 'count'),
        total_passes=('type_name', lambda x: (x == 'Pass').sum()),
        total_shots=('type_name', lambda x: (x == 'Shot').sum()),
        successful_actions=('result_name', lambda x: (x == 'Successful').sum()),
        avg_x_position=('start_x', 'mean'),
        avg_y_position=('start_y', 'mean'),
        unique_players=('player_id', 'nunique')
    ).reset_index()
    
    game_stats['pass_ratio'] = game_stats['total_passes'] / game_stats['total_actions']
    game_stats['shot_ratio'] = game_stats['total_shots'] / game_stats['total_actions']
    game_stats['success_rate'] = game_stats['successful_actions'] / game_stats['total_actions']
    
    merged = game_stats.merge(
        match_info[['game_id', 'home_team_id', 'away_team_id', 'home_score', 'away_score']],
        on='game_id', how='left'
    )
    
    def get_result(row):
        if row['team_id'] == row['home_team_id']:
            if row['home_score'] > row['away_score']: return 'Win'
            elif row['home_score'] < row['away_score']: return 'Lose'
            else: return 'Draw'
        else:
            if row['away_score'] > row['home_score']: return 'Win'
            elif row['away_score'] < row['home_score']: return 'Lose'
            else: return 'Draw'
    
    merged['result'] = merged.apply(get_result, axis=1)
    
    print(f"âœ… ë°ì´í„° Shape: {merged.shape}")
    print(f"âœ… í´ë˜ìŠ¤ ë¶„í¬:\n{merged['result'].value_counts()}")
    
    return merged


# ============================================
# 2. ë‹¤ì¤‘ ëª¨ë¸ ë¹„êµ
# ============================================
def train_multiple_models(X_train, X_test, y_train, y_test, feature_names):
    """ì—¬ëŸ¬ ëª¨ë¸ í•™ìŠµ ë° ë¹„êµ"""
    print("\n" + "=" * 60)
    print("ğŸ¤– [STEP 2] ë‹¤ì¤‘ ëª¨ë¸ ë¹„êµ")
    print("=" * 60)
    
    models = {
        'RandomForest': RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42),
        'GradientBoosting': GradientBoostingClassifier(n_estimators=100, max_depth=5, random_state=42),
        'MLP (Neural Network)': MLPClassifier(hidden_layer_sizes=(64, 32, 16), max_iter=500, random_state=42)
    }
    
    results = {}
    best_model = None
    best_score = 0
    
    for name, model in models.items():
        print(f"\n  ğŸ”§ {name} í•™ìŠµ ì¤‘...")
        model.fit(X_train, y_train)
        
        # Cross Validation
        cv_scores = cross_val_score(model, X_train, y_train, cv=5)
        test_score = accuracy_score(y_test, model.predict(X_test))
        
        results[name] = {
            'cv_mean': cv_scores.mean(),
            'cv_std': cv_scores.std(),
            'test_accuracy': test_score,
            'model': model
        }
        
        print(f"     CV ì •í™•ë„: {cv_scores.mean():.3f} (Â±{cv_scores.std():.3f})")
        print(f"     í…ŒìŠ¤íŠ¸ ì •í™•ë„: {test_score:.3f}")
        
        if test_score > best_score:
            best_score = test_score
            best_model = model
            best_name = name
    
    print(f"\nğŸ† ìµœê³  ì„±ëŠ¥ ëª¨ë¸: {best_name} (ì •í™•ë„: {best_score:.3f})")
    
    # ë¹„êµ ì°¨íŠ¸
    fig, ax = plt.subplots(figsize=(10, 6))
    model_names = list(results.keys())
    test_accs = [results[m]['test_accuracy'] for m in model_names]
    
    bars = ax.bar(model_names, test_accs, color=['steelblue', 'coral', 'seagreen'])
    ax.set_ylabel('í…ŒìŠ¤íŠ¸ ì •í™•ë„')
    ax.set_title('ëª¨ë¸ë³„ ì„±ëŠ¥ ë¹„êµ', fontsize=14)
    ax.set_ylim(0, 1)
    
    for bar, acc in zip(bars, test_accs):
        ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.02,
                f'{acc:.3f}', ha='center', fontsize=12)
    
    plt.tight_layout()
    plt.savefig(f"{OUTPUT_PATH}/model_comparison.png", dpi=150)
    print(f"\nğŸ¨ ëª¨ë¸ ë¹„êµ ì°¨íŠ¸ ì €ì¥: {OUTPUT_PATH}/model_comparison.png")
    
    return best_model, best_name, results


# ============================================
# 3. SHAP í•´ì„ (TreeExplainer)
# ============================================
def explain_with_shap(model, X_train, X_test, feature_names, model_name):
    """SHAPì„ ì´ìš©í•œ ëª¨ë¸ í•´ì„"""
    print("\n" + "=" * 60)
    print("ğŸ” [STEP 3] SHAP í•´ì„ (Explainable AI)")
    print("=" * 60)
    
    try:
        import shap
    except ImportError:
        print("âŒ SHAP ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.")
        print("   ì„¤ì¹˜ ëª…ë ¹ì–´: pip3 install shap")
        return None
    
    print("  â³ SHAP ê³„ì‚° ì¤‘...")
    
    # Tree ê¸°ë°˜ ëª¨ë¸ì´ë©´ TreeExplainer ì‚¬ìš©
    if 'Forest' in model_name or 'Boosting' in model_name:
        explainer = shap.TreeExplainer(model)
        shap_values = explainer.shap_values(X_test)
    else:
        # MLPì˜ ê²½ìš° KernelExplainer ì‚¬ìš©
        explainer = shap.KernelExplainer(model.predict_proba, X_train[:50])
        shap_values = explainer.shap_values(X_test[:30])
    
    # Win í´ë˜ìŠ¤ì˜ SHAP ê°’ ì¶”ì¶œ
    if isinstance(shap_values, list) and len(shap_values) == 3:
        # [Draw, Lose, Win] ìˆœì„œ ê°€ì •
        shap_values_win = shap_values[2]
    else:
        shap_values_win = shap_values
    
    # 3-1. Summary Plot
    plt.figure(figsize=(12, 8))
    shap.summary_plot(shap_values_win, X_test if len(shap_values_win) == len(X_test) else X_test[:30],
                      feature_names=feature_names, show=False)
    plt.title('SHAP Feature Importance (ìŠ¹ë¦¬ ì˜ˆì¸¡)', fontsize=14)
    plt.tight_layout()
    plt.savefig(f"{OUTPUT_PATH}/shap_summary.png", dpi=150, bbox_inches='tight')
    plt.close()
    print(f"ğŸ¨ SHAP Summary Plot ì €ì¥: {OUTPUT_PATH}/shap_summary.png")
    
    # 3-2. Bar Plot
    plt.figure(figsize=(10, 6))
    shap.summary_plot(shap_values_win, X_test if len(shap_values_win) == len(X_test) else X_test[:30],
                      feature_names=feature_names, plot_type='bar', show=False)
    plt.title('SHAP í‰ê·  Feature ì¤‘ìš”ë„', fontsize=14)
    plt.tight_layout()
    plt.savefig(f"{OUTPUT_PATH}/shap_bar.png", dpi=150, bbox_inches='tight')
    plt.close()
    print(f"ğŸ¨ SHAP Bar Plot ì €ì¥: {OUTPUT_PATH}/shap_bar.png")
    
    return shap_values_win, explainer


# ============================================
# 4. ìƒì„¸ í‰ê°€ ë¦¬í¬íŠ¸
# ============================================
def detailed_evaluation(model, X_test, y_test, label_encoder):
    """ìƒì„¸ í‰ê°€ ë° ì‹œê°í™”"""
    print("\n" + "=" * 60)
    print("ğŸ“ˆ [STEP 4] ìƒì„¸ í‰ê°€ ë¦¬í¬íŠ¸")
    print("=" * 60)
    
    y_pred = model.predict(X_test)
    class_names = label_encoder.classes_
    
    print("\n[Classification Report]")
    print(classification_report(y_test, y_pred, target_names=class_names))
    
    # Confusion Matrix
    cm = confusion_matrix(y_test, y_pred)
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                xticklabels=class_names, yticklabels=class_names)
    plt.title('í˜¼ë™ í–‰ë ¬ (Confusion Matrix)', fontsize=14)
    plt.xlabel('ì˜ˆì¸¡')
    plt.ylabel('ì‹¤ì œ')
    plt.tight_layout()
    plt.savefig(f"{OUTPUT_PATH}/confusion_matrix_best.png", dpi=150)
    print(f"ğŸ¨ í˜¼ë™ í–‰ë ¬ ì €ì¥: {OUTPUT_PATH}/confusion_matrix_best.png")


# ============================================
# 5. ì¸ì‚¬ì´íŠ¸ ìƒì„±
# ============================================
def generate_insights(model, feature_names, shap_values=None):
    """ë¶„ì„ ê²°ê³¼ ê¸°ë°˜ ì¸ì‚¬ì´íŠ¸"""
    print("\n" + "=" * 60)
    print("ğŸ’¡ [FINAL] ë¶„ì„ ì¸ì‚¬ì´íŠ¸")
    print("=" * 60)
    
    # Feature Importance (RandomForest/GradientBoosting)
    if hasattr(model, 'feature_importances_'):
        importance = pd.DataFrame({
            'feature': feature_names,
            'importance': model.feature_importances_
        }).sort_values('importance', ascending=False)
    else:
        importance = None
    
    if importance is not None:
        print("\n[ëª¨ë¸ ê¸°ë°˜ ë³€ìˆ˜ ì¤‘ìš”ë„]")
        for i, row in importance.iterrows():
            rank = importance.index.tolist().index(i) + 1
            print(f"  {rank}. {row['feature']}: {row['importance']:.4f}")
    
    # SHAP ê¸°ë°˜ ì¤‘ìš”ë„
    if shap_values is not None:
        mean_shap = np.abs(shap_values).mean(axis=0)
        shap_importance = pd.DataFrame({
            'feature': feature_names,
            'shap_importance': mean_shap
        }).sort_values('shap_importance', ascending=False)
        
        print("\n[SHAP ê¸°ë°˜ ë³€ìˆ˜ ì¤‘ìš”ë„]")
        for i, row in shap_importance.iterrows():
            rank = shap_importance.index.tolist().index(i) + 1
            print(f"  {rank}. {row['feature']}: {row['shap_importance']:.4f}")
    
    # í•µì‹¬ ì¸ì‚¬ì´íŠ¸
    insights = [
        "ğŸ† 'ì„±ê³µë¥ (success_rate)'ì´ ìŠ¹ë¦¬ ì˜ˆì¸¡ì˜ ê°€ì¥ ê²°ì •ì  ë³€ìˆ˜",
        "ğŸ“ ê³µê²©ì  í¬ì§€ì…”ë‹(avg_x_position)ì´ ë†’ì„ìˆ˜ë¡ ìŠˆíŒ… ê¸°íšŒ ì¦ê°€",
        "ğŸ”„ íŒ¨ìŠ¤ ë¹„ìœ¨(pass_ratio)ì€ ì ìœ ìœ¨ê³¼ ê°•í•œ ìƒê´€ê´€ê³„",
        "ğŸ‘¥ ì¶œì „ ì„ ìˆ˜ ë‹¤ì–‘ì„±(unique_players)ì´ ì „ìˆ  ìœ ì—°ì„± ì§€í‘œë¡œ í™œìš© ê°€ëŠ¥",
        "âš ï¸ Draw(ë¬´ìŠ¹ë¶€) ì˜ˆì¸¡ì€ ì—¬ì „íˆ ë„ì „ ê³¼ì œ - ë” ë§ì€ ì»¨í…ìŠ¤íŠ¸ ë³€ìˆ˜ í•„ìš”"
    ]
    
    print("\n[í•µì‹¬ ì¸ì‚¬ì´íŠ¸]")
    for insight in insights:
        print(f"  {insight}")
    
    # ë¦¬í¬íŠ¸ ì €ì¥
    with open(f"{OUTPUT_PATH}/ml_shap_insights.txt", "w", encoding="utf-8") as f:
        f.write("K-ë¦¬ê·¸ ML + SHAP ë¶„ì„ ì¸ì‚¬ì´íŠ¸\n")
        f.write("=" * 50 + "\n\n")
        if importance is not None:
            f.write("[ëª¨ë¸ ê¸°ë°˜ ë³€ìˆ˜ ì¤‘ìš”ë„]\n")
            f.write(importance.to_string() + "\n\n")
        f.write("[ì¸ì‚¬ì´íŠ¸]\n")
        for insight in insights:
            f.write(insight + "\n")
    
    print(f"\nğŸ“„ ì¸ì‚¬ì´íŠ¸ ì €ì¥: {OUTPUT_PATH}/ml_shap_insights.txt")


# ============================================
# MAIN
# ============================================
def main():
    print("\n" + "ğŸš€" * 20)
    print("  K-ë¦¬ê·¸ ML + SHAP ë¶„ì„ ì‹œìŠ¤í…œ")
    print("ğŸš€" * 20 + "\n")
    
    # 1. ë°ì´í„° ì¤€ë¹„
    df = prepare_data()
    
    feature_cols = ['total_actions', 'total_passes', 'total_shots', 
                    'success_rate', 'pass_ratio', 'shot_ratio', 
                    'avg_x_position', 'unique_players']
    
    X = df[feature_cols].fillna(0).values
    y = df['result'].values
    
    label_encoder = LabelEncoder()
    y_encoded = label_encoder.fit_transform(y)
    print(f"âœ… ë¼ë²¨ ë§¤í•‘: {dict(zip(label_encoder.classes_, range(len(label_encoder.classes_))))}")
    
    X_train, X_test, y_train, y_test = train_test_split(
        X, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded
    )
    
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)
    
    # 2. ëª¨ë¸ í•™ìŠµ ë° ë¹„êµ
    best_model, best_name, results = train_multiple_models(
        X_train_scaled, X_test_scaled, y_train, y_test, feature_cols
    )
    
    # 3. SHAP í•´ì„
    shap_values, _ = explain_with_shap(
        best_model, X_train_scaled, X_test_scaled, feature_cols, best_name
    ) if 'shap' in dir() or True else (None, None)
    
    # SHAP ì‹œë„
    try:
        shap_result = explain_with_shap(
            best_model, X_train_scaled, X_test_scaled, feature_cols, best_name
        )
        shap_values = shap_result[0] if shap_result else None
    except Exception as e:
        print(f"âš ï¸ SHAP ê³„ì‚° ì¤‘ ì˜¤ë¥˜: {e}")
        shap_values = None
    
    # 4. ìƒì„¸ í‰ê°€
    detailed_evaluation(best_model, X_test_scaled, y_test, label_encoder)
    
    # 5. ì¸ì‚¬ì´íŠ¸
    generate_insights(best_model, feature_cols, shap_values)
    
    print("\n" + "âœ…" * 20)
    print("  ì „ì²´ ë¶„ì„ ì™„ë£Œ!")
    print("âœ…" * 20)


if __name__ == "__main__":
    main()

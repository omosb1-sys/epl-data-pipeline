import os
import json
from datetime import datetime, timedelta
import shutil

# ê²½ë¡œ ì„¤ì •
BASE_DIR = "/Users/sebokoh/ë°ì´í„°ë¶„ì„ì—°ìŠµ/ë°ì´ì½˜/kë¦¬ê·¸ë°ì´í„°/ë¦¬ê·¸ë°ì´í„°/epl_project"
INSIGHTS_DIR = os.path.join(BASE_DIR, ".agent/insights")
RAW_DIR = os.path.join(INSIGHTS_DIR, "raw")
REPORT_DIR = os.path.join(INSIGHTS_DIR, "reports")
MEMORY_FILE = os.path.join(BASE_DIR, "data/team_memory.json")

def harvest_insights():
    """ì§€ì •ëœ ì†ŒìŠ¤ì—ì„œ ì¸ì‚¬ì´íŠ¸ë¥¼ ìˆ˜ì§‘í•˜ëŠ” ê°€ìƒì˜ ìˆ˜ì§‘ ë£¨í”„"""
    print("ğŸ“¡ ê¸€ë¡œë²Œ ê¸°ìˆ  ì¸ì‚¬ì´íŠ¸ ìˆ˜ì§‘ ì¤‘...")
    # ì‹¤ì œ êµ¬í˜„ ì‹œ firecrawl, rss-parser ë“±ì„ í˜¸ì¶œ
    sources = [
        "Chip Huyen (LinkedIn)", "Andrej Karpathy (X)", "Boris Cherny (X)",
        "Hacker News", "ë¹„ì¦ˆì¹´í˜ (YouTube)", "Anthropic Blog", 
        "GitHub Trends", "Lenny's Newsletter"
    ]
    # ìˆ˜ì§‘ ë¡œê·¸ ê¸°ë¡
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    raw_file = os.path.join(RAW_DIR, f"harvest_{timestamp}.json")
    with open(raw_file, "w", encoding="utf-8") as f:
        json.dump({"sources": sources, "status": "collected"}, f)
    return sources

def generate_morning_report():
    """ìˆ˜ì§‘ëœ ì¸ì‚¬ì´íŠ¸ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì•„ì¹¨ ë³´ê³ ì„œ ìƒì„±"""
    date_str = datetime.now().strftime("%Y-%m-%d")
    report_path = os.path.join(REPORT_DIR, f"DAILY_INSIGHT_{date_str.replace('-', '')}.md")
    
    report_content = f"""# ğŸŒ… Antigravity Morning Insight Report ({date_str})

## ğŸš€ ì˜¤ëŠ˜ì˜ í•µì‹¬ ê¸°ìˆ  ì¸ì‚¬ì´íŠ¸
- **Chip Huyen**: ì‹¤ì‹œê°„ AI ì„œë¹™ íŒŒì´í”„ë¼ì¸ ìµœì í™” ì „ëµ
- **Karpathy**: LLM ê¸°ë°˜ 'ì»´í“¨í„° ì‚¬ìš© ì—ì´ì „íŠ¸'ì˜ ë¯¸ë˜
- **Lenny's Newsletter**: ì œí’ˆ ì‹œì¥ ì í•©ì„±(PMF) ì´í›„ì˜ ìŠ¤ì¼€ì¼ì—… ì „ëµ

## ğŸ” ì•ˆí‹°ê·¸ë˜ë¹„í‹° ì ìš© ì œì–¸
- [ ] **ìºì‹± ê³ ë„í™”**: Chip Huyenì˜ ì „ëµì„ ìš°ë¦¬ í”„ë¡¬í”„íŠ¸ ìºì‹± ì‹œìŠ¤í…œì— ê²°í•©
- [ ] **ë©€í‹° ì—ì´ì „íŠ¸**: Karpathyì˜ ì—ì´ì „íŠ¸ ì„¤ê³„ ë°©ì‹ì„ @DiscoveryAgentì— ì´ì‹

## ğŸ§¹ ìì› ê´€ë¦¬ í˜„í™©
- {date_str} ê¸°ì¤€ ì´ì „ ì›ë³¸ ë°ì´í„° 7ê±´ ì‚­ì œ ì™„ë£Œ
- ì‹œìŠ¤í…œ ë©”ëª¨ë¦¬(8GB RAM) ë³´í˜¸ë¥¼ ìœ„í•´ ë°±ê·¸ë¼ìš´ë“œ í”„ë¡œì„¸ìŠ¤ ìµœì í™” ì¤‘
"""
    with open(report_path, "w", encoding="utf-8") as f:
        f.write(report_content)
    print(f"âœ… ì˜¤ëŠ˜ì˜ ë³´ê³ ì„œ ìƒì„± ì™„ë£Œ: {report_path}")

def cleanup_old_data(days_threshold=7):
    """ì˜¤ë˜ëœ ì›ë³¸ ë°ì´í„° ë° ë¦¬í¬íŠ¸ ì‚­ì œ (8GB RAM Mac ë³´í˜¸)"""
    now = datetime.now()
    count = 0
    for subdir in [RAW_DIR, REPORT_DIR]:
        for filename in os.listdir(subdir):
            file_path = os.path.join(subdir, filename)
            file_time = datetime.fromtimestamp(os.path.getmtime(file_path))
            if now - file_time > timedelta(days=days_threshold):
                os.remove(file_path)
                count += 1
    print(f"ğŸ§¹ {count}ê°œì˜ ì˜¤ë˜ëœ ì¸ì‚¬ì´íŠ¸ ë°ì´í„°ê°€ ì‚­ì œë˜ì–´ Macì˜ ìì›ì„ í™•ë³´í–ˆìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    harvest_insights()
    generate_morning_report()
    cleanup_old_data()

"""
ğŸš— Kmong Big Data Analytics Engine (v1.0)
========================================
- Optimized for 8GB RAM Mac (Intel)
- Core: Polars (Rust-based Vectorized Processing)
- Storage: Apache Parquet (High Compression)
- Strategy: Chunk-based Memory Management

Author: Antigravity AI (Strategic Senior Analyst)
Date: 2026-01-22
"""

import polars as pl
import duckdb
from pathlib import Path
import os
import time

# ----------------------------------------------------------------------
# 1. ì‹œë‹ˆì–´ì˜ ë©”ëª¨ë¦¬ ë³´í˜¸ ì„¤ì • (Memory Management)
# ----------------------------------------------------------------------
RAW_DATA_PATH = Path("./data/kmong_project/raw")
PROCESSED_PATH = Path("./data/kmong_project/processed")
OUTPUT_PATH = Path("./data/kmong_project/output")

# í´ë” ìë™ ìƒì„±
for p in [RAW_DATA_PATH, PROCESSED_PATH, OUTPUT_PATH]:
    p.mkdir(parents=True, exist_ok=True)

class KmongAnalyticsEngine:
    def __init__(self):
        self.master_df = None
        print("ğŸ’¡ Antigravity Engine Ready: 8GB RAM ìµœì í™” ëª¨ë“œ í™œì„±")

    def integrate_excel_files(self):
        """240ë§Œ í–‰ ì‹œíŠ¸ í†µí•© (np.where ë°©ì‹ì˜ ê³ íš¨ìœ¨ ë¡œì§ í¬í•¨)"""
        start_time = time.time()
        excel_files = list(RAW_DATA_PATH.glob("*.xls*"))
        
        if not excel_files:
            print("âŒ RAW í´ë”ì— ì—‘ì…€ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
            return

        all_chunks = []
        
        for file in excel_files:
            print(f"ğŸ”„ ì²˜ë¦¬ ì¤‘: {file.name}")
            # fastexcel ì—”ì§„ìœ¼ë¡œ ë©”ëª¨ë¦¬ ì ˆì•½í•˜ë©° ë¡œë“œ
            try:
                # 1. ëª¨ë“  ì»¬ëŸ¼ì„ ê°•ì œë¡œ Stringìœ¼ë¡œ ì½ì–´ ì—ëŸ¬ ë°œí˜„ ì›ì²œ ì°¨ë‹¨
                df = pl.read_excel(file, infer_schema_length=0)
                
                # 2. ëª¨ë“  ì»¬ëŸ¼ì˜ ì•ë’¤ ê³µë°± ì œê±° (Trim) ë° NaN ì²˜ë¦¬
                df = df.with_columns([
                    pl.col(c).cast(pl.String).str.strip_chars().fill_null("ë¯¸ë¶„ë¥˜")
                    for c in df.columns
                ])

                # 3. Vectorized logic (np.where ìŠ¤íƒ€ì¼) ì ìš©
                # êµ¬ì²´ì ì¸ ë¡œì§ ì ìš© ì‹œ ì—ëŸ¬ ë°©ì§€ë¥¼ ìœ„í•´ fill_null ì„ í–‰
                df = df.with_columns([
                    pl.when(pl.col("íšŒì›êµ¬ë¶„ëª…").str.contains("ê°œì¸"))
                      .then(pl.lit("ê°œì¸"))
                      .when(pl.col("íšŒì›êµ¬ë¶„ëª…").str.contains("ë²•ì¸|ì‚¬ì—…ì"))
                      .then(pl.lit("ë²•ì¸"))
                      .otherwise(pl.lit("ê¸°íƒ€/ë¯¸ë¶„ë¥˜"))
                      .alias("ê³ ê°ìœ í˜•_ë¶„ë¥˜"),
                      
                    # ë²ˆí˜¸íŒ ê¸°ë°˜ ë¡œì§ (ë Œíƒˆ/íƒì‹œ)
                    pl.when(pl.col("ì°¨ëŸ‰ë“±ë¡ë²ˆí˜¸").str.contains("í•˜|í—ˆ|í˜¸"))
                      .then(pl.lit("Rental"))
                      .when(pl.col("ì°¨ëŸ‰ë“±ë¡ë²ˆí˜¸").str.contains("ë°”|ì‚¬|ì•„|ì"))
                      .then(pl.lit("Taxi"))
                      .otherwise(pl.lit("ì¼ë°˜"))
                      .alias("ë²•ì¸ì„¸ë¶€_ë¶„ë¥˜")
                ])
                
                # ë©”ëª¨ë¦¬ ì ˆì•½ì„ ìœ„í•´ í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ì„ íƒí•˜ê³  ë°ì´í„° íƒ€ì… ë‹¤ìš´ìºìŠ¤íŒ…
                # (8GB RAM í•µì‹¬ í…Œí¬ë‹‰)
                df = df.select([
                    "ë°ì´í„° ì—°ë„ (YYYY)", "ë°ì´í„° ì›” (MM)", "ì°¨ì¢…ëª…", 
                    "ë°°ê¸°ëŸ‰", "ì°¨ëª…", "ì§€ì—­", "ì·¨ë“ê¸ˆì•¡", 
                    "ê³ ê°ìœ í˜•_ë¶„ë¥˜", "ë²•ì¸ì„¸ë¶€_ë¶„ë¥˜"
                ])
                
                all_chunks.append(df)
                
            except Exception as e:
                print(f"âš ï¸ {file.name} ì²˜ë¦¬ ì¤‘ ì—ëŸ¬ ë°œìƒ: {e}")

        # ëª¨ë“  ì²­í¬ í†µí•©
        if all_chunks:
            self.master_df = pl.concat(all_chunks)
            # Parquetìœ¼ë¡œ ì••ì¶• ì €ì¥ (ì—‘ì…€ ëŒ€ë¹„ ìš©ëŸ‰ 90% ì ˆê°)
            self.master_df.write_parquet(PROCESSED_PATH / "master_data.parquet")
            
            elapsed = time.time() - start_time
            print(f"âœ… í†µí•© ì™„ë£Œ: {len(self.master_df):,} í–‰")
            print(f"â±ï¸ ì†Œìš” ì‹œê°„: {elapsed:.2f} ì´ˆ")

    def get_strategic_insights(self):
        """DuckDBë¥¼ ì´ìš©í•œ ì´ˆê³ ì† í†µê³„ ë¶„ì„ (ìƒë¬´ë‹˜ ë³´ê³ ìš© ì§€í‘œ)"""
        if self.master_df is None:
            self.master_df = pl.read_parquet(PROCESSED_PATH / "master_data.parquet")
            
        print("\nğŸ“Š ìƒë¬´ë‹˜ ë³´ê³ ìš© ì¸ì‚¬ì´íŠ¸ ìš”ì•½ ì¶”ì¶œ ì¤‘...")
        
        # SQLë¡œ ì‹œê³„ì—´ íŠ¸ë Œë“œ ì¦‰ì‹œ ì§‘ê³„
        db = duckdb.connect()
        trends = db.query("""
            SELECT 
                "ë°ì´í„° ì—°ë„ (YYYY)" as ì—°ë„,
                ê³ ê°ìœ í˜•_ë¶„ë¥˜,
                COUNT(*) as ë“±ë¡ìˆ˜,
                ROUND(AVG(CAST(ë°°ê¸°ëŸ‰ AS INT)), 0) as í‰ê· ë°°ê¸°ëŸ‰
            FROM master_df
            GROUP BY 1, 2
            ORDER BY 1, 2
        """).pl()
        
        print(trends)
        return trends

    # ----------------------------------------------------------------------
    # 3. ë°ì´í„° ë¶„ì„ê°€ ì„±ì¥ì„ ìœ„í•œ í•µì‹¬ ì—”ì§€ë‹ˆì–´ë§ ë ˆì´ì–´ (Advanced Protocol)
    # ----------------------------------------------------------------------
    def validate_data_quality(self, df: pl.DataFrame) -> bool:
        """
        [Engineering] ë°ì´í„° ì •í•©ì„± ê²€ì¦ ë ˆì´ì–´ (Data Quality Guard)
        Reference: Made-With-ML (Validation & Monitoring)
        """
        print("ğŸ›¡ï¸ [Audit] ë°ì´í„° í’ˆì§ˆ ê²€ì¦ ê°€ë™...")
        
        # 1. í•„ìˆ˜ ì»¬ëŸ¼ ì¡´ì¬ ì—¬ë¶€ ì²´í¬
        required_cols = ["ë°ì´í„° ì—°ë„ (YYYY)", "ì°¨ì¢…ëª…", "ì·¨ë“ê¸ˆì•¡"]
        missing = [c for c in required_cols if c not in df.columns]
        if missing:
            print(f"âŒ í•„ìˆ˜ ì»¬ëŸ¼ ëˆ„ë½: {missing}")
            return False

        # 2. ê²°ì¸¡ì¹˜ ë¹„ìœ¨ ì²´í¬ (Critical Level: 30%)
        null_counts = df.null_count()
        for col in df.columns:
            null_ratio = null_counts[col][0] / len(df)
            if null_ratio > 0.3:
                print(f"âš ï¸ ê²½ê³ : '{col}' ì»¬ëŸ¼ ê²°ì¸¡ì¹˜ ë¹„ìœ¨ {null_ratio*100:.1f}% ì´ˆê³¼")

        # 3. ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ ìœ íš¨ê°’ ì²´í¬
        years = df["ë°ì´í„° ì—°ë„ (YYYY)"].unique().to_list()
        print(f"âœ… ë°ì´í„° ì—°ë„ ë²”ìœ„: {min(years)} ~ {max(years)}")
        
        return True

    def track_observability(self, stage: str, message: str):
        """
        [Observability] íŒŒì´í”„ë¼ì¸ ê°€ì‹œì„± í™•ë³´ (Logging & Audit)
        Reference: Data Engineer Handbook
        """
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        log_entry = f"[{timestamp}] [{stage}] {message}"
        print(f"ğŸ“ {log_entry}")
        
        # ë¡œê·¸ íŒŒì¼ë¡œ ë³´ê´€
        log_path = PROCESSED_PATH / "pipeline_audit.log"
        with open(log_path, "a") as f:
            f.write(log_entry + "\n")

# ----------------------------------------------------------------------
# ì‹¤í–‰ ì§„ì…ì 
# ----------------------------------------------------------------------
if __name__ == "__main__":
    engine = KmongAnalyticsEngine()
    # 1ë‹¨ê³„: í†µí•© (ì‹¤í–‰ ì‹œ RAW í´ë”ì— íŒŒì¼ì´ ìˆì–´ì•¼ í•¨)
    # engine.integrate_excel_files()
    # 2ë‹¨ê³„: ì¸ì‚¬ì´íŠ¸ (í†µí•© í›„ ì‹¤í–‰)
    # engine.get_strategic_insights()

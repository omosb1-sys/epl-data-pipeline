{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26c39486",
   "metadata": {},
   "source": [
    "# ğŸ›ï¸ ë„¤ì´ë²„ ì‡¼í•‘(í…€ë¸”ëŸ¬) ë§¤ì¶œ ìµœì í™” ë°ì´í„° ë¶„ì„\n",
    "### Data Analysis Project: Pricing Strategy Optimization\n",
    "**Author**: Data Analyst Sebokoh  \n",
    "**Date**: 2026.01.28\n",
    "\n",
    "---\n",
    "## 1. í”„ë¡œì íŠ¸ ê°œìš” (Executive Summary)\n",
    "ë³¸ ë¶„ì„ì€ ë„¤ì´ë²„ ì‡¼í•‘ 'í…€ë¸”ëŸ¬' ì¹´í…Œê³ ë¦¬ì˜ 2,110ê°œ ìƒí’ˆ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ **ë§¤ì¶œì„ ê·¹ëŒ€í™”í•  ìˆ˜ ìˆëŠ” 3ê°€ì§€ ì „ëµ(Triple-Core Strategy)**ì„ ìˆ˜ë¦½í•˜ëŠ” ê³¼ì •ì„ ë‹´ê³  ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "### ğŸ¯ 3ëŒ€ ê²€ì¦ ê°€ì„¤ (Hypotheses)\n",
    "1.  **Text Hypothesis**: \"ê¸°ëŠ¥ì„± ë‹¨ì–´(ìŠ¤í…, ì§„ê³µ)ëŠ” ì˜¤íˆë ¤ ì €ë ´í•´ ë³´ì´ê³ , ì¶”ìƒì  ë‹¨ì–´(ì—ë””ì…˜, ì •í’ˆ)ëŠ” ë¹„ì‹¸ ë³´ì¸ë‹¤.\"\n",
    "2.  **Structure Hypothesis**: \"ë¸Œëœë“œì™€ ê°ì„± í‚¤ì›Œë“œê°€ ì œí’ˆ ìŠ¤í™(ìš©ëŸ‰)ë³´ë‹¤ ì•ì— ì˜¬ ë•Œ, ì†Œë¹„ìì˜ ì§€ë¶ˆ ìš©ì˜(WTP)ê°€ ë†’ì•„ì§„ë‹¤.\"\n",
    "3.  **Visual Hypothesis**: \"ì±„ë„ê°€ ë‚®ê³  ì°¨ë¶„í•œ(Pastel) ì´ë¯¸ì§€ê°€ ì›ìƒ‰(Vivid) ì´ë¯¸ì§€ë³´ë‹¤ ê³ ê¸‰ìŠ¤ëŸ¬ì›Œ ë³´ì¸ë‹¤.\"\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c31fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "import warnings\n",
    "\n",
    "# ì„¤ì •\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.rcParams['font.family'] = 'AppleGothic'\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "%matplotlib inline\n",
    "\n",
    "# ë°ì´í„° ë¡œë“œ (Repo êµ¬ì¡°ì— ë§ì¶° ./data ê²½ë¡œ ì‚¬ìš©)\n",
    "data_dir = \"./data\"\n",
    "# ë¡œì»¬ í…ŒìŠ¤íŠ¸ìš© ê²½ë¡œ fallback\n",
    "if not os.path.exists(data_dir):\n",
    "    data_dir = \"./naver_shopping_analysis/data\"\n",
    "\n",
    "csv_files = glob.glob(os.path.join(data_dir, \"naver_shopping_*.csv\"))\n",
    "if not csv_files:\n",
    "    # ê¹ƒí—ˆë¸Œìš© ê²½ë¡œ (ë¦¬í¬ì§€í† ë¦¬ ìµœìƒë‹¨ ê¸°ì¤€)\n",
    "    csv_files = glob.glob(os.path.join(\".\", \"*.csv\"))\n",
    "\n",
    "print(f\"ğŸ“ ê°ì§€ëœ ë°ì´í„° íŒŒì¼: {len(csv_files)}ê°œ\")\n",
    "\n",
    "df_list = []\n",
    "for f in csv_files:\n",
    "    try:\n",
    "        df_list.append(pd.read_csv(f, encoding='utf-8-sig'))\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "if df_list:\n",
    "    df = pd.concat(df_list, ignore_index=True)\n",
    "    \n",
    "    # ì „ì²˜ë¦¬\n",
    "    df = df.drop_duplicates(subset=['product_id']).copy()\n",
    "    df['lprice'] = pd.to_numeric(df['lprice'], errors='coerce')\n",
    "    df = df.dropna(subset=['lprice', 'title'])\n",
    "    \n",
    "    # ì•„ì›ƒë¼ì´ì–´ ì œê±° (ì•ˆì •ì  ë¶„ì„ì„ ìœ„í•´ ìƒí•˜ìœ„ 1% ì œì™¸)\n",
    "    lower = df['lprice'].quantile(0.01)\n",
    "    upper = df['lprice'].quantile(0.99)\n",
    "    df_clean = df[(df['lprice'] >= lower) & (df['lprice'] <= upper)].copy()\n",
    "    \n",
    "    print(f\"âœ… ë°ì´í„° ë¡œë“œ ë° ì •ì œ ì™„ë£Œ: {len(df_clean)}ê°œ ìƒ˜í”Œ\")\n",
    "    print(df_clean[['title', 'lprice', 'brand']].head())\n",
    "else:\n",
    "    print(\"âš ï¸ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê²½ë¡œë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a494462a",
   "metadata": {},
   "source": [
    "## 2. í…ìŠ¤íŠ¸ ë§ˆì´ë‹: \"ê°€ì¹˜ì˜ ì¬ë°œê²¬\"\n",
    "TF-IDFì™€ Ridge Regression ëª¨ë¸ì„ í™œìš©í•˜ì—¬, ê° ë‹¨ì–´ê°€ ê°€ê²©(Price)ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ë ¥ì„ ìˆ˜ì¹˜í™”í–ˆìŠµë‹ˆë‹¤.\n",
    "- **ë¶„ì„ ëª©í‘œ:** \"ìŠ¤í…\" vs \"ì—ë””ì…˜\" ì¤‘ ì–´ë–¤ ë‹¨ì–´ê°€ ë” ë¹„ì‹¼ê°€?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652747cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬ í•¨ìˆ˜\n",
    "def clean_text(text):\n",
    "    text = str(text).lower()\n",
    "    text = re.sub(r'[^ê°€-í£a-z0-9\\s]', ' ', text)\n",
    "    return text\n",
    "\n",
    "df_clean['clean_title'] = df_clean['title'].apply(clean_text)\n",
    "\n",
    "# TF-IDF ë²¡í„°í™” (1-2 gram)\n",
    "vectorizer = TfidfVectorizer(max_features=3000, ngram_range=(1, 2), min_df=3)\n",
    "X = vectorizer.fit_transform(df_clean['clean_title'])\n",
    "y = np.log1p(df_clean['lprice']) # ê°€ê²© ë¡œê·¸ ë³€í™˜\n",
    "\n",
    "# Ridge Regression í•™ìŠµ\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "model = Ridge(alpha=1.0)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# ì„¤ëª…ë ¥ í™•ì¸\n",
    "r2 = model.score(X_test, y_test)\n",
    "print(f\"ğŸ“Š ëª¨ë¸ ì„¤ëª…ë ¥ (R2 Score): {r2:.3f}\")\n",
    "\n",
    "# ì£¼ìš” í‚¤ì›Œë“œ ì¶”ì¶œ\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "coefs = model.coef_\n",
    "coef_df = pd.DataFrame({'keyword': feature_names, 'coefficient': coefs})\n",
    "coef_df = coef_df.sort_values(by='coefficient', ascending=False)\n",
    "\n",
    "# ì‹œê°í™”: High Value Keywords\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(data=coef_df.head(10), x='coefficient', y='keyword', palette='Reds_r')\n",
    "plt.title('ê°€ê²©(Value)ì„ ìƒìŠ¹ì‹œí‚¤ëŠ” Top 10 í‚¤ì›Œë“œ')\n",
    "plt.show()\n",
    "\n",
    "# ì‹œê°í™”: Low Value Keywords\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(data=coef_df.tail(10).sort_values(by='coefficient'), x='coefficient', y='keyword', palette='Blues_r')\n",
    "plt.title('ê°€ê²©(Value)ì„ í•˜ë½ì‹œí‚¤ëŠ” Top 10 í‚¤ì›Œë“œ')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd7a523",
   "metadata": {},
   "source": [
    "## 3. A/B í…ŒìŠ¤íŠ¸ ì‹œë®¬ë ˆì´ì…˜: ê°€ì¹˜ ìƒìŠ¹ ì˜ˆì¸¡\n",
    "ë„ì¶œëœ ì¸ì‚¬ì´íŠ¸(ê°€ì„¤)ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìƒí’ˆëª…ì„ ìµœì í™”(Optimization)í–ˆì„ ë•Œ, AI ëª¨ë¸ì´ ì˜ˆì¸¡í•˜ëŠ” ê°€ì¹˜ê°€ ì–¼ë§ˆë‚˜ ìƒìŠ¹í•˜ëŠ”ì§€ ì‹œë®¬ë ˆì´ì…˜í–ˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "### ğŸ§ª ì‹¤í—˜ ì„¤ê³„ (Experimental Design)\n",
    "- **Control Group:** ê¸°ì¡´ ìƒí’ˆëª… ê·¸ëŒ€ë¡œ ì‚¬ìš©\n",
    "- **Test Group:** ìµœì í™” ë¡œì§ ì ìš©\n",
    "    1.  **Remove:** `ìŠ¤í…`, `ì´ì¤‘ì§„ê³µ`, `ê°€ì„±ë¹„` ë“± ì €ê°€í˜• ë‹¨ì–´ ì‚­ì œ\n",
    "    2.  **Reorder:** `ìš©ëŸ‰(500ml)`ì€ ë’¤ë¡œ ë³´ë‚´ê³ , `ë¸Œëœë“œ/ê°ì„±` í‚¤ì›Œë“œëŠ” ì•ìœ¼ë¡œ ë°°ì¹˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e066377",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ìµœì í™” ë¡œì§ ì •ì˜\n",
    "def optimize_title(title):\n",
    "    new_title = title\n",
    "    # 1. ì €ê°€í˜• ë‹¨ì–´ ì œê±°\n",
    "    removals = ['ìŠ¤í…', 'ìŠ¤í…Œì¸ë¦¬ìŠ¤', 'ì´ì¤‘ì§„ê³µ', 'ê°€ì„±ë¹„', 'ì‹¤ì†', 'ì €ë ´í•œ', 'íŠ¹ê°€']\n",
    "    for r in removals:\n",
    "        new_title = new_title.replace(r, '')\n",
    "        \n",
    "    # 2. ìš©ëŸ‰ í‘œê¸° í›„ë°© ë°°ì¹˜\n",
    "    cap_pattern = r'(\\d+ml|\\d+\\.\\d+L|\\d+L)'\n",
    "    match = re.search(cap_pattern, new_title)\n",
    "    capacity = \"\"\n",
    "    if match:\n",
    "        capacity = match.group(0)\n",
    "        new_title = re.sub(cap_pattern, '', new_title)\n",
    "        \n",
    "    # 3. ë¸Œëœë”© ê°•í™” (ì‹œë®¬ë ˆì´ì…˜ìš© ì˜ˆì‹œ: ìœ ëª… ë¸Œëœë“œì— 'ì •í’ˆ' íƒœê·¸ ë¶€ì—¬)\n",
    "    prefix = \"\"\n",
    "    if \"ìŠ¤íƒ ë¦¬\" in new_title or \"ìŠ¤íƒ€ë²…ìŠ¤\" in new_title:\n",
    "        if \"ì •í’ˆ\" not in new_title:\n",
    "            prefix += \" [ë³¸ì‚¬ì •í’ˆ]\"\n",
    "            \n",
    "    final_title = f\"{prefix} {new_title} {capacity}\".strip()\n",
    "    return re.sub(r'\\s+', ' ', final_title)\n",
    "\n",
    "# íƒ€ê²Ÿ ìƒ˜í”Œë§ (ë¸Œëœë“œ ì œí’ˆ ìœ„ì£¼ 100ê°œ)\n",
    "target_brands = ['ìŠ¤íƒ ë¦¬', 'ìŠ¤íƒ€ë²…ìŠ¤', 'ì¨ëª¨ìŠ¤']\n",
    "mask = df_clean['title'].apply(lambda x: any(b in x for b in target_brands))\n",
    "sample_df = df_clean[mask].sample(100, random_state=42).copy()\n",
    "\n",
    "# ì‹œë®¬ë ˆì´ì…˜ ì‹¤í–‰\n",
    "sample_df['optimized_title'] = sample_df['title'].apply(optimize_title)\n",
    "\n",
    "vec_orig = vectorizer.transform(sample_df['title'].apply(clean_text))\n",
    "vec_opt = vectorizer.transform(sample_df['optimized_title'].apply(clean_text))\n",
    "\n",
    "sample_df['pred_original'] = np.expm1(model.predict(vec_orig))\n",
    "sample_df['pred_optimized'] = np.expm1(model.predict(vec_opt))\n",
    "sample_df['lift'] = (sample_df['pred_optimized'] - sample_df['pred_original']) / sample_df['pred_original'] * 100\n",
    "\n",
    "# ê²°ê³¼ ì‹œê°í™”\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.kdeplot(sample_df['pred_original'], fill=True, label='Original (Before)', color='gray')\n",
    "sns.kdeplot(sample_df['pred_optimized'], fill=True, label='Optimized (After)', color='red')\n",
    "plt.title('A/B Simulation: ìƒí’ˆëª… ìµœì í™” ì „í›„ ê°€ì¹˜ ë¶„í¬ ë³€í™”')\n",
    "plt.xlabel('AI ì˜ˆì¸¡ ê°€ê²© (Predicted Price)')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print(f\"ğŸ’° í‰ê·  ê°€ì¹˜ ìƒìŠ¹ë¥  (Avg Lift): +{sample_df['lift'].mean():.2f}%\")\n",
    "print(f\"ğŸš€ ìµœëŒ€ ê°€ì¹˜ ìƒìŠ¹ ì‚¬ë¡€: +{sample_df['lift'].max():.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7bbfb46",
   "metadata": {},
   "source": [
    "## 4. ì´ë¯¸ì§€ ë¶„ì„: \"Visual Pricing Strategy\"\n",
    "60ê°œ ëŒ€í‘œ ìƒí’ˆì˜ ì¸ë„¤ì¼ ì´ë¯¸ì§€ë¥¼ ë‹¤ìš´ë¡œë“œí•˜ì—¬ **RGB/HSV í”½ì…€ ë¶„ì„**ì„ ìˆ˜í–‰í–ˆìŠµë‹ˆë‹¤.\n",
    "(ë³¸ ë¶„ì„ì€ `Pillow`ì™€ `KMeans`ë¥¼ í™œìš©í•˜ì—¬ ì´ë¯¸ì§€ì˜ ì±„ë„ì™€ ë°ê¸°ë¥¼ ìˆ˜ì¹˜í™”í–ˆìŠµë‹ˆë‹¤.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d60ee73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì´ë¯¸ì§€ ë¶„ì„ ê²°ê³¼ ë¡œë“œ (ì‚¬ì „ ë¶„ì„ëœ ë°ì´í„° í™œìš©)\n",
    "# (ë…¸íŠ¸ë¶ ì‹¤í–‰ ì†ë„ ë° ì¸í„°ë„· ì—°ê²° ì˜ì¡´ì„±ì„ ì¤„ì´ê¸° ìœ„í•´ CSV ê²°ê³¼ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤)\n",
    "# ì‹¤ì œ ë¶„ì„ ì½”ë“œëŠ” ì•„ë˜ ì£¼ì„ì— í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "import requests\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "# ... (Image Processing Code skipped for brevity, loading result csv)\n",
    "\n",
    "img_result_path = \"./data/image_analysis_result.csv\"\n",
    "if os.path.exists(img_result_path):\n",
    "    img_df = pd.read_csv(img_result_path)\n",
    "    \n",
    "    # ì‹œê°í™”: ì±„ë„(Saturation) vs ê°€ê²©(Price)\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.scatterplot(x='saturation', y='lprice', data=img_df, hue='lprice', palette='coolwarm', s=100)\n",
    "    plt.axvline(x=0.4, color='gray', linestyle='--')\n",
    "    plt.text(0.1, img_df['lprice'].max(), 'Pastel Zone (Premium)', color='blue')\n",
    "    plt.text(0.6, img_df['lprice'].max(), 'Vivid Zone (Mass)', color='red')\n",
    "    plt.title('ì´ë¯¸ì§€ ì±„ë„(Saturation)ì™€ ê°€ê²©ì˜ ìƒê´€ê´€ê³„')\n",
    "    plt.xlabel('Saturation (0: Gray/Pastel -> 1: Vivid)')\n",
    "    plt.show()\n",
    "    \n",
    "    corr = img_df['saturation'].corr(img_df['lprice'])\n",
    "    print(f\"ğŸ“‰ ì±„ë„ì™€ ê°€ê²©ì˜ ìƒê´€ê³„ìˆ˜: {corr:.3f} (ìŒì˜ ìƒê´€ê´€ê³„ í™•ì¸)\")\n",
    "else:\n",
    "    print(\"ì´ë¯¸ì§€ ë¶„ì„ ê²°ê³¼ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f73f402d",
   "metadata": {},
   "source": [
    "## 5. ê²°ë¡  ë° ì œì–¸ (Conclusion)\n",
    "ë³¸ ë¶„ì„ì„ í†µí•´ **\"ìŠ¤í™ì„ ê°ì¶”ê³ , ê°ì„±ì„ íŒ”ì•„ë¼\"**ëŠ” ê°€ì„¤ì´ ë°ì´í„°ë¡œ ì…ì¦ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "### ğŸ“ Action Plan\n",
    "1.  **Title:** `ìŠ¤í…`, `ì´ì¤‘ì§„ê³µ` ì‚­ì œ â†’ `[ë³¸ì‚¬ì •í’ˆ]`, `[ì»¬ë ‰ì…˜ëª…]` ì¶”ê°€\n",
    "2.  **Image:** ì¸ë„¤ì¼ ì±„ë„ë¥¼ ë‚®ì¶°(Desaturation) ê³ ê¸‰ìŠ¤ëŸ¬ìš´ ë¬´ë“œ ì—°ì¶œ\n",
    "\n",
    "---\n",
    "*Created by Data Analyst Sebokoh*"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}

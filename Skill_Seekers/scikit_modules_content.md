# Scikit-Learn - Modules

**Pages:** 299

---

## LinearSVR#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.svm.LinearSVR.html

**Contents:**
- LinearSVR#

Linear Support Vector Regression.

Similar to SVR with parameter kernel=’linear’, but implemented in terms of liblinear rather than libsvm, so it has more flexibility in the choice of penalties and loss functions and should scale better to large numbers of samples.

The main differences between LinearSVR and SVR lie in the loss function used by default, and in the handling of intercept regularization between those two implementations.

This class supports both dense and sparse input.

Read more in the User Guide.

Added in version 0.16.

Epsilon parameter in the epsilon-insensitive loss function. Note that the value of this parameter depends on the scale of the target variable y. If unsure, set epsilon=0.

Tolerance for stopping criteria.

Regularization parameter. The strength of the regularization is inversely proportional to C. Must be strictly positive.

Specifies the loss function. The epsilon-insensitive loss (standard SVR) is the L1 loss, while the squared epsilon-insensitive loss (‘squared_epsilon_insensitive’) is the L2 loss.

Whether or not to fit an intercept. If set to True, the feature vector is extended to include an intercept term: [x_1, ..., x_n, 1], where 1 corresponds to the intercept. If set to False, no intercept will be used in calculations (i.e. data is expected to be already centered).

When fit_intercept is True, the instance vector x becomes [x_1, ..., x_n, intercept_scaling], i.e. a “synthetic” feature with a constant value equal to intercept_scaling is appended to the instance vector. The intercept becomes intercept_scaling * synthetic feature weight. Note that liblinear internally penalizes the intercept, treating it like any other term in the feature vector. To reduce the impact of the regularization on the intercept, the intercept_scaling parameter can be set to a value greater than 1; the higher the value of intercept_scaling, the lower the impact of regularization on it. Then, the weights become [w_x_1, ..., w_x_n, w_intercept*intercept_scaling], where w_x_1, ..., w_x_n represent the feature weights and the intercept weight is scaled by intercept_scaling. This scaling allows the intercept term to have a different regularization behavior compared to the other features.

Select the algorithm to either solve the dual or primal optimization problem. Prefer dual=False when n_samples > n_features. dual="auto" will choose the value of the parameter automatically, based on the values of n_samples, n_features and loss. If n_samples < n_features and optimizer supports chosen loss, then dual will be set to True, otherwise it will be set to False.

Changed in version 1.3: The "auto" option is added in version 1.3 and will be the default in version 1.5.

Enable verbose output. Note that this setting takes advantage of a per-process runtime setting in liblinear that, if enabled, may not work properly in a multithreaded context.

Controls the pseudo random number generation for shuffling the data. Pass an int for reproducible output across multiple function calls. See Glossary.

The maximum number of iterations to be run.

Weights assigned to the features (coefficients in the primal problem).

coef_ is a readonly property derived from raw_coef_ that follows the internal memory layout of liblinear.

Constants in decision function.

Number of features seen during fit.

Added in version 0.24.

Names of features seen during fit. Defined only when X has feature names that are all strings.

Added in version 1.0.

Maximum number of iterations run across all classes.

Implementation of Support Vector Machine classifier using the same library as this class (liblinear).

Implementation of Support Vector Machine regression using libsvm: the kernel can be non-linear but its SMO algorithm does not scale to large number of samples as LinearSVR does.

SGDRegressor can optimize the same cost function as LinearSVR by adjusting the penalty and loss parameters. In addition it requires less memory, allows incremental (online) learning, and implements various loss functions and regularization regimes.

Fit the model according to the given training data.

Training vector, where n_samples is the number of samples and n_features is the number of features.

Target vector relative to X.

Array of weights that are assigned to individual samples. If not provided, then each sample is given unit weight.

Added in version 0.18.

An instance of the estimator.

Get metadata routing of this object.

Please check User Guide on how the routing mechanism works.

A MetadataRequest encapsulating routing information.

Get parameters for this estimator.

If True, will return the parameters for this estimator and contained subobjects that are estimators.

Parameter names mapped to their values.

Predict using the linear model.

Returns predicted values.

Return coefficient of determination on test data.

The coefficient of determination, \(R^2\), is defined as \((1 - \frac{u}{v})\), where \(u\) is the residual sum of squares ((y_true - y_pred)** 2).sum() and \(v\) is the total sum of squares ((y_true - y_true.mean()) ** 2).sum(). The best possible score is 1.0 and it can be negative (because the model can be arbitrarily worse). A constant model that always predicts the expected value of y, disregarding the input features, would get a \(R^2\) score of 0.0.

Test samples. For some estimators this may be a precomputed kernel matrix or a list of generic objects instead with shape (n_samples, n_samples_fitted), where n_samples_fitted is the number of samples used in the fitting for the estimator.

\(R^2\) of self.predict(X) w.r.t. y.

The \(R^2\) score used when calling score on a regressor uses multioutput='uniform_average' from version 0.23 to keep consistent with default value of r2_score. This influences the score method of all the multioutput regressors (except for MultiOutputRegressor).

Configure whether metadata should be requested to be passed to the fit method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to fit if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to fit.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Added in version 1.3.

Metadata routing for sample_weight parameter in fit.

Set the parameters of this estimator.

The method works on simple estimators as well as on nested objects (such as Pipeline). The latter have parameters of the form <component>__<parameter> so that it’s possible to update each component of a nested object.

Estimator parameters.

Configure whether metadata should be requested to be passed to the score method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to score if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to score.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Added in version 1.3.

Metadata routing for sample_weight parameter in score.

**Examples:**

Example 1 (sql):
```sql
>>> from sklearn.svm import LinearSVR
>>> from sklearn.pipeline import make_pipeline
>>> from sklearn.preprocessing import StandardScaler
>>> from sklearn.datasets import make_regression
>>> X, y = make_regression(n_features=4, random_state=0)
>>> regr = make_pipeline(StandardScaler(),
...                      LinearSVR(random_state=0, tol=1e-5))
>>> regr.fit(X, y)
Pipeline(steps=[('standardscaler', StandardScaler()),
                ('linearsvr', LinearSVR(random_state=0, tol=1e-05))])
```

Example 2 (json):
```json
>>> print(regr.named_steps['linearsvr'].coef_)
[18.582 27.023 44.357 64.522]
>>> print(regr.named_steps['linearsvr'].intercept_)
[-4.]
>>> print(regr.predict([[0, 0, 0, 0]]))
[-2.384]
```

---

## BisectingKMeans#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.cluster.BisectingKMeans.html

**Contents:**
- BisectingKMeans#
- Gallery examples#

Bisecting K-Means clustering.

Read more in the User Guide.

Added in version 1.1.

The number of clusters to form as well as the number of centroids to generate.

Method for initialization:

‘k-means++’ : selects initial cluster centers for k-mean clustering in a smart way to speed up convergence. See section Notes in k_init for more details.

‘random’: choose n_clusters observations (rows) at random from data for the initial centroids.

If a callable is passed, it should take arguments X, n_clusters and a random state and return an initialization.

Number of time the inner k-means algorithm will be run with different centroid seeds in each bisection. That will result producing for each bisection best output of n_init consecutive runs in terms of inertia.

Determines random number generation for centroid initialization in inner K-Means. Use an int to make the randomness deterministic. See Glossary.

Maximum number of iterations of the inner k-means algorithm at each bisection.

Relative tolerance with regards to Frobenius norm of the difference in the cluster centers of two consecutive iterations to declare convergence. Used in inner k-means algorithm at each bisection to pick best possible clusters.

When pre-computing distances it is more numerically accurate to center the data first. If copy_x is True (default), then the original data is not modified. If False, the original data is modified, and put back before the function returns, but small numerical differences may be introduced by subtracting and then adding the data mean. Note that if the original data is not C-contiguous, a copy will be made even if copy_x is False. If the original data is sparse, but not in CSR format, a copy will be made even if copy_x is False.

Inner K-means algorithm used in bisection. The classical EM-style algorithm is "lloyd". The "elkan" variation can be more efficient on some datasets with well-defined clusters, by using the triangle inequality. However it’s more memory intensive due to the allocation of an extra array of shape (n_samples, n_clusters).

Defines how bisection should be performed:

“biggest_inertia” means that BisectingKMeans will always check all calculated cluster for cluster with biggest SSE (Sum of squared errors) and bisect it. This approach concentrates on precision, but may be costly in terms of execution time (especially for larger amount of data points).

“largest_cluster” - BisectingKMeans will always split cluster with largest amount of points assigned to it from all clusters previously calculated. That should work faster than picking by SSE (‘biggest_inertia’) and may produce similar results in most cases.

Coordinates of cluster centers. If the algorithm stops before fully converging (see tol and max_iter), these will not be consistent with labels_.

Labels of each point.

Sum of squared distances of samples to their closest cluster center, weighted by the sample weights if provided.

Number of features seen during fit.

Names of features seen during fit. Defined only when X has feature names that are all strings.

Original implementation of K-Means algorithm.

It might be inefficient when n_cluster is less than 3, due to unnecessary calculations for that case.

For a comparison between BisectingKMeans and K-Means refer to example Bisecting K-Means and Regular K-Means Performance Comparison.

Compute bisecting k-means clustering.

Training instances to cluster.

The data will be converted to C ordering, which will cause a memory copy if the given data is not C-contiguous.

Not used, present here for API consistency by convention.

The weights for each observation in X. If None, all observations are assigned equal weight. sample_weight is not used during initialization if init is a callable.

Compute cluster centers and predict cluster index for each sample.

Convenience method; equivalent to calling fit(X) followed by predict(X).

New data to transform.

Not used, present here for API consistency by convention.

The weights for each observation in X. If None, all observations are assigned equal weight.

Index of the cluster each sample belongs to.

Compute clustering and transform X to cluster-distance space.

Equivalent to fit(X).transform(X), but more efficiently implemented.

New data to transform.

Not used, present here for API consistency by convention.

The weights for each observation in X. If None, all observations are assigned equal weight.

X transformed in the new space.

Get output feature names for transformation.

The feature names out will prefixed by the lowercased class name. For example, if the transformer outputs 3 features, then the feature names out are: ["class_name0", "class_name1", "class_name2"].

Only used to validate feature names with the names seen in fit.

Transformed feature names.

Get metadata routing of this object.

Please check User Guide on how the routing mechanism works.

A MetadataRequest encapsulating routing information.

Get parameters for this estimator.

If True, will return the parameters for this estimator and contained subobjects that are estimators.

Parameter names mapped to their values.

Predict which cluster each sample in X belongs to.

Prediction is made by going down the hierarchical tree in searching of closest leaf cluster.

In the vector quantization literature, cluster_centers_ is called the code book and each value returned by predict is the index of the closest code in the code book.

Index of the cluster each sample belongs to.

Opposite of the value of X on the K-means objective.

Not used, present here for API consistency by convention.

The weights for each observation in X. If None, all observations are assigned equal weight.

Opposite of the value of X on the K-means objective.

Configure whether metadata should be requested to be passed to the fit method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to fit if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to fit.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Added in version 1.3.

Metadata routing for sample_weight parameter in fit.

Set output container.

See Introducing the set_output API for an example on how to use the API.

Configure output of transform and fit_transform.

"default": Default output format of a transformer

"pandas": DataFrame output

"polars": Polars output

None: Transform configuration is unchanged

Added in version 1.4: "polars" option was added.

Set the parameters of this estimator.

The method works on simple estimators as well as on nested objects (such as Pipeline). The latter have parameters of the form <component>__<parameter> so that it’s possible to update each component of a nested object.

Estimator parameters.

Configure whether metadata should be requested to be passed to the score method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to score if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to score.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Added in version 1.3.

Metadata routing for sample_weight parameter in score.

Transform X to a cluster-distance space.

In the new space, each dimension is the distance to the cluster centers. Note that even if X is sparse, the array returned by transform will typically be dense.

New data to transform.

X transformed in the new space.

Bisecting K-Means and Regular K-Means Performance Comparison

Release Highlights for scikit-learn 1.1

**Examples:**

Example 1 (sql):
```sql
>>> from sklearn.cluster import BisectingKMeans
>>> import numpy as np
>>> X = np.array([[1, 1], [10, 1], [3, 1],
...               [10, 0], [2, 1], [10, 2],
...               [10, 8], [10, 9], [10, 10]])
>>> bisect_means = BisectingKMeans(n_clusters=3, random_state=0).fit(X)
>>> bisect_means.labels_
array([0, 2, 0, 2, 0, 2, 1, 1, 1], dtype=int32)
>>> bisect_means.predict([[0, 0], [12, 3]])
array([0, 2], dtype=int32)
>>> bisect_means.cluster_centers_
array([[ 2., 1.],
       [10., 9.],
       [10., 1.]])
```

---

## RadiusNeighborsClassifier#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.RadiusNeighborsClassifier.html

**Contents:**
- RadiusNeighborsClassifier#

Classifier implementing a vote among neighbors within a given radius.

Read more in the User Guide.

Range of parameter space to use by default for radius_neighbors queries.

Weight function used in prediction. Possible values:

‘uniform’ : uniform weights. All points in each neighborhood are weighted equally.

‘distance’ : weight points by the inverse of their distance. in this case, closer neighbors of a query point will have a greater influence than neighbors which are further away.

[callable] : a user-defined function which accepts an array of distances, and returns an array of the same shape containing the weights.

Uniform weights are used by default.

Algorithm used to compute the nearest neighbors:

‘ball_tree’ will use BallTree

‘kd_tree’ will use KDTree

‘brute’ will use a brute-force search.

‘auto’ will attempt to decide the most appropriate algorithm based on the values passed to fit method.

Note: fitting on sparse input will override the setting of this parameter, using brute force.

Leaf size passed to BallTree or KDTree. This can affect the speed of the construction and query, as well as the memory required to store the tree. The optimal value depends on the nature of the problem.

Power parameter for the Minkowski metric. When p = 1, this is equivalent to using manhattan_distance (l1), and euclidean_distance (l2) for p = 2. For arbitrary p, minkowski_distance (l_p) is used. This parameter is expected to be positive.

Metric to use for distance computation. Default is “minkowski”, which results in the standard Euclidean distance when p = 2. See the documentation of scipy.spatial.distance and the metrics listed in distance_metrics for valid metric values.

If metric is “precomputed”, X is assumed to be a distance matrix and must be square during fit. X may be a sparse graph, in which case only “nonzero” elements may be considered neighbors.

If metric is a callable function, it takes two arrays representing 1D vectors as inputs and must return one value indicating the distance between those vectors. This works for Scipy’s metrics, but is less efficient than passing the metric name as a string.

Label for outlier samples (samples with no neighbors in given radius).

manual label: str or int label (should be the same type as y) or list of manual labels if multi-output is used.

‘most_frequent’ : assign the most frequent label of y to outliers.

None : when any outlier is detected, ValueError will be raised.

The outlier label should be selected from among the unique ‘Y’ labels. If it is specified with a different value a warning will be raised and all class probabilities of outliers will be assigned to be 0.

Additional keyword arguments for the metric function.

The number of parallel jobs to run for neighbors search. None means 1 unless in a joblib.parallel_backend context. -1 means using all processors. See Glossary for more details.

Class labels known to the classifier.

The distance metric used. It will be same as the metric parameter or a synonym of it, e.g. ‘euclidean’ if the metric parameter set to ‘minkowski’ and p parameter set to 2.

Additional keyword arguments for the metric function. For most metrics will be same with metric_params parameter, but may also contain the p parameter value if the effective_metric_ attribute is set to ‘minkowski’.

Number of features seen during fit.

Added in version 0.24.

Names of features seen during fit. Defined only when X has feature names that are all strings.

Added in version 1.0.

Number of samples in the fitted data.

Label which is given for outlier samples (samples with no neighbors on given radius).

False when y’s shape is (n_samples, ) or (n_samples, 1) during fit otherwise True.

Classifier implementing the k-nearest neighbors vote.

Regression based on neighbors within a fixed radius.

Regression based on k-nearest neighbors.

Unsupervised learner for implementing neighbor searches.

See Nearest Neighbors in the online documentation for a discussion of the choice of algorithm and leaf_size.

https://en.wikipedia.org/wiki/K-nearest_neighbor_algorithm

Fit the radius neighbors classifier from the training dataset.

The fitted radius neighbors classifier.

Get metadata routing of this object.

Please check User Guide on how the routing mechanism works.

A MetadataRequest encapsulating routing information.

Get parameters for this estimator.

If True, will return the parameters for this estimator and contained subobjects that are estimators.

Parameter names mapped to their values.

Predict the class labels for the provided data.

Test samples. If None, predictions for all indexed points are returned; in this case, points are not considered their own neighbors.

Class labels for each data sample.

Return probability estimates for the test data X.

Test samples. If None, predictions for all indexed points are returned; in this case, points are not considered their own neighbors.

The class probabilities of the input samples. Classes are ordered by lexicographic order.

Find the neighbors within a given radius of a point or points.

Return the indices and distances of each point from the dataset lying in a ball with size radius around the points of the query array. Points lying on the boundary are included in the results.

The result points are not necessarily sorted by distance to their query point.

The query point or points. If not provided, neighbors of each indexed point are returned. In this case, the query point is not considered its own neighbor.

Limiting distance of neighbors to return. The default is the value passed to the constructor.

Whether or not to return the distances.

If True, the distances and indices will be sorted by increasing distances before being returned. If False, the results may not be sorted. If return_distance=False, setting sort_results=True will result in an error.

Added in version 0.22.

Array representing the distances to each point, only present if return_distance=True. The distance values are computed according to the metric constructor parameter.

An array of arrays of indices of the approximate nearest points from the population matrix that lie within a ball of size radius around the query points.

Because the number of neighbors of each point is not necessarily equal, the results for multiple query points cannot be fit in a standard data array. For efficiency, radius_neighbors returns arrays of objects, where each object is a 1D array of indices or distances.

In the following example, we construct a NeighborsClassifier class from an array representing our data set and ask who’s the closest point to [1, 1, 1]:

The first array returned contains the distances to all points which are closer than 1.6, while the second array returned contains their indices. In general, multiple points can be queried at the same time.

Compute the (weighted) graph of Neighbors for points in X.

Neighborhoods are restricted the points at a distance lower than radius.

The query point or points. If not provided, neighbors of each indexed point are returned. In this case, the query point is not considered its own neighbor.

Radius of neighborhoods. The default is the value passed to the constructor.

Type of returned matrix: ‘connectivity’ will return the connectivity matrix with ones and zeros, in ‘distance’ the edges are distances between points, type of distance depends on the selected metric parameter in NearestNeighbors class.

If True, in each row of the result, the non-zero entries will be sorted by increasing distances. If False, the non-zero entries may not be sorted. Only used with mode=’distance’.

Added in version 0.22.

n_samples_fit is the number of samples in the fitted data. A[i, j] gives the weight of the edge connecting i to j. The matrix is of CSR format.

Compute the (weighted) graph of k-Neighbors for points in X.

Return the mean accuracy on the given test data and labels.

In multi-label classification, this is the subset accuracy which is a harsh metric since you require for each sample that each label set be correctly predicted.

Test samples. If None, predictions for all indexed points are used; in this case, points are not considered their own neighbors. This means that knn.fit(X, y).score(None, y) implicitly performs a leave-one-out cross-validation procedure and is equivalent to cross_val_score(knn, X, y, cv=LeaveOneOut()) but typically much faster.

Mean accuracy of self.predict(X) w.r.t. y.

Set the parameters of this estimator.

The method works on simple estimators as well as on nested objects (such as Pipeline). The latter have parameters of the form <component>__<parameter> so that it’s possible to update each component of a nested object.

Estimator parameters.

Configure whether metadata should be requested to be passed to the score method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to score if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to score.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Added in version 1.3.

Metadata routing for sample_weight parameter in score.

**Examples:**

Example 1 (python):
```python
>>> X = [[0], [1], [2], [3]]
>>> y = [0, 0, 1, 1]
>>> from sklearn.neighbors import RadiusNeighborsClassifier
>>> neigh = RadiusNeighborsClassifier(radius=1.0)
>>> neigh.fit(X, y)
RadiusNeighborsClassifier(...)
>>> print(neigh.predict([[1.5]]))
[0]
>>> print(neigh.predict_proba([[1.0]]))
[[0.66666667 0.33333333]]
```

Example 2 (python):
```python
>>> import numpy as np
>>> samples = [[0., 0., 0.], [0., .5, 0.], [1., 1., .5]]
>>> from sklearn.neighbors import NearestNeighbors
>>> neigh = NearestNeighbors(radius=1.6)
>>> neigh.fit(samples)
NearestNeighbors(radius=1.6)
>>> rng = neigh.radius_neighbors([[1., 1., 1.]])
>>> print(np.asarray(rng[0][0]))
[1.5 0.5]
>>> print(np.asarray(rng[1][0]))
[1 2]
```

Example 3 (sql):
```sql
>>> X = [[0], [3], [1]]
>>> from sklearn.neighbors import NearestNeighbors
>>> neigh = NearestNeighbors(radius=1.5)
>>> neigh.fit(X)
NearestNeighbors(radius=1.5)
>>> A = neigh.radius_neighbors_graph(X)
>>> A.toarray()
array([[1., 0., 1.],
       [0., 1., 0.],
       [1., 0., 1.]])
```

---

## OneHotEncoder#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html

**Contents:**
- OneHotEncoder#
- Gallery examples#

Encode categorical features as a one-hot numeric array.

The input to this transformer should be an array-like of integers or strings, denoting the values taken on by categorical (discrete) features. The features are encoded using a one-hot (aka ‘one-of-K’ or ‘dummy’) encoding scheme. This creates a binary column for each category and returns a sparse matrix or dense array (depending on the sparse_output parameter).

By default, the encoder derives the categories based on the unique values in each feature. Alternatively, you can also specify the categories manually.

This encoding is needed for feeding categorical data to many scikit-learn estimators, notably linear models and SVMs with the standard kernels.

Note: a one-hot encoding of y labels should use a LabelBinarizer instead.

Read more in the User Guide. For a comparison of different encoders, refer to: Comparing Target Encoder with Other Encoders.

Categories (unique values) per feature:

‘auto’ : Determine categories automatically from the training data.

list : categories[i] holds the categories expected in the ith column. The passed categories should not mix strings and numeric values within a single feature, and should be sorted in case of numeric values.

The used categories can be found in the categories_ attribute.

Added in version 0.20.

Specifies a methodology to use to drop one of the categories per feature. This is useful in situations where perfectly collinear features cause problems, such as when feeding the resulting data into an unregularized linear regression model.

However, dropping one category breaks the symmetry of the original representation and can therefore induce a bias in downstream models, for instance for penalized linear classification or regression models.

None : retain all features (the default).

‘first’ : drop the first category in each feature. If only one category is present, the feature will be dropped entirely.

‘if_binary’ : drop the first category in each feature with two categories. Features with 1 or more than 2 categories are left intact.

array : drop[i] is the category in feature X[:, i] that should be dropped.

When max_categories or min_frequency is configured to group infrequent categories, the dropping behavior is handled after the grouping.

Added in version 0.21: The parameter drop was added in 0.21.

Changed in version 0.23: The option drop='if_binary' was added in 0.23.

Changed in version 1.1: Support for dropping infrequent categories.

When True, it returns a scipy.sparse.csr_matrix, i.e. a sparse matrix in “Compressed Sparse Row” (CSR) format.

Added in version 1.2: sparse was renamed to sparse_output

Desired dtype of output.

Specifies the way unknown categories are handled during transform.

‘error’ : Raise an error if an unknown category is present during transform.

‘ignore’ : When an unknown category is encountered during transform, the resulting one-hot encoded columns for this feature will be all zeros. In the inverse transform, an unknown category will be denoted as None.

‘infrequent_if_exist’ : When an unknown category is encountered during transform, the resulting one-hot encoded columns for this feature will map to the infrequent category if it exists. The infrequent category will be mapped to the last position in the encoding. During inverse transform, an unknown category will be mapped to the category denoted 'infrequent' if it exists. If the 'infrequent' category does not exist, then transform and inverse_transform will handle an unknown category as with handle_unknown='ignore'. Infrequent categories exist based on min_frequency and max_categories. Read more in the User Guide.

‘warn’ : When an unknown category is encountered during transform a warning is issued, and the encoding then proceeds as described for handle_unknown="infrequent_if_exist".

Changed in version 1.1: 'infrequent_if_exist' was added to automatically handle unknown categories and infrequent categories.

Added in version 1.6: The option "warn" was added in 1.6.

Specifies the minimum frequency below which a category will be considered infrequent.

If int, categories with a smaller cardinality will be considered infrequent.

If float, categories with a smaller cardinality than min_frequency * n_samples will be considered infrequent.

Added in version 1.1: Read more in the User Guide.

Specifies an upper limit to the number of output features for each input feature when considering infrequent categories. If there are infrequent categories, max_categories includes the category representing the infrequent categories along with the frequent categories. If None, there is no limit to the number of output features.

Added in version 1.1: Read more in the User Guide.

Callable with signature def callable(input_feature, category) that returns a string. This is used to create feature names to be returned by get_feature_names_out.

"concat" concatenates encoded feature name and category with feature + "_" + str(category).E.g. feature X with values 1, 6, 7 create feature names X_1, X_6, X_7.

Added in version 1.3.

The categories of each feature determined during fitting (in order of the features in X and corresponding with the output of transform). This includes the category specified in drop (if any).

drop_idx_[i] is the index in categories_[i] of the category to be dropped for each feature.

drop_idx_[i] = None if no category is to be dropped from the feature with index i, e.g. when drop='if_binary' and the feature isn’t binary.

drop_idx_ = None if all the transformed features will be retained.

If infrequent categories are enabled by setting min_frequency or max_categories to a non-default value and drop_idx[i] corresponds to an infrequent category, then the entire infrequent category is dropped.

Changed in version 0.23: Added the possibility to contain None values.

Infrequent categories for each feature.

Number of features seen during fit.

Added in version 1.0.

Names of features seen during fit. Defined only when X has feature names that are all strings.

Added in version 1.0.

Callable with signature def callable(input_feature, category) that returns a string. This is used to create feature names to be returned by get_feature_names_out.

Added in version 1.3.

Performs an ordinal (integer) encoding of the categorical features.

Encodes categorical features using the target.

Performs a one-hot encoding of dictionary items (also handles string-valued features).

Performs an approximate one-hot encoding of dictionary items or strings.

Binarizes labels in a one-vs-all fashion.

Transforms between iterable of iterables and a multilabel format, e.g. a (samples x classes) binary matrix indicating the presence of a class label.

Given a dataset with two features, we let the encoder find the unique values per feature and transform the data to a binary one-hot encoding.

One can discard categories not seen during fit:

One can always drop the first column for each feature:

Or drop a column for feature only having 2 categories:

One can change the way feature names are created.

Infrequent categories are enabled by setting max_categories or min_frequency.

Fit OneHotEncoder to X.

The data to determine the categories of each feature.

Ignored. This parameter exists only for compatibility with Pipeline.

Fit to data, then transform it.

Fits transformer to X and y with optional parameters fit_params and returns a transformed version of X.

Target values (None for unsupervised transformations).

Additional fit parameters. Pass only if the estimator accepts additional params in its fit method.

Get output feature names for transformation.

If input_features is None, then feature_names_in_ is used as feature names in. If feature_names_in_ is not defined, then the following input feature names are generated: ["x0", "x1", ..., "x(n_features_in_ - 1)"].

If input_features is an array-like, then input_features must match feature_names_in_ if feature_names_in_ is defined.

Transformed feature names.

Get metadata routing of this object.

Please check User Guide on how the routing mechanism works.

A MetadataRequest encapsulating routing information.

Get parameters for this estimator.

If True, will return the parameters for this estimator and contained subobjects that are estimators.

Parameter names mapped to their values.

Convert the data back to the original representation.

When unknown categories are encountered (all zeros in the one-hot encoding), None is used to represent this category. If the feature with the unknown category has a dropped category, the dropped category will be its inverse.

For a given input feature, if there is an infrequent category, ‘infrequent_sklearn’ will be used to represent the infrequent category.

The transformed data.

Inverse transformed array.

Set output container.

See Introducing the set_output API for an example on how to use the API.

Configure output of transform and fit_transform.

"default": Default output format of a transformer

"pandas": DataFrame output

"polars": Polars output

None: Transform configuration is unchanged

Added in version 1.4: "polars" option was added.

Set the parameters of this estimator.

The method works on simple estimators as well as on nested objects (such as Pipeline). The latter have parameters of the form <component>__<parameter> so that it’s possible to update each component of a nested object.

Estimator parameters.

Transform X using one-hot encoding.

If sparse_output=True (default), it returns an instance of scipy.sparse._csr.csr_matrix (CSR format).

If there are infrequent categories for a feature, set by specifying max_categories or min_frequency, the infrequent categories are grouped into a single category.

Transformed input. If sparse_output=True, a sparse matrix will be returned.

Time-related feature engineering

Column Transformer with Mixed Types

Feature transformations with ensembles of trees

Categorical Feature Support in Gradient Boosting

Combine predictors using stacking

Common pitfalls in the interpretation of coefficients of linear models

Partial Dependence and Individual Conditional Expectation Plots

Poisson regression and non-normal loss

Tweedie regression on insurance claims

Displaying estimators and complex pipelines

Evaluation of outlier detection estimators

Introducing the set_output API

Comparing Target Encoder with Other Encoders

Release Highlights for scikit-learn 0.23

Release Highlights for scikit-learn 1.0

Release Highlights for scikit-learn 1.1

Release Highlights for scikit-learn 1.4

Release Highlights for scikit-learn 1.5

**Examples:**

Example 1 (sql):
```sql
>>> from sklearn.preprocessing import OneHotEncoder
```

Example 2 (csharp):
```csharp
>>> enc = OneHotEncoder(handle_unknown='ignore')
>>> X = [['Male', 1], ['Female', 3], ['Female', 2]]
>>> enc.fit(X)
OneHotEncoder(handle_unknown='ignore')
>>> enc.categories_
[array(['Female', 'Male'], dtype=object), array([1, 2, 3], dtype=object)]
>>> enc.transform([['Female', 1], ['Male', 4]]).toarray()
array([[1., 0., 1., 0., 0.],
       [0., 1., 0., 0., 0.]])
>>> enc.inverse_transform([[0, 1, 1, 0, 0], [0, 0, 0, 1, 0]])
array([['Male', 1],
       [None, 2]], dtype=object)
>>> enc.get_feature_names_out(['gender', 'group'])
array(['gender_Female', 'gender_Male', 'group_1', 'group_2', 'group_3'], ...)
```

Example 3 (csharp):
```csharp
>>> drop_enc = OneHotEncoder(drop='first').fit(X)
>>> drop_enc.categories_
[array(['Female', 'Male'], dtype=object), array([1, 2, 3], dtype=object)]
>>> drop_enc.transform([['Female', 1], ['Male', 2]]).toarray()
array([[0., 0., 0.],
       [1., 1., 0.]])
```

Example 4 (csharp):
```csharp
>>> drop_binary_enc = OneHotEncoder(drop='if_binary').fit(X)
>>> drop_binary_enc.transform([['Female', 1], ['Male', 2]]).toarray()
array([[0., 1., 0., 0.],
       [1., 0., 1., 0.]])
```

---

## TfidfVectorizer#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html

**Contents:**
- TfidfVectorizer#
- Gallery examples#

Convert a collection of raw documents to a matrix of TF-IDF features.

Equivalent to CountVectorizer followed by TfidfTransformer.

Read more in the User Guide.

If 'filename', the sequence passed as an argument to fit is expected to be a list of filenames that need reading to fetch the raw content to analyze.

If 'file', the sequence items must have a ‘read’ method (file-like object) that is called to fetch the bytes in memory.

If 'content', the input is expected to be a sequence of items that can be of type string or byte.

If bytes or files are given to analyze, this encoding is used to decode.

Instruction on what to do if a byte sequence is given to analyze that contains characters not of the given encoding. By default, it is ‘strict’, meaning that a UnicodeDecodeError will be raised. Other values are ‘ignore’ and ‘replace’.

Remove accents and perform other character normalization during the preprocessing step. ‘ascii’ is a fast method that only works on characters that have a direct ASCII mapping. ‘unicode’ is a slightly slower method that works on any characters. None (default) means no character normalization is performed.

Both ‘ascii’ and ‘unicode’ use NFKD normalization from unicodedata.normalize.

Convert all characters to lowercase before tokenizing.

Override the preprocessing (string transformation) stage while preserving the tokenizing and n-grams generation steps. Only applies if analyzer is not callable.

Override the string tokenization step while preserving the preprocessing and n-grams generation steps. Only applies if analyzer == 'word'.

Whether the feature should be made of word or character n-grams. Option ‘char_wb’ creates character n-grams only from text inside word boundaries; n-grams at the edges of words are padded with space.

If a callable is passed it is used to extract the sequence of features out of the raw, unprocessed input.

Changed in version 0.21: Since v0.21, if input is 'filename' or 'file', the data is first read from the file and then passed to the given callable analyzer.

If a string, it is passed to _check_stop_list and the appropriate stop list is returned. ‘english’ is currently the only supported string value. There are several known issues with ‘english’ and you should consider an alternative (see Using stop words).

If a list, that list is assumed to contain stop words, all of which will be removed from the resulting tokens. Only applies if analyzer == 'word'.

If None, no stop words will be used. In this case, setting max_df to a higher value, such as in the range (0.7, 1.0), can automatically detect and filter stop words based on intra corpus document frequency of terms.

Regular expression denoting what constitutes a “token”, only used if analyzer == 'word'. The default regexp selects tokens of 2 or more alphanumeric characters (punctuation is completely ignored and always treated as a token separator).

If there is a capturing group in token_pattern then the captured group content, not the entire match, becomes the token. At most one capturing group is permitted.

The lower and upper boundary of the range of n-values for different n-grams to be extracted. All values of n such that min_n <= n <= max_n will be used. For example an ngram_range of (1, 1) means only unigrams, (1, 2) means unigrams and bigrams, and (2, 2) means only bigrams. Only applies if analyzer is not callable.

When building the vocabulary ignore terms that have a document frequency strictly higher than the given threshold (corpus-specific stop words). If float in range [0.0, 1.0], the parameter represents a proportion of documents, integer absolute counts. This parameter is ignored if vocabulary is not None.

When building the vocabulary ignore terms that have a document frequency strictly lower than the given threshold. This value is also called cut-off in the literature. If float in range of [0.0, 1.0], the parameter represents a proportion of documents, integer absolute counts. This parameter is ignored if vocabulary is not None.

If not None, build a vocabulary that only consider the top max_features ordered by term frequency across the corpus. Otherwise, all features are used.

This parameter is ignored if vocabulary is not None.

Either a Mapping (e.g., a dict) where keys are terms and values are indices in the feature matrix, or an iterable over terms. If not given, a vocabulary is determined from the input documents.

If True, all non-zero term counts are set to 1. This does not mean outputs will have only 0/1 values, only that the tf term in tf-idf is binary. (Set binary to True, use_idf to False and norm to None to get 0/1 outputs).

Type of the matrix returned by fit_transform() or transform().

Each output row will have unit norm, either:

‘l2’: Sum of squares of vector elements is 1. The cosine similarity between two vectors is their dot product when l2 norm has been applied.

‘l1’: Sum of absolute values of vector elements is 1. See normalize.

None: No normalization.

Enable inverse-document-frequency reweighting. If False, idf(t) = 1.

Smooth idf weights by adding one to document frequencies, as if an extra document was seen containing every term in the collection exactly once. Prevents zero divisions.

Apply sublinear tf scaling, i.e. replace tf with 1 + log(tf).

A mapping of terms to feature indices.

True if a fixed vocabulary of term to indices mapping is provided by the user.

Inverse document frequency vector, only defined if use_idf=True.

Transforms text into a sparse matrix of n-gram counts.

Performs the TF-IDF transformation from a provided matrix of counts.

Return a callable to process input data.

The callable handles preprocessing, tokenization, and n-grams generation.

A function to handle preprocessing, tokenization and n-grams generation.

Return a function to preprocess the text before tokenization.

A function to preprocess the text before tokenization.

Return a function that splits a string into a sequence of tokens.

A function to split a string into a sequence of tokens.

Decode the input into a string of unicode symbols.

The decoding strategy depends on the vectorizer parameters.

The string to decode.

A string of unicode symbols.

Learn vocabulary and idf from training set.

An iterable which generates either str, unicode or file objects.

This parameter is not needed to compute tfidf.

Learn vocabulary and idf, return document-term matrix.

This is equivalent to fit followed by transform, but more efficiently implemented.

An iterable which generates either str, unicode or file objects.

This parameter is ignored.

Tf-idf-weighted document-term matrix.

Get output feature names for transformation.

Not used, present here for API consistency by convention.

Transformed feature names.

Get metadata routing of this object.

Please check User Guide on how the routing mechanism works.

A MetadataRequest encapsulating routing information.

Get parameters for this estimator.

If True, will return the parameters for this estimator and contained subobjects that are estimators.

Parameter names mapped to their values.

Build or fetch the effective stop words list.

A list of stop words.

Return terms per document with nonzero entries in X.

Document-term matrix.

List of arrays of terms.

Set the parameters of this estimator.

The method works on simple estimators as well as on nested objects (such as Pipeline). The latter have parameters of the form <component>__<parameter> so that it’s possible to update each component of a nested object.

Estimator parameters.

Transform documents to document-term matrix.

Uses the vocabulary and document frequencies (df) learned by fit (or fit_transform).

An iterable which generates either str, unicode or file objects.

Tf-idf-weighted document-term matrix.

Topic extraction with Non-negative Matrix Factorization and Latent Dirichlet Allocation

Biclustering documents with the Spectral Co-clustering algorithm

Column Transformer with Heterogeneous Data Sources

Sample pipeline for text feature extraction and evaluation

Classification of text documents using sparse features

Clustering text documents using k-means

FeatureHasher and DictVectorizer Comparison

**Examples:**

Example 1 (python):
```python
>>> from sklearn.feature_extraction.text import TfidfVectorizer
>>> corpus = [
...     'This is the first document.',
...     'This document is the second document.',
...     'And this is the third one.',
...     'Is this the first document?',
... ]
>>> vectorizer = TfidfVectorizer()
>>> X = vectorizer.fit_transform(corpus)
>>> vectorizer.get_feature_names_out()
array(['and', 'document', 'first', 'is', 'one', 'second', 'the', 'third',
       'this'], ...)
>>> print(X.shape)
(4, 9)
```

---

## homogeneity_completeness_v_measure#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.metrics.homogeneity_completeness_v_measure.html

**Contents:**
- homogeneity_completeness_v_measure#

Compute the homogeneity and completeness and V-Measure scores at once.

Those metrics are based on normalized conditional entropy measures of the clustering labeling to evaluate given the knowledge of a Ground Truth class labels of the same samples.

A clustering result satisfies homogeneity if all of its clusters contain only data points which are members of a single class.

A clustering result satisfies completeness if all the data points that are members of a given class are elements of the same cluster.

Both scores have positive values between 0.0 and 1.0, larger values being desirable.

Those 3 metrics are independent of the absolute values of the labels: a permutation of the class or cluster label values won’t change the score values in any way.

V-Measure is furthermore symmetric: swapping labels_true and label_pred will give the same score. This does not hold for homogeneity and completeness. V-Measure is identical to normalized_mutual_info_score with the arithmetic averaging method.

Read more in the User Guide.

Ground truth class labels to be used as a reference.

Cluster labels to evaluate.

Ratio of weight attributed to homogeneity vs completeness. If beta is greater than 1, completeness is weighted more strongly in the calculation. If beta is less than 1, homogeneity is weighted more strongly.

Score between 0.0 and 1.0. 1.0 stands for perfectly homogeneous labeling.

Score between 0.0 and 1.0. 1.0 stands for perfectly complete labeling.

Harmonic mean of the first two.

Homogeneity metric of cluster labeling.

Completeness metric of cluster labeling.

V-Measure (NMI with arithmetic mean option).

**Examples:**

Example 1 (sql):
```sql
>>> from sklearn.metrics import homogeneity_completeness_v_measure
>>> y_true, y_pred = [0, 0, 1, 1, 2, 2], [0, 0, 1, 2, 2, 2]
>>> homogeneity_completeness_v_measure(y_true, y_pred)
(0.71, 0.771, 0.74)
```

---

## normalized_mutual_info_score#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.metrics.normalized_mutual_info_score.html

**Contents:**
- normalized_mutual_info_score#
- Gallery examples#

Normalized Mutual Information between two clusterings.

Normalized Mutual Information (NMI) is a normalization of the Mutual Information (MI) score to scale the results between 0 (no mutual information) and 1 (perfect correlation). In this function, mutual information is normalized by some generalized mean of H(labels_true) and H(labels_pred)), defined by the average_method.

This measure is not adjusted for chance. Therefore adjusted_mutual_info_score might be preferred.

This metric is independent of the absolute values of the labels: a permutation of the class or cluster label values won’t change the score value in any way.

This metric is furthermore symmetric: switching label_true with label_pred will return the same score value. This can be useful to measure the agreement of two independent label assignments strategies on the same dataset when the real ground truth is not known.

Read more in the User Guide.

A clustering of the data into disjoint subsets.

A clustering of the data into disjoint subsets.

How to compute the normalizer in the denominator.

Added in version 0.20.

Changed in version 0.22: The default value of average_method changed from ‘geometric’ to ‘arithmetic’.

Score between 0.0 and 1.0 in normalized nats (based on the natural logarithm). 1.0 stands for perfectly complete labeling.

V-Measure (NMI with arithmetic mean option).

Adjusted Mutual Information (adjusted against chance).

Perfect labelings are both homogeneous and complete, hence have score 1.0:

If classes members are completely split across different clusters, the assignment is totally in-complete, hence the NMI is null:

Adjustment for chance in clustering performance evaluation

**Examples:**

Example 1 (sql):
```sql
>>> from sklearn.metrics.cluster import normalized_mutual_info_score
>>> normalized_mutual_info_score([0, 0, 1, 1], [0, 0, 1, 1])
1.0
>>> normalized_mutual_info_score([0, 0, 1, 1], [1, 1, 0, 0])
1.0
```

Example 2 (unknown):
```unknown
>>> normalized_mutual_info_score([0, 0, 0, 0], [0, 1, 2, 3])
0.0
```

---

## KernelRidge#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.kernel_ridge.KernelRidge.html

**Contents:**
- KernelRidge#
- Gallery examples#

Kernel ridge regression.

Kernel ridge regression (KRR) combines ridge regression (linear least squares with l2-norm regularization) with the kernel trick. It thus learns a linear function in the space induced by the respective kernel and the data. For non-linear kernels, this corresponds to a non-linear function in the original space.

The form of the model learned by KRR is identical to support vector regression (SVR). However, different loss functions are used: KRR uses squared error loss while support vector regression uses epsilon-insensitive loss, both combined with l2 regularization. In contrast to SVR, fitting a KRR model can be done in closed-form and is typically faster for medium-sized datasets. On the other hand, the learned model is non-sparse and thus slower than SVR, which learns a sparse model for epsilon > 0, at prediction-time.

This estimator has built-in support for multi-variate regression (i.e., when y is a 2d-array of shape [n_samples, n_targets]).

Read more in the User Guide.

Regularization strength; must be a positive float. Regularization improves the conditioning of the problem and reduces the variance of the estimates. Larger values specify stronger regularization. Alpha corresponds to 1 / (2C) in other linear models such as LogisticRegression or LinearSVC. If an array is passed, penalties are assumed to be specific to the targets. Hence they must correspond in number. See Ridge regression and classification for formula.

Kernel mapping used internally. This parameter is directly passed to pairwise_kernels. If kernel is a string, it must be one of the metrics in pairwise.PAIRWISE_KERNEL_FUNCTIONS or “precomputed”. If kernel is “precomputed”, X is assumed to be a kernel matrix. Alternatively, if kernel is a callable function, it is called on each pair of instances (rows) and the resulting value recorded. The callable should take two rows from X as input and return the corresponding kernel value as a single number. This means that callables from sklearn.metrics.pairwise are not allowed, as they operate on matrices, not single samples. Use the string identifying the kernel instead.

Gamma parameter for the RBF, laplacian, polynomial, exponential chi2 and sigmoid kernels. Interpretation of the default value is left to the kernel; see the documentation for sklearn.metrics.pairwise. Ignored by other kernels.

Degree of the polynomial kernel. Ignored by other kernels.

Zero coefficient for polynomial and sigmoid kernels. Ignored by other kernels.

Additional parameters (keyword arguments) for kernel function passed as callable object.

Representation of weight vector(s) in kernel space

Training data, which is also required for prediction. If kernel == “precomputed” this is instead the precomputed training matrix, of shape (n_samples, n_samples).

Number of features seen during fit.

Added in version 0.24.

Names of features seen during fit. Defined only when X has feature names that are all strings.

Added in version 1.0.

Gaussian Process regressor providing automatic kernel hyperparameters tuning and predictions uncertainty.

Linear ridge regression.

Ridge regression with built-in cross-validation.

Support Vector Regression accepting a large variety of kernels.

Kevin P. Murphy “Machine Learning: A Probabilistic Perspective”, The MIT Press chapter 14.4.3, pp. 492-493

Fit Kernel Ridge regression model.

Training data. If kernel == “precomputed” this is instead a precomputed kernel matrix, of shape (n_samples, n_samples).

Individual weights for each sample, ignored if None is passed.

Returns the instance itself.

Get metadata routing of this object.

Please check User Guide on how the routing mechanism works.

A MetadataRequest encapsulating routing information.

Get parameters for this estimator.

If True, will return the parameters for this estimator and contained subobjects that are estimators.

Parameter names mapped to their values.

Predict using the kernel ridge model.

Samples. If kernel == “precomputed” this is instead a precomputed kernel matrix, shape = [n_samples, n_samples_fitted], where n_samples_fitted is the number of samples used in the fitting for this estimator.

Returns predicted values.

Return coefficient of determination on test data.

The coefficient of determination, \(R^2\), is defined as \((1 - \frac{u}{v})\), where \(u\) is the residual sum of squares ((y_true - y_pred)** 2).sum() and \(v\) is the total sum of squares ((y_true - y_true.mean()) ** 2).sum(). The best possible score is 1.0 and it can be negative (because the model can be arbitrarily worse). A constant model that always predicts the expected value of y, disregarding the input features, would get a \(R^2\) score of 0.0.

Test samples. For some estimators this may be a precomputed kernel matrix or a list of generic objects instead with shape (n_samples, n_samples_fitted), where n_samples_fitted is the number of samples used in the fitting for the estimator.

\(R^2\) of self.predict(X) w.r.t. y.

The \(R^2\) score used when calling score on a regressor uses multioutput='uniform_average' from version 0.23 to keep consistent with default value of r2_score. This influences the score method of all the multioutput regressors (except for MultiOutputRegressor).

Configure whether metadata should be requested to be passed to the fit method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to fit if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to fit.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Added in version 1.3.

Metadata routing for sample_weight parameter in fit.

Set the parameters of this estimator.

The method works on simple estimators as well as on nested objects (such as Pipeline). The latter have parameters of the form <component>__<parameter> so that it’s possible to update each component of a nested object.

Estimator parameters.

Configure whether metadata should be requested to be passed to the score method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to score if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to score.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Added in version 1.3.

Metadata routing for sample_weight parameter in score.

Comparison of kernel ridge and Gaussian process regression

Comparison of kernel ridge regression and SVR

**Examples:**

Example 1 (sql):
```sql
>>> from sklearn.kernel_ridge import KernelRidge
>>> import numpy as np
>>> n_samples, n_features = 10, 5
>>> rng = np.random.RandomState(0)
>>> y = rng.randn(n_samples)
>>> X = rng.randn(n_samples, n_features)
>>> krr = KernelRidge(alpha=1.0)
>>> krr.fit(X, y)
KernelRidge(alpha=1.0)
```

---

## SpectralBiclustering#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.cluster.SpectralBiclustering.html

**Contents:**
- SpectralBiclustering#
- Gallery examples#

Spectral biclustering (Kluger, 2003) [1].

Partitions rows and columns under the assumption that the data has an underlying checkerboard structure. For instance, if there are two row partitions and three column partitions, each row will belong to three biclusters, and each column will belong to two biclusters. The outer product of the corresponding row and column label vectors gives this checkerboard structure.

Read more in the User Guide.

The number of row and column clusters in the checkerboard structure.

Method of normalizing and converting singular vectors into biclusters. May be one of ‘scale’, ‘bistochastic’, or ‘log’. The authors recommend using ‘log’. If the data is sparse, however, log normalization will not work, which is why the default is ‘bistochastic’.

if method='log', the data must not be sparse.

Number of singular vectors to check.

Number of best singular vectors to which to project the data for clustering.

Selects the algorithm for finding singular vectors. May be ‘randomized’ or ‘arpack’. If ‘randomized’, uses randomized_svd, which may be faster for large matrices. If ‘arpack’, uses scipy.sparse.linalg.svds, which is more accurate, but possibly slower in some cases.

Number of vectors to use in calculating the SVD. Corresponds to ncv when svd_method=arpack and n_oversamples when svd_method is ‘randomized`.

Whether to use mini-batch k-means, which is faster but may get different results.

Method for initialization of k-means algorithm; defaults to ‘k-means++’.

Number of random initializations that are tried with the k-means algorithm.

If mini-batch k-means is used, the best initialization is chosen and the algorithm runs once. Otherwise, the algorithm is run for each initialization and the best solution chosen.

Used for randomizing the singular value decomposition and the k-means initialization. Use an int to make the randomness deterministic. See Glossary.

Results of the clustering. rows[i, r] is True if cluster i contains row r. Available only after calling fit.

Results of the clustering, like rows.

Row partition labels.

Column partition labels.

Convenient way to get row and column indicators together.

Number of features seen during fit.

Added in version 0.24.

Names of features seen during fit. Defined only when X has feature names that are all strings.

Added in version 1.0.

Clusters rows and columns of an array X to solve the relaxed normalized cut of the bipartite graph created from X.

Kluger, Yuval, et. al., 2003. Spectral biclustering of microarray data: coclustering genes and conditions.

For a more detailed example, see A demo of the Spectral Biclustering algorithm

Create a biclustering for X.

Not used, present for API consistency by convention.

SpectralBiclustering instance.

Row and column indices of the i’th bicluster.

Only works if rows_ and columns_ attributes exist.

The index of the cluster.

Indices of rows in the dataset that belong to the bicluster.

Indices of columns in the dataset that belong to the bicluster.

Get metadata routing of this object.

Please check User Guide on how the routing mechanism works.

A MetadataRequest encapsulating routing information.

Get parameters for this estimator.

If True, will return the parameters for this estimator and contained subobjects that are estimators.

Parameter names mapped to their values.

Shape of the i’th bicluster.

The index of the cluster.

Number of rows in the bicluster.

Number of columns in the bicluster.

Return the submatrix corresponding to bicluster i.

The index of the cluster.

The submatrix corresponding to bicluster i.

Works with sparse matrices. Only works if rows_ and columns_ attributes exist.

Set the parameters of this estimator.

The method works on simple estimators as well as on nested objects (such as Pipeline). The latter have parameters of the form <component>__<parameter> so that it’s possible to update each component of a nested object.

Estimator parameters.

A demo of the Spectral Biclustering algorithm

**Examples:**

Example 1 (sql):
```sql
>>> from sklearn.cluster import SpectralBiclustering
>>> import numpy as np
>>> X = np.array([[1, 1], [2, 1], [1, 0],
...               [4, 7], [3, 5], [3, 6]])
>>> clustering = SpectralBiclustering(n_clusters=2, random_state=0).fit(X)
>>> clustering.row_labels_
array([1, 1, 1, 0, 0, 0], dtype=int32)
>>> clustering.column_labels_
array([1, 0], dtype=int32)
>>> clustering
SpectralBiclustering(n_clusters=2, random_state=0)
```

---

## 3.3. Tuning the decision threshold for class prediction#

**URL:** https://scikit-learn.org/stable/modules/classification_threshold.html

**Contents:**
- 3.3. Tuning the decision threshold for class prediction#
- 3.3.1. Post-tuning the decision threshold#
  - 3.3.1.1. Options to tune the decision threshold#
  - 3.3.1.2. Important notes regarding the internal cross-validation#
  - 3.3.1.3. Manually setting the decision threshold#
  - 3.3.1.4. Examples#

Classification is best divided into two parts:

the statistical problem of learning a model to predict, ideally, class probabilities;

the decision problem to take concrete action based on those probability predictions.

Let’s take a straightforward example related to weather forecasting: the first point is related to answering “what is the chance that it will rain tomorrow?” while the second point is related to answering “should I take an umbrella tomorrow?”.

When it comes to the scikit-learn API, the first point is addressed by providing scores using predict_proba or decision_function. The former returns conditional probability estimates \(P(y|X)\) for each class, while the latter returns a decision score for each class.

The decision corresponding to the labels is obtained with predict. In binary classification, a decision rule or action is then defined by thresholding the scores, leading to the prediction of a single class label for each sample. For binary classification in scikit-learn, class labels predictions are obtained by hard-coded cut-off rules: a positive class is predicted when the conditional probability \(P(y|X)\) is greater than 0.5 (obtained with predict_proba) or if the decision score is greater than 0 (obtained with decision_function).

Here, we show an example that illustrates the relatonship between conditional probability estimates \(P(y|X)\) and class labels:

While these hard-coded rules might at first seem reasonable as default behavior, they are most certainly not ideal for most use cases. Let’s illustrate with an example.

Consider a scenario where a predictive model is being deployed to assist physicians in detecting tumors. In this setting, physicians will most likely be interested in identifying all patients with cancer and not missing anyone with cancer so that they can provide them with the right treatment. In other words, physicians prioritize achieving a high recall rate. This emphasis on recall comes, of course, with the trade-off of potentially more false-positive predictions, reducing the precision of the model. That is a risk physicians are willing to take because the cost of a missed cancer is much higher than the cost of further diagnostic tests. Consequently, when it comes to deciding whether to classify a patient as having cancer or not, it may be more beneficial to classify them as positive for cancer when the conditional probability estimate is much lower than 0.5.

One solution to address the problem stated in the introduction is to tune the decision threshold of the classifier once the model has been trained. The TunedThresholdClassifierCV tunes this threshold using an internal cross-validation. The optimum threshold is chosen to maximize a given metric.

The following image illustrates the tuning of the decision threshold for a gradient boosting classifier. While the vanilla and tuned classifiers provide the same predict_proba outputs and thus the same Receiver Operating Characteristic (ROC) and Precision-Recall curves, the class label predictions differ because of the tuned decision threshold. The vanilla classifier predicts the class of interest for a conditional probability greater than 0.5 while the tuned classifier predicts the class of interest for a very low probability (around 0.02). This decision threshold optimizes a utility metric defined by the business (in this case an insurance company).

The decision threshold can be tuned through different strategies controlled by the parameter scoring.

One way to tune the threshold is by maximizing a pre-defined scikit-learn metric. These metrics can be found by calling the function get_scorer_names. By default, the balanced accuracy is the metric used but be aware that one should choose a meaningful metric for their use case.

It is important to notice that these metrics come with default parameters, notably the label of the class of interest (i.e. pos_label). Thus, if this label is not the right one for your application, you need to define a scorer and pass the right pos_label (and additional parameters) using the make_scorer. Refer to Callable scorers to get information to define your own scoring function. For instance, we show how to pass the information to the scorer that the label of interest is 0 when maximizing the f1_score:

By default TunedThresholdClassifierCV uses a 5-fold stratified cross-validation to tune the decision threshold. The parameter cv allows to control the cross-validation strategy. It is possible to bypass cross-validation by setting cv="prefit" and providing a fitted classifier. In this case, the decision threshold is tuned on the data provided to the fit method.

However, you should be extremely careful when using this option. You should never use the same data for training the classifier and tuning the decision threshold due to the risk of overfitting. Refer to the following example section for more details (cf. Consideration regarding model refitting and cross-validation). If you have limited resources, consider using a float number for cv to limit to an internal single train-test split.

The option cv="prefit" should only be used when the provided classifier was already trained, and you just want to find the best decision threshold using a new validation set.

The previous sections discussed strategies to find an optimal decision threshold. It is also possible to manually set the decision threshold using the class FixedThresholdClassifier. In case that you don’t want to refit the model when calling fit, wrap your sub-estimator with a FrozenEstimator and do FixedThresholdClassifier(FrozenEstimator(estimator), ...).

See the example entitled Post-hoc tuning the cut-off point of decision function, to get insights on the post-tuning of the decision threshold.

See the example entitled Post-tuning the decision threshold for cost-sensitive learning, to learn about cost-sensitive learning and decision threshold tuning.

**Examples:**

Example 1 (json):
```json
>>> from sklearn.datasets import make_classification
>>> from sklearn.tree import DecisionTreeClassifier
>>> X, y = make_classification(random_state=0)
>>> classifier = DecisionTreeClassifier(max_depth=2, random_state=0).fit(X, y)
>>> classifier.predict_proba(X[:4])
array([[0.94     , 0.06     ],
       [0.94     , 0.06     ],
       [0.0416, 0.9583],
       [0.0416, 0.9583]])
>>> classifier.predict(X[:4])
array([0, 0, 1, 1])
```

Example 2 (sql):
```sql
>>> from sklearn.linear_model import LogisticRegression
>>> from sklearn.model_selection import TunedThresholdClassifierCV
>>> from sklearn.metrics import make_scorer, f1_score
>>> X, y = make_classification(
...   n_samples=1_000, weights=[0.1, 0.9], random_state=0)
>>> pos_label = 0
>>> scorer = make_scorer(f1_score, pos_label=pos_label)
>>> base_model = LogisticRegression()
>>> model = TunedThresholdClassifierCV(base_model, scoring=scorer)
>>> scorer(model.fit(X, y), X, y)
0.88
>>> # compare it with the internal score found by cross-validation
>>> model.best_score_
np.float64(0.86)
```

---

## TruncatedSVD#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.TruncatedSVD.html

**Contents:**
- TruncatedSVD#
- Gallery examples#

Dimensionality reduction using truncated SVD (aka LSA).

This transformer performs linear dimensionality reduction by means of truncated singular value decomposition (SVD). Contrary to PCA, this estimator does not center the data before computing the singular value decomposition. This means it can work with sparse matrices efficiently.

In particular, truncated SVD works on term count/tf-idf matrices as returned by the vectorizers in sklearn.feature_extraction.text. In that context, it is known as latent semantic analysis (LSA).

This estimator supports two algorithms: a fast randomized SVD solver, and a “naive” algorithm that uses ARPACK as an eigensolver on X * X.T or X.T * X, whichever is more efficient.

Read more in the User Guide.

Desired dimensionality of output data. If algorithm=’arpack’, must be strictly less than the number of features. If algorithm=’randomized’, must be less than or equal to the number of features. The default value is useful for visualisation. For LSA, a value of 100 is recommended.

SVD solver to use. Either “arpack” for the ARPACK wrapper in SciPy (scipy.sparse.linalg.svds), or “randomized” for the randomized algorithm due to Halko (2009).

Number of iterations for randomized SVD solver. Not used by ARPACK. The default is larger than the default in randomized_svd to handle sparse matrices that may have large slowly decaying spectrum.

Number of oversamples for randomized SVD solver. Not used by ARPACK. See randomized_svd for a complete description.

Added in version 1.1.

Power iteration normalizer for randomized SVD solver. Not used by ARPACK. See randomized_svd for more details.

Added in version 1.1.

Used during randomized svd. Pass an int for reproducible results across multiple function calls. See Glossary.

Tolerance for ARPACK. 0 means machine precision. Ignored by randomized SVD solver.

The right singular vectors of the input data.

The variance of the training samples transformed by a projection to each component.

Percentage of variance explained by each of the selected components.

The singular values corresponding to each of the selected components. The singular values are equal to the 2-norms of the n_components variables in the lower-dimensional space.

Number of features seen during fit.

Added in version 0.24.

Names of features seen during fit. Defined only when X has feature names that are all strings.

Added in version 1.0.

Find a dictionary that sparsely encodes data.

A simple linear generative model with Gaussian latent variables.

Incremental principal components analysis.

Kernel Principal component analysis.

Non-Negative Matrix Factorization.

Principal component analysis.

SVD suffers from a problem called “sign indeterminacy”, which means the sign of the components_ and the output from transform depend on the algorithm and random state. To work around this, fit instances of this class to data once, then keep the instance around to do transformations.

Halko, et al. (2009). “Finding structure with randomness: Stochastic algorithms for constructing approximate matrix decompositions”

Fit model on training data X.

Not used, present here for API consistency by convention.

Returns the transformer object.

Fit model to X and perform dimensionality reduction on X.

Not used, present here for API consistency by convention.

Reduced version of X. This will always be a dense array.

Get output feature names for transformation.

The feature names out will prefixed by the lowercased class name. For example, if the transformer outputs 3 features, then the feature names out are: ["class_name0", "class_name1", "class_name2"].

Only used to validate feature names with the names seen in fit.

Transformed feature names.

Get metadata routing of this object.

Please check User Guide on how the routing mechanism works.

A MetadataRequest encapsulating routing information.

Get parameters for this estimator.

If True, will return the parameters for this estimator and contained subobjects that are estimators.

Parameter names mapped to their values.

Transform X back to its original space.

Returns an array X_original whose transform would be X.

Note that this is always a dense array.

Set output container.

See Introducing the set_output API for an example on how to use the API.

Configure output of transform and fit_transform.

"default": Default output format of a transformer

"pandas": DataFrame output

"polars": Polars output

None: Transform configuration is unchanged

Added in version 1.4: "polars" option was added.

Set the parameters of this estimator.

The method works on simple estimators as well as on nested objects (such as Pipeline). The latter have parameters of the form <component>__<parameter> so that it’s possible to update each component of a nested object.

Estimator parameters.

Perform dimensionality reduction on X.

Reduced version of X. This will always be a dense array.

Hashing feature transformation using Totally Random Trees

Manifold learning on handwritten digits: Locally Linear Embedding, Isomap…

Clustering text documents using k-means

**Examples:**

Example 1 (python):
```python
>>> from sklearn.decomposition import TruncatedSVD
>>> from scipy.sparse import csr_matrix
>>> import numpy as np
>>> np.random.seed(0)
>>> X_dense = np.random.rand(100, 100)
>>> X_dense[:, 2 * np.arange(50)] = 0
>>> X = csr_matrix(X_dense)
>>> svd = TruncatedSVD(n_components=5, n_iter=7, random_state=42)
>>> svd.fit(X)
TruncatedSVD(n_components=5, n_iter=7, random_state=42)
>>> print(svd.explained_variance_ratio_)
[0.0157 0.0512 0.0499 0.0479 0.0453]
>>> print(svd.explained_variance_ratio_.sum())
0.2102
>>> print(svd.singular_values_)
[35.2410  4.5981   4.5420  4.4486  4.3288]
```

---

## LassoLars#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LassoLars.html

**Contents:**
- LassoLars#

Lasso model fit with Least Angle Regression a.k.a. Lars.

It is a Linear Model trained with an L1 prior as regularizer.

The optimization objective for Lasso is:

Read more in the User Guide.

Constant that multiplies the penalty term. Defaults to 1.0. alpha = 0 is equivalent to an ordinary least square, solved by LinearRegression. For numerical reasons, using alpha = 0 with the LassoLars object is not advised and you should prefer the LinearRegression object.

Whether to calculate the intercept for this model. If set to false, no intercept will be used in calculations (i.e. data is expected to be centered).

Sets the verbosity amount.

Whether to use a precomputed Gram matrix to speed up calculations. If set to 'auto' let us decide. The Gram matrix can also be passed as argument.

Maximum number of iterations to perform.

The machine-precision regularization in the computation of the Cholesky diagonal factors. Increase this for very ill-conditioned systems. Unlike the tol parameter in some iterative optimization-based algorithms, this parameter does not control the tolerance of the optimization.

If True, X will be copied; else, it may be overwritten.

If True the full path is stored in the coef_path_ attribute. If you compute the solution for a large problem or many targets, setting fit_path to False will lead to a speedup, especially with a small alpha.

Restrict coefficients to be >= 0. Be aware that you might want to remove fit_intercept which is set True by default. Under the positive restriction the model coefficients will not converge to the ordinary-least-squares solution for small values of alpha. Only coefficients up to the smallest alpha value (alphas_[alphas_ > 0.].min() when fit_path=True) reached by the stepwise Lars-Lasso algorithm are typically in congruence with the solution of the coordinate descent Lasso estimator.

Upper bound on a uniform noise parameter to be added to the y values, to satisfy the model’s assumption of one-at-a-time computations. Might help with stability.

Added in version 0.23.

Determines random number generation for jittering. Pass an int for reproducible output across multiple function calls. See Glossary. Ignored if jitter is None.

Added in version 0.23.

Maximum of covariances (in absolute value) at each iteration. n_alphas is either max_iter, n_features or the number of nodes in the path with alpha >= alpha_min, whichever is smaller. If this is a list of array-like, the length of the outer list is n_targets.

Indices of active variables at the end of the path. If this is a list of list, the length of the outer list is n_targets.

If a list is passed it’s expected to be one of n_targets such arrays. The varying values of the coefficients along the path. It is not present if the fit_path parameter is False. If this is a list of array-like, the length of the outer list is n_targets.

Parameter vector (w in the formulation formula).

Independent term in decision function.

The number of iterations taken by lars_path to find the grid of alphas for each target.

Number of features seen during fit.

Added in version 0.24.

Names of features seen during fit. Defined only when X has feature names that are all strings.

Added in version 1.0.

Compute Least Angle Regression or Lasso path using LARS algorithm.

Compute Lasso path with coordinate descent.

Linear Model trained with L1 prior as regularizer (aka the Lasso).

Lasso linear model with iterative fitting along a regularization path.

Cross-validated Lasso, using the LARS algorithm.

Lasso model fit with Lars using BIC or AIC for model selection.

Fit the model using X, y as training data.

Xy = np.dot(X.T, y) that can be precomputed. It is useful only when the Gram matrix is precomputed.

Returns an instance of self.

Get metadata routing of this object.

Please check User Guide on how the routing mechanism works.

A MetadataRequest encapsulating routing information.

Get parameters for this estimator.

If True, will return the parameters for this estimator and contained subobjects that are estimators.

Parameter names mapped to their values.

Predict using the linear model.

Returns predicted values.

Return coefficient of determination on test data.

The coefficient of determination, \(R^2\), is defined as \((1 - \frac{u}{v})\), where \(u\) is the residual sum of squares ((y_true - y_pred)** 2).sum() and \(v\) is the total sum of squares ((y_true - y_true.mean()) ** 2).sum(). The best possible score is 1.0 and it can be negative (because the model can be arbitrarily worse). A constant model that always predicts the expected value of y, disregarding the input features, would get a \(R^2\) score of 0.0.

Test samples. For some estimators this may be a precomputed kernel matrix or a list of generic objects instead with shape (n_samples, n_samples_fitted), where n_samples_fitted is the number of samples used in the fitting for the estimator.

\(R^2\) of self.predict(X) w.r.t. y.

The \(R^2\) score used when calling score on a regressor uses multioutput='uniform_average' from version 0.23 to keep consistent with default value of r2_score. This influences the score method of all the multioutput regressors (except for MultiOutputRegressor).

Configure whether metadata should be requested to be passed to the fit method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to fit if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to fit.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Added in version 1.3.

Metadata routing for Xy parameter in fit.

Set the parameters of this estimator.

The method works on simple estimators as well as on nested objects (such as Pipeline). The latter have parameters of the form <component>__<parameter> so that it’s possible to update each component of a nested object.

Estimator parameters.

Configure whether metadata should be requested to be passed to the score method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to score if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to score.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Added in version 1.3.

Metadata routing for sample_weight parameter in score.

**Examples:**

Example 1 (unknown):
```unknown
(1 / (2 * n_samples)) * ||y - Xw||^2_2 + alpha * ||w||_1
```

Example 2 (python):
```python
>>> from sklearn import linear_model
>>> reg = linear_model.LassoLars(alpha=0.01)
>>> reg.fit([[-1, 1], [0, 0], [1, 1]], [-1, 0, -1])
LassoLars(alpha=0.01)
>>> print(reg.coef_)
[ 0.         -0.955]
```

---

## export_graphviz#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.tree.export_graphviz.html

**Contents:**
- export_graphviz#

Export a decision tree in DOT format.

This function generates a GraphViz representation of the decision tree, which is then written into out_file. Once exported, graphical renderings can be generated using, for example:

The sample counts that are shown are weighted with any sample_weights that might be present.

Read more in the User Guide.

The decision tree estimator to be exported to GraphViz.

Handle or name of the output file. If None, the result is returned as a string.

Changed in version 0.20: Default of out_file changed from “tree.dot” to None.

The maximum depth of the representation. If None, the tree is fully generated.

An array containing the feature names. If None, generic names will be used (“x[0]”, “x[1]”, …).

Names of each of the target classes in ascending numerical order. Only relevant for classification and not supported for multi-output. If True, shows a symbolic representation of the class name.

Whether to show informative labels for impurity, etc. Options include ‘all’ to show at every node, ‘root’ to show only at the top root node, or ‘none’ to not show at any node.

When set to True, paint nodes to indicate majority class for classification, extremity of values for regression, or purity of node for multi-output.

When set to True, draw all leaf nodes at the bottom of the tree.

When set to True, show the impurity at each node.

When set to True, show the ID number on each node.

When set to True, change the display of ‘values’ and/or ‘samples’ to be proportions and percentages respectively.

When set to True, orient tree left to right rather than top-down.

When set to True, draw node boxes with rounded corners.

When set to False, ignore special characters for PostScript compatibility.

Number of digits of precision for floating point in the values of impurity, threshold and value attributes of each node.

Name of font used to render text.

String representation of the input tree in GraphViz dot format. Only returned if out_file is None.

Added in version 0.18.

**Examples:**

Example 1 (unknown):
```unknown
$ dot -Tps tree.dot -o tree.ps      (PostScript format)
$ dot -Tpng tree.dot -o tree.png    (PNG format)
```

Example 2 (python):
```python
>>> from sklearn.datasets import load_iris
>>> from sklearn import tree
```

Example 3 (unknown):
```unknown
>>> clf = tree.DecisionTreeClassifier()
>>> iris = load_iris()
```

Example 4 (unknown):
```unknown
>>> clf = clf.fit(iris.data, iris.target)
>>> tree.export_graphviz(clf)
'digraph Tree {...
```

---

## type_of_target#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.utils.multiclass.type_of_target.html

**Contents:**
- type_of_target#

Determine the type of data indicated by the target.

Note that this type is the most specific type that can be inferred. For example:

binary is more specific but compatible with multiclass.

multiclass of integers is more specific but compatible with continuous.

multilabel-indicator is more specific but compatible with multiclass-multioutput.

Target values. If a sparse matrix, y is expected to be a CSR/CSC matrix.

The data name used to construct the error message.

Added in version 1.1.0.

If True, raise an error when the type of target returned by type_of_target is "unknown".

Added in version 1.6.

‘continuous’: y is an array-like of floats that are not all integers, and is 1d or a column vector.

‘continuous-multioutput’: y is a 2d array of floats that are not all integers, and both dimensions are of size > 1.

‘binary’: y contains <= 2 discrete values and is 1d or a column vector.

‘multiclass’: y contains more than two discrete values, is not a sequence of sequences, and is 1d or a column vector.

‘multiclass-multioutput’: y is a 2d array that contains more than two discrete values, is not a sequence of sequences, and both dimensions are of size > 1.

‘multilabel-indicator’: y is a label indicator matrix, an array of two dimensions with at least two columns, and at most 2 unique values.

‘unknown’: y is array-like but none of the above, such as a 3d array, sequence of sequences, or an array of non-sequence objects.

**Examples:**

Example 1 (sql):
```sql
>>> from sklearn.utils.multiclass import type_of_target
>>> import numpy as np
>>> type_of_target([0.1, 0.6])
'continuous'
>>> type_of_target([1, -1, -1, 1])
'binary'
>>> type_of_target(['a', 'b', 'a'])
'binary'
>>> type_of_target([1.0, 2.0])
'binary'
>>> type_of_target([1, 0, 2])
'multiclass'
>>> type_of_target([1.0, 0.0, 3.0])
'multiclass'
>>> type_of_target(['a', 'b', 'c'])
'multiclass'
>>> type_of_target(np.array([[1, 2], [3, 1]]))
'multiclass-multioutput'
>>> type_of_target([[1, 2]])
'multilabel-indicator'
>>> type_of_target(np.array([[1.5, 2.0], [3.0, 1.6]]))
'continuous-multioutput'
>>> type_of_target(np.array([[0, 1], [1, 1]]))
'multilabel-indicator'
```

---

## LogisticRegression#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html

**Contents:**
- LogisticRegression#
- Gallery examples#

Logistic Regression (aka logit, MaxEnt) classifier.

This class implements regularized logistic regression using a set of available solvers. Note that regularization is applied by default. It can handle both dense and sparse input X. Use C-ordered arrays or CSR matrices containing 64-bit floats for optimal performance; any other input format will be converted (and copied).

The solvers ‘lbfgs’, ‘newton-cg’, ‘newton-cholesky’ and ‘sag’ support only L2 regularization with primal formulation, or no regularization. The ‘liblinear’ solver supports both L1 and L2 regularization (but not both, i.e. elastic-net), with a dual formulation only for the L2 penalty. The Elastic-Net (combination of L1 and L2) regularization is only supported by the ‘saga’ solver.

For multiclass problems (whenever n_classes >= 3), all solvers except ‘liblinear’ optimize the (penalized) multinomial loss. ‘liblinear’ only handles binary classification but can be extended to handle multiclass by using OneVsRestClassifier.

Read more in the User Guide.

Specify the norm of the penalty:

None: no penalty is added;

'l2': add a L2 penalty term and it is the default choice;

'l1': add a L1 penalty term;

'elasticnet': both L1 and L2 penalty terms are added.

Some penalties may not work with some solvers. See the parameter solver below, to know the compatibility between the penalty and solver.

Added in version 0.19: l1 penalty with SAGA solver (allowing ‘multinomial’ + L1)

Deprecated since version 1.8: penalty was deprecated in version 1.8 and will be removed in 1.10. Use l1_ratio instead. l1_ratio=0 for penalty='l2', l1_ratio=1 for penalty='l1' and l1_ratio set to any float between 0 and 1 for 'penalty='elasticnet'.

Inverse of regularization strength; must be a positive float. Like in support vector machines, smaller values specify stronger regularization. C=np.inf results in unpenalized logistic regression. For a visual example on the effect of tuning the C parameter with an L1 penalty, see: Regularization path of L1- Logistic Regression.

The Elastic-Net mixing parameter, with 0 <= l1_ratio <= 1. Setting l1_ratio=1 gives a pure L1-penalty, setting l1_ratio=0 a pure L2-penalty. Any value between 0 and 1 gives an Elastic-Net penalty of the form l1_ratio * L1 + (1 - l1_ratio) * L2.

Certain values of l1_ratio, i.e. some penalties, may not work with some solvers. See the parameter solver below, to know the compatibility between the penalty and solver.

Changed in version 1.8: Default value changed from None to 0.0.

Deprecated since version 1.8: None is deprecated and will be removed in version 1.10. Always use l1_ratio to specify the penalty type.

Dual (constrained) or primal (regularized, see also this equation) formulation. Dual formulation is only implemented for l2 penalty with liblinear solver. Prefer dual=False when n_samples > n_features.

Tolerance for stopping criteria.

Specifies if a constant (a.k.a. bias or intercept) should be added to the decision function.

Useful only when the solver liblinear is used and self.fit_intercept is set to True. In this case, x becomes [x, self.intercept_scaling], i.e. a “synthetic” feature with constant value equal to intercept_scaling is appended to the instance vector. The intercept becomes intercept_scaling * synthetic_feature_weight.

The synthetic feature weight is subject to L1 or L2 regularization as all other features. To lessen the effect of regularization on synthetic feature weight (and therefore on the intercept) intercept_scaling has to be increased.

Weights associated with classes in the form {class_label: weight}. If not given, all classes are supposed to have weight one.

The “balanced” mode uses the values of y to automatically adjust weights inversely proportional to class frequencies in the input data as n_samples / (n_classes * np.bincount(y)).

Note that these weights will be multiplied with sample_weight (passed through the fit method) if sample_weight is specified.

Added in version 0.17: class_weight=’balanced’

Used when solver == ‘sag’, ‘saga’ or ‘liblinear’ to shuffle the data. See Glossary for details.

Algorithm to use in the optimization problem. Default is ‘lbfgs’. To choose a solver, you might want to consider the following aspects:

‘lbfgs’ is a good default solver because it works reasonably well for a wide class of problems.

For multiclass problems (n_classes >= 3), all solvers except ‘liblinear’ minimize the full multinomial loss, ‘liblinear’ will raise an error.

‘newton-cholesky’ is a good choice for n_samples >> n_features * n_classes, especially with one-hot encoded categorical features with rare categories. Be aware that the memory usage of this solver has a quadratic dependency on n_features * n_classes because it explicitly computes the full Hessian matrix.

For small datasets, ‘liblinear’ is a good choice, whereas ‘sag’ and ‘saga’ are faster for large ones;

‘liblinear’ can only handle binary classification by default. To apply a one-versus-rest scheme for the multiclass setting one can wrap it with the OneVsRestClassifier.

The choice of the algorithm depends on the penalty chosen (l1_ratio=0 for L2-penalty, l1_ratio=1 for L1-penalty and 0 < l1_ratio < 1 for Elastic-Net) and on (multinomial) multiclass support:

multinomial multiclass

l1_ratio=1 or l1_ratio=0

‘sag’ and ‘saga’ fast convergence is only guaranteed on features with approximately the same scale. You can preprocess the data with a scaler from sklearn.preprocessing.

Refer to the User Guide for more information regarding LogisticRegression and more specifically the Table summarizing solver/penalty supports.

Added in version 0.17: Stochastic Average Gradient (SAG) descent solver. Multinomial support in version 0.18.

Added in version 0.19: SAGA solver.

Changed in version 0.22: The default solver changed from ‘liblinear’ to ‘lbfgs’ in 0.22.

Added in version 1.2: newton-cholesky solver. Multinomial support in version 1.6.

Maximum number of iterations taken for the solvers to converge.

For the liblinear and lbfgs solvers set verbose to any positive number for verbosity.

When set to True, reuse the solution of the previous call to fit as initialization, otherwise, just erase the previous solution. Useless for liblinear solver. See the Glossary.

Added in version 0.17: warm_start to support lbfgs, newton-cg, sag, saga solvers.

Does not have any effect.

Deprecated since version 1.8: n_jobs is deprecated in version 1.8 and will be removed in 1.10.

A list of class labels known to the classifier.

Coefficient of the features in the decision function.

coef_ is of shape (1, n_features) when the given problem is binary.

Intercept (a.k.a. bias) added to the decision function.

If fit_intercept is set to False, the intercept is set to zero. intercept_ is of shape (1,) when the given problem is binary.

Number of features seen during fit.

Added in version 0.24.

Names of features seen during fit. Defined only when X has feature names that are all strings.

Added in version 1.0.

Actual number of iterations for all classes.

Changed in version 0.20: In SciPy <= 1.0.0 the number of lbfgs iterations may exceed max_iter. n_iter_ will now report at most max_iter.

Incrementally trained logistic regression (when given the parameter loss="log_loss").

Logistic regression with built-in cross validation.

The underlying C implementation uses a random number generator to select features when fitting the model. It is thus not uncommon, to have slightly different results for the same input data. If that happens, try with a smaller tol parameter.

Predict output may not match that of standalone liblinear in certain cases. See differences from liblinear in the narrative documentation.

Ciyou Zhu, Richard Byrd, Jorge Nocedal and Jose Luis Morales. http://users.iems.northwestern.edu/~nocedal/lbfgsb.html

https://www.csie.ntu.edu.tw/~cjlin/liblinear/

Minimizing Finite Sums with the Stochastic Average Gradient https://hal.inria.fr/hal-00860051/document

“SAGA: A Fast Incremental Gradient Method With Support for Non-Strongly Convex Composite Objectives”

methods for logistic regression and maximum entropy models. Machine Learning 85(1-2):41-75. https://www.csie.ntu.edu.tw/~cjlin/papers/maxent_dual.pdf

For a comparison of the LogisticRegression with other classifiers see: Plot classification probability.

Predict confidence scores for samples.

The confidence score for a sample is proportional to the signed distance of that sample to the hyperplane.

The data matrix for which we want to get the confidence scores.

Confidence scores per (n_samples, n_classes) combination. In the binary case, confidence score for self.classes_[1] where >0 means this class would be predicted.

Convert coefficient matrix to dense array format.

Converts the coef_ member (back) to a numpy.ndarray. This is the default format of coef_ and is required for fitting, so calling this method is only required on models that have previously been sparsified; otherwise, it is a no-op.

Fit the model according to the given training data.

Training vector, where n_samples is the number of samples and n_features is the number of features.

Target vector relative to X.

Array of weights that are assigned to individual samples. If not provided, then each sample is given unit weight.

Added in version 0.17: sample_weight support to LogisticRegression.

The SAGA solver supports both float64 and float32 bit arrays.

Get metadata routing of this object.

Please check User Guide on how the routing mechanism works.

A MetadataRequest encapsulating routing information.

Get parameters for this estimator.

If True, will return the parameters for this estimator and contained subobjects that are estimators.

Parameter names mapped to their values.

Predict class labels for samples in X.

The data matrix for which we want to get the predictions.

Vector containing the class labels for each sample.

Predict logarithm of probability estimates.

The returned estimates for all classes are ordered by the label of classes.

Vector to be scored, where n_samples is the number of samples and n_features is the number of features.

Returns the log-probability of the sample for each class in the model, where classes are ordered as they are in self.classes_.

Probability estimates.

The returned estimates for all classes are ordered by the label of classes.

For a multiclass / multinomial problem the softmax function is used to find the predicted probability of each class.

Vector to be scored, where n_samples is the number of samples and n_features is the number of features.

Returns the probability of the sample for each class in the model, where classes are ordered as they are in self.classes_.

Return accuracy on provided data and labels.

In multi-label classification, this is the subset accuracy which is a harsh metric since you require for each sample that each label set be correctly predicted.

Mean accuracy of self.predict(X) w.r.t. y.

Configure whether metadata should be requested to be passed to the fit method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to fit if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to fit.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Added in version 1.3.

Metadata routing for sample_weight parameter in fit.

Set the parameters of this estimator.

The method works on simple estimators as well as on nested objects (such as Pipeline). The latter have parameters of the form <component>__<parameter> so that it’s possible to update each component of a nested object.

Estimator parameters.

Configure whether metadata should be requested to be passed to the score method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to score if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to score.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Added in version 1.3.

Metadata routing for sample_weight parameter in score.

Convert coefficient matrix to sparse format.

Converts the coef_ member to a scipy.sparse matrix, which for L1-regularized models can be much more memory- and storage-efficient than the usual numpy.ndarray representation.

The intercept_ member is not converted.

For non-sparse models, i.e. when there are not many zeros in coef_, this may actually increase memory usage, so use this method with care. A rule of thumb is that the number of zero elements, which can be computed with (coef_ == 0).sum(), must be more than 50% for this to provide significant benefits.

After calling this method, further fitting with the partial_fit method (if any) will not work until you call densify.

Probability Calibration curves

Plot classification probability

Column Transformer with Mixed Types

Pipelining: chaining a PCA and a logistic regression

Feature transformations with ensembles of trees

Visualizing the probabilistic predictions of a VotingClassifier

Recursive feature elimination

Recursive feature elimination with cross-validation

Model-based and sequential feature selection

Examples of Using FrozenEstimator

L1 Penalty and Sparsity in Logistic Regression

Decision Boundaries of Multinomial and One-vs-Rest Logistic Regression

Regularization path of L1- Logistic Regression

Multiclass sparse logistic regression on 20newgroups

MNIST classification using multinomial logistic + L1

Visualizations with Display Objects

Displaying estimators and complex pipelines

Introducing the set_output API

Post-tuning the decision threshold for cost-sensitive learning

Balance model complexity and cross-validated score

Class Likelihood Ratios to measure classification performance

Multiclass Receiver Operating Characteristic (ROC)

Post-hoc tuning the cut-off point of decision function

Multilabel classification using a classifier chain

Restricted Boltzmann Machine features for digit classification

Feature discretization

Release Highlights for scikit-learn 0.22

Release Highlights for scikit-learn 0.23

Release Highlights for scikit-learn 0.24

Release Highlights for scikit-learn 1.0

Release Highlights for scikit-learn 1.1

Release Highlights for scikit-learn 1.3

Release Highlights for scikit-learn 1.5

Release Highlights for scikit-learn 1.7

Release Highlights for scikit-learn 1.8

Classification of text documents using sparse features

**Examples:**

Example 1 (json):
```json
>>> from sklearn.datasets import load_iris
>>> from sklearn.linear_model import LogisticRegression
>>> X, y = load_iris(return_X_y=True)
>>> clf = LogisticRegression(random_state=0).fit(X, y)
>>> clf.predict(X[:2, :])
array([0, 0])
>>> clf.predict_proba(X[:2, :])
array([[9.82e-01, 1.82e-02, 1.44e-08],
       [9.72e-01, 2.82e-02, 3.02e-08]])
>>> clf.score(X, y)
0.97
```

---

## oas#

**URL:** https://scikit-learn.org/stable/modules/generated/oas-function.html

**Contents:**
- oas#

Estimate covariance with the Oracle Approximating Shrinkage.

Read more in the User Guide.

Data from which to compute the covariance estimate.

If True, data will not be centered before computation. Useful to work with data whose mean is significantly equal to zero but is not exactly zero. If False, data will be centered before computation.

Coefficient in the convex combination used for the computation of the shrunk estimate.

The regularised covariance is:

(1 - shrinkage) * cov + shrinkage * mu * np.identity(n_features),

where mu = trace(cov) / n_features and shrinkage is given by the OAS formula (see [1]).

The shrinkage formulation implemented here differs from Eq. 23 in [1]. In the original article, formula (23) states that 2/p (p being the number of features) is multiplied by Trace(cov*cov) in both the numerator and denominator, but this operation is omitted because for a large p, the value of 2/p is so small that it doesn’t affect the value of the estimator.

“Shrinkage algorithms for MMSE covariance estimation.”, Chen, Y., Wiesel, A., Eldar, Y. C., & Hero, A. O. IEEE Transactions on Signal Processing, 58(10), 5016-5029, 2010.

**Examples:**

Example 1 (sql):
```sql
>>> import numpy as np
>>> from sklearn.covariance import oas
>>> rng = np.random.RandomState(0)
>>> real_cov = [[.8, .3], [.3, .4]]
>>> X = rng.multivariate_normal(mean=[0, 0], cov=real_cov, size=500)
>>> shrunk_cov, shrinkage = oas(X)
>>> shrunk_cov
array([[0.7533, 0.2763],
       [0.2763, 0.3964]])
>>> shrinkage
np.float64(0.0195)
```

---

## Lars#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lars.html

**Contents:**
- Lars#

Least Angle Regression model a.k.a. LAR.

Read more in the User Guide.

Whether to calculate the intercept for this model. If set to false, no intercept will be used in calculations (i.e. data is expected to be centered).

Sets the verbosity amount.

Whether to use a precomputed Gram matrix to speed up calculations. If set to 'auto' let us decide. The Gram matrix can also be passed as argument.

Target number of non-zero coefficients. Use np.inf for no limit.

The machine-precision regularization in the computation of the Cholesky diagonal factors. Increase this for very ill-conditioned systems. Unlike the tol parameter in some iterative optimization-based algorithms, this parameter does not control the tolerance of the optimization.

If True, X will be copied; else, it may be overwritten.

If True the full path is stored in the coef_path_ attribute. If you compute the solution for a large problem or many targets, setting fit_path to False will lead to a speedup, especially with a small alpha.

Upper bound on a uniform noise parameter to be added to the y values, to satisfy the model’s assumption of one-at-a-time computations. Might help with stability.

Added in version 0.23.

Determines random number generation for jittering. Pass an int for reproducible output across multiple function calls. See Glossary. Ignored if jitter is None.

Added in version 0.23.

Maximum of covariances (in absolute value) at each iteration. n_alphas is either max_iter, n_features or the number of nodes in the path with alpha >= alpha_min, whichever is smaller. If this is a list of array-like, the length of the outer list is n_targets.

Indices of active variables at the end of the path. If this is a list of list, the length of the outer list is n_targets.

The varying values of the coefficients along the path. It is not present if the fit_path parameter is False. If this is a list of array-like, the length of the outer list is n_targets.

Parameter vector (w in the formulation formula).

Independent term in decision function.

The number of iterations taken by lars_path to find the grid of alphas for each target.

Number of features seen during fit.

Added in version 0.24.

Names of features seen during fit. Defined only when X has feature names that are all strings.

Added in version 1.0.

Compute Least Angle Regression or Lasso path using LARS algorithm.

Cross-validated Least Angle Regression model.

Fit the model using X, y as training data.

Xy = np.dot(X.T, y) that can be precomputed. It is useful only when the Gram matrix is precomputed.

Returns an instance of self.

Get metadata routing of this object.

Please check User Guide on how the routing mechanism works.

A MetadataRequest encapsulating routing information.

Get parameters for this estimator.

If True, will return the parameters for this estimator and contained subobjects that are estimators.

Parameter names mapped to their values.

Predict using the linear model.

Returns predicted values.

Return coefficient of determination on test data.

The coefficient of determination, \(R^2\), is defined as \((1 - \frac{u}{v})\), where \(u\) is the residual sum of squares ((y_true - y_pred)** 2).sum() and \(v\) is the total sum of squares ((y_true - y_true.mean()) ** 2).sum(). The best possible score is 1.0 and it can be negative (because the model can be arbitrarily worse). A constant model that always predicts the expected value of y, disregarding the input features, would get a \(R^2\) score of 0.0.

Test samples. For some estimators this may be a precomputed kernel matrix or a list of generic objects instead with shape (n_samples, n_samples_fitted), where n_samples_fitted is the number of samples used in the fitting for the estimator.

\(R^2\) of self.predict(X) w.r.t. y.

The \(R^2\) score used when calling score on a regressor uses multioutput='uniform_average' from version 0.23 to keep consistent with default value of r2_score. This influences the score method of all the multioutput regressors (except for MultiOutputRegressor).

Configure whether metadata should be requested to be passed to the fit method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to fit if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to fit.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Added in version 1.3.

Metadata routing for Xy parameter in fit.

Set the parameters of this estimator.

The method works on simple estimators as well as on nested objects (such as Pipeline). The latter have parameters of the form <component>__<parameter> so that it’s possible to update each component of a nested object.

Estimator parameters.

Configure whether metadata should be requested to be passed to the score method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to score if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to score.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Added in version 1.3.

Metadata routing for sample_weight parameter in score.

**Examples:**

Example 1 (python):
```python
>>> from sklearn import linear_model
>>> reg = linear_model.Lars(n_nonzero_coefs=1)
>>> reg.fit([[-1, 1], [0, 0], [1, 1]], [-1.1111, 0, -1.1111])
Lars(n_nonzero_coefs=1)
>>> print(reg.coef_)
[ 0. -1.11]
```

---

## OrdinalEncoder#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OrdinalEncoder.html

**Contents:**
- OrdinalEncoder#
- Gallery examples#

Encode categorical features as an integer array.

The input to this transformer should be an array-like of integers or strings, denoting the values taken on by categorical (discrete) features. The features are converted to ordinal integers. This results in a single column of integers (0 to n_categories - 1) per feature.

Read more in the User Guide. For a comparison of different encoders, refer to: Comparing Target Encoder with Other Encoders.

Added in version 0.20.

Categories (unique values) per feature:

‘auto’ : Determine categories automatically from the training data.

list : categories[i] holds the categories expected in the ith column. The passed categories should not mix strings and numeric values, and should be sorted in case of numeric values.

The used categories can be found in the categories_ attribute.

Desired dtype of output.

When set to ‘error’ an error will be raised in case an unknown categorical feature is present during transform. When set to ‘use_encoded_value’, the encoded value of unknown categories will be set to the value given for the parameter unknown_value. In inverse_transform, an unknown category will be denoted as None.

Added in version 0.24.

When the parameter handle_unknown is set to ‘use_encoded_value’, this parameter is required and will set the encoded value of unknown categories. It has to be distinct from the values used to encode any of the categories in fit. If set to np.nan, the dtype parameter must be a float dtype.

Added in version 0.24.

Encoded value of missing categories. If set to np.nan, then the dtype parameter must be a float dtype.

Added in version 1.1.

Specifies the minimum frequency below which a category will be considered infrequent.

If int, categories with a smaller cardinality will be considered infrequent.

If float, categories with a smaller cardinality than min_frequency * n_samples will be considered infrequent.

Added in version 1.3: Read more in the User Guide.

Specifies an upper limit to the number of output categories for each input feature when considering infrequent categories. If there are infrequent categories, max_categories includes the category representing the infrequent categories along with the frequent categories. If None, there is no limit to the number of output features.

max_categories do not take into account missing or unknown categories. Setting unknown_value or encoded_missing_value to an integer will increase the number of unique integer codes by one each. This can result in up to max_categories + 2 integer codes.

Added in version 1.3: Read more in the User Guide.

The categories of each feature determined during fit (in order of the features in X and corresponding with the output of transform). This does not include categories that weren’t seen during fit.

Number of features seen during fit.

Added in version 1.0.

Names of features seen during fit. Defined only when X has feature names that are all strings.

Added in version 1.0.

Infrequent categories for each feature.

Performs a one-hot encoding of categorical features. This encoding is suitable for low to medium cardinality categorical variables, both in supervised and unsupervised settings.

Encodes categorical features using supervised signal in a classification or regression pipeline. This encoding is typically suitable for high cardinality categorical variables.

Encodes target labels with values between 0 and n_classes-1.

Given a dataset with two features, we let the encoder find the unique values per feature and transform the data to an ordinal encoding.

By default, OrdinalEncoder is lenient towards missing values by propagating them.

You can use the parameter encoded_missing_value to encode missing values.

Infrequent categories are enabled by setting max_categories or min_frequency. In the following example, “a” and “d” are considered infrequent and grouped together into a single category, “b” and “c” are their own categories, unknown values are encoded as 3 and missing values are encoded as 4.

Fit the OrdinalEncoder to X.

The data to determine the categories of each feature.

Ignored. This parameter exists only for compatibility with Pipeline.

Fit to data, then transform it.

Fits transformer to X and y with optional parameters fit_params and returns a transformed version of X.

Target values (None for unsupervised transformations).

Additional fit parameters. Pass only if the estimator accepts additional params in its fit method.

Get output feature names for transformation.

If input_features is None, then feature_names_in_ is used as feature names in. If feature_names_in_ is not defined, then the following input feature names are generated: ["x0", "x1", ..., "x(n_features_in_ - 1)"].

If input_features is an array-like, then input_features must match feature_names_in_ if feature_names_in_ is defined.

Same as input features.

Get metadata routing of this object.

Please check User Guide on how the routing mechanism works.

A MetadataRequest encapsulating routing information.

Get parameters for this estimator.

If True, will return the parameters for this estimator and contained subobjects that are estimators.

Parameter names mapped to their values.

Convert the data back to the original representation.

The transformed data.

Inverse transformed array.

Set output container.

See Introducing the set_output API for an example on how to use the API.

Configure output of transform and fit_transform.

"default": Default output format of a transformer

"pandas": DataFrame output

"polars": Polars output

None: Transform configuration is unchanged

Added in version 1.4: "polars" option was added.

Set the parameters of this estimator.

The method works on simple estimators as well as on nested objects (such as Pipeline). The latter have parameters of the form <component>__<parameter> so that it’s possible to update each component of a nested object.

Estimator parameters.

Transform X to ordinal codes.

Categorical Feature Support in Gradient Boosting

Combine predictors using stacking

Partial Dependence and Individual Conditional Expectation Plots

Permutation Importance vs Random Forest Feature Importance (MDI)

Poisson regression and non-normal loss

Evaluation of outlier detection estimators

Comparing Target Encoder with Other Encoders

Release Highlights for scikit-learn 1.2

Release Highlights for scikit-learn 1.3

**Examples:**

Example 1 (csharp):
```csharp
>>> from sklearn.preprocessing import OrdinalEncoder
>>> enc = OrdinalEncoder()
>>> X = [['Male', 1], ['Female', 3], ['Female', 2]]
>>> enc.fit(X)
OrdinalEncoder()
>>> enc.categories_
[array(['Female', 'Male'], dtype=object), array([1, 2, 3], dtype=object)]
>>> enc.transform([['Female', 3], ['Male', 1]])
array([[0., 2.],
       [1., 0.]])
```

Example 2 (json):
```json
>>> enc.inverse_transform([[1, 0], [0, 1]])
array([['Male', 1],
       ['Female', 2]], dtype=object)
```

Example 3 (json):
```json
>>> import numpy as np
>>> X = [['Male', 1], ['Female', 3], ['Female', np.nan]]
>>> enc.fit_transform(X)
array([[ 1.,  0.],
       [ 0.,  1.],
       [ 0., nan]])
```

Example 4 (json):
```json
>>> enc.set_params(encoded_missing_value=-1).fit_transform(X)
array([[ 1.,  0.],
       [ 0.,  1.],
       [ 0., -1.]])
```

---

## SGDRegressor#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDRegressor.html

**Contents:**
- SGDRegressor#
- Gallery examples#

Linear model fitted by minimizing a regularized empirical loss with SGD.

SGD stands for Stochastic Gradient Descent: the gradient of the loss is estimated each sample at a time and the model is updated along the way with a decreasing strength schedule (aka learning rate).

The regularizer is a penalty added to the loss function that shrinks model parameters towards the zero vector using either the squared euclidean norm L2 or the absolute norm L1 or a combination of both (Elastic Net). If the parameter update crosses the 0.0 value because of the regularizer, the update is truncated to 0.0 to allow for learning sparse models and achieve online feature selection.

This implementation works with data represented as dense numpy arrays of floating point values for the features.

Read more in the User Guide.

The loss function to be used. The possible values are ‘squared_error’, ‘huber’, ‘epsilon_insensitive’, or ‘squared_epsilon_insensitive’

The ‘squared_error’ refers to the ordinary least squares fit. ‘huber’ modifies ‘squared_error’ to focus less on getting outliers correct by switching from squared to linear loss past a distance of epsilon. ‘epsilon_insensitive’ ignores errors less than epsilon and is linear past that; this is the loss function used in SVR. ‘squared_epsilon_insensitive’ is the same but becomes squared loss past a tolerance of epsilon.

More details about the losses formulas can be found in the User Guide.

The penalty (aka regularization term) to be used. Defaults to ‘l2’ which is the standard regularizer for linear SVM models. ‘l1’ and ‘elasticnet’ might bring sparsity to the model (feature selection) not achievable with ‘l2’. No penalty is added when set to None.

You can see a visualisation of the penalties in SGD: Penalties.

Constant that multiplies the regularization term. The higher the value, the stronger the regularization. Also used to compute the learning rate when learning_rate is set to ‘optimal’. Values must be in the range [0.0, inf).

The Elastic Net mixing parameter, with 0 <= l1_ratio <= 1. l1_ratio=0 corresponds to L2 penalty, l1_ratio=1 to L1. Only used if penalty is ‘elasticnet’. Values must be in the range [0.0, 1.0] or can be None if penalty is not elasticnet.

Changed in version 1.7: l1_ratio can be None when penalty is not “elasticnet”.

Whether the intercept should be estimated or not. If False, the data is assumed to be already centered.

The maximum number of passes over the training data (aka epochs). It only impacts the behavior in the fit method, and not the partial_fit method. Values must be in the range [1, inf).

Added in version 0.19.

The stopping criterion. If it is not None, training will stop when (loss > best_loss - tol) for n_iter_no_change consecutive epochs. Convergence is checked against the training loss or the validation loss depending on the early_stopping parameter. Values must be in the range [0.0, inf).

Added in version 0.19.

Whether or not the training data should be shuffled after each epoch.

The verbosity level. Values must be in the range [0, inf).

Epsilon in the epsilon-insensitive loss functions; only if loss is ‘huber’, ‘epsilon_insensitive’, or ‘squared_epsilon_insensitive’. For ‘huber’, determines the threshold at which it becomes less important to get the prediction exactly right. For epsilon-insensitive, any differences between the current prediction and the correct label are ignored if they are less than this threshold. Values must be in the range [0.0, inf).

Used for shuffling the data, when shuffle is set to True. Pass an int for reproducible output across multiple function calls. See Glossary.

The learning rate schedule:

‘constant’: eta = eta0

‘optimal’: eta = 1.0 / (alpha * (t + t0)) where t0 is chosen by a heuristic proposed by Leon Bottou.

‘invscaling’: eta = eta0 / pow(t, power_t)

‘adaptive’: eta = eta0, as long as the training keeps decreasing. Each time n_iter_no_change consecutive epochs fail to decrease the training loss by tol or fail to increase validation score by tol if early_stopping is True, the current learning rate is divided by 5.

‘pa1’: passive-aggressive algorithm 1, see [1]. Only with loss='epsilon_insensitive'. Update is w += eta y x with eta = min(eta0, loss/||x||**2).

‘pa2’: passive-aggressive algorithm 2, see [1]. Only with loss='epsilon_insensitive'. Update is w += eta y x with eta = hinge_loss / (||x||**2 + 1/(2 eta0)).

Added in version 0.20: Added ‘adaptive’ option.

Added in version 1.8: Added options ‘pa1’ and ‘pa2’

The initial learning rate for the ‘constant’, ‘invscaling’ or ‘adaptive’ schedules. The default value is 0.01. Values must be in the range (0.0, inf).

For PA-1 (learning_rate=pa1) and PA-II (pa2), it specifies the aggressiveness parameter for the passive-agressive algorithm, see [1] where it is called C:

For PA-I it is the maximum step size.

For PA-II it regularizes the step size (the smaller eta0 the more it regularizes).

As a general rule-of-thumb for PA, eta0 should be small when the data is noisy.

The exponent for inverse scaling learning rate. Values must be in the range [0.0, inf).

Deprecated since version 1.8: Negative values for power_t are deprecated in version 1.8 and will raise an error in 1.10. Use values in the range [0.0, inf) instead.

Whether to use early stopping to terminate training when validation score is not improving. If set to True, it will automatically set aside a fraction of training data as validation and terminate training when validation score returned by the score method is not improving by at least tol for n_iter_no_change consecutive epochs.

See Early stopping of Stochastic Gradient Descent for an example of the effects of early stopping.

Added in version 0.20: Added ‘early_stopping’ option

The proportion of training data to set aside as validation set for early stopping. Must be between 0 and 1. Only used if early_stopping is True. Values must be in the range (0.0, 1.0).

Added in version 0.20: Added ‘validation_fraction’ option

Number of iterations with no improvement to wait before stopping fitting. Convergence is checked against the training loss or the validation loss depending on the early_stopping parameter. Integer values must be in the range [1, max_iter).

Added in version 0.20: Added ‘n_iter_no_change’ option

When set to True, reuse the solution of the previous call to fit as initialization, otherwise, just erase the previous solution. See the Glossary.

Repeatedly calling fit or partial_fit when warm_start is True can result in a different solution than when calling fit a single time because of the way the data is shuffled. If a dynamic learning rate is used, the learning rate is adapted depending on the number of samples already seen. Calling fit resets this counter, while partial_fit will result in increasing the existing counter.

When set to True, computes the averaged SGD weights across all updates and stores the result in the coef_ attribute. If set to an int greater than 1, averaging will begin once the total number of samples seen reaches average. So average=10 will begin averaging after seeing 10 samples.

Weights assigned to the features.

The actual number of iterations before reaching the stopping criterion.

Number of weight updates performed during training. Same as (n_iter_ * n_samples + 1).

Number of features seen during fit.

Added in version 0.24.

Names of features seen during fit. Defined only when X has feature names that are all strings.

Added in version 1.0.

Linear regression model that is robust to outliers.

Least Angle Regression model.

Linear Model trained with L1 prior as regularizer.

RANSAC (RANdom SAmple Consensus) algorithm.

Linear least squares with l2 regularization.

Epsilon-Support Vector Regression.

Theil-Sen Estimator robust multivariate regression model.

Online Passive-Aggressive Algorithms <http://jmlr.csail.mit.edu/papers/volume7/crammer06a/crammer06a.pdf> K. Crammer, O. Dekel, J. Keshat, S. Shalev-Shwartz, Y. Singer - JMLR (2006)

Convert coefficient matrix to dense array format.

Converts the coef_ member (back) to a numpy.ndarray. This is the default format of coef_ and is required for fitting, so calling this method is only required on models that have previously been sparsified; otherwise, it is a no-op.

Fit linear model with Stochastic Gradient Descent.

The initial coefficients to warm-start the optimization.

The initial intercept to warm-start the optimization.

Weights applied to individual samples (1. for unweighted).

Fitted SGDRegressor estimator.

Get metadata routing of this object.

Please check User Guide on how the routing mechanism works.

A MetadataRequest encapsulating routing information.

Get parameters for this estimator.

If True, will return the parameters for this estimator and contained subobjects that are estimators.

Parameter names mapped to their values.

Perform one epoch of stochastic gradient descent on given samples.

Internally, this method uses max_iter = 1. Therefore, it is not guaranteed that a minimum of the cost function is reached after calling it once. Matters such as objective convergence and early stopping should be handled by the user.

Subset of training data.

Subset of target values.

Weights applied to individual samples. If not provided, uniform weights are assumed.

Returns an instance of self.

Predict using the linear model.

Predicted target values per element in X.

Return coefficient of determination on test data.

The coefficient of determination, \(R^2\), is defined as \((1 - \frac{u}{v})\), where \(u\) is the residual sum of squares ((y_true - y_pred)** 2).sum() and \(v\) is the total sum of squares ((y_true - y_true.mean()) ** 2).sum(). The best possible score is 1.0 and it can be negative (because the model can be arbitrarily worse). A constant model that always predicts the expected value of y, disregarding the input features, would get a \(R^2\) score of 0.0.

Test samples. For some estimators this may be a precomputed kernel matrix or a list of generic objects instead with shape (n_samples, n_samples_fitted), where n_samples_fitted is the number of samples used in the fitting for the estimator.

\(R^2\) of self.predict(X) w.r.t. y.

The \(R^2\) score used when calling score on a regressor uses multioutput='uniform_average' from version 0.23 to keep consistent with default value of r2_score. This influences the score method of all the multioutput regressors (except for MultiOutputRegressor).

Configure whether metadata should be requested to be passed to the fit method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to fit if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to fit.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Added in version 1.3.

Metadata routing for coef_init parameter in fit.

Metadata routing for intercept_init parameter in fit.

Metadata routing for sample_weight parameter in fit.

Set the parameters of this estimator.

The method works on simple estimators as well as on nested objects (such as Pipeline). The latter have parameters of the form <component>__<parameter> so that it’s possible to update each component of a nested object.

Estimator parameters.

Configure whether metadata should be requested to be passed to the partial_fit method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to partial_fit if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to partial_fit.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Added in version 1.3.

Metadata routing for sample_weight parameter in partial_fit.

Configure whether metadata should be requested to be passed to the score method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to score if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to score.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Added in version 1.3.

Metadata routing for sample_weight parameter in score.

Convert coefficient matrix to sparse format.

Converts the coef_ member to a scipy.sparse matrix, which for L1-regularized models can be much more memory- and storage-efficient than the usual numpy.ndarray representation.

The intercept_ member is not converted.

For non-sparse models, i.e. when there are not many zeros in coef_, this may actually increase memory usage, so use this method with care. A rule of thumb is that the number of zero elements, which can be computed with (coef_ == 0).sum(), must be more than 50% for this to provide significant benefits.

After calling this method, further fitting with the partial_fit method (if any) will not work until you call densify.

**Examples:**

Example 1 (sql):
```sql
>>> import numpy as np
>>> from sklearn.linear_model import SGDRegressor
>>> from sklearn.pipeline import make_pipeline
>>> from sklearn.preprocessing import StandardScaler
>>> n_samples, n_features = 10, 5
>>> rng = np.random.RandomState(0)
>>> y = rng.randn(n_samples)
>>> X = rng.randn(n_samples, n_features)
>>> # Always scale the input. The most convenient way is to use a pipeline.
>>> reg = make_pipeline(StandardScaler(),
...                     SGDRegressor(max_iter=1000, tol=1e-3))
>>> reg.fit(X, y)
Pipeline(steps=[('standardscaler', StandardScaler()),
                ('sgdregressor', SGDRegressor())])
```

---

## orthogonal_mp#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.orthogonal_mp.html

**Contents:**
- orthogonal_mp#

Orthogonal Matching Pursuit (OMP).

Solves n_targets Orthogonal Matching Pursuit problems. An instance of the problem has the form:

When parametrized by the number of non-zero coefficients using n_nonzero_coefs: argmin ||y - Xgamma||^2 subject to ||gamma||_0 <= n_{nonzero coefs}

When parametrized by error using the parameter tol: argmin ||gamma||_0 subject to ||y - Xgamma||^2 <= tol

Read more in the User Guide.

Input data. Columns are assumed to have unit norm.

Desired number of non-zero entries in the solution. If None (by default) this value is set to 10% of n_features.

Maximum squared norm of the residual. If not None, overrides n_nonzero_coefs.

Whether to perform precomputations. Improves performance when n_targets or n_samples is very large.

Whether the design matrix X must be copied by the algorithm. A false value is only helpful if X is already Fortran-ordered, otherwise a copy is made anyway.

Whether to return every value of the nonzero coefficients along the forward path. Useful for cross-validation.

Whether or not to return the number of iterations.

Coefficients of the OMP solution. If return_path=True, this contains the whole coefficient path. In this case its shape is (n_features, n_features) or (n_features, n_targets, n_features) and iterating over the last axis generates coefficients in increasing order of active features.

Number of active features across every target. Returned only if return_n_iter is set to True.

Orthogonal Matching Pursuit model.

Solve OMP problems using Gram matrix and the product X.T * y.

Compute Least Angle Regression or Lasso path using LARS algorithm.

Orthogonal matching pursuit was introduced in S. Mallat, Z. Zhang, Matching pursuits with time-frequency dictionaries, IEEE Transactions on Signal Processing, Vol. 41, No. 12. (December 1993), pp. 3397-3415. (https://www.di.ens.fr/~mallat/papiers/MallatPursuit93.pdf)

This implementation is based on Rubinstein, R., Zibulevsky, M. and Elad, M., Efficient Implementation of the K-SVD Algorithm using Batch Orthogonal Matching Pursuit Technical Report - CS Technion, April 2008. https://www.cs.technion.ac.il/~ronrubin/Publications/KSVD-OMP-v2.pdf

**Examples:**

Example 1 (sql):
```sql
>>> from sklearn.datasets import make_regression
>>> from sklearn.linear_model import orthogonal_mp
>>> X, y = make_regression(noise=4, random_state=0)
>>> coef = orthogonal_mp(X, y)
>>> coef.shape
(100,)
>>> X[:1,] @ coef
array([-78.68])
```

---

## contingency_matrix#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.metrics.cluster.contingency_matrix.html

**Contents:**
- contingency_matrix#

Build a contingency matrix describing the relationship between labels.

Read more in the User Guide.

Ground truth class labels to be used as a reference.

Cluster labels to evaluate.

If a float, that value is added to all values in the contingency matrix. This helps to stop NaN propagation. If None, nothing is adjusted.

If True, return a sparse CSR contingency matrix. If eps is not None and sparse is True will raise ValueError.

Added in version 0.18.

Output dtype. Ignored if eps is not None.

Added in version 0.24.

Matrix \(C\) such that \(C_{i, j}\) is the number of samples in true class \(i\) and in predicted class \(j\). If eps is None, the dtype of this array will be integer unless set otherwise with the dtype argument. If eps is given, the dtype will be float. Will be a sklearn.sparse.csr_matrix if sparse=True.

**Examples:**

Example 1 (sql):
```sql
>>> from sklearn.metrics.cluster import contingency_matrix
>>> labels_true = [0, 0, 1, 1, 2, 2]
>>> labels_pred = [1, 0, 2, 1, 0, 2]
>>> contingency_matrix(labels_true, labels_pred)
array([[1, 1, 0],
       [0, 1, 1],
       [1, 0, 1]])
```

---

## 5.1. Partial Dependence and Individual Conditional Expectation plots#

**URL:** https://scikit-learn.org/stable/modules/partial_dependence.html

**Contents:**
- 5.1. Partial Dependence and Individual Conditional Expectation plots#
- 5.1.1. Partial dependence plots#
- 5.1.2. Individual conditional expectation (ICE) plot#
- 5.1.3. Mathematical Definition#
- 5.1.4. Computation methods#

Partial dependence plots (PDP) and individual conditional expectation (ICE) plots can be used to visualize and analyze interaction between the target response [1] and a set of input features of interest.

Both PDPs [H2009] and ICEs [G2015] assume that the input features of interest are independent from the complement features, and this assumption is often violated in practice. Thus, in the case of correlated features, we will create absurd data points to compute the PDP/ICE [M2019].

Partial dependence plots (PDP) show the dependence between the target response and a set of input features of interest, marginalizing over the values of all other input features (the ‘complement’ features). Intuitively, we can interpret the partial dependence as the expected target response as a function of the input features of interest.

Due to the limits of human perception, the size of the set of input features of interest must be small (usually, one or two) thus the input features of interest are usually chosen among the most important features.

The figure below shows two one-way and one two-way partial dependence plots for the bike sharing dataset, with a HistGradientBoostingRegressor:

One-way PDPs tell us about the interaction between the target response and an input feature of interest (e.g. linear, non-linear). The left plot in the above figure shows the effect of the temperature on the number of bike rentals; we can clearly see that a higher temperature is related with a higher number of bike rentals. Similarly, we could analyze the effect of the humidity on the number of bike rentals (middle plot). Thus, these interpretations are marginal, considering a feature at a time.

PDPs with two input features of interest show the interactions among the two features. For example, the two-variable PDP in the above figure shows the dependence of the number of bike rentals on joint values of temperature and humidity. We can clearly see an interaction between the two features: with a temperature higher than 20 degrees Celsius, mainly the humidity has a strong impact on the number of bike rentals. For lower temperatures, both the temperature and the humidity have an impact on the number of bike rentals.

The sklearn.inspection module provides a convenience function from_estimator to create one-way and two-way partial dependence plots. In the below example we show how to create a grid of partial dependence plots: two one-way PDPs for the features 0 and 1 and a two-way PDP between the two features:

You can access the newly created figure and Axes objects using plt.gcf() and plt.gca().

To make a partial dependence plot with categorical features, you need to specify which features are categorical using the parameter categorical_features. This parameter takes a list of indices, names of the categorical features or a boolean mask. The graphical representation of partial dependence for categorical features is a bar plot or a 2D heatmap.

For multi-class classification, you need to set the class label for which the PDPs should be created via the target argument:

The same parameter target is used to specify the target in multi-output regression settings.

If you need the raw values of the partial dependence function rather than the plots, you can use the sklearn.inspection.partial_dependence function:

The values at which the partial dependence should be evaluated are directly generated from X. For 2-way partial dependence, a 2D-grid of values is generated. The values field returned by sklearn.inspection.partial_dependence gives the actual values used in the grid for each input feature of interest. They also correspond to the axis of the plots.

Similar to a PDP, an individual conditional expectation (ICE) plot shows the dependence between the target function and an input feature of interest. However, unlike a PDP, which shows the average effect of the input feature, an ICE plot visualizes the dependence of the prediction on a feature for each sample separately with one line per sample. Due to the limits of human perception, only one input feature of interest is supported for ICE plots.

The figures below show two ICE plots for the bike sharing dataset, with a HistGradientBoostingRegressor. The figures plot the corresponding PD line overlaid on ICE lines.

While the PDPs are good at showing the average effect of the target features, they can obscure a heterogeneous relationship created by interactions. When interactions are present the ICE plot will provide many more insights. For example, we see that the ICE for the temperature feature gives us some additional information: some of the ICE lines are flat while some others show a decrease of the dependence for temperature above 35 degrees Celsius. We observe a similar pattern for the humidity feature: some of the ICE lines show a sharp decrease when the humidity is above 80%.

The sklearn.inspection module’s PartialDependenceDisplay.from_estimator convenience function can be used to create ICE plots by setting kind='individual'. In the example below, we show how to create a grid of ICE plots:

In ICE plots it might not be easy to see the average effect of the input feature of interest. Hence, it is recommended to use ICE plots alongside PDPs. They can be plotted together with kind='both'.

If there are too many lines in an ICE plot, it can be difficult to see differences between individual samples and interpret the model. Centering the ICE at the first value on the x-axis, produces centered Individual Conditional Expectation (cICE) plots [G2015]. This puts emphasis on the divergence of individual conditional expectations from the mean line, thus making it easier to explore heterogeneous relationships. cICE plots can be plotted by setting centered=True:

Let \(X_S\) be the set of input features of interest (i.e. the features parameter) and let \(X_C\) be its complement.

The partial dependence of the response \(f\) at a point \(x_S\) is defined as:

where \(f(x_S, x_C)\) is the response function (predict, predict_proba or decision_function) for a given sample whose values are defined by \(x_S\) for the features in \(X_S\), and by \(x_C\) for the features in \(X_C\). Note that \(x_S\) and \(x_C\) may be tuples.

Computing this integral for various values of \(x_S\) produces a PDP plot as above. An ICE line is defined as a single \(f(x_{S}, x_{C}^{(i)})\) evaluated at \(x_{S}\).

There are two main methods to approximate the integral above, namely the 'brute' and 'recursion' methods. The method parameter controls which method to use.

The 'brute' method is a generic method that works with any estimator. Note that computing ICE plots is only supported with the 'brute' method. It approximates the above integral by computing an average over the data X:

where \(x_C^{(i)}\) is the value of the i-th sample for the features in \(X_C\). For each value of \(x_S\), this method requires a full pass over the dataset X which is computationally intensive.

Each of the \(f(x_{S}, x_{C}^{(i)})\) corresponds to one ICE line evaluated at \(x_{S}\). Computing this for multiple values of \(x_{S}\), one obtains a full ICE line. As one can see, the average of the ICE lines corresponds to the partial dependence line.

The 'recursion' method is faster than the 'brute' method, but it is only supported for PDP plots by some tree-based estimators. It is computed as follows. For a given point \(x_S\), a weighted tree traversal is performed: if a split node involves an input feature of interest, the corresponding left or right branch is followed; otherwise both branches are followed, each branch being weighted by the fraction of training samples that entered that branch. Finally, the partial dependence is given by a weighted average of all the visited leaves’ values.

With the 'brute' method, the parameter X is used both for generating the grid of values \(x_S\) and the complement feature values \(x_C\). However with the ‘recursion’ method, X is only used for the grid values: implicitly, the \(x_C\) values are those of the training data.

By default, the 'recursion' method is used for plotting PDPs on tree-based estimators that support it, and ‘brute’ is used for the rest.

While both methods should be close in general, they might differ in some specific settings. The 'brute' method assumes the existence of the data points \((x_S, x_C^{(i)})\). When the features are correlated, such artificial samples may have a very low probability mass. The 'brute' and 'recursion' methods will likely disagree regarding the value of the partial dependence, because they will treat these unlikely samples differently. Remember, however, that the primary assumption for interpreting PDPs is that the features should be independent.

Partial Dependence and Individual Conditional Expectation Plots

For classification, the target response may be the probability of a class (the positive class for binary classification), or the decision function.

T. Hastie, R. Tibshirani and J. Friedman, The Elements of Statistical Learning, Second Edition, Section 10.13.2, Springer, 2009.

C. Molnar, Interpretable Machine Learning, Section 5.1, 2019.

A. Goldstein, A. Kapelner, J. Bleich, and E. Pitkin, “Peeking Inside the Black Box: Visualizing Statistical Learning With Plots of Individual Conditional Expectation” Journal of Computational and Graphical Statistics, 24(1): 44-65, Springer, 2015.

**Examples:**

Example 1 (sql):
```sql
>>> from sklearn.datasets import make_hastie_10_2
>>> from sklearn.ensemble import GradientBoostingClassifier
>>> from sklearn.inspection import PartialDependenceDisplay

>>> X, y = make_hastie_10_2(random_state=0)
>>> clf = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0,
...     max_depth=1, random_state=0).fit(X, y)
>>> features = [0, 1, (0, 1)]
>>> PartialDependenceDisplay.from_estimator(clf, X, features)
<...>
```

Example 2 (sql):
```sql
>>> from sklearn.datasets import load_iris
>>> iris = load_iris()
>>> mc_clf = GradientBoostingClassifier(n_estimators=10,
...     max_depth=1).fit(iris.data, iris.target)
>>> features = [3, 2, (3, 2)]
>>> PartialDependenceDisplay.from_estimator(mc_clf, X, features, target=0)
<...>
```

Example 3 (sql):
```sql
>>> from sklearn.inspection import partial_dependence

>>> results = partial_dependence(clf, X, [0])
>>> results["average"]
array([[ 2.466...,  2.466..., ...
>>> results["grid_values"]
[array([-1.624..., -1.592..., ...
```

Example 4 (sql):
```sql
>>> from sklearn.datasets import make_hastie_10_2
>>> from sklearn.ensemble import GradientBoostingClassifier
>>> from sklearn.inspection import PartialDependenceDisplay
```

---

## VarianceThreshold#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.VarianceThreshold.html

**Contents:**
- VarianceThreshold#

Feature selector that removes all low-variance features.

This feature selection algorithm looks only at the features (X), not the desired outputs (y), and can thus be used for unsupervised learning.

Read more in the User Guide.

Features with a training-set variance lower than this threshold will be removed. The default is to keep all features with non-zero variance, i.e. remove the features that have the same value in all samples.

Variances of individual features.

Number of features seen during fit.

Added in version 0.24.

Names of features seen during fit. Defined only when X has feature names that are all strings.

Added in version 1.0.

Meta-transformer for selecting features based on importance weights.

Select features according to a percentile of the highest scores.

Transformer that performs Sequential Feature Selection.

Allows NaN in the input. Raises ValueError if no feature in X meets the variance threshold.

The following dataset has integer features, two of which are the same in every sample. These are removed with the default setting for threshold:

Learn empirical variances from X.

Data from which to compute variances, where n_samples is the number of samples and n_features is the number of features.

Ignored. This parameter exists only for compatibility with sklearn.pipeline.Pipeline.

Returns the instance itself.

Fit to data, then transform it.

Fits transformer to X and y with optional parameters fit_params and returns a transformed version of X.

Target values (None for unsupervised transformations).

Additional fit parameters. Pass only if the estimator accepts additional params in its fit method.

Mask feature names according to selected features.

If input_features is None, then feature_names_in_ is used as feature names in. If feature_names_in_ is not defined, then the following input feature names are generated: ["x0", "x1", ..., "x(n_features_in_ - 1)"].

If input_features is an array-like, then input_features must match feature_names_in_ if feature_names_in_ is defined.

Transformed feature names.

Get metadata routing of this object.

Please check User Guide on how the routing mechanism works.

A MetadataRequest encapsulating routing information.

Get parameters for this estimator.

If True, will return the parameters for this estimator and contained subobjects that are estimators.

Parameter names mapped to their values.

Get a mask, or integer index, of the features selected.

If True, the return value will be an array of integers, rather than a boolean mask.

An index that selects the retained features from a feature vector. If indices is False, this is a boolean array of shape [# input features], in which an element is True iff its corresponding feature is selected for retention. If indices is True, this is an integer array of shape [# output features] whose values are indices into the input feature vector.

Reverse the transformation operation.

X with columns of zeros inserted where features would have been removed by transform.

Set output container.

See Introducing the set_output API for an example on how to use the API.

Configure output of transform and fit_transform.

"default": Default output format of a transformer

"pandas": DataFrame output

"polars": Polars output

None: Transform configuration is unchanged

Added in version 1.4: "polars" option was added.

Set the parameters of this estimator.

The method works on simple estimators as well as on nested objects (such as Pipeline). The latter have parameters of the form <component>__<parameter> so that it’s possible to update each component of a nested object.

Estimator parameters.

Reduce X to the selected features.

The input samples with only the selected features.

**Examples:**

Example 1 (sql):
```sql
>>> from sklearn.feature_selection import VarianceThreshold
>>> X = [[0, 2, 0, 3], [0, 1, 4, 3], [0, 1, 1, 3]]
>>> selector = VarianceThreshold()
>>> selector.fit_transform(X)
array([[2, 0],
       [1, 4],
       [1, 1]])
```

---

## SequentialFeatureSelector#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SequentialFeatureSelector.html

**Contents:**
- SequentialFeatureSelector#
- Gallery examples#

Transformer that performs Sequential Feature Selection.

This Sequential Feature Selector adds (forward selection) or removes (backward selection) features to form a feature subset in a greedy fashion. At each stage, this estimator chooses the best feature to add or remove based on the cross-validation score of an estimator. In the case of unsupervised learning, this Sequential Feature Selector looks only at the features (X), not the desired outputs (y).

Read more in the User Guide.

Added in version 0.24.

An unfitted estimator.

If "auto", the behaviour depends on the tol parameter:

if tol is not None, then features are selected while the score change does not exceed tol.

otherwise, half of the features are selected.

If integer, the parameter is the absolute number of features to select. If float between 0 and 1, it is the fraction of features to select.

Added in version 1.1: The option "auto" was added in version 1.1.

Changed in version 1.3: The default changed from "warn" to "auto" in 1.3.

If the score is not incremented by at least tol between two consecutive feature additions or removals, stop adding or removing.

tol can be negative when removing features using direction="backward". tol is required to be strictly positive when doing forward selection. It can be useful to reduce the number of features at the cost of a small decrease in the score.

tol is enabled only when n_features_to_select is "auto".

Added in version 1.1.

Whether to perform forward selection or backward selection.

Scoring method to use for cross-validation. Options:

str: see String name scorers for options.

callable: a scorer callable object (e.g., function) with signature scorer(estimator, X, y) that returns a single value. See Callable scorers for details.

None: the estimator’s default evaluation criterion is used.

Determines the cross-validation splitting strategy. Possible inputs for cv are:

None, to use the default 5-fold cross validation,

integer, to specify the number of folds in a (Stratified)KFold,

An iterable yielding (train, test) splits as arrays of indices.

For integer/None inputs, if the estimator is a classifier and y is either binary or multiclass, StratifiedKFold is used. In all other cases, KFold is used. These splitters are instantiated with shuffle=False so the splits will be the same across calls.

Refer User Guide for the various cross-validation strategies that can be used here.

Number of jobs to run in parallel. When evaluating a new feature to add or remove, the cross-validation procedure is parallel over the folds. None means 1 unless in a joblib.parallel_backend context. -1 means using all processors. See Glossary for more details.

Number of features seen during fit. Only defined if the underlying estimator exposes such an attribute when fit.

Added in version 0.24.

Names of features seen during fit. Defined only when X has feature names that are all strings.

Added in version 1.0.

The number of features that were selected.

The mask of selected features.

Univariate feature selector with configurable strategy.

Recursive feature elimination based on importance weights.

Recursive feature elimination based on importance weights, with automatic selection of the number of features.

Feature selection based on thresholds of importance weights.

Learn the features to select from X.

Training vectors, where n_samples is the number of samples and n_features is the number of predictors.

Target values. This parameter may be ignored for unsupervised learning.

Parameters to be passed to the underlying estimator, cv and scorer objects.

Added in version 1.6: Only available if enable_metadata_routing=True, which can be set by using sklearn.set_config(enable_metadata_routing=True). See Metadata Routing User Guide for more details.

Returns the instance itself.

Fit to data, then transform it.

Fits transformer to X and y with optional parameters fit_params and returns a transformed version of X.

Target values (None for unsupervised transformations).

Additional fit parameters. Pass only if the estimator accepts additional params in its fit method.

Mask feature names according to selected features.

If input_features is None, then feature_names_in_ is used as feature names in. If feature_names_in_ is not defined, then the following input feature names are generated: ["x0", "x1", ..., "x(n_features_in_ - 1)"].

If input_features is an array-like, then input_features must match feature_names_in_ if feature_names_in_ is defined.

Transformed feature names.

Get metadata routing of this object.

Please check User Guide on how the routing mechanism works.

Added in version 1.6.

A MetadataRouter encapsulating routing information.

Get parameters for this estimator.

If True, will return the parameters for this estimator and contained subobjects that are estimators.

Parameter names mapped to their values.

Get a mask, or integer index, of the features selected.

If True, the return value will be an array of integers, rather than a boolean mask.

An index that selects the retained features from a feature vector. If indices is False, this is a boolean array of shape [# input features], in which an element is True iff its corresponding feature is selected for retention. If indices is True, this is an integer array of shape [# output features] whose values are indices into the input feature vector.

Reverse the transformation operation.

X with columns of zeros inserted where features would have been removed by transform.

Set output container.

See Introducing the set_output API for an example on how to use the API.

Configure output of transform and fit_transform.

"default": Default output format of a transformer

"pandas": DataFrame output

"polars": Polars output

None: Transform configuration is unchanged

Added in version 1.4: "polars" option was added.

Set the parameters of this estimator.

The method works on simple estimators as well as on nested objects (such as Pipeline). The latter have parameters of the form <component>__<parameter> so that it’s possible to update each component of a nested object.

Estimator parameters.

Reduce X to the selected features.

The input samples with only the selected features.

Model-based and sequential feature selection

Release Highlights for scikit-learn 0.24

**Examples:**

Example 1 (csharp):
```csharp
>>> from sklearn.feature_selection import SequentialFeatureSelector
>>> from sklearn.neighbors import KNeighborsClassifier
>>> from sklearn.datasets import load_iris
>>> X, y = load_iris(return_X_y=True)
>>> knn = KNeighborsClassifier(n_neighbors=3)
>>> sfs = SequentialFeatureSelector(knn, n_features_to_select=3)
>>> sfs.fit(X, y)
SequentialFeatureSelector(estimator=KNeighborsClassifier(n_neighbors=3),
                          n_features_to_select=3)
>>> sfs.get_support()
array([ True, False,  True,  True])
>>> sfs.transform(X).shape
(150, 3)
```

---

## PLSSVD#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.cross_decomposition.PLSSVD.html

**Contents:**
- PLSSVD#

Partial Least Square SVD.

This transformer simply performs an SVD on the cross-covariance matrix X'y. It is able to project both the training data X and the targets y. The training data X is projected on the left singular vectors, while the targets are projected on the right singular vectors.

Read more in the User Guide.

Added in version 0.8.

The number of components to keep. Should be in [1, min(n_samples, n_features, n_targets)].

Whether to scale X and y.

Whether to copy X and y in fit before applying centering, and potentially scaling. If False, these operations will be done inplace, modifying both arrays.

The left singular vectors of the SVD of the cross-covariance matrix. Used to project X in transform.

The right singular vectors of the SVD of the cross-covariance matrix. Used to project X in transform.

Number of features seen during fit.

Names of features seen during fit. Defined only when X has feature names that are all strings.

Added in version 1.0.

Partial Least Squares transformer and regressor.

Canonical Correlation Analysis.

Learn and apply the dimensionality reduction.

The transformed data X_transformed if y is not None, (X_transformed, y_transformed) otherwise.

Get output feature names for transformation.

The feature names out will prefixed by the lowercased class name. For example, if the transformer outputs 3 features, then the feature names out are: ["class_name0", "class_name1", "class_name2"].

Only used to validate feature names with the names seen in fit.

Transformed feature names.

Get metadata routing of this object.

Please check User Guide on how the routing mechanism works.

A MetadataRequest encapsulating routing information.

Get parameters for this estimator.

If True, will return the parameters for this estimator and contained subobjects that are estimators.

Parameter names mapped to their values.

Set output container.

See Introducing the set_output API for an example on how to use the API.

Configure output of transform and fit_transform.

"default": Default output format of a transformer

"pandas": DataFrame output

"polars": Polars output

None: Transform configuration is unchanged

Added in version 1.4: "polars" option was added.

Set the parameters of this estimator.

The method works on simple estimators as well as on nested objects (such as Pipeline). The latter have parameters of the form <component>__<parameter> so that it’s possible to update each component of a nested object.

Estimator parameters.

Apply the dimensionality reduction.

Samples to be transformed.

The transformed data X_transformed if y is not None, (X_transformed, y_transformed) otherwise.

**Examples:**

Example 1 (csharp):
```csharp
>>> import numpy as np
>>> from sklearn.cross_decomposition import PLSSVD
>>> X = np.array([[0., 0., 1.],
...               [1., 0., 0.],
...               [2., 2., 2.],
...               [2., 5., 4.]])
>>> y = np.array([[0.1, -0.2],
...               [0.9, 1.1],
...               [6.2, 5.9],
...               [11.9, 12.3]])
>>> pls = PLSSVD(n_components=2).fit(X, y)
>>> X_c, y_c = pls.transform(X, y)
>>> X_c.shape, y_c.shape
((4, 2), (4, 2))
```

---

## LocallyLinearEmbedding#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.manifold.LocallyLinearEmbedding.html

**Contents:**
- LocallyLinearEmbedding#
- Gallery examples#

Locally Linear Embedding.

Read more in the User Guide.

Number of neighbors to consider for each point.

Number of coordinates for the manifold.

Regularization constant, multiplies the trace of the local covariance matrix of the distances.

The solver used to compute the eigenvectors. The available options are:

'auto' : algorithm will attempt to choose the best method for input data.

'arpack' : use arnoldi iteration in shift-invert mode. For this method, M may be a dense matrix, sparse matrix, or general linear operator.

'dense' : use standard dense matrix operations for the eigenvalue decomposition. For this method, M must be an array or matrix type. This method should be avoided for large problems.

ARPACK can be unstable for some problems. It is best to try several random seeds in order to check results.

Tolerance for ‘arpack’ method Not used if eigen_solver==’dense’.

Maximum number of iterations for the arpack solver. Not used if eigen_solver==’dense’.

standard: use the standard locally linear embedding algorithm. see reference [1]

hessian: use the Hessian eigenmap method. This method requires n_neighbors > n_components * (1 + (n_components + 1) / 2. see reference [2]

modified: use the modified locally linear embedding algorithm. see reference [3]

ltsa: use local tangent space alignment algorithm. see reference [4]

Tolerance for Hessian eigenmapping method. Only used if method == 'hessian'.

Tolerance for modified LLE method. Only used if method == 'modified'.

Algorithm to use for nearest neighbors search, passed to NearestNeighbors instance.

Determines the random number generator when eigen_solver == ‘arpack’. Pass an int for reproducible results across multiple function calls. See Glossary.

The number of parallel jobs to run. None means 1 unless in a joblib.parallel_backend context. -1 means using all processors. See Glossary for more details.

Stores the embedding vectors

Reconstruction error associated with embedding_

Number of features seen during fit.

Added in version 0.24.

Names of features seen during fit. Defined only when X has feature names that are all strings.

Added in version 1.0.

Stores nearest neighbors instance, including BallTree or KDtree if applicable.

Spectral embedding for non-linear dimensionality reduction.

Distributed Stochastic Neighbor Embedding.

Roweis, S. & Saul, L. Nonlinear dimensionality reduction by locally linear embedding. Science 290:2323 (2000).

Donoho, D. & Grimes, C. Hessian eigenmaps: Locally linear embedding techniques for high-dimensional data. Proc Natl Acad Sci U S A. 100:5591 (2003).

Zhang, Z. & Wang, J. MLLE: Modified Locally Linear Embedding Using Multiple Weights.

Zhang, Z. & Zha, H. Principal manifolds and nonlinear dimensionality reduction via tangent space alignment. Journal of Shanghai Univ. 8:406 (2004)

Compute the embedding vectors for data X.

Not used, present here for API consistency by convention.

Fitted LocallyLinearEmbedding class instance.

Compute the embedding vectors for data X and transform X.

Not used, present here for API consistency by convention.

Returns the instance itself.

Get output feature names for transformation.

The feature names out will prefixed by the lowercased class name. For example, if the transformer outputs 3 features, then the feature names out are: ["class_name0", "class_name1", "class_name2"].

Only used to validate feature names with the names seen in fit.

Transformed feature names.

Get metadata routing of this object.

Please check User Guide on how the routing mechanism works.

A MetadataRequest encapsulating routing information.

Get parameters for this estimator.

If True, will return the parameters for this estimator and contained subobjects that are estimators.

Parameter names mapped to their values.

Set output container.

See Introducing the set_output API for an example on how to use the API.

Configure output of transform and fit_transform.

"default": Default output format of a transformer

"pandas": DataFrame output

"polars": Polars output

None: Transform configuration is unchanged

Added in version 1.4: "polars" option was added.

Set the parameters of this estimator.

The method works on simple estimators as well as on nested objects (such as Pipeline). The latter have parameters of the form <component>__<parameter> so that it’s possible to update each component of a nested object.

Estimator parameters.

Transform new points into embedding space.

Returns the instance itself.

Because of scaling performed by this method, it is discouraged to use it together with methods that are not scale-invariant (like SVMs).

Visualizing the stock market structure

Comparison of Manifold Learning methods

Manifold learning on handwritten digits: Locally Linear Embedding, Isomap…

Manifold Learning methods on a severed sphere

**Examples:**

Example 1 (sql):
```sql
>>> from sklearn.datasets import load_digits
>>> from sklearn.manifold import LocallyLinearEmbedding
>>> X, _ = load_digits(return_X_y=True)
>>> X.shape
(1797, 64)
>>> embedding = LocallyLinearEmbedding(n_components=2)
>>> X_transformed = embedding.fit_transform(X[:100])
>>> X_transformed.shape
(100, 2)
```

---

## SelectFdr#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectFdr.html

**Contents:**
- SelectFdr#

Filter: Select the p-values for an estimated false discovery rate.

This uses the Benjamini-Hochberg procedure. alpha is an upper bound on the expected false discovery rate.

Read more in the User Guide.

Function taking two arrays X and y, and returning a pair of arrays (scores, pvalues). Default is f_classif (see below “See Also”). The default function only works with classification tasks.

The highest uncorrected p-value for features to keep.

p-values of feature scores.

Number of features seen during fit.

Added in version 0.24.

Names of features seen during fit. Defined only when X has feature names that are all strings.

Added in version 1.0.

ANOVA F-value between label/feature for classification tasks.

Mutual information for a discrete target.

Chi-squared stats of non-negative features for classification tasks.

F-value between label/feature for regression tasks.

Mutual information for a continuous target.

Select features based on percentile of the highest scores.

Select features based on the k highest scores.

Select features based on a false positive rate test.

Select features based on family-wise error rate.

Univariate feature selector with configurable mode.

https://en.wikipedia.org/wiki/False_discovery_rate

Run score function on (X, y) and get the appropriate features.

The training input samples.

The target values (class labels in classification, real numbers in regression). If the selector is unsupervised then y can be set to None.

Returns the instance itself.

Fit to data, then transform it.

Fits transformer to X and y with optional parameters fit_params and returns a transformed version of X.

Target values (None for unsupervised transformations).

Additional fit parameters. Pass only if the estimator accepts additional params in its fit method.

Mask feature names according to selected features.

If input_features is None, then feature_names_in_ is used as feature names in. If feature_names_in_ is not defined, then the following input feature names are generated: ["x0", "x1", ..., "x(n_features_in_ - 1)"].

If input_features is an array-like, then input_features must match feature_names_in_ if feature_names_in_ is defined.

Transformed feature names.

Get metadata routing of this object.

Please check User Guide on how the routing mechanism works.

A MetadataRequest encapsulating routing information.

Get parameters for this estimator.

If True, will return the parameters for this estimator and contained subobjects that are estimators.

Parameter names mapped to their values.

Get a mask, or integer index, of the features selected.

If True, the return value will be an array of integers, rather than a boolean mask.

An index that selects the retained features from a feature vector. If indices is False, this is a boolean array of shape [# input features], in which an element is True iff its corresponding feature is selected for retention. If indices is True, this is an integer array of shape [# output features] whose values are indices into the input feature vector.

Reverse the transformation operation.

X with columns of zeros inserted where features would have been removed by transform.

Set output container.

See Introducing the set_output API for an example on how to use the API.

Configure output of transform and fit_transform.

"default": Default output format of a transformer

"pandas": DataFrame output

"polars": Polars output

None: Transform configuration is unchanged

Added in version 1.4: "polars" option was added.

Set the parameters of this estimator.

The method works on simple estimators as well as on nested objects (such as Pipeline). The latter have parameters of the form <component>__<parameter> so that it’s possible to update each component of a nested object.

Estimator parameters.

Reduce X to the selected features.

The input samples with only the selected features.

**Examples:**

Example 1 (sql):
```sql
>>> from sklearn.datasets import load_breast_cancer
>>> from sklearn.feature_selection import SelectFdr, chi2
>>> X, y = load_breast_cancer(return_X_y=True)
>>> X.shape
(569, 30)
>>> X_new = SelectFdr(chi2, alpha=0.01).fit_transform(X, y)
>>> X_new.shape
(569, 16)
```

---

## KNeighborsClassifier#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html

**Contents:**
- KNeighborsClassifier#
- Gallery examples#

Classifier implementing the k-nearest neighbors vote.

Read more in the User Guide.

Number of neighbors to use by default for kneighbors queries.

Weight function used in prediction. Possible values:

‘uniform’ : uniform weights. All points in each neighborhood are weighted equally.

‘distance’ : weight points by the inverse of their distance. in this case, closer neighbors of a query point will have a greater influence than neighbors which are further away.

[callable] : a user-defined function which accepts an array of distances, and returns an array of the same shape containing the weights.

Refer to the example entitled Nearest Neighbors Classification showing the impact of the weights parameter on the decision boundary.

Algorithm used to compute the nearest neighbors:

‘ball_tree’ will use BallTree

‘kd_tree’ will use KDTree

‘brute’ will use a brute-force search.

‘auto’ will attempt to decide the most appropriate algorithm based on the values passed to fit method.

Note: fitting on sparse input will override the setting of this parameter, using brute force.

Leaf size passed to BallTree or KDTree. This can affect the speed of the construction and query, as well as the memory required to store the tree. The optimal value depends on the nature of the problem.

Power parameter for the Minkowski metric. When p = 1, this is equivalent to using manhattan_distance (l1), and euclidean_distance (l2) for p = 2. For arbitrary p, minkowski_distance (l_p) is used. This parameter is expected to be positive.

Metric to use for distance computation. Default is “minkowski”, which results in the standard Euclidean distance when p = 2. See the documentation of scipy.spatial.distance and the metrics listed in distance_metrics for valid metric values.

If metric is “precomputed”, X is assumed to be a distance matrix and must be square during fit. X may be a sparse graph, in which case only “nonzero” elements may be considered neighbors.

If metric is a callable function, it takes two arrays representing 1D vectors as inputs and must return one value indicating the distance between those vectors. This works for Scipy’s metrics, but is less efficient than passing the metric name as a string.

Additional keyword arguments for the metric function.

The number of parallel jobs to run for neighbors search. None means 1 unless in a joblib.parallel_backend context. -1 means using all processors. See Glossary for more details. Doesn’t affect fit method.

Class labels known to the classifier

The distance metric used. It will be same as the metric parameter or a synonym of it, e.g. ‘euclidean’ if the metric parameter set to ‘minkowski’ and p parameter set to 2.

Additional keyword arguments for the metric function. For most metrics will be same with metric_params parameter, but may also contain the p parameter value if the effective_metric_ attribute is set to ‘minkowski’.

Number of features seen during fit.

Added in version 0.24.

Names of features seen during fit. Defined only when X has feature names that are all strings.

Added in version 1.0.

Number of samples in the fitted data.

False when y’s shape is (n_samples, ) or (n_samples, 1) during fit otherwise True.

Classifier based on neighbors within a fixed radius.

Regression based on k-nearest neighbors.

Regression based on neighbors within a fixed radius.

Unsupervised learner for implementing neighbor searches.

See Nearest Neighbors in the online documentation for a discussion of the choice of algorithm and leaf_size.

Regarding the Nearest Neighbors algorithms, if it is found that two neighbors, neighbor k+1 and k, have identical distances but different labels, the results will depend on the ordering of the training data.

https://en.wikipedia.org/wiki/K-nearest_neighbor_algorithm

Fit the k-nearest neighbors classifier from the training dataset.

The fitted k-nearest neighbors classifier.

Get metadata routing of this object.

Please check User Guide on how the routing mechanism works.

A MetadataRequest encapsulating routing information.

Get parameters for this estimator.

If True, will return the parameters for this estimator and contained subobjects that are estimators.

Parameter names mapped to their values.

Find the K-neighbors of a point.

Returns indices of and distances to the neighbors of each point.

The query point or points. If not provided, neighbors of each indexed point are returned. In this case, the query point is not considered its own neighbor.

Number of neighbors required for each sample. The default is the value passed to the constructor.

Whether or not to return the distances.

Array representing the lengths to points, only present if return_distance=True.

Indices of the nearest points in the population matrix.

In the following example, we construct a NearestNeighbors class from an array representing our data set and ask who’s the closest point to [1,1,1]

As you can see, it returns [[0.5]], and [[2]], which means that the element is at distance 0.5 and is the third element of samples (indexes start at 0). You can also query for multiple points:

Compute the (weighted) graph of k-Neighbors for points in X.

The query point or points. If not provided, neighbors of each indexed point are returned. In this case, the query point is not considered its own neighbor. For metric='precomputed' the shape should be (n_queries, n_indexed). Otherwise the shape should be (n_queries, n_features).

Number of neighbors for each sample. The default is the value passed to the constructor.

Type of returned matrix: ‘connectivity’ will return the connectivity matrix with ones and zeros, in ‘distance’ the edges are distances between points, type of distance depends on the selected metric parameter in NearestNeighbors class.

n_samples_fit is the number of samples in the fitted data. A[i, j] gives the weight of the edge connecting i to j. The matrix is of CSR format.

Compute the (weighted) graph of Neighbors for points in X.

Predict the class labels for the provided data.

Test samples. If None, predictions for all indexed points are returned; in this case, points are not considered their own neighbors.

Class labels for each data sample.

Return probability estimates for the test data X.

Test samples. If None, predictions for all indexed points are returned; in this case, points are not considered their own neighbors.

The class probabilities of the input samples. Classes are ordered by lexicographic order.

Return the mean accuracy on the given test data and labels.

In multi-label classification, this is the subset accuracy which is a harsh metric since you require for each sample that each label set be correctly predicted.

Test samples. If None, predictions for all indexed points are used; in this case, points are not considered their own neighbors. This means that knn.fit(X, y).score(None, y) implicitly performs a leave-one-out cross-validation procedure and is equivalent to cross_val_score(knn, X, y, cv=LeaveOneOut()) but typically much faster.

Mean accuracy of self.predict(X) w.r.t. y.

Set the parameters of this estimator.

The method works on simple estimators as well as on nested objects (such as Pipeline). The latter have parameters of the form <component>__<parameter> so that it’s possible to update each component of a nested object.

Estimator parameters.

Configure whether metadata should be requested to be passed to the score method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to score if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to score.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Added in version 1.3.

Metadata routing for sample_weight parameter in score.

Classifier comparison

Caching nearest neighbors

Nearest Neighbors Classification

Comparing Nearest Neighbors with and without Neighborhood Components Analysis

Dimensionality Reduction with Neighborhood Components Analysis

Importance of Feature Scaling

Release Highlights for scikit-learn 0.24

Classification of text documents using sparse features

**Examples:**

Example 1 (python):
```python
>>> X = [[0], [1], [2], [3]]
>>> y = [0, 0, 1, 1]
>>> from sklearn.neighbors import KNeighborsClassifier
>>> neigh = KNeighborsClassifier(n_neighbors=3)
>>> neigh.fit(X, y)
KNeighborsClassifier(...)
>>> print(neigh.predict([[1.1]]))
[0]
>>> print(neigh.predict_proba([[0.9]]))
[[0.666 0.333]]
```

Example 2 (python):
```python
>>> samples = [[0., 0., 0.], [0., .5, 0.], [1., 1., .5]]
>>> from sklearn.neighbors import NearestNeighbors
>>> neigh = NearestNeighbors(n_neighbors=1)
>>> neigh.fit(samples)
NearestNeighbors(n_neighbors=1)
>>> print(neigh.kneighbors([[1., 1., 1.]]))
(array([[0.5]]), array([[2]]))
```

Example 3 (json):
```json
>>> X = [[0., 1., 0.], [1., 0., 1.]]
>>> neigh.kneighbors(X, return_distance=False)
array([[1],
       [2]]...)
```

Example 4 (sql):
```sql
>>> X = [[0], [3], [1]]
>>> from sklearn.neighbors import NearestNeighbors
>>> neigh = NearestNeighbors(n_neighbors=2)
>>> neigh.fit(X)
NearestNeighbors(n_neighbors=2)
>>> A = neigh.kneighbors_graph(X)
>>> A.toarray()
array([[1., 0., 1.],
       [0., 1., 1.],
       [1., 0., 1.]])
```

---

## KMeans#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html

**Contents:**
- KMeans#
- Gallery examples#

Read more in the User Guide.

The number of clusters to form as well as the number of centroids to generate.

For an example of how to choose an optimal value for n_clusters refer to Selecting the number of clusters with silhouette analysis on KMeans clustering.

Method for initialization:

‘k-means++’ : selects initial cluster centroids using sampling based on an empirical probability distribution of the points’ contribution to the overall inertia. This technique speeds up convergence. The algorithm implemented is “greedy k-means++”. It differs from the vanilla k-means++ by making several trials at each sampling step and choosing the best centroid among them.

‘random’: choose n_clusters observations (rows) at random from data for the initial centroids.

If an array is passed, it should be of shape (n_clusters, n_features) and gives the initial centers.

If a callable is passed, it should take arguments X, n_clusters and a random state and return an initialization.

For an example of how to use the different init strategies, see A demo of K-Means clustering on the handwritten digits data.

For an evaluation of the impact of initialization, see the example Empirical evaluation of the impact of k-means initialization.

Number of times the k-means algorithm is run with different centroid seeds. The final results is the best output of n_init consecutive runs in terms of inertia. Several runs are recommended for sparse high-dimensional problems (see Clustering sparse data with k-means).

When n_init='auto', the number of runs depends on the value of init: 10 if using init='random' or init is a callable; 1 if using init='k-means++' or init is an array-like.

Added in version 1.2: Added ‘auto’ option for n_init.

Changed in version 1.4: Default value for n_init changed to 'auto'.

Maximum number of iterations of the k-means algorithm for a single run.

Relative tolerance with regards to Frobenius norm of the difference in the cluster centers of two consecutive iterations to declare convergence.

Determines random number generation for centroid initialization. Use an int to make the randomness deterministic. See Glossary.

When pre-computing distances it is more numerically accurate to center the data first. If copy_x is True (default), then the original data is not modified. If False, the original data is modified, and put back before the function returns, but small numerical differences may be introduced by subtracting and then adding the data mean. Note that if the original data is not C-contiguous, a copy will be made even if copy_x is False. If the original data is sparse, but not in CSR format, a copy will be made even if copy_x is False.

K-means algorithm to use. The classical EM-style algorithm is "lloyd". The "elkan" variation can be more efficient on some datasets with well-defined clusters, by using the triangle inequality. However it’s more memory intensive due to the allocation of an extra array of shape (n_samples, n_clusters).

Changed in version 0.18: Added Elkan algorithm

Changed in version 1.1: Renamed “full” to “lloyd”, and deprecated “auto” and “full”. Changed “auto” to use “lloyd” instead of “elkan”.

Coordinates of cluster centers. If the algorithm stops before fully converging (see tol and max_iter), these will not be consistent with labels_.

Sum of squared distances of samples to their closest cluster center, weighted by the sample weights if provided.

Number of iterations run.

Number of features seen during fit.

Added in version 0.24.

Names of features seen during fit. Defined only when X has feature names that are all strings.

Added in version 1.0.

Alternative online implementation that does incremental updates of the centers positions using mini-batches. For large scale learning (say n_samples > 10k) MiniBatchKMeans is probably much faster than the default batch implementation.

The k-means problem is solved using either Lloyd’s or Elkan’s algorithm.

The average complexity is given by O(k n T), where n is the number of samples and T is the number of iteration.

The worst case complexity is given by O(n^(k+2/p)) with n = n_samples, p = n_features. Refer to “How slow is the k-means method?” D. Arthur and S. Vassilvitskii - SoCG2006. for more details.

In practice, the k-means algorithm is very fast (one of the fastest clustering algorithms available), but it falls in local minima. That’s why it can be useful to restart it several times.

If the algorithm stops before fully converging (because of tol or max_iter), labels_ and cluster_centers_ will not be consistent, i.e. the cluster_centers_ will not be the means of the points in each cluster. Also, the estimator will reassign labels_ after the last iteration to make labels_ consistent with predict on the training set.

For examples of common problems with K-Means and how to address them see Demonstration of k-means assumptions.

For a demonstration of how K-Means can be used to cluster text documents see Clustering text documents using k-means.

For a comparison between K-Means and MiniBatchKMeans refer to example Comparison of the K-Means and MiniBatchKMeans clustering algorithms.

For a comparison between K-Means and BisectingKMeans refer to example Bisecting K-Means and Regular K-Means Performance Comparison.

Compute k-means clustering.

Training instances to cluster. It must be noted that the data will be converted to C ordering, which will cause a memory copy if the given data is not C-contiguous. If a sparse matrix is passed, a copy will be made if it’s not in CSR format.

Not used, present here for API consistency by convention.

The weights for each observation in X. If None, all observations are assigned equal weight. sample_weight is not used during initialization if init is a callable or a user provided array.

Added in version 0.20.

Compute cluster centers and predict cluster index for each sample.

Convenience method; equivalent to calling fit(X) followed by predict(X).

New data to transform.

Not used, present here for API consistency by convention.

The weights for each observation in X. If None, all observations are assigned equal weight.

Index of the cluster each sample belongs to.

Compute clustering and transform X to cluster-distance space.

Equivalent to fit(X).transform(X), but more efficiently implemented.

New data to transform.

Not used, present here for API consistency by convention.

The weights for each observation in X. If None, all observations are assigned equal weight.

X transformed in the new space.

Get output feature names for transformation.

The feature names out will prefixed by the lowercased class name. For example, if the transformer outputs 3 features, then the feature names out are: ["class_name0", "class_name1", "class_name2"].

Only used to validate feature names with the names seen in fit.

Transformed feature names.

Get metadata routing of this object.

Please check User Guide on how the routing mechanism works.

A MetadataRequest encapsulating routing information.

Get parameters for this estimator.

If True, will return the parameters for this estimator and contained subobjects that are estimators.

Parameter names mapped to their values.

Predict the closest cluster each sample in X belongs to.

In the vector quantization literature, cluster_centers_ is called the code book and each value returned by predict is the index of the closest code in the code book.

Index of the cluster each sample belongs to.

Opposite of the value of X on the K-means objective.

Not used, present here for API consistency by convention.

The weights for each observation in X. If None, all observations are assigned equal weight.

Opposite of the value of X on the K-means objective.

Configure whether metadata should be requested to be passed to the fit method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to fit if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to fit.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Added in version 1.3.

Metadata routing for sample_weight parameter in fit.

Set output container.

See Introducing the set_output API for an example on how to use the API.

Configure output of transform and fit_transform.

"default": Default output format of a transformer

"pandas": DataFrame output

"polars": Polars output

None: Transform configuration is unchanged

Added in version 1.4: "polars" option was added.

Set the parameters of this estimator.

The method works on simple estimators as well as on nested objects (such as Pipeline). The latter have parameters of the form <component>__<parameter> so that it’s possible to update each component of a nested object.

Estimator parameters.

Configure whether metadata should be requested to be passed to the score method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to score if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to score.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Added in version 1.3.

Metadata routing for sample_weight parameter in score.

Transform X to a cluster-distance space.

In the new space, each dimension is the distance to the cluster centers. Note that even if X is sparse, the array returned by transform will typically be dense.

New data to transform.

X transformed in the new space.

Bisecting K-Means and Regular K-Means Performance Comparison

Demonstration of k-means assumptions

A demo of K-Means clustering on the handwritten digits data

Selecting the number of clusters with silhouette analysis on KMeans clustering

Empirical evaluation of the impact of k-means initialization

Comparison of the K-Means and MiniBatchKMeans clustering algorithms

Release Highlights for scikit-learn 0.23

Release Highlights for scikit-learn 1.1

Clustering text documents using k-means

**Examples:**

Example 1 (sql):
```sql
>>> from sklearn.cluster import KMeans
>>> import numpy as np
>>> X = np.array([[1, 2], [1, 4], [1, 0],
...               [10, 2], [10, 4], [10, 0]])
>>> kmeans = KMeans(n_clusters=2, random_state=0, n_init="auto").fit(X)
>>> kmeans.labels_
array([1, 1, 1, 0, 0, 0], dtype=int32)
>>> kmeans.predict([[0, 0], [12, 3]])
array([1, 0], dtype=int32)
>>> kmeans.cluster_centers_
array([[10.,  2.],
       [ 1.,  2.]])
```

---

## HistGradientBoostingRegressor#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.HistGradientBoostingRegressor.html

**Contents:**
- HistGradientBoostingRegressor#
- Gallery examples#

Histogram-based Gradient Boosting Regression Tree.

This estimator is much faster than GradientBoostingRegressor for big datasets (n_samples >= 10 000).

This estimator has native support for missing values (NaNs). During training, the tree grower learns at each split point whether samples with missing values should go to the left or right child, based on the potential gain. When predicting, samples with missing values are assigned to the left or right child consequently. If no missing values were encountered for a given feature during training, then samples with missing values are mapped to whichever child has the most samples. See Features in Histogram Gradient Boosting Trees for a usecase example of this feature.

This implementation is inspired by LightGBM.

Read more in the User Guide.

Added in version 0.21.

The loss function to use in the boosting process. Note that the “squared error”, “gamma” and “poisson” losses actually implement “half least squares loss”, “half gamma deviance” and “half poisson deviance” to simplify the computation of the gradient. Furthermore, “gamma” and “poisson” losses internally use a log-link, “gamma” requires y > 0 and “poisson” requires y >= 0. “quantile” uses the pinball loss.

Changed in version 0.23: Added option ‘poisson’.

Changed in version 1.1: Added option ‘quantile’.

Changed in version 1.3: Added option ‘gamma’.

If loss is “quantile”, this parameter specifies which quantile to be estimated and must be between 0 and 1.

The learning rate, also known as shrinkage. This is used as a multiplicative factor for the leaves values. Use 1 for no shrinkage.

The maximum number of iterations of the boosting process, i.e. the maximum number of trees.

The maximum number of leaves for each tree. Must be strictly greater than 1. If None, there is no maximum limit.

The maximum depth of each tree. The depth of a tree is the number of edges to go from the root to the deepest leaf. Depth isn’t constrained by default.

The minimum number of samples per leaf. For small datasets with less than a few hundred samples, it is recommended to lower this value since only very shallow trees would be built.

The L2 regularization parameter penalizing leaves with small hessians. Use 0 for no regularization (default).

Proportion of randomly chosen features in each and every node split. This is a form of regularization, smaller values make the trees weaker learners and might prevent overfitting. If interaction constraints from interaction_cst are present, only allowed features are taken into account for the subsampling.

Added in version 1.4.

The maximum number of bins to use for non-missing values. Before training, each feature of the input array X is binned into integer-valued bins, which allows for a much faster training stage. Features with a small number of unique values may use less than max_bins bins. In addition to the max_bins bins, one more bin is always reserved for missing values. Must be no larger than 255.

Indicates the categorical features.

None : no feature will be considered categorical.

boolean array-like : boolean mask indicating categorical features.

integer array-like : integer indices indicating categorical features.

str array-like: names of categorical features (assuming the training data has feature names).

"from_dtype": dataframe columns with dtype “category” are considered to be categorical features. The input must be an object exposing a __dataframe__ method such as pandas or polars DataFrames to use this feature.

For each categorical feature, there must be at most max_bins unique categories. Negative values for categorical features encoded as numeric dtypes are treated as missing values. All categorical values are converted to floating point numbers. This means that categorical values of 1.0 and 1 are treated as the same category.

Read more in the User Guide and Categorical Feature Support in Gradient Boosting.

Added in version 0.24.

Changed in version 1.2: Added support for feature names.

Changed in version 1.4: Added "from_dtype" option.

Changed in version 1.6: The default value changed from None to "from_dtype".

Monotonic constraint to enforce on each feature are specified using the following integer values:

1: monotonic increase

-1: monotonic decrease

If a dict with str keys, map feature to monotonic constraints by name. If an array, the features are mapped to constraints by position. See Using feature names to specify monotonic constraints for a usage example.

Read more in the User Guide.

Added in version 0.23.

Changed in version 1.2: Accept dict of constraints with feature names as keys.

Specify interaction constraints, the sets of features which can interact with each other in child node splits.

Each item specifies the set of feature indices that are allowed to interact with each other. If there are more features than specified in these constraints, they are treated as if they were specified as an additional set.

The strings “pairwise” and “no_interactions” are shorthands for allowing only pairwise or no interactions, respectively.

For instance, with 5 features in total, interaction_cst=[{0, 1}] is equivalent to interaction_cst=[{0, 1}, {2, 3, 4}], and specifies that each branch of a tree will either only split on features 0 and 1 or only split on features 2, 3 and 4.

See this example on how to use interaction_cst.

Added in version 1.2.

When set to True, reuse the solution of the previous call to fit and add more estimators to the ensemble. For results to be valid, the estimator should be re-trained on the same data only. See the Glossary.

If ‘auto’, early stopping is enabled if the sample size is larger than 10000 or if X_val and y_val are passed to fit. If True, early stopping is enabled, otherwise early stopping is disabled.

Added in version 0.23.

Scoring method to use for early stopping. Only used if early_stopping is enabled. Options:

str: see String name scorers for options.

callable: a scorer callable object (e.g., function) with signature scorer(estimator, X, y). See Callable scorers for details.

None: the coefficient of determination (\(R^2\)) is used.

‘loss’: early stopping is checked w.r.t the loss value.

Proportion (or absolute size) of training data to set aside as validation data for early stopping. If None, early stopping is done on the training data. The value is ignored if either early stopping is not performed, e.g. early_stopping=False, or if X_val and y_val are passed to fit.

Used to determine when to “early stop”. The fitting process is stopped when none of the last n_iter_no_change scores are better than the n_iter_no_change - 1 -th-to-last one, up to some tolerance. Only used if early stopping is performed.

The absolute tolerance to use when comparing scores during early stopping. The higher the tolerance, the more likely we are to early stop: higher tolerance means that it will be harder for subsequent iterations to be considered an improvement upon the reference score.

The verbosity level. If not zero, print some information about the fitting process. 1 prints only summary info, 2 prints info per iteration.

Pseudo-random number generator to control the subsampling in the binning process, and the train/validation data split if early stopping is enabled. Pass an int for reproducible output across multiple function calls. See Glossary.

Indicates whether early stopping is used during training.

Number of iterations of the boosting process.

The number of tree that are built at each iteration. For regressors, this is always 1.

The scores at each iteration on the training data. The first entry is the score of the ensemble before the first iteration. Scores are computed according to the scoring parameter. If scoring is not ‘loss’, scores are computed on a subset of at most 10 000 samples. Empty if no early stopping.

The scores at each iteration on the held-out validation data. The first entry is the score of the ensemble before the first iteration. Scores are computed according to the scoring parameter. Empty if no early stopping or if validation_fraction is None.

Boolean mask for the categorical features. None if there are no categorical features.

Number of features seen during fit.

Added in version 0.24.

Names of features seen during fit. Defined only when X has feature names that are all strings.

Added in version 1.0.

Exact gradient boosting method that does not scale as good on datasets with a large number of samples.

A decision tree regressor.

A meta-estimator that fits a number of decision tree regressors on various sub-samples of the dataset and uses averaging to improve the statistical performance and control over-fitting.

A meta-estimator that begins by fitting a regressor on the original dataset and then fits additional copies of the regressor on the same dataset but where the weights of instances are adjusted according to the error of the current prediction. As such, subsequent regressors focus more on difficult cases.

Fit the gradient boosting model.

Weights of training data.

Added in version 0.23.

Additional sample of features for validation used in early stopping. In a Pipeline, X_val can be transformed the same way as X with Pipeline(..., transform_input=["X_val"]).

Added in version 1.7.

Additional sample of target values for validation used in early stopping.

Added in version 1.7.

Additional weights for validation used in early stopping.

Added in version 1.7.

Get metadata routing of this object.

Please check User Guide on how the routing mechanism works.

A MetadataRequest encapsulating routing information.

Get parameters for this estimator.

If True, will return the parameters for this estimator and contained subobjects that are estimators.

Parameter names mapped to their values.

Predict values for X.

The predicted values.

Return coefficient of determination on test data.

The coefficient of determination, \(R^2\), is defined as \((1 - \frac{u}{v})\), where \(u\) is the residual sum of squares ((y_true - y_pred)** 2).sum() and \(v\) is the total sum of squares ((y_true - y_true.mean()) ** 2).sum(). The best possible score is 1.0 and it can be negative (because the model can be arbitrarily worse). A constant model that always predicts the expected value of y, disregarding the input features, would get a \(R^2\) score of 0.0.

Test samples. For some estimators this may be a precomputed kernel matrix or a list of generic objects instead with shape (n_samples, n_samples_fitted), where n_samples_fitted is the number of samples used in the fitting for the estimator.

\(R^2\) of self.predict(X) w.r.t. y.

The \(R^2\) score used when calling score on a regressor uses multioutput='uniform_average' from version 0.23 to keep consistent with default value of r2_score. This influences the score method of all the multioutput regressors (except for MultiOutputRegressor).

Configure whether metadata should be requested to be passed to the fit method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to fit if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to fit.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Added in version 1.3.

Metadata routing for X_val parameter in fit.

Metadata routing for sample_weight parameter in fit.

Metadata routing for sample_weight_val parameter in fit.

Metadata routing for y_val parameter in fit.

Set the parameters of this estimator.

The method works on simple estimators as well as on nested objects (such as Pipeline). The latter have parameters of the form <component>__<parameter> so that it’s possible to update each component of a nested object.

Estimator parameters.

Configure whether metadata should be requested to be passed to the score method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to score if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to score.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Added in version 1.3.

Metadata routing for sample_weight parameter in score.

Predict regression target for each iteration.

This method allows monitoring (i.e. determine error on testing set) after each stage.

Added in version 0.24.

The predicted values of the input samples, for each iteration.

Time-related feature engineering

Model Complexity Influence

Lagged features for time series forecasting

Comparing Random Forests and Histogram Gradient Boosting models

Categorical Feature Support in Gradient Boosting

Prediction Intervals for Gradient Boosting Regression

Gradient Boosting regression

Features in Histogram Gradient Boosting Trees

Monotonic Constraints

Combine predictors using stacking

Partial Dependence and Individual Conditional Expectation Plots

Poisson regression and non-normal loss

Comparing Target Encoder with Other Encoders

Release Highlights for scikit-learn 0.23

Release Highlights for scikit-learn 0.24

Release Highlights for scikit-learn 1.0

Release Highlights for scikit-learn 1.1

Release Highlights for scikit-learn 1.2

Release Highlights for scikit-learn 1.3

**Examples:**

Example 1 (sql):
```sql
>>> from sklearn.ensemble import HistGradientBoostingRegressor
>>> from sklearn.datasets import load_diabetes
>>> X, y = load_diabetes(return_X_y=True)
>>> est = HistGradientBoostingRegressor().fit(X, y)
>>> est.score(X, y)
0.92...
```

---

## 1.1. Linear Models#

**URL:** https://scikit-learn.org/stable/modules/linear_model.html

**Contents:**
- 1.1. Linear Models#
- 1.1.1. Ordinary Least Squares#
  - 1.1.1.1. Non-Negative Least Squares#
  - 1.1.1.2. Ordinary Least Squares Complexity#
- 1.1.2. Ridge regression and classification#
  - 1.1.2.1. Regression#
  - 1.1.2.2. Classification#
  - 1.1.2.3. Ridge Complexity#
  - 1.1.2.4. Setting the regularization parameter: leave-one-out Cross-Validation#
- 1.1.3. Lasso#

The following are a set of methods intended for regression in which the target value is expected to be a linear combination of the features. In mathematical notation, if \(\hat{y}\) is the predicted value.

Across the module, we designate the vector \(w = (w_1, ..., w_p)\) as coef_ and \(w_0\) as intercept_.

To perform classification with generalized linear models, see Logistic regression.

LinearRegression fits a linear model with coefficients \(w = (w_1, ..., w_p)\) to minimize the residual sum of squares between the observed targets in the dataset, and the targets predicted by the linear approximation. Mathematically it solves a problem of the form:

LinearRegression takes in its fit method arguments X, y, sample_weight and stores the coefficients \(w\) of the linear model in its coef_ and intercept_ attributes:

The coefficient estimates for Ordinary Least Squares rely on the independence of the features. When features are correlated and some columns of the design matrix \(X\) have an approximately linear dependence, the design matrix becomes close to singular and as a result, the least-squares estimate becomes highly sensitive to random errors in the observed target, producing a large variance. This situation of multicollinearity can arise, for example, when data are collected without an experimental design.

Ordinary Least Squares and Ridge Regression

It is possible to constrain all the coefficients to be non-negative, which may be useful when they represent some physical or naturally non-negative quantities (e.g., frequency counts or prices of goods). LinearRegression accepts a boolean positive parameter: when set to True Non-Negative Least Squares are then applied.

Non-negative least squares

The least squares solution is computed using the singular value decomposition of \(X\). If \(X\) is a matrix of shape (n_samples, n_features) this method has a cost of \(O(n_{\text{samples}} n_{\text{features}}^2)\), assuming that \(n_{\text{samples}} \geq n_{\text{features}}\).

Ridge regression addresses some of the problems of Ordinary Least Squares by imposing a penalty on the size of the coefficients. The ridge coefficients minimize a penalized residual sum of squares:

The complexity parameter \(\alpha \geq 0\) controls the amount of shrinkage: the larger the value of \(\alpha\), the greater the amount of shrinkage and thus the coefficients become more robust to collinearity.

As with other linear models, Ridge will take in its fit method arrays X, y and will store the coefficients \(w\) of the linear model in its coef_ member:

Note that the class Ridge allows for the user to specify that the solver be automatically chosen by setting solver="auto". When this option is specified, Ridge will choose between the "lbfgs", "cholesky", and "sparse_cg" solvers. Ridge will begin checking the conditions shown in the following table from top to bottom. If the condition is true, the corresponding solver is chosen.

The positive=True option is specified.

The input array X is not sparse.

None of the above conditions are fulfilled.

Ordinary Least Squares and Ridge Regression

Plot Ridge coefficients as a function of the regularization

Common pitfalls in the interpretation of coefficients of linear models

Ridge coefficients as a function of the L2 Regularization

The Ridge regressor has a classifier variant: RidgeClassifier. This classifier first converts binary targets to {-1, 1} and then treats the problem as a regression task, optimizing the same objective as above. The predicted class corresponds to the sign of the regressor’s prediction. For multiclass classification, the problem is treated as multi-output regression, and the predicted class corresponds to the output with the highest value.

It might seem questionable to use a (penalized) Least Squares loss to fit a classification model instead of the more traditional logistic or hinge losses. However, in practice, all those models can lead to similar cross-validation scores in terms of accuracy or precision/recall, while the penalized least squares loss used by the RidgeClassifier allows for a very different choice of the numerical solvers with distinct computational performance profiles.

The RidgeClassifier can be significantly faster than e.g. LogisticRegression with a high number of classes because it can compute the projection matrix \((X^T X)^{-1} X^T\) only once.

This classifier is sometimes referred to as a Least Squares Support Vector Machine with a linear kernel.

Classification of text documents using sparse features

This method has the same order of complexity as Ordinary Least Squares.

RidgeCV and RidgeClassifierCV implement ridge regression/classification with built-in cross-validation of the alpha parameter. They work in the same way as GridSearchCV except that it defaults to efficient Leave-One-Out cross-validation. When using the default cross-validation, alpha cannot be 0 due to the formulation used to calculate Leave-One-Out error. See [RL2007] for details.

Specifying the value of the cv attribute will trigger the use of cross-validation with GridSearchCV, for example cv=10 for 10-fold cross-validation, rather than Leave-One-Out Cross-Validation.

“Notes on Regularized Least Squares”, Rifkin & Lippert (technical report, course slides).

The Lasso is a linear model that estimates sparse coefficients, i.e., it is able to set coefficients exactly to zero. It is useful in some contexts due to its tendency to prefer solutions with fewer non-zero coefficients, effectively reducing the number of features upon which the given solution is dependent. For this reason, Lasso and its variants are fundamental to the field of compressed sensing. Under certain conditions, it can recover the exact set of non-zero coefficients (see Compressive sensing: tomography reconstruction with L1 prior (Lasso)).

Mathematically, it consists of a linear model with an added regularization term. The objective function to minimize is:

The lasso estimate thus solves the least-squares with added penalty \(\alpha ||w||_1\), where \(\alpha\) is a constant and \(||w||_1\) is the \(\ell_1\)-norm of the coefficient vector.

The implementation in the class Lasso uses coordinate descent as the algorithm to fit the coefficients. See Least Angle Regression for another implementation:

The function lasso_path is useful for lower-level tasks, as it computes the coefficients along the full path of possible values.

L1-based models for Sparse Signals

Compressive sensing: tomography reconstruction with L1 prior (Lasso)

Common pitfalls in the interpretation of coefficients of linear models

Lasso model selection: AIC-BIC / cross-validation

Feature selection with Lasso

As the Lasso regression yields sparse models, it can thus be used to perform feature selection, as detailed in L1-based feature selection.

The following references explain the origin of the Lasso as well as properties of the Lasso problem and the duality gap computation used for convergence control.

Robert Tibshirani. (1996) Regression Shrinkage and Selection Via the Lasso. J. R. Stat. Soc. Ser. B Stat. Methodol., 58(1):267-288

“An Interior-Point Method for Large-Scale L1-Regularized Least Squares,” S. J. Kim, K. Koh, M. Lustig, S. Boyd and D. Gorinevsky, in IEEE Journal of Selected Topics in Signal Processing, 2007 (Paper)

Coordinate descent (CD) is a strategy to solve a minimization problem that considers a single feature \(j\) at a time. This way, the optimization problem is reduced to a 1-dimensional problem which is easier to solve:

with index \(-j\) meaning all features but \(j\). The solution is

with the soft-thresholding function \(S(z, \alpha) = \operatorname{sign}(z) \max(0, |z|-\alpha)\). Note that the soft-thresholding function is exactly zero whenever \(\alpha \geq |z|\). The CD solver then loops over the features either in a cycle, picking one feature after the other in the order given by X (selection="cyclic"), or by randomly picking features (selection="random"). It stops if the duality gap is smaller than the provided tolerance tol.

The duality gap \(G(w, v)\) is an upper bound of the difference between the current primal objective function of the Lasso, \(P(w)\), and its minimum \(P(w^\star)\), i.e. \(G(w, v) \geq P(w) - P(w^\star)\). It is given by \(G(w, v) = P(w) - D(v)\) with dual objective function

subject to \(v \in ||X^Tv||_{\infty} \leq n_{\text{samples}}\alpha\). At optimum, the duality gap is zero, \(G(w^\star, v^\star) = 0\) (a property called strong duality). With (scaled) dual variable \(v = c r\), current residual \(r = y - Xw\) and dual scaling

the stopping criterion is

A clever method to speedup the coordinate descent algorithm is to screen features such that at optimum \(w_j = 0\). Gap safe screening rules are such a tool. Anywhere during the optimization algorithm, they can tell which feature we can safely exclude, i.e., set to zero with certainty.

The first reference explains the coordinate descent solver used in scikit-learn, the others treat gap safe screening rules.

Friedman, Hastie & Tibshirani. (2010). Regularization Path For Generalized linear Models by Coordinate Descent. J Stat Softw 33(1), 1-22

O. Fercoq, A. Gramfort, J. Salmon. (2015). Mind the duality gap: safer rules for the Lasso. Proceedings of Machine Learning Research 37:333-342, 2015.

E. Ndiaye, O. Fercoq, A. Gramfort, J. Salmon. (2017). Gap Safe Screening Rules for Sparsity Enforcing Penalties. Journal of Machine Learning Research 18(128):1-33, 2017.

The alpha parameter controls the degree of sparsity of the estimated coefficients.

scikit-learn exposes objects that set the Lasso alpha parameter by cross-validation: LassoCV and LassoLarsCV. LassoLarsCV is based on the Least Angle Regression algorithm explained below.

For high-dimensional datasets with many collinear features, LassoCV is most often preferable. However, LassoLarsCV has the advantage of exploring more relevant values of alpha parameter, and if the number of samples is very small compared to the number of features, it is often faster than LassoCV.

Alternatively, the estimator LassoLarsIC proposes to use the Akaike information criterion (AIC) and the Bayes Information criterion (BIC). It is a computationally cheaper alternative to find the optimal value of alpha as the regularization path is computed only once instead of k+1 times when using k-fold cross-validation.

Indeed, these criteria are computed on the in-sample training set. In short, they penalize the over-optimistic scores of the different Lasso models by their flexibility (cf. to “Mathematical details” section below).

However, such criteria need a proper estimation of the degrees of freedom of the solution, are derived for large samples (asymptotic results) and assume the correct model is candidates under investigation. They also tend to break when the problem is badly conditioned (e.g. more features than samples).

Lasso model selection: AIC-BIC / cross-validation

Lasso model selection via information criteria

The definition of AIC (and thus BIC) might differ in the literature. In this section, we give more information regarding the criterion computed in scikit-learn.

The AIC criterion is defined as:

where \(\hat{L}\) is the maximum likelihood of the model and \(d\) is the number of parameters (as well referred to as degrees of freedom in the previous section).

The definition of BIC replaces the constant \(2\) by \(\log(N)\):

where \(N\) is the number of samples.

For a linear Gaussian model, the maximum log-likelihood is defined as:

where \(\sigma^2\) is an estimate of the noise variance, \(y_i\) and \(\hat{y}_i\) are respectively the true and predicted targets, and \(n\) is the number of samples.

Plugging the maximum log-likelihood in the AIC formula yields:

The first term of the above expression is sometimes discarded since it is a constant when \(\sigma^2\) is provided. In addition, it is sometimes stated that the AIC is equivalent to the \(C_p\) statistic [12]. In a strict sense, however, it is equivalent only up to some constant and a multiplicative factor.

At last, we mentioned above that \(\sigma^2\) is an estimate of the noise variance. In LassoLarsIC when the parameter noise_variance is not provided (default), the noise variance is estimated via the unbiased estimator [13] defined as:

where \(p\) is the number of features and \(\hat{y}_i\) is the predicted target using an ordinary least squares regression. Note, that this formula is valid only when n_samples > n_features.

Zou, Hui, Trevor Hastie, and Robert Tibshirani. “On the degrees of freedom of the lasso.” The Annals of Statistics 35.5 (2007): 2173-2192.

Cherkassky, Vladimir, and Yunqian Ma. “Comparison of model selection for regression.” Neural computation 15.7 (2003): 1691-1714.

The equivalence between alpha and the regularization parameter of SVM, C is given by alpha = 1 / C or alpha = 1 / (n_samples * C), depending on the estimator and the exact objective function optimized by the model.

The MultiTaskLasso is a linear model that estimates sparse coefficients for multiple regression problems jointly: y is a 2D array, of shape (n_samples, n_tasks). The constraint is that the selected features are the same for all the regression problems, also called tasks.

The following figure compares the location of the non-zero entries in the coefficient matrix W obtained with a simple Lasso or a MultiTaskLasso. The Lasso estimates yield scattered non-zeros while the non-zeros of the MultiTaskLasso are full columns.

Fitting a time-series model, imposing that any active feature be active at all times.

Joint feature selection with multi-task Lasso

Mathematically, it consists of a linear model trained with a mixed \(\ell_1\) \(\ell_2\)-norm for regularization. The objective function to minimize is:

where \(\text{Fro}\) indicates the Frobenius norm

and \(\ell_1\) \(\ell_2\) reads

The implementation in the class MultiTaskLasso uses coordinate descent as the algorithm to fit the coefficients.

ElasticNet is a linear regression model trained with both \(\ell_1\) and \(\ell_2\)-norm regularization of the coefficients. This combination allows for learning a sparse model where few of the weights are non-zero like Lasso, while still maintaining the regularization properties of Ridge. We control the convex combination of \(\ell_1\) and \(\ell_2\) using the l1_ratio parameter.

Elastic-net is useful when there are multiple features that are correlated with one another. Lasso is likely to pick one of these at random, while elastic-net is likely to pick both.

A practical advantage of trading-off between Lasso and Ridge is that it allows Elastic-Net to inherit some of Ridge’s stability under rotation.

The objective function to minimize is in this case

The class ElasticNetCV can be used to set the parameters alpha (\(\alpha\)) and l1_ratio (\(\rho\)) by cross-validation.

L1-based models for Sparse Signals

Lasso, Lasso-LARS, and Elastic Net paths

Fitting an Elastic Net with a precomputed Gram Matrix and Weighted Samples

The following two references explain the iterations used in the coordinate descent solver of scikit-learn, as well as the duality gap computation used for convergence control.

“Regularization Path For Generalized linear Models by Coordinate Descent”, Friedman, Hastie & Tibshirani, J Stat Softw, 2010 (Paper).

“An Interior-Point Method for Large-Scale L1-Regularized Least Squares,” S. J. Kim, K. Koh, M. Lustig, S. Boyd and D. Gorinevsky, in IEEE Journal of Selected Topics in Signal Processing, 2007 (Paper)

The MultiTaskElasticNet is an elastic-net model that estimates sparse coefficients for multiple regression problems jointly: Y is a 2D array of shape (n_samples, n_tasks). The constraint is that the selected features are the same for all the regression problems, also called tasks.

Mathematically, it consists of a linear model trained with a mixed \(\ell_1\) \(\ell_2\)-norm and \(\ell_2\)-norm for regularization. The objective function to minimize is:

The implementation in the class MultiTaskElasticNet uses coordinate descent as the algorithm to fit the coefficients.

The class MultiTaskElasticNetCV can be used to set the parameters alpha (\(\alpha\)) and l1_ratio (\(\rho\)) by cross-validation.

Least-angle regression (LARS) is a regression algorithm for high-dimensional data, developed by Bradley Efron, Trevor Hastie, Iain Johnstone and Robert Tibshirani. LARS is similar to forward stepwise regression. At each step, it finds the feature most correlated with the target. When there are multiple features having equal correlation, instead of continuing along the same feature, it proceeds in a direction equiangular between the features.

The advantages of LARS are:

It is numerically efficient in contexts where the number of features is significantly greater than the number of samples.

It is computationally just as fast as forward selection and has the same order of complexity as ordinary least squares.

It produces a full piecewise linear solution path, which is useful in cross-validation or similar attempts to tune the model.

If two features are almost equally correlated with the target, then their coefficients should increase at approximately the same rate. The algorithm thus behaves as intuition would expect, and also is more stable.

It is easily modified to produce solutions for other estimators, like the Lasso.

The disadvantages of the LARS method include:

Because LARS is based upon an iterative refitting of the residuals, it would appear to be especially sensitive to the effects of noise. This problem is discussed in detail by Weisberg in the discussion section of the Efron et al. (2004) Annals of Statistics article.

The LARS model can be used via the estimator Lars, or its low-level implementation lars_path or lars_path_gram.

LassoLars is a lasso model implemented using the LARS algorithm, and unlike the implementation based on coordinate descent, this yields the exact solution, which is piecewise linear as a function of the norm of its coefficients.

Lasso, Lasso-LARS, and Elastic Net paths

The LARS algorithm provides the full path of the coefficients along the regularization parameter almost for free, thus a common operation is to retrieve the path with one of the functions lars_path or lars_path_gram.

The algorithm is similar to forward stepwise regression, but instead of including features at each step, the estimated coefficients are increased in a direction equiangular to each one’s correlations with the residual.

Instead of giving a vector result, the LARS solution consists of a curve denoting the solution for each value of the \(\ell_1\) norm of the parameter vector. The full coefficients path is stored in the array coef_path_ of shape (n_features, max_features + 1). The first column is always zero.

Original Algorithm is detailed in the paper Least Angle Regression by Hastie et al.

OrthogonalMatchingPursuit and orthogonal_mp implement the OMP algorithm for approximating the fit of a linear model with constraints imposed on the number of non-zero coefficients (i.e. the \(\ell_0\) pseudo-norm).

Being a forward feature selection method like Least Angle Regression, orthogonal matching pursuit can approximate the optimum solution vector with a fixed number of non-zero elements:

Alternatively, orthogonal matching pursuit can target a specific error instead of a specific number of non-zero coefficients. This can be expressed as:

OMP is based on a greedy algorithm that includes at each step the atom most highly correlated with the current residual. It is similar to the simpler matching pursuit (MP) method, but better in that at each iteration, the residual is recomputed using an orthogonal projection on the space of the previously chosen dictionary elements.

Orthogonal Matching Pursuit

https://www.cs.technion.ac.il/~ronrubin/Publications/KSVD-OMP-v2.pdf

Matching pursuits with time-frequency dictionaries, S. G. Mallat, Z. Zhang, 1993.

Bayesian regression techniques can be used to include regularization parameters in the estimation procedure: the regularization parameter is not set in a hard sense but tuned to the data at hand.

This can be done by introducing uninformative priors over the hyper parameters of the model. The \(\ell_{2}\) regularization used in Ridge regression and classification is equivalent to finding a maximum a posteriori estimation under a Gaussian prior over the coefficients \(w\) with precision \(\lambda^{-1}\). Instead of setting lambda manually, it is possible to treat it as a random variable to be estimated from the data.

To obtain a fully probabilistic model, the output \(y\) is assumed to be Gaussian distributed around \(X w\):

where \(\alpha\) is again treated as a random variable that is to be estimated from the data.

The advantages of Bayesian Regression are:

It adapts to the data at hand.

It can be used to include regularization parameters in the estimation procedure.

The disadvantages of Bayesian regression include:

Inference of the model can be time consuming.

A good introduction to Bayesian methods is given in C. Bishop: Pattern Recognition and Machine Learning.

Original Algorithm is detailed in the book Bayesian learning for neural networks by Radford M. Neal.

BayesianRidge estimates a probabilistic model of the regression problem as described above. The prior for the coefficient \(w\) is given by a spherical Gaussian:

The priors over \(\alpha\) and \(\lambda\) are chosen to be gamma distributions, the conjugate prior for the precision of the Gaussian. The resulting model is called Bayesian Ridge Regression, and is similar to the classical Ridge.

The parameters \(w\), \(\alpha\) and \(\lambda\) are estimated jointly during the fit of the model, the regularization parameters \(\alpha\) and \(\lambda\) being estimated by maximizing the log marginal likelihood. The scikit-learn implementation is based on the algorithm described in Appendix A of (Tipping, 2001) where the update of the parameters \(\alpha\) and \(\lambda\) is done as suggested in (MacKay, 1992). The initial value of the maximization procedure can be set with the hyperparameters alpha_init and lambda_init.

There are four more hyperparameters, \(\alpha_1\), \(\alpha_2\), \(\lambda_1\) and \(\lambda_2\) of the gamma prior distributions over \(\alpha\) and \(\lambda\). These are usually chosen to be non-informative. By default \(\alpha_1 = \alpha_2 = \lambda_1 = \lambda_2 = 10^{-6}\).

Bayesian Ridge Regression is used for regression:

After being fitted, the model can then be used to predict new values:

The coefficients \(w\) of the model can be accessed:

Due to the Bayesian framework, the weights found are slightly different from the ones found by Ordinary Least Squares. However, Bayesian Ridge Regression is more robust to ill-posed problems.

Curve Fitting with Bayesian Ridge Regression

Section 3.3 in Christopher M. Bishop: Pattern Recognition and Machine Learning, 2006

David J. C. MacKay, Bayesian Interpolation, 1992.

Michael E. Tipping, Sparse Bayesian Learning and the Relevance Vector Machine, 2001.

The Automatic Relevance Determination (as being implemented in ARDRegression) is a kind of linear model which is very similar to the Bayesian Ridge Regression, but that leads to sparser coefficients \(w\) [1] [2].

ARDRegression poses a different prior over \(w\): it drops the spherical Gaussian distribution for a centered elliptic Gaussian distribution. This means each coefficient \(w_{i}\) can itself be drawn from a Gaussian distribution, centered on zero and with a precision \(\lambda_{i}\):

with \(A\) being a positive definite diagonal matrix and \(\text{diag}(A) = \lambda = \{\lambda_{1},...,\lambda_{p}\}\).

In contrast to the Bayesian Ridge Regression, each coordinate of \(w_{i}\) has its own standard deviation \(\frac{1}{\lambda_i}\). The prior over all \(\lambda_i\) is chosen to be the same gamma distribution given by the hyperparameters \(\lambda_1\) and \(\lambda_2\).

ARD is also known in the literature as Sparse Bayesian Learning and Relevance Vector Machine [3] [4].

See Comparing Linear Bayesian Regressors for a worked-out comparison between ARD and Bayesian Ridge Regression.

See L1-based models for Sparse Signals for a comparison between various methods - Lasso, ARD and ElasticNet - on correlated data.

Christopher M. Bishop: Pattern Recognition and Machine Learning, Chapter 7.2.1

David Wipf and Srikantan Nagarajan: A New View of Automatic Relevance Determination

Michael E. Tipping: Sparse Bayesian Learning and the Relevance Vector Machine

Tristan Fletcher: Relevance Vector Machines Explained

The logistic regression is implemented in LogisticRegression. Despite its name, it is implemented as a linear model for classification rather than regression in terms of the scikit-learn/ML nomenclature. The logistic regression is also known in the literature as logit regression, maximum-entropy classification (MaxEnt) or the log-linear classifier. In this model, the probabilities describing the possible outcomes of a single trial are modeled using a logistic function.

This implementation can fit binary, One-vs-Rest, or multinomial logistic regression with optional \(\ell_1\), \(\ell_2\) or Elastic-Net regularization.

Regularization is applied by default, which is common in machine learning but not in statistics. Another advantage of regularization is that it improves numerical stability. No regularization amounts to setting C to a very high value.

Logistic Regression as a special case of the Generalized Linear Models (GLM)

Logistic regression is a special case of Generalized Linear Models with a Binomial / Bernoulli conditional distribution and a Logit link. The numerical output of the logistic regression, which is the predicted probability, can be used as a classifier by applying a threshold (by default 0.5) to it. This is how it is implemented in scikit-learn, so it expects a categorical target, making the Logistic Regression a classifier.

L1 Penalty and Sparsity in Logistic Regression

Regularization path of L1- Logistic Regression

Decision Boundaries of Multinomial and One-vs-Rest Logistic Regression

Multiclass sparse logistic regression on 20newgroups

MNIST classification using multinomial logistic + L1

Plot classification probability

For notational ease, we assume that the target \(y_i\) takes values in the set \(\{0, 1\}\) for data point \(i\). Once fitted, the predict_proba method of LogisticRegression predicts the probability of the positive class \(P(y_i=1|X_i)\) as

As an optimization problem, binary class logistic regression with regularization term \(r(w)\) minimizes the following cost function:

where \({s_i}\) corresponds to the weights assigned by the user to a specific training sample (the vector \(s\) is formed by element-wise multiplication of the class weights and sample weights), and the sum \(S = \sum_{i=1}^n s_i\).

We currently provide four choices for the regularization or penalty term \(r(w)\) via the arguments C and l1_ratio:

\(\ell_1\) (l1_ratio=1)

\(\ell_2\) (l1_ratio=0)

\(\frac{1}{2}\|w\|_2^2 = \frac{1}{2}w^T w\)

ElasticNet (0<l1_ratio<1)

\(\frac{1 - \rho}{2}w^T w + \rho \|w\|_1\)

For ElasticNet, \(\rho\) (which corresponds to the l1_ratio parameter) controls the strength of \(\ell_1\) regularization vs. \(\ell_2\) regularization. Elastic-Net is equivalent to \(\ell_1\) when \(\rho = 1\) and equivalent to \(\ell_2\) when \(\rho=0\).

Note that the scale of the class weights and the sample weights will influence the optimization problem. For instance, multiplying the sample weights by a constant \(b>0\) is equivalent to multiplying the (inverse) regularization strength C by \(b\).

The binary case can be extended to \(K\) classes leading to the multinomial logistic regression, see also log-linear model.

It is possible to parameterize a \(K\)-class classification model using only \(K-1\) weight vectors, leaving one class probability fully determined by the other class probabilities by leveraging the fact that all class probabilities must sum to one. We deliberately choose to overparameterize the model using \(K\) weight vectors for ease of implementation and to preserve the symmetrical inductive bias regarding ordering of classes, see [16]. This effect becomes especially important when using regularization. The choice of overparameterization can be detrimental for unpenalized models since then the solution may not be unique, as shown in [16].

Let \(y_i \in \{1, \ldots, K\}\) be the label (ordinal) encoded target variable for observation \(i\). Instead of a single coefficient vector, we now have a matrix of coefficients \(W\) where each row vector \(W_k\) corresponds to class \(k\). We aim at predicting the class probabilities \(P(y_i=k|X_i)\) via predict_proba as:

The objective for the optimization becomes

where \([P]\) represents the Iverson bracket which evaluates to \(0\) if \(P\) is false, otherwise it evaluates to \(1\).

Again, \(s_{ik}\) are the weights assigned by the user (multiplication of sample weights and class weights) with their sum \(S = \sum_{i=1}^n \sum_{k=0}^{K-1} s_{ik}\).

We currently provide four choices for the regularization or penalty term \(r(W)\) via the arguments C and l1_ratio, where \(m\) is the number of features:

\(\ell_1\) (l1_ratio=1)

\(\|W\|_{1,1} = \sum_{i=1}^m\sum_{j=1}^{K}|W_{i,j}|\)

\(\ell_2\) (l1_ratio=0)

\(\frac{1}{2}\|W\|_F^2 = \frac{1}{2}\sum_{i=1}^m\sum_{j=1}^{K} W_{i,j}^2\)

ElasticNet (0<l1_ratio<1)

\(\frac{1 - \rho}{2}\|W\|_F^2 + \rho \|W\|_{1,1}\)

The solvers implemented in the class LogisticRegression are “lbfgs”, “liblinear”, “newton-cg”, “newton-cholesky”, “sag” and “saga”:

The following table summarizes the penalties and multinomial multiclass supported by each solver:

Elastic-Net (L1 + L2)

multinomial multiclass

Penalize the intercept (bad)

Faster for large datasets

Robust to unscaled datasets

The “lbfgs” solver is used by default for its robustness. For n_samples >> n_features, “newton-cholesky” is a good choice and can reach high precision (tiny tol values). For large datasets the “saga” solver is usually faster (than “lbfgs”), in particular for low precision (high tol). For large dataset, you may also consider using SGDClassifier with loss="log_loss", which might be even faster but requires more tuning.

There might be a difference in the scores obtained between LogisticRegression with solver=liblinear or LinearSVC and the external liblinear library directly, when fit_intercept=False and the fit coef_ (or) the data to be predicted are zeroes. This is because for the sample(s) with decision_function zero, LogisticRegression and LinearSVC predict the negative class, while liblinear predicts the positive class. Note that a model with fit_intercept=False and having many samples with decision_function zero, is likely to be an underfit, bad model and you are advised to set fit_intercept=True and increase the intercept_scaling.

The solver “liblinear” uses a coordinate descent (CD) algorithm, and relies on the excellent C++ LIBLINEAR library, which is shipped with scikit-learn. However, the CD algorithm implemented in liblinear cannot learn a true multinomial (multiclass) model. If you still want to use “liblinear” on multiclass problems, you can use a “one-vs-rest” scheme OneVsRestClassifier(LogisticRegression(solver="liblinear")), see :class:`~sklearn.multiclass.OneVsRestClassifier. Note that minimizing the multinomial loss is expected to give better calibrated results as compared to a “one-vs-rest” scheme. For \(\ell_1\) regularization sklearn.svm.l1_min_c allows to calculate the lower bound for C in order to get a non “null” (all feature weights to zero) model.

The “lbfgs”, “newton-cg”, “newton-cholesky” and “sag” solvers only support \(\ell_2\) regularization or no regularization, and are found to converge faster for some high-dimensional data. These solvers (and “saga”) learn a true multinomial logistic regression model [5].

The “sag” solver uses Stochastic Average Gradient descent [6]. It is faster than other solvers for large datasets, when both the number of samples and the number of features are large.

The “saga” solver [7] is a variant of “sag” that also supports the non-smooth \(\ell_1\) penalty (l1_ratio=1). This is therefore the solver of choice for sparse multinomial logistic regression. It is also the only solver that supports Elastic-Net (0 < l1_ratio < 1).

The “lbfgs” is an optimization algorithm that approximates the Broyden–Fletcher–Goldfarb–Shanno algorithm [8], which belongs to quasi-Newton methods. As such, it can deal with a wide range of different training data and is therefore the default solver. Its performance, however, suffers on poorly scaled datasets and on datasets with one-hot encoded categorical features with rare categories.

The “newton-cholesky” solver is an exact Newton solver that calculates the Hessian matrix and solves the resulting linear system. It is a very good choice for n_samples >> n_features and can reach high precision (tiny values of tol), but has a few shortcomings: Only \(\ell_2\) regularization is supported. Furthermore, because the Hessian matrix is explicitly computed, the memory usage has a quadratic dependency on n_features as well as on n_classes.

For a comparison of some of these solvers, see [9].

Christopher M. Bishop: Pattern Recognition and Machine Learning, Chapter 4.3.4

Mark Schmidt, Nicolas Le Roux, and Francis Bach: Minimizing Finite Sums with the Stochastic Average Gradient.

Aaron Defazio, Francis Bach, Simon Lacoste-Julien: SAGA: A Fast Incremental Gradient Method With Support for Non-Strongly Convex Composite Objectives.

https://en.wikipedia.org/wiki/Broyden%E2%80%93Fletcher%E2%80%93Goldfarb%E2%80%93Shanno_algorithm

Thomas P. Minka “A comparison of numerical optimizers for logistic regression”

Simon, Noah, J. Friedman and T. Hastie. “A Blockwise Descent Algorithm for Group-penalized Multiresponse and Multinomial Regression.”

Feature selection with sparse logistic regression

A logistic regression with \(\ell_1\) penalty yields sparse models, and can thus be used to perform feature selection, as detailed in L1-based feature selection.

It is possible to obtain the p-values and confidence intervals for coefficients in cases of regression without penalization. The statsmodels package natively supports this. Within sklearn, one could use bootstrapping instead as well.

LogisticRegressionCV implements Logistic Regression with built-in cross-validation support, to find the optimal C and l1_ratio parameters according to the scoring attribute. The “newton-cg”, “sag”, “saga” and “lbfgs” solvers are found to be faster for high-dimensional dense data, due to warm-starting (see Glossary).

Generalized Linear Models (GLM) extend linear models in two ways [10]. First, the predicted values \(\hat{y}\) are linked to a linear combination of the input variables \(X\) via an inverse link function \(h\) as

Secondly, the squared loss function is replaced by the unit deviance \(d\) of a distribution in the exponential family (or more precisely, a reproductive exponential dispersion model (EDM) [11]).

The minimization problem becomes:

where \(\alpha\) is the L2 regularization penalty. When sample weights are provided, the average becomes a weighted average.

The following table lists some specific EDMs and their unit deviance :

Unit Deviance \(d(y, \hat{y})\)

\(y \in (-\infty, \infty)\)

\(2({y}\log\frac{y}{\hat{y}}+({1}-{y})\log\frac{{1}-{y}}{{1}-\hat{y}})\)

\(y \in \{0, 1, ..., k\}\)

\(2\sum_{i \in \{0, 1, ..., k\}} I(y = i) y_\text{i}\log\frac{I(y = i)}{\hat{I(y = i)}}\)

\(y \in [0, \infty)\)

\(2(y\log\frac{y}{\hat{y}}-y+\hat{y})\)

\(y \in (0, \infty)\)

\(2(\log\frac{\hat{y}}{y}+\frac{y}{\hat{y}}-1)\)

\(y \in (0, \infty)\)

\(\frac{(y-\hat{y})^2}{y\hat{y}^2}\)

The Probability Density Functions (PDF) of these distributions are illustrated in the following figure,

PDF of a random variable Y following Poisson, Tweedie (power=1.5) and Gamma distributions with different mean values (\(\mu\)). Observe the point mass at \(Y=0\) for the Poisson distribution and the Tweedie (power=1.5) distribution, but not for the Gamma distribution which has a strictly positive target domain.#

The Bernoulli distribution is a discrete probability distribution modelling a Bernoulli trial - an event that has only two mutually exclusive outcomes. The Categorical distribution is a generalization of the Bernoulli distribution for a categorical random variable. While a random variable in a Bernoulli distribution has two possible outcomes, a Categorical random variable can take on one of K possible categories, with the probability of each category specified separately.

The choice of the distribution depends on the problem at hand:

If the target values \(y\) are counts (non-negative integer valued) or relative frequencies (non-negative), you might use a Poisson distribution with a log-link.

If the target values are positive valued and skewed, you might try a Gamma distribution with a log-link.

If the target values seem to be heavier tailed than a Gamma distribution, you might try an Inverse Gaussian distribution (or even higher variance powers of the Tweedie family).

If the target values \(y\) are probabilities, you can use the Bernoulli distribution. The Bernoulli distribution with a logit link can be used for binary classification. The Categorical distribution with a softmax link can be used for multiclass classification.

Agriculture / weather modeling: number of rain events per year (Poisson), amount of rainfall per event (Gamma), total rainfall per year (Tweedie / Compound Poisson Gamma).

Risk modeling / insurance policy pricing: number of claim events / policyholder per year (Poisson), cost per event (Gamma), total cost per policyholder per year (Tweedie / Compound Poisson Gamma).

Credit Default: probability that a loan can’t be paid back (Bernoulli).

Fraud Detection: probability that a financial transaction like a cash transfer is a fraudulent transaction (Bernoulli).

Predictive maintenance: number of production interruption events per year (Poisson), duration of interruption (Gamma), total interruption time per year (Tweedie / Compound Poisson Gamma).

Medical Drug Testing: probability of curing a patient in a set of trials or probability that a patient will experience side effects (Bernoulli).

News Classification: classification of news articles into three categories namely Business News, Politics and Entertainment news (Categorical).

McCullagh, Peter; Nelder, John (1989). Generalized Linear Models, Second Edition. Boca Raton: Chapman and Hall/CRC. ISBN 0-412-31760-5.

Jørgensen, B. (1992). The theory of exponential dispersion models and analysis of deviance. Monografias de matemática, no. 51. See also Exponential dispersion model.

TweedieRegressor implements a generalized linear model for the Tweedie distribution, that allows to model any of the above mentioned distributions using the appropriate power parameter. In particular:

power = 0: Normal distribution. Specific estimators such as Ridge, ElasticNet are generally more appropriate in this case.

power = 1: Poisson distribution. PoissonRegressor is exposed for convenience. However, it is strictly equivalent to TweedieRegressor(power=1, link='log').

power = 2: Gamma distribution. GammaRegressor is exposed for convenience. However, it is strictly equivalent to TweedieRegressor(power=2, link='log').

power = 3: Inverse Gaussian distribution.

The link function is determined by the link parameter.

Poisson regression and non-normal loss

Tweedie regression on insurance claims

The feature matrix X should be standardized before fitting. This ensures that the penalty treats features equally.

Since the linear predictor \(Xw\) can be negative and Poisson, Gamma and Inverse Gaussian distributions don’t support negative values, it is necessary to apply an inverse link function that guarantees the non-negativeness. For example with link='log', the inverse link function becomes \(h(Xw)=\exp(Xw)\).

If you want to model a relative frequency, i.e. counts per exposure (time, volume, …) you can do so by using a Poisson distribution and passing \(y=\frac{\mathrm{counts}}{\mathrm{exposure}}\) as target values together with \(\mathrm{exposure}\) as sample weights. For a concrete example see e.g. Tweedie regression on insurance claims.

When performing cross-validation for the power parameter of TweedieRegressor, it is advisable to specify an explicit scoring function, because the default scorer TweedieRegressor.score is a function of power itself.

Stochastic gradient descent is a simple yet very efficient approach to fit linear models. It is particularly useful when the number of samples (and the number of features) is very large. The partial_fit method allows online/out-of-core learning.

The classes SGDClassifier and SGDRegressor provide functionality to fit linear models for classification and regression using different (convex) loss functions and different penalties. E.g., with loss="log", SGDClassifier fits a logistic regression model, while with loss="hinge" it fits a linear support vector machine (SVM).

You can refer to the dedicated Stochastic Gradient Descent documentation section for more details.

The Perceptron is another simple classification algorithm suitable for large scale learning and derives from SGD. By default:

It does not require a learning rate.

It is not regularized (penalized).

It updates its model only on mistakes.

The last characteristic implies that the Perceptron is slightly faster to train than SGD with the hinge loss and that the resulting models are sparser.

In fact, the Perceptron is a wrapper around the SGDClassifier class using a perceptron loss and a constant learning rate. Refer to mathematical section of the SGD procedure for more details.

The passive-aggressive (PA) algorithms are another family of 2 algorithms (PA-I and PA-II) for large-scale online learning that derive from SGD. They are similar to the Perceptron in that they do not require a learning rate. However, contrary to the Perceptron, they include a regularization parameter eta0 (\(C\) in the reference paper).

For classification, SGDClassifier(loss="hinge", penalty=None, learning_rate="pa1", eta0=1.0) can be used for PA-I or with learning_rate="pa2" for PA-II. For regression, SGDRegressor(loss="epsilon_insensitive", penalty=None, learning_rate="pa1", eta0=1.0) can be used for PA-I or with learning_rate="pa2" for PA-II.

“Online Passive-Aggressive Algorithms” K. Crammer, O. Dekel, J. Keshat, S. Shalev-Shwartz, Y. Singer - JMLR 7 (2006)

Robust regression aims to fit a regression model in the presence of corrupt data: either outliers, or error in the model.

There are different things to keep in mind when dealing with data corrupted by outliers:

Outliers in X or in y?

Outliers in the y direction

Outliers in the X direction

Fraction of outliers versus amplitude of error

The number of outlying points matters, but also how much they are outliers.

An important notion of robust fitting is that of breakdown point: the fraction of data that can be outlying for the fit to start missing the inlying data.

Note that in general, robust fitting in high-dimensional setting (large n_features) is very hard. The robust models here will probably not work in these settings.

Trade-offs: which estimator ?

Scikit-learn provides 3 robust regression estimators: RANSAC, Theil Sen and HuberRegressor.

HuberRegressor should be faster than RANSAC and Theil Sen unless the number of samples is very large, i.e. n_samples >> n_features. This is because RANSAC and Theil Sen fit on smaller subsets of the data. However, both Theil Sen and RANSAC are unlikely to be as robust as HuberRegressor for the default parameters.

RANSAC is faster than Theil Sen and scales much better with the number of samples.

RANSAC will deal better with large outliers in the y direction (most common situation).

Theil Sen will cope better with medium-size outliers in the X direction, but this property will disappear in high-dimensional settings.

When in doubt, use RANSAC.

RANSAC (RANdom SAmple Consensus) fits a model from random subsets of inliers from the complete data set.

RANSAC is a non-deterministic algorithm producing only a reasonable result with a certain probability, which is dependent on the number of iterations (see max_trials parameter). It is typically used for linear and non-linear regression problems and is especially popular in the field of photogrammetric computer vision.

The algorithm splits the complete input sample data into a set of inliers, which may be subject to noise, and outliers, which are e.g. caused by erroneous measurements or invalid hypotheses about the data. The resulting model is then estimated only from the determined inliers.

Robust linear model estimation using RANSAC

Robust linear estimator fitting

Each iteration performs the following steps:

Select min_samples random samples from the original data and check whether the set of data is valid (see is_data_valid).

Fit a model to the random subset (estimator.fit) and check whether the estimated model is valid (see is_model_valid).

Classify all data as inliers or outliers by calculating the residuals to the estimated model (estimator.predict(X) - y) - all data samples with absolute residuals smaller than or equal to the residual_threshold are considered as inliers.

Save fitted model as best model if number of inlier samples is maximal. In case the current estimated model has the same number of inliers, it is only considered as the best model if it has better score.

These steps are performed either a maximum number of times (max_trials) or until one of the special stop criteria are met (see stop_n_inliers and stop_score). The final model is estimated using all inlier samples (consensus set) of the previously determined best model.

The is_data_valid and is_model_valid functions allow to identify and reject degenerate combinations of random sub-samples. If the estimated model is not needed for identifying degenerate cases, is_data_valid should be used as it is called prior to fitting the model and thus leading to better computational performance.

https://en.wikipedia.org/wiki/RANSAC

“Random Sample Consensus: A Paradigm for Model Fitting with Applications to Image Analysis and Automated Cartography” Martin A. Fischler and Robert C. Bolles - SRI International (1981)

“Performance Evaluation of RANSAC Family” Sunglok Choi, Taemin Kim and Wonpil Yu - BMVC (2009)

The TheilSenRegressor estimator uses a generalization of the median in multiple dimensions. It is thus robust to multivariate outliers. Note however that the robustness of the estimator decreases quickly with the dimensionality of the problem. It loses its robustness properties and becomes no better than an ordinary least squares in high dimension.

Robust linear estimator fitting

TheilSenRegressor is comparable to the Ordinary Least Squares (OLS) in terms of asymptotic efficiency and as an unbiased estimator. In contrast to OLS, Theil-Sen is a non-parametric method which means it makes no assumption about the underlying distribution of the data. Since Theil-Sen is a median-based estimator, it is more robust against corrupted data aka outliers. In univariate setting, Theil-Sen has a breakdown point of about 29.3% in case of a simple linear regression which means that it can tolerate arbitrary corrupted data of up to 29.3%.

The implementation of TheilSenRegressor in scikit-learn follows a generalization to a multivariate linear regression model [14] using the spatial median which is a generalization of the median to multiple dimensions [15].

In terms of time and space complexity, Theil-Sen scales according to

which makes it infeasible to be applied exhaustively to problems with a large number of samples and features. Therefore, the magnitude of a subpopulation can be chosen to limit the time and space complexity by considering only a random subset of all possible combinations.

Xin Dang, Hanxiang Peng, Xueqin Wang and Heping Zhang: Theil-Sen Estimators in a Multiple Linear Regression Model.

Kärkkäinen and S. Äyrämö: On Computation of Spatial Median for Robust Data Mining.

Also see the Wikipedia page

The HuberRegressor is different from Ridge because it applies a linear loss to samples that are defined as outliers by the epsilon parameter. A sample is classified as an inlier if the absolute error of that sample is less than the threshold epsilon. It differs from TheilSenRegressor and RANSACRegressor because it does not ignore the effect of the outliers but gives a lesser weight to them.

HuberRegressor vs Ridge on dataset with strong outliers

HuberRegressor minimizes

where the loss function is given by

It is advised to set the parameter epsilon to 1.35 to achieve 95% statistical efficiency.

Peter J. Huber, Elvezio M. Ronchetti: Robust Statistics, Concomitant scale estimates, p. 172.

The HuberRegressor differs from using SGDRegressor with loss set to huber in the following ways.

HuberRegressor is scaling invariant. Once epsilon is set, scaling X and y down or up by different values would produce the same robustness to outliers as before. as compared to SGDRegressor where epsilon has to be set again when X and y are scaled.

HuberRegressor should be more efficient to use on data with small number of samples while SGDRegressor needs a number of passes on the training data to produce the same robustness.

Note that this estimator is different from the R implementation of Robust Regression because the R implementation does a weighted least squares implementation with weights given to each sample on the basis of how much the residual is greater than a certain threshold.

Quantile regression estimates the median or other quantiles of \(y\) conditional on \(X\), while ordinary least squares (OLS) estimates the conditional mean.

Quantile regression may be useful if one is interested in predicting an interval instead of point prediction. Sometimes, prediction intervals are calculated based on the assumption that prediction error is distributed normally with zero mean and constant variance. Quantile regression provides sensible prediction intervals even for errors with non-constant (but predictable) variance or non-normal distribution.

Based on minimizing the pinball loss, conditional quantiles can also be estimated by models other than linear models. For example, GradientBoostingRegressor can predict conditional quantiles if its parameter loss is set to "quantile" and parameter alpha is set to the quantile that should be predicted. See the example in Prediction Intervals for Gradient Boosting Regression.

Most implementations of quantile regression are based on linear programming problem. The current implementation is based on scipy.optimize.linprog.

As a linear model, the QuantileRegressor gives linear predictions \(\hat{y}(w, X) = Xw\) for the \(q\)-th quantile, \(q \in (0, 1)\). The weights or coefficients \(w\) are then found by the following minimization problem:

This consists of the pinball loss (also known as linear loss), see also mean_pinball_loss,

and the L1 penalty controlled by parameter alpha, similar to Lasso.

As the pinball loss is only linear in the residuals, quantile regression is much more robust to outliers than squared error based estimation of the mean. Somewhat in between is the HuberRegressor.

Koenker, R., & Bassett Jr, G. (1978). Regression quantiles. Econometrica: journal of the Econometric Society, 33-50.

Portnoy, S., & Koenker, R. (1997). The Gaussian hare and the Laplacian tortoise: computability of squared-error versus absolute-error estimators. Statistical Science, 12, 279-300.

Koenker, R. (2005). Quantile Regression. Cambridge University Press.

One common pattern within machine learning is to use linear models trained on nonlinear functions of the data. This approach maintains the generally fast performance of linear methods, while allowing them to fit a much wider range of data.

For example, a simple linear regression can be extended by constructing polynomial features from the coefficients. In the standard linear regression case, you might have a model that looks like this for two-dimensional data:

If we want to fit a paraboloid to the data instead of a plane, we can combine the features in second-order polynomials, so that the model looks like this:

The (sometimes surprising) observation is that this is still a linear model: to see this, imagine creating a new set of features

With this re-labeling of the data, our problem can be written

We see that the resulting polynomial regression is in the same class of linear models we considered above (i.e. the model is linear in \(w\)) and can be solved by the same techniques. By considering linear fits within a higher-dimensional space built with these basis functions, the model has the flexibility to fit a much broader range of data.

Here is an example of applying this idea to one-dimensional data, using polynomial features of varying degrees:

This figure is created using the PolynomialFeatures transformer, which transforms an input data matrix into a new data matrix of a given degree. It can be used as follows:

The features of X have been transformed from \([x_1, x_2]\) to \([1, x_1, x_2, x_1^2, x_1 x_2, x_2^2]\), and can now be used within any linear model.

This sort of preprocessing can be streamlined with the Pipeline tools. A single object representing a simple polynomial regression can be created and used as follows:

The linear model trained on polynomial features is able to exactly recover the input polynomial coefficients.

In some cases it’s not necessary to include higher powers of any single feature, but only the so-called interaction features that multiply together at most \(d\) distinct features. These can be gotten from PolynomialFeatures with the setting interaction_only=True.

For example, when dealing with boolean features, \(x_i^n = x_i\) for all \(n\) and is therefore useless; but \(x_i x_j\) represents the conjunction of two booleans. This way, we can solve the XOR problem with a linear classifier:

And the classifier “predictions” are perfect:

**Examples:**

Example 1 (python):
```python
>>> from sklearn import linear_model
>>> reg = linear_model.LinearRegression()
>>> reg.fit([[0, 0], [1, 1], [2, 2]], [0, 1, 2])
LinearRegression()
>>> reg.coef_
array([0.5, 0.5])
>>> reg.intercept_
0.0
```

Example 2 (python):
```python
>>> from sklearn import linear_model
>>> reg = linear_model.Ridge(alpha=.5)
>>> reg.fit([[0, 0], [0, 0], [1, 1]], [0, .1, 1])
Ridge(alpha=0.5)
>>> reg.coef_
array([0.34545455, 0.34545455])
>>> reg.intercept_
np.float64(0.13636)
```

Example 3 (python):
```python
>>> import numpy as np
>>> from sklearn import linear_model
>>> reg = linear_model.RidgeCV(alphas=np.logspace(-6, 6, 13))
>>> reg.fit([[0, 0], [0, 0], [1, 1]], [0, .1, 1])
RidgeCV(alphas=array([1.e-06, 1.e-05, 1.e-04, 1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01,
      1.e+02, 1.e+03, 1.e+04, 1.e+05, 1.e+06]))
>>> reg.alpha_
np.float64(0.01)
```

Example 4 (python):
```python
>>> from sklearn import linear_model
>>> reg = linear_model.Lasso(alpha=0.1)
>>> reg.fit([[0, 0], [1, 1]], [0, 1])
Lasso(alpha=0.1)
>>> reg.predict([[1, 1]])
array([0.8])
```

---

## adjusted_mutual_info_score#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.metrics.adjusted_mutual_info_score.html

**Contents:**
- adjusted_mutual_info_score#
- Gallery examples#

Adjusted Mutual Information between two clusterings.

Adjusted Mutual Information (AMI) is an adjustment of the Mutual Information (MI) score to account for chance. It accounts for the fact that the MI is generally higher for two clusterings with a larger number of clusters, regardless of whether there is actually more information shared. For two clusterings \(U\) and \(V\), the AMI is given as:

This metric is independent of the absolute values of the labels: a permutation of the class or cluster label values won’t change the score value in any way.

This metric is furthermore symmetric: switching \(U\) (label_true) with \(V\) (labels_pred) will return the same score value. This can be useful to measure the agreement of two independent label assignments strategies on the same dataset when the real ground truth is not known.

Be mindful that this function is an order of magnitude slower than other metrics, such as the Adjusted Rand Index.

Read more in the User Guide.

A clustering of the data into disjoint subsets, called \(U\) in the above formula.

A clustering of the data into disjoint subsets, called \(V\) in the above formula.

How to compute the normalizer in the denominator.

Added in version 0.20.

Changed in version 0.22: The default value of average_method changed from ‘max’ to ‘arithmetic’.

The AMI returns a value of 1 when the two partitions are identical (ie perfectly matched). Random partitions (independent labellings) have an expected AMI around 0 on average hence can be negative. The value is in adjusted nats (based on the natural logarithm).

Mutual Information (not adjusted for chance).

Vinh, Epps, and Bailey, (2010). Information Theoretic Measures for Clusterings Comparison: Variants, Properties, Normalization and Correction for Chance, JMLR

Wikipedia entry for the Adjusted Mutual Information

Perfect labelings are both homogeneous and complete, hence have score 1.0:

If classes members are completely split across different clusters, the assignment is totally in-complete, hence the AMI is null:

Adjustment for chance in clustering performance evaluation

Demo of affinity propagation clustering algorithm

Demo of DBSCAN clustering algorithm

A demo of K-Means clustering on the handwritten digits data

**Examples:**

Example 1 (unknown):
```unknown
AMI(U, V) = [MI(U, V) - E(MI(U, V))] / [avg(H(U), H(V)) - E(MI(U, V))]
```

Example 2 (sql):
```sql
>>> from sklearn.metrics.cluster import adjusted_mutual_info_score
>>> adjusted_mutual_info_score([0, 0, 1, 1], [0, 0, 1, 1])
1.0
>>> adjusted_mutual_info_score([0, 0, 1, 1], [1, 1, 0, 0])
1.0
```

Example 3 (unknown):
```unknown
>>> adjusted_mutual_info_score([0, 0, 0, 0], [0, 1, 2, 3])
0.0
```

---

## IncrementalPCA#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.IncrementalPCA.html

**Contents:**
- IncrementalPCA#
- Gallery examples#

Incremental principal components analysis (IPCA).

Linear dimensionality reduction using Singular Value Decomposition of the data, keeping only the most significant singular vectors to project the data to a lower dimensional space. The input data is centered but not scaled for each feature before applying the SVD.

Depending on the size of the input data, this algorithm can be much more memory efficient than a PCA, and allows sparse input.

This algorithm has constant memory complexity, on the order of batch_size * n_features, enabling use of np.memmap files without loading the entire file into memory. For sparse matrices, the input is converted to dense in batches (in order to be able to subtract the mean) which avoids storing the entire dense matrix at any one time.

The computational overhead of each SVD is O(batch_size * n_features ** 2), but only 2 * batch_size samples remain in memory at a time. There will be n_samples / batch_size SVD computations to get the principal components, versus 1 large SVD of complexity O(n_samples * n_features ** 2) for PCA.

For a usage example, see Incremental PCA.

Read more in the User Guide.

Added in version 0.16.

Number of components to keep. If n_components is None, then n_components is set to min(n_samples, n_features).

When True (False by default) the components_ vectors are divided by n_samples times components_ to ensure uncorrelated outputs with unit component-wise variances.

Whitening will remove some information from the transformed signal (the relative variance scales of the components) but can sometimes improve the predictive accuracy of the downstream estimators by making data respect some hard-wired assumptions.

If False, X will be overwritten. copy=False can be used to save memory but is unsafe for general use.

The number of samples to use for each batch. Only used when calling fit. If batch_size is None, then batch_size is inferred from the data and set to 5 * n_features, to provide a balance between approximation accuracy and memory consumption.

Principal axes in feature space, representing the directions of maximum variance in the data. Equivalently, the right singular vectors of the centered input data, parallel to its eigenvectors. The components are sorted by decreasing explained_variance_.

Variance explained by each of the selected components.

Percentage of variance explained by each of the selected components. If all components are stored, the sum of explained variances is equal to 1.0.

The singular values corresponding to each of the selected components. The singular values are equal to the 2-norms of the n_components variables in the lower-dimensional space.

Per-feature empirical mean, aggregate over calls to partial_fit.

Per-feature empirical variance, aggregate over calls to partial_fit.

The estimated noise covariance following the Probabilistic PCA model from Tipping and Bishop 1999. See “Pattern Recognition and Machine Learning” by C. Bishop, 12.2.1 p. 574 or http://www.miketipping.com/papers/met-mppca.pdf.

The estimated number of components. Relevant when n_components=None.

The number of samples processed by the estimator. Will be reset on new calls to fit, but increments across partial_fit calls.

Inferred batch size from batch_size.

Number of features seen during fit.

Added in version 0.24.

Names of features seen during fit. Defined only when X has feature names that are all strings.

Added in version 1.0.

Principal component analysis (PCA).

Kernel Principal component analysis (KPCA).

Sparse Principal Components Analysis (SparsePCA).

Dimensionality reduction using truncated SVD.

Implements the incremental PCA model from Ross et al. (2008) [1]. This model is an extension of the Sequential Karhunen-Loeve Transform from Levy and Lindenbaum (2000) [2].

We have specifically abstained from an optimization used by authors of both papers, a QR decomposition used in specific situations to reduce the algorithmic complexity of the SVD. The source for this technique is Matrix Computations (Golub and Van Loan 1997 [3]). This technique has been omitted because it is advantageous only when decomposing a matrix with n_samples (rows) >= 5/3 * n_features (columns), and hurts the readability of the implemented algorithm. This would be a good opportunity for future optimization, if it is deemed necessary.

D. Ross, J. Lim, R. Lin, M. Yang. Incremental Learning for Robust Visual Tracking, International Journal of Computer Vision, Volume 77, Issue 1-3, pp. 125-141, May 2008. https://www.cs.toronto.edu/~dross/ivt/RossLimLinYang_ijcv.pdf

A. Levy and M. Lindenbaum, Sequential Karhunen-Loeve Basis Extraction and its Application to Images, IEEE Transactions on Image Processing, Volume 9, Number 8, pp. 1371-1374, August 2000.

G. Golub and C. Van Loan. Matrix Computations, Third Edition, Chapter 5, Section 5.4.4, pp. 252-253, 1997.

Fit the model with X, using minibatches of size batch_size.

Training data, where n_samples is the number of samples and n_features is the number of features.

Not used, present for API consistency by convention.

Returns the instance itself.

Fit to data, then transform it.

Fits transformer to X and y with optional parameters fit_params and returns a transformed version of X.

Target values (None for unsupervised transformations).

Additional fit parameters. Pass only if the estimator accepts additional params in its fit method.

Compute data covariance with the generative model.

cov = components_.T * S**2 * components_ + sigma2 * eye(n_features) where S**2 contains the explained variances, and sigma2 contains the noise variances.

Estimated covariance of data.

Get output feature names for transformation.

The feature names out will prefixed by the lowercased class name. For example, if the transformer outputs 3 features, then the feature names out are: ["class_name0", "class_name1", "class_name2"].

Only used to validate feature names with the names seen in fit.

Transformed feature names.

Get metadata routing of this object.

Please check User Guide on how the routing mechanism works.

A MetadataRequest encapsulating routing information.

Get parameters for this estimator.

If True, will return the parameters for this estimator and contained subobjects that are estimators.

Parameter names mapped to their values.

Compute data precision matrix with the generative model.

Equals the inverse of the covariance but computed with the matrix inversion lemma for efficiency.

Estimated precision of data.

Transform data back to its original space.

In other words, return an input X_original whose transform would be X.

New data, where n_samples is the number of samples and n_components is the number of components.

Original data, where n_samples is the number of samples and n_features is the number of features.

If whitening is enabled, inverse_transform will compute the exact inverse operation, which includes reversing whitening.

Incremental fit with X. All of X is processed as a single batch.

Training data, where n_samples is the number of samples and n_features is the number of features.

Not used, present for API consistency by convention.

Run check_array on X.

Returns the instance itself.

Set output container.

See Introducing the set_output API for an example on how to use the API.

Configure output of transform and fit_transform.

"default": Default output format of a transformer

"pandas": DataFrame output

"polars": Polars output

None: Transform configuration is unchanged

Added in version 1.4: "polars" option was added.

Set the parameters of this estimator.

The method works on simple estimators as well as on nested objects (such as Pipeline). The latter have parameters of the form <component>__<parameter> so that it’s possible to update each component of a nested object.

Estimator parameters.

Apply dimensionality reduction to X.

X is projected on the first principal components previously extracted from a training set, using minibatches of size batch_size if X is sparse.

New data, where n_samples is the number of samples and n_features is the number of features.

Projection of X in the first principal components.

**Examples:**

Example 1 (python):
```python
>>> from sklearn.datasets import load_digits
>>> from sklearn.decomposition import IncrementalPCA
>>> from scipy import sparse
>>> X, _ = load_digits(return_X_y=True)
>>> transformer = IncrementalPCA(n_components=7, batch_size=200)
>>> # either partially fit on smaller batches of data
>>> transformer.partial_fit(X[:100, :])
IncrementalPCA(batch_size=200, n_components=7)
>>> # or let the fit function itself divide the data into batches
>>> X_sparse = sparse.csr_matrix(X)
>>> X_transformed = transformer.fit_transform(X_sparse)
>>> X_transformed.shape
(1797, 7)
```

Example 2 (csharp):
```csharp
>>> import numpy as np
>>> from sklearn.decomposition import IncrementalPCA
>>> X = np.array([[-1, -1], [-2, -1], [-3, -2],
...               [1, 1], [2, 1], [3, 2]])
>>> ipca = IncrementalPCA(n_components=2, batch_size=3)
>>> ipca.fit(X)
IncrementalPCA(batch_size=3, n_components=2)
>>> ipca.transform(X)
```

---

## 2.3. Clustering#

**URL:** https://scikit-learn.org/stable/modules/clustering.html

**Contents:**
- 2.3. Clustering#
- 2.3.1. Overview of clustering methods#
- 2.3.2. K-means#
  - 2.3.2.1. Low-level parallelism#
  - 2.3.2.2. Mini Batch K-Means#
- 2.3.3. Affinity Propagation#
- 2.3.4. Mean Shift#
- 2.3.5. Spectral clustering#
  - 2.3.5.1. Different label assignment strategies#
  - 2.3.5.2. Spectral Clustering Graphs#

Clustering of unlabeled data can be performed with the module sklearn.cluster.

Each clustering algorithm comes in two variants: a class, that implements the fit method to learn the clusters on train data, and a function, that, given train data, returns an array of integer labels corresponding to the different clusters. For the class, the labels over the training data can be found in the labels_ attribute.

One important thing to note is that the algorithms implemented in this module can take different kinds of matrix as input. All the methods accept standard data matrices of shape (n_samples, n_features). These can be obtained from the classes in the sklearn.feature_extraction module. For AffinityPropagation, SpectralClustering and DBSCAN one can also input similarity matrices of shape (n_samples, n_samples). These can be obtained from the functions in the sklearn.metrics.pairwise module.

A comparison of the clustering algorithms in scikit-learn#

Geometry (metric used)

Very large n_samples, medium n_clusters with MiniBatch code

General-purpose, even cluster size, flat geometry, not too many clusters, inductive

Distances between points

damping, sample preference

Not scalable with n_samples

Many clusters, uneven cluster size, non-flat geometry, inductive

Graph distance (e.g. nearest-neighbor graph)

Not scalable with n_samples

Many clusters, uneven cluster size, non-flat geometry, inductive

Distances between points

Medium n_samples, small n_clusters

Few clusters, even cluster size, non-flat geometry, transductive

Graph distance (e.g. nearest-neighbor graph)

Ward hierarchical clustering

number of clusters or distance threshold

Large n_samples and n_clusters

Many clusters, possibly connectivity constraints, transductive

Distances between points

Agglomerative clustering

number of clusters or distance threshold, linkage type, distance

Large n_samples and n_clusters

Many clusters, possibly connectivity constraints, non Euclidean distances, transductive

Any pairwise distance

Very large n_samples, medium n_clusters

Non-flat geometry, uneven cluster sizes, outlier removal, transductive

Distances between nearest points

minimum cluster membership, minimum point neighbors

large n_samples, medium n_clusters

Non-flat geometry, uneven cluster sizes, outlier removal, transductive, hierarchical, variable cluster density

Distances between nearest points

minimum cluster membership

Very large n_samples, large n_clusters

Non-flat geometry, uneven cluster sizes, variable cluster density, outlier removal, transductive

Distances between points

Flat geometry, good for density estimation, inductive

Mahalanobis distances to centers

branching factor, threshold, optional global clusterer.

Large n_clusters and n_samples

Large dataset, outlier removal, data reduction, inductive

Euclidean distance between points

Very large n_samples, medium n_clusters

General-purpose, even cluster size, flat geometry, no empty clusters, inductive, hierarchical

Distances between points

Non-flat geometry clustering is useful when the clusters have a specific shape, i.e. a non-flat manifold, and the standard euclidean distance is not the right metric. This case arises in the two top rows of the figure above.

Gaussian mixture models, useful for clustering, are described in another chapter of the documentation dedicated to mixture models. KMeans can be seen as a special case of Gaussian mixture model with equal covariance per component.

Transductive clustering methods (in contrast to inductive clustering methods) are not designed to be applied to new, unseen data.

Inductive Clustering: An example of an inductive clustering model for handling new data.

The KMeans algorithm clusters data by trying to separate samples in n groups of equal variance, minimizing a criterion known as the inertia or within-cluster sum-of-squares (see below). This algorithm requires the number of clusters to be specified. It scales well to large numbers of samples and has been used across a large range of application areas in many different fields.

The k-means algorithm divides a set of \(N\) samples \(X\) into \(K\) disjoint clusters \(C\), each described by the mean \(\mu_j\) of the samples in the cluster. The means are commonly called the cluster “centroids”; note that they are not, in general, points from \(X\), although they live in the same space.

The K-means algorithm aims to choose centroids that minimise the inertia, or within-cluster sum-of-squares criterion:

Inertia can be recognized as a measure of how internally coherent clusters are. It suffers from various drawbacks:

Inertia makes the assumption that clusters are convex and isotropic, which is not always the case. It responds poorly to elongated clusters, or manifolds with irregular shapes.

Inertia is not a normalized metric: we just know that lower values are better and zero is optimal. But in very high-dimensional spaces, Euclidean distances tend to become inflated (this is an instance of the so-called “curse of dimensionality”). Running a dimensionality reduction algorithm such as Principal component analysis (PCA) prior to k-means clustering can alleviate this problem and speed up the computations.

For more detailed descriptions of the issues shown above and how to address them, refer to the examples Demonstration of k-means assumptions and Selecting the number of clusters with silhouette analysis on KMeans clustering.

K-means is often referred to as Lloyd’s algorithm. In basic terms, the algorithm has three steps. The first step chooses the initial centroids, with the most basic method being to choose \(k\) samples from the dataset \(X\). After initialization, K-means consists of looping between the two other steps. The first step assigns each sample to its nearest centroid. The second step creates new centroids by taking the mean value of all of the samples assigned to each previous centroid. The difference between the old and the new centroids are computed and the algorithm repeats these last two steps until this value is less than a threshold. In other words, it repeats until the centroids do not move significantly.

K-means is equivalent to the expectation-maximization algorithm with a small, all-equal, diagonal covariance matrix.

The algorithm can also be understood through the concept of Voronoi diagrams. First the Voronoi diagram of the points is calculated using the current centroids. Each segment in the Voronoi diagram becomes a separate cluster. Secondly, the centroids are updated to the mean of each segment. The algorithm then repeats this until a stopping criterion is fulfilled. Usually, the algorithm stops when the relative decrease in the objective function between iterations is less than the given tolerance value. This is not the case in this implementation: iteration stops when centroids move less than the tolerance.

Given enough time, K-means will always converge, however this may be to a local minimum. This is highly dependent on the initialization of the centroids. As a result, the computation is often done several times, with different initializations of the centroids. One method to help address this issue is the k-means++ initialization scheme, which has been implemented in scikit-learn (use the init='k-means++' parameter). This initializes the centroids to be (generally) distant from each other, leading to probably better results than random initialization, as shown in the reference. For detailed examples of comparing different initialization schemes, refer to A demo of K-Means clustering on the handwritten digits data and Empirical evaluation of the impact of k-means initialization.

K-means++ can also be called independently to select seeds for other clustering algorithms, see sklearn.cluster.kmeans_plusplus for details and example usage.

The algorithm supports sample weights, which can be given by a parameter sample_weight. This allows to assign more weight to some samples when computing cluster centers and values of inertia. For example, assigning a weight of 2 to a sample is equivalent to adding a duplicate of that sample to the dataset \(X\).

Clustering text documents using k-means: Document clustering using KMeans and MiniBatchKMeans based on sparse data

An example of K-Means++ initialization: Using K-means++ to select seeds for other clustering algorithms.

KMeans benefits from OpenMP based parallelism through Cython. Small chunks of data (256 samples) are processed in parallel, which in addition yields a low memory footprint. For more details on how to control the number of threads, please refer to our Parallelism notes.

Demonstration of k-means assumptions: Demonstrating when k-means performs intuitively and when it does not

A demo of K-Means clustering on the handwritten digits data: Clustering handwritten digits

“k-means++: The advantages of careful seeding” Arthur, David, and Sergei Vassilvitskii, Proceedings of the eighteenth annual ACM-SIAM symposium on Discrete algorithms, Society for Industrial and Applied Mathematics (2007)

The MiniBatchKMeans is a variant of the KMeans algorithm which uses mini-batches to reduce the computation time, while still attempting to optimise the same objective function. Mini-batches are subsets of the input data, randomly sampled in each training iteration. These mini-batches drastically reduce the amount of computation required to converge to a local solution. In contrast to other algorithms that reduce the convergence time of k-means, mini-batch k-means produces results that are generally only slightly worse than the standard algorithm.

The algorithm iterates between two major steps, similar to vanilla k-means. In the first step, \(b\) samples are drawn randomly from the dataset, to form a mini-batch. These are then assigned to the nearest centroid. In the second step, the centroids are updated. In contrast to k-means, this is done on a per-sample basis. For each sample in the mini-batch, the assigned centroid is updated by taking the streaming average of the sample and all previous samples assigned to that centroid. This has the effect of decreasing the rate of change for a centroid over time. These steps are performed until convergence or a predetermined number of iterations is reached.

MiniBatchKMeans converges faster than KMeans, but the quality of the results is reduced. In practice this difference in quality can be quite small, as shown in the example and cited reference.

Comparison of the K-Means and MiniBatchKMeans clustering algorithms: Comparison of KMeans and MiniBatchKMeans

Clustering text documents using k-means: Document clustering using KMeans and MiniBatchKMeans based on sparse data

Online learning of a dictionary of parts of faces

“Web Scale K-Means clustering” D. Sculley, Proceedings of the 19th international conference on World wide web (2010).

AffinityPropagation creates clusters by sending messages between pairs of samples until convergence. A dataset is then described using a small number of exemplars, which are identified as those most representative of other samples. The messages sent between pairs represent the suitability for one sample to be the exemplar of the other, which is updated in response to the values from other pairs. This updating happens iteratively until convergence, at which point the final exemplars are chosen, and hence the final clustering is given.

Affinity Propagation can be interesting as it chooses the number of clusters based on the data provided. For this purpose, the two important parameters are the preference, which controls how many exemplars are used, and the damping factor which damps the responsibility and availability messages to avoid numerical oscillations when updating these messages.

The main drawback of Affinity Propagation is its complexity. The algorithm has a time complexity of the order \(O(N^2 T)\), where \(N\) is the number of samples and \(T\) is the number of iterations until convergence. Further, the memory complexity is of the order \(O(N^2)\) if a dense similarity matrix is used, but reducible if a sparse similarity matrix is used. This makes Affinity Propagation most appropriate for small to medium sized datasets.

The messages sent between points belong to one of two categories. The first is the responsibility \(r(i, k)\), which is the accumulated evidence that sample \(k\) should be the exemplar for sample \(i\). The second is the availability \(a(i, k)\) which is the accumulated evidence that sample \(i\) should choose sample \(k\) to be its exemplar, and considers the values for all other samples that \(k\) should be an exemplar. In this way, exemplars are chosen by samples if they are (1) similar enough to many samples and (2) chosen by many samples to be representative of themselves.

More formally, the responsibility of a sample \(k\) to be the exemplar of sample \(i\) is given by:

Where \(s(i, k)\) is the similarity between samples \(i\) and \(k\). The availability of sample \(k\) to be the exemplar of sample \(i\) is given by:

To begin with, all values for \(r\) and \(a\) are set to zero, and the calculation of each iterates until convergence. As discussed above, in order to avoid numerical oscillations when updating the messages, the damping factor \(\lambda\) is introduced to iteration process:

where \(t\) indicates the iteration times.

Demo of affinity propagation clustering algorithm: Affinity Propagation on a synthetic 2D datasets with 3 classes

Visualizing the stock market structure Affinity Propagation on financial time series to find groups of companies

MeanShift clustering aims to discover blobs in a smooth density of samples. It is a centroid based algorithm, which works by updating candidates for centroids to be the mean of the points within a given region. These candidates are then filtered in a post-processing stage to eliminate near-duplicates to form the final set of centroids.

The position of centroid candidates is iteratively adjusted using a technique called hill climbing, which finds local maxima of the estimated probability density. Given a candidate centroid \(x\) for iteration \(t\), the candidate is updated according to the following equation:

Where \(m\) is the mean shift vector that is computed for each centroid that points towards a region of the maximum increase in the density of points. To compute \(m\) we define \(N(x)\) as the neighborhood of samples within a given distance around \(x\). Then \(m\) is computed using the following equation, effectively updating a centroid to be the mean of the samples within its neighborhood:

In general, the equation for \(m\) depends on a kernel used for density estimation. The generic formula is:

In our implementation, \(K(x)\) is equal to 1 if \(x\) is small enough and is equal to 0 otherwise. Effectively \(K(y - x)\) indicates whether \(y\) is in the neighborhood of \(x\).

The algorithm automatically sets the number of clusters, instead of relying on a parameter bandwidth, which dictates the size of the region to search through. This parameter can be set manually, but can be estimated using the provided estimate_bandwidth function, which is called if the bandwidth is not set.

The algorithm is not highly scalable, as it requires multiple nearest neighbor searches during the execution of the algorithm. The algorithm is guaranteed to converge, however the algorithm will stop iterating when the change in centroids is small.

Labelling a new sample is performed by finding the nearest centroid for a given sample.

A demo of the mean-shift clustering algorithm: Mean Shift clustering on a synthetic 2D datasets with 3 classes.

“Mean shift: A robust approach toward feature space analysis” D. Comaniciu and P. Meer, IEEE Transactions on Pattern Analysis and Machine Intelligence (2002)

SpectralClustering performs a low-dimension embedding of the affinity matrix between samples, followed by clustering, e.g., by KMeans, of the components of the eigenvectors in the low dimensional space. It is especially computationally efficient if the affinity matrix is sparse and the amg solver is used for the eigenvalue problem (Note, the amg solver requires that the pyamg module is installed.)

The present version of SpectralClustering requires the number of clusters to be specified in advance. It works well for a small number of clusters, but is not advised for many clusters.

For two clusters, SpectralClustering solves a convex relaxation of the normalized cuts problem on the similarity graph: cutting the graph in two so that the weight of the edges cut is small compared to the weights of the edges inside each cluster. This criteria is especially interesting when working on images, where graph vertices are pixels, and weights of the edges of the similarity graph are computed using a function of a gradient of the image.

Transforming distance to well-behaved similarities

Note that if the values of your similarity matrix are not well distributed, e.g. with negative values or with a distance matrix rather than a similarity, the spectral problem will be singular and the problem not solvable. In which case it is advised to apply a transformation to the entries of the matrix. For instance, in the case of a signed distance matrix, is common to apply a heat kernel:

See the examples for such an application.

Spectral clustering for image segmentation: Segmenting objects from a noisy background using spectral clustering.

Segmenting the picture of greek coins in regions: Spectral clustering to split the image of coins in regions.

Different label assignment strategies can be used, corresponding to the assign_labels parameter of SpectralClustering. "kmeans" strategy can match finer details, but can be unstable. In particular, unless you control the random_state, it may not be reproducible from run-to-run, as it depends on random initialization. The alternative "discretize" strategy is 100% reproducible, but tends to create parcels of fairly even and geometrical shape. The recently added "cluster_qr" option is a deterministic alternative that tends to create the visually best partitioning on the example application below.

assign_labels="kmeans"

assign_labels="discretize"

assign_labels="cluster_qr"

“Multiclass spectral clustering” Stella X. Yu, Jianbo Shi, 2003

“Simple, direct, and efficient multi-way spectral clustering” Anil Damle, Victor Minden, Lexing Ying, 2019

Spectral Clustering can also be used to partition graphs via their spectral embeddings. In this case, the affinity matrix is the adjacency matrix of the graph, and SpectralClustering is initialized with affinity='precomputed':

“A Tutorial on Spectral Clustering” Ulrike von Luxburg, 2007

“Normalized cuts and image segmentation” Jianbo Shi, Jitendra Malik, 2000

“A Random Walks View of Spectral Segmentation” Marina Meila, Jianbo Shi, 2001

“On Spectral Clustering: Analysis and an algorithm” Andrew Y. Ng, Michael I. Jordan, Yair Weiss, 2001

“Preconditioned Spectral Clustering for Stochastic Block Partition Streaming Graph Challenge” David Zhuzhunashvili, Andrew Knyazev

Hierarchical clustering is a general family of clustering algorithms that build nested clusters by merging or splitting them successively. This hierarchy of clusters is represented as a tree (or dendrogram). The root of the tree is the unique cluster that gathers all the samples, the leaves being the clusters with only one sample. See the Wikipedia page for more details.

The AgglomerativeClustering object performs a hierarchical clustering using a bottom up approach: each observation starts in its own cluster, and clusters are successively merged together. The linkage criteria determines the metric used for the merge strategy:

Ward minimizes the sum of squared differences within all clusters. It is a variance-minimizing approach and in this sense is similar to the k-means objective function but tackled with an agglomerative hierarchical approach.

Maximum or complete linkage minimizes the maximum distance between observations of pairs of clusters.

Average linkage minimizes the average of the distances between all observations of pairs of clusters.

Single linkage minimizes the distance between the closest observations of pairs of clusters.

AgglomerativeClustering can also scale to large number of samples when it is used jointly with a connectivity matrix, but is computationally expensive when no connectivity constraints are added between samples: it considers at each step all the possible merges.

The FeatureAgglomeration uses agglomerative clustering to group together features that look very similar, thus decreasing the number of features. It is a dimensionality reduction tool, see Unsupervised dimensionality reduction.

AgglomerativeClustering supports Ward, single, average, and complete linkage strategies.

Agglomerative cluster has a “rich get richer” behavior that leads to uneven cluster sizes. In this regard, single linkage is the worst strategy, and Ward gives the most regular sizes. However, the affinity (or distance used in clustering) cannot be varied with Ward, thus for non Euclidean metrics, average linkage is a good alternative. Single linkage, while not robust to noisy data, can be computed very efficiently and can therefore be useful to provide hierarchical clustering of larger datasets. Single linkage can also perform well on non-globular data.

Various Agglomerative Clustering on a 2D embedding of digits: exploration of the different linkage strategies in a real dataset.

Comparing different hierarchical linkage methods on toy datasets: exploration of the different linkage strategies in toy datasets.

It’s possible to visualize the tree representing the hierarchical merging of clusters as a dendrogram. Visual inspection can often be useful for understanding the structure of the data, though more so in the case of small sample sizes.

Plot Hierarchical Clustering Dendrogram

An interesting aspect of AgglomerativeClustering is that connectivity constraints can be added to this algorithm (only adjacent clusters can be merged together), through a connectivity matrix that defines for each sample the neighboring samples following a given structure of the data. For instance, in the Swiss-roll example below, the connectivity constraints forbid the merging of points that are not adjacent on the Swiss roll, and thus avoid forming clusters that extend across overlapping folds of the roll.

These constraints are not only useful to impose a certain local structure, but they also make the algorithm faster, especially when the number of the samples is high.

The connectivity constraints are imposed via a connectivity matrix: a scipy sparse matrix that has elements only at the intersection of a row and a column with indices of the dataset that should be connected. This matrix can be constructed from a-priori information: for instance, you may wish to cluster web pages by only merging pages with a link pointing from one to another. It can also be learned from the data, for instance using sklearn.neighbors.kneighbors_graph to restrict merging to nearest neighbors as in this example, or using sklearn.feature_extraction.image.grid_to_graph to enable only merging of neighboring pixels on an image, as in the coin example.

Connectivity constraints with single, average and complete linkage

Connectivity constraints and single, complete or average linkage can enhance the ‘rich getting richer’ aspect of agglomerative clustering, particularly so if they are built with sklearn.neighbors.kneighbors_graph. In the limit of a small number of clusters, they tend to give a few macroscopically occupied clusters and almost empty ones. (see the discussion in Hierarchical clustering with and without structure). Single linkage is the most brittle linkage option with regard to this issue.

A demo of structured Ward hierarchical clustering on an image of coins: Ward clustering to split the image of coins in regions.

Hierarchical clustering with and without structure: Example of Ward algorithm on a Swiss-roll, comparison of structured approaches versus unstructured approaches.

Feature agglomeration vs. univariate selection: Example of dimensionality reduction with feature agglomeration based on Ward hierarchical clustering.

Single, average and complete linkage can be used with a variety of distances (or affinities), in particular Euclidean distance (l2), Manhattan distance (or Cityblock, or l1), cosine distance, or any precomputed affinity matrix.

l1 distance is often good for sparse features, or sparse noise: i.e. many of the features are zero, as in text mining using occurrences of rare words.

cosine distance is interesting because it is invariant to global scalings of the signal.

The guidelines for choosing a metric is to use one that maximizes the distance between samples in different classes, and minimizes that within each class.

Agglomerative clustering with different metrics

The BisectingKMeans is an iterative variant of KMeans, using divisive hierarchical clustering. Instead of creating all centroids at once, centroids are picked progressively based on a previous clustering: a cluster is split into two new clusters repeatedly until the target number of clusters is reached.

BisectingKMeans is more efficient than KMeans when the number of clusters is large since it only works on a subset of the data at each bisection while KMeans always works on the entire dataset.

Although BisectingKMeans can’t benefit from the advantages of the "k-means++" initialization by design, it will still produce comparable results than KMeans(init="k-means++") in terms of inertia at cheaper computational costs, and will likely produce better results than KMeans with a random initialization.

This variant is more efficient to agglomerative clustering if the number of clusters is small compared to the number of data points.

This variant also does not produce empty clusters.

bisecting_strategy="largest_cluster" selects the cluster having the most points

bisecting_strategy="biggest_inertia" selects the cluster with biggest inertia (cluster with biggest Sum of Squared Errors within)

Picking by largest amount of data points in most cases produces result as accurate as picking by inertia and is faster (especially for larger amount of data points, where calculating error may be costly).

Picking by largest amount of data points will also likely produce clusters of similar sizes while KMeans is known to produce clusters of different sizes.

Difference between Bisecting K-Means and regular K-Means can be seen on example Bisecting K-Means and Regular K-Means Performance Comparison. While the regular K-Means algorithm tends to create non-related clusters, clusters from Bisecting K-Means are well ordered and create quite a visible hierarchy.

“A Comparison of Document Clustering Techniques” Michael Steinbach, George Karypis and Vipin Kumar, Department of Computer Science and Egineering, University of Minnesota (June 2000)

“Performance Analysis of K-Means and Bisecting K-Means Algorithms in Weblog Data” K.Abirami and Dr.P.Mayilvahanan, International Journal of Emerging Technologies in Engineering Research (IJETER) Volume 4, Issue 8, (August 2016)

“Bisecting K-means Algorithm Based on K-valued Self-determining and Clustering Center Optimization” Jian Di, Xinyue Gou School of Control and Computer Engineering,North China Electric Power University, Baoding, Hebei, China (August 2017)

The DBSCAN algorithm views clusters as areas of high density separated by areas of low density. Due to this rather generic view, clusters found by DBSCAN can be any shape, as opposed to k-means which assumes that clusters are convex shaped. The central component to the DBSCAN is the concept of core samples, which are samples that are in areas of high density. A cluster is therefore a set of core samples, each close to each other (measured by some distance measure) and a set of non-core samples that are close to a core sample (but are not themselves core samples). There are two parameters to the algorithm, min_samples and eps, which define formally what we mean when we say dense. Higher min_samples or lower eps indicate higher density necessary to form a cluster.

More formally, we define a core sample as being a sample in the dataset such that there exist min_samples other samples within a distance of eps, which are defined as neighbors of the core sample. This tells us that the core sample is in a dense area of the vector space. A cluster is a set of core samples that can be built by recursively taking a core sample, finding all of its neighbors that are core samples, finding all of their neighbors that are core samples, and so on. A cluster also has a set of non-core samples, which are samples that are neighbors of a core sample in the cluster but are not themselves core samples. Intuitively, these samples are on the fringes of a cluster.

Any core sample is part of a cluster, by definition. Any sample that is not a core sample, and is at least eps in distance from any core sample, is considered an outlier by the algorithm.

While the parameter min_samples primarily controls how tolerant the algorithm is towards noise (on noisy and large data sets it may be desirable to increase this parameter), the parameter eps is crucial to choose appropriately for the data set and distance function and usually cannot be left at the default value. It controls the local neighborhood of the points. When chosen too small, most data will not be clustered at all (and labeled as -1 for “noise”). When chosen too large, it causes close clusters to be merged into one cluster, and eventually the entire data set to be returned as a single cluster. Some heuristics for choosing this parameter have been discussed in the literature, for example based on a knee in the nearest neighbor distances plot (as discussed in the references below).

In the figure below, the color indicates cluster membership, with large circles indicating core samples found by the algorithm. Smaller circles are non-core samples that are still part of a cluster. Moreover, the outliers are indicated by black points below.

Demo of DBSCAN clustering algorithm

The DBSCAN algorithm is deterministic, always generating the same clusters when given the same data in the same order. However, the results can differ when data is provided in a different order. First, even though the core samples will always be assigned to the same clusters, the labels of those clusters will depend on the order in which those samples are encountered in the data. Second and more importantly, the clusters to which non-core samples are assigned can differ depending on the data order. This would happen when a non-core sample has a distance lower than eps to two core samples in different clusters. By the triangular inequality, those two core samples must be more distant than eps from each other, or they would be in the same cluster. The non-core sample is assigned to whichever cluster is generated first in a pass through the data, and so the results will depend on the data ordering.

The current implementation uses ball trees and kd-trees to determine the neighborhood of points, which avoids calculating the full distance matrix (as was done in scikit-learn versions before 0.14). The possibility to use custom metrics is retained; for details, see NearestNeighbors.

This implementation is by default not memory efficient because it constructs a full pairwise similarity matrix in the case where kd-trees or ball-trees cannot be used (e.g., with sparse matrices). This matrix will consume \(n^2\) floats. A couple of mechanisms for getting around this are:

Use OPTICS clustering in conjunction with the extract_dbscan method. OPTICS clustering also calculates the full pairwise matrix, but only keeps one row in memory at a time (memory complexity \(\mathcal{O}(n)\)).

A sparse radius neighborhood graph (where missing entries are presumed to be out of eps) can be precomputed in a memory-efficient way and dbscan can be run over this with metric='precomputed'. See sklearn.neighbors.NearestNeighbors.radius_neighbors_graph.

The dataset can be compressed, either by removing exact duplicates if these occur in your data, or by using BIRCH. Then you only have a relatively small number of representatives for a large number of points. You can then provide a sample_weight when fitting DBSCAN.

A Density-Based Algorithm for Discovering Clusters in Large Spatial Databases with Noise Ester, M., H. P. Kriegel, J. Sander, and X. Xu, In Proceedings of the 2nd International Conference on Knowledge Discovery and Data Mining, Portland, OR, AAAI Press, pp. 226-231. 1996.

DBSCAN revisited, revisited: why and how you should (still) use DBSCAN. Schubert, E., Sander, J., Ester, M., Kriegel, H. P., & Xu, X. (2017). In ACM Transactions on Database Systems (TODS), 42(3), 19.

The HDBSCAN algorithm can be seen as an extension of DBSCAN and OPTICS. Specifically, DBSCAN assumes that the clustering criterion (i.e. density requirement) is globally homogeneous. In other words, DBSCAN may struggle to successfully capture clusters with different densities. HDBSCAN alleviates this assumption and explores all possible density scales by building an alternative representation of the clustering problem.

This implementation is adapted from the original implementation of HDBSCAN, scikit-learn-contrib/hdbscan based on [LJ2017].

Demo of HDBSCAN clustering algorithm

HDBSCAN first defines \(d_c(x_p)\), the core distance of a sample \(x_p\), as the distance to its min_samples th-nearest neighbor, counting itself. For example, if min_samples=5 and \(x_*\) is the 5th-nearest neighbor of \(x_p\) then the core distance is:

Next it defines \(d_m(x_p, x_q)\), the mutual reachability distance of two points \(x_p, x_q\), as:

These two notions allow us to construct the mutual reachability graph \(G_{ms}\) defined for a fixed choice of min_samples by associating each sample \(x_p\) with a vertex of the graph, and thus edges between points \(x_p, x_q\) are the mutual reachability distance \(d_m(x_p, x_q)\) between them. We may build subsets of this graph, denoted as \(G_{ms,\varepsilon}\), by removing any edges with value greater than \(\varepsilon\): from the original graph. Any points whose core distance is less than \(\varepsilon\): are at this staged marked as noise. The remaining points are then clustered by finding the connected components of this trimmed graph.

Taking the connected components of a trimmed graph \(G_{ms,\varepsilon}\) is equivalent to running DBSCAN* with min_samples and \(\varepsilon\). DBSCAN* is a slightly modified version of DBSCAN mentioned in [CM2013].

HDBSCAN can be seen as an algorithm which performs DBSCAN* clustering across all values of \(\varepsilon\). As mentioned prior, this is equivalent to finding the connected components of the mutual reachability graphs for all values of \(\varepsilon\). To do this efficiently, HDBSCAN first extracts a minimum spanning tree (MST) from the fully -connected mutual reachability graph, then greedily cuts the edges with highest weight. An outline of the HDBSCAN algorithm is as follows:

Extract the MST of \(G_{ms}\).

Extend the MST by adding a “self edge” for each vertex, with weight equal to the core distance of the underlying sample.

Initialize a single cluster and label for the MST.

Remove the edge with the greatest weight from the MST (ties are removed simultaneously).

Assign cluster labels to the connected components which contain the end points of the now-removed edge. If the component does not have at least one edge it is instead assigned a “null” label marking it as noise.

Repeat 4-5 until there are no more connected components.

HDBSCAN is therefore able to obtain all possible partitions achievable by DBSCAN* for a fixed choice of min_samples in a hierarchical fashion. Indeed, this allows HDBSCAN to perform clustering across multiple densities and as such it no longer needs \(\varepsilon\) to be given as a hyperparameter. Instead it relies solely on the choice of min_samples, which tends to be a more robust hyperparameter.

HDBSCAN can be smoothed with an additional hyperparameter min_cluster_size which specifies that during the hierarchical clustering, components with fewer than minimum_cluster_size many samples are considered noise. In practice, one can set minimum_cluster_size = min_samples to couple the parameters and simplify the hyperparameter space.

Campello, R.J.G.B., Moulavi, D., Sander, J. (2013). Density-Based Clustering Based on Hierarchical Density Estimates. In: Pei, J., Tseng, V.S., Cao, L., Motoda, H., Xu, G. (eds) Advances in Knowledge Discovery and Data Mining. PAKDD 2013. Lecture Notes in Computer Science(), vol 7819. Springer, Berlin, Heidelberg. Density-Based Clustering Based on Hierarchical Density Estimates

L. McInnes and J. Healy, (2017). Accelerated Hierarchical Density Based Clustering. In: IEEE International Conference on Data Mining Workshops (ICDMW), 2017, pp. 33-42. Accelerated Hierarchical Density Based Clustering

The OPTICS algorithm shares many similarities with the DBSCAN algorithm, and can be considered a generalization of DBSCAN that relaxes the eps requirement from a single value to a value range. The key difference between DBSCAN and OPTICS is that the OPTICS algorithm builds a reachability graph, which assigns each sample both a reachability_ distance, and a spot within the cluster ordering_ attribute; these two attributes are assigned when the model is fitted, and are used to determine cluster membership. If OPTICS is run with the default value of inf set for max_eps, then DBSCAN style cluster extraction can be performed repeatedly in linear time for any given eps value using the cluster_optics_dbscan method. Setting max_eps to a lower value will result in shorter run times, and can be thought of as the maximum neighborhood radius from each point to find other potential reachable points.

The reachability distances generated by OPTICS allow for variable density extraction of clusters within a single data set. As shown in the above plot, combining reachability distances and data set ordering_ produces a reachability plot, where point density is represented on the Y-axis, and points are ordered such that nearby points are adjacent. ‘Cutting’ the reachability plot at a single value produces DBSCAN like results; all points above the ‘cut’ are classified as noise, and each time that there is a break when reading from left to right signifies a new cluster. The default cluster extraction with OPTICS looks at the steep slopes within the graph to find clusters, and the user can define what counts as a steep slope using the parameter xi. There are also other possibilities for analysis on the graph itself, such as generating hierarchical representations of the data through reachability-plot dendrograms, and the hierarchy of clusters detected by the algorithm can be accessed through the cluster_hierarchy_ parameter. The plot above has been color-coded so that cluster colors in planar space match the linear segment clusters of the reachability plot. Note that the blue and red clusters are adjacent in the reachability plot, and can be hierarchically represented as children of a larger parent cluster.

Demo of OPTICS clustering algorithm

The results from OPTICS cluster_optics_dbscan method and DBSCAN are very similar, but not always identical; specifically, labeling of periphery and noise points. This is in part because the first samples of each dense area processed by OPTICS have a large reachability value while being close to other points in their area, and will thus sometimes be marked as noise rather than periphery. This affects adjacent points when they are considered as candidates for being marked as either periphery or noise.

Note that for any single value of eps, DBSCAN will tend to have a shorter run time than OPTICS; however, for repeated runs at varying eps values, a single run of OPTICS may require less cumulative runtime than DBSCAN. It is also important to note that OPTICS’ output is close to DBSCAN’s only if eps and max_eps are close.

Spatial indexing trees are used to avoid calculating the full distance matrix, and allow for efficient memory usage on large sets of samples. Different distance metrics can be supplied via the metric keyword.

For large datasets, similar (but not identical) results can be obtained via HDBSCAN. The HDBSCAN implementation is multithreaded, and has better algorithmic runtime complexity than OPTICS, at the cost of worse memory scaling. For extremely large datasets that exhaust system memory using HDBSCAN, OPTICS will maintain \(n\) (as opposed to \(n^2\)) memory scaling; however, tuning of the max_eps parameter will likely need to be used to give a solution in a reasonable amount of wall time.

“OPTICS: ordering points to identify the clustering structure.” Ankerst, Mihael, Markus M. Breunig, Hans-Peter Kriegel, and Jörg Sander. In ACM Sigmod Record, vol. 28, no. 2, pp. 49-60. ACM, 1999.

The Birch builds a tree called the Clustering Feature Tree (CFT) for the given data. The data is essentially lossy compressed to a set of Clustering Feature nodes (CF Nodes). The CF Nodes have a number of subclusters called Clustering Feature subclusters (CF Subclusters) and these CF Subclusters located in the non-terminal CF Nodes can have CF Nodes as children.

The CF Subclusters hold the necessary information for clustering which prevents the need to hold the entire input data in memory. This information includes:

Number of samples in a subcluster.

Linear Sum - An n-dimensional vector holding the sum of all samples

Squared Sum - Sum of the squared L2 norm of all samples.

Centroids - To avoid recalculation linear sum / n_samples.

Squared norm of the centroids.

The BIRCH algorithm has two parameters, the threshold and the branching factor. The branching factor limits the number of subclusters in a node and the threshold limits the distance between the entering sample and the existing subclusters.

This algorithm can be viewed as an instance of a data reduction method, since it reduces the input data to a set of subclusters which are obtained directly from the leaves of the CFT. This reduced data can be further processed by feeding it into a global clusterer. This global clusterer can be set by n_clusters. If n_clusters is set to None, the subclusters from the leaves are directly read off, otherwise a global clustering step labels these subclusters into global clusters (labels) and the samples are mapped to the global label of the nearest subcluster.

A new sample is inserted into the root of the CF Tree which is a CF Node. It is then merged with the subcluster of the root, that has the smallest radius after merging, constrained by the threshold and branching factor conditions. If the subcluster has any child node, then this is done repeatedly till it reaches a leaf. After finding the nearest subcluster in the leaf, the properties of this subcluster and the parent subclusters are recursively updated.

If the radius of the subcluster obtained by merging the new sample and the nearest subcluster is greater than the square of the threshold and if the number of subclusters is greater than the branching factor, then a space is temporarily allocated to this new sample. The two farthest subclusters are taken and the subclusters are divided into two groups on the basis of the distance between these subclusters.

If this split node has a parent subcluster and there is room for a new subcluster, then the parent is split into two. If there is no room, then this node is again split into two and the process is continued recursively, till it reaches the root.

BIRCH does not scale very well to high dimensional data. As a rule of thumb if n_features is greater than twenty, it is generally better to use MiniBatchKMeans.

If the number of instances of data needs to be reduced, or if one wants a large number of subclusters either as a preprocessing step or otherwise, BIRCH is more useful than MiniBatchKMeans.

To avoid the computation of global clustering, for every call of partial_fit the user is advised:

To set n_clusters=None initially.

Train all data by multiple calls to partial_fit.

Set n_clusters to a required value using brc.set_params(n_clusters=n_clusters).

Call partial_fit finally with no arguments, i.e. brc.partial_fit() which performs the global clustering.

Tian Zhang, Raghu Ramakrishnan, Maron Livny BIRCH: An efficient data clustering method for large databases. https://www.cs.sfu.ca/CourseCentral/459/han/papers/zhang96.pdf

Roberto Perdisci JBirch - Java implementation of BIRCH clustering algorithm https://code.google.com/archive/p/jbirch

Evaluating the performance of a clustering algorithm is not as trivial as counting the number of errors or the precision and recall of a supervised classification algorithm. In particular any evaluation metric should not take the absolute values of the cluster labels into account but rather if this clustering define separations of the data similar to some ground truth set of classes or satisfying some assumption such that members belong to the same class are more similar than members of different classes according to some similarity metric.

Given the knowledge of the ground truth class assignments labels_true and our clustering algorithm assignments of the same samples labels_pred, the (adjusted or unadjusted) Rand index is a function that measures the similarity of the two assignments, ignoring permutations:

The Rand index does not ensure to obtain a value close to 0.0 for a random labelling. The adjusted Rand index corrects for chance and will give such a baseline.

As with all clustering metrics, one can permute 0 and 1 in the predicted labels, rename 2 to 3, and get the same score:

Furthermore, both rand_score and adjusted_rand_score are symmetric: swapping the argument does not change the scores. They can thus be used as consensus measures:

Perfect labeling is scored 1.0:

Poorly agreeing labels (e.g. independent labelings) have lower scores, and for the adjusted Rand index the score will be negative or close to zero. However, for the unadjusted Rand index the score, while lower, will not necessarily be close to zero:

Interpretability: The unadjusted Rand index is proportional to the number of sample pairs whose labels are the same in both labels_pred and labels_true, or are different in both.

Random (uniform) label assignments have an adjusted Rand index score close to 0.0 for any value of n_clusters and n_samples (which is not the case for the unadjusted Rand index or the V-measure for instance).

Bounded range: Lower values indicate different labelings, similar clusterings have a high (adjusted or unadjusted) Rand index, 1.0 is the perfect match score. The score range is [0, 1] for the unadjusted Rand index and [-0.5, 1] for the adjusted Rand index.

No assumption is made on the cluster structure: The (adjusted or unadjusted) Rand index can be used to compare all kinds of clustering algorithms, and can be used to compare clustering algorithms such as k-means which assumes isotropic blob shapes with results of spectral clustering algorithms which can find cluster with “folded” shapes.

Contrary to inertia, the (adjusted or unadjusted) Rand index requires knowledge of the ground truth classes which is almost never available in practice or requires manual assignment by human annotators (as in the supervised learning setting).

However (adjusted or unadjusted) Rand index can also be useful in a purely unsupervised setting as a building block for a Consensus Index that can be used for clustering model selection (TODO).

The unadjusted Rand index is often close to 1.0 even if the clusterings themselves differ significantly. This can be understood when interpreting the Rand index as the accuracy of element pair labeling resulting from the clusterings: In practice there often is a majority of element pairs that are assigned the different pair label under both the predicted and the ground truth clustering resulting in a high proportion of pair labels that agree, which leads subsequently to a high score.

Adjustment for chance in clustering performance evaluation: Analysis of the impact of the dataset size on the value of clustering measures for random assignments.

If C is a ground truth class assignment and K the clustering, let us define \(a\) and \(b\) as:

\(a\), the number of pairs of elements that are in the same set in C and in the same set in K

\(b\), the number of pairs of elements that are in different sets in C and in different sets in K

The unadjusted Rand index is then given by:

where \(C_2^{n_{samples}}\) is the total number of possible pairs in the dataset. It does not matter if the calculation is performed on ordered pairs or unordered pairs as long as the calculation is performed consistently.

However, the Rand index does not guarantee that random label assignments will get a value close to zero (esp. if the number of clusters is in the same order of magnitude as the number of samples).

To counter this effect we can discount the expected RI \(E[\text{RI}]\) of random labelings by defining the adjusted Rand index as follows:

Comparing Partitions L. Hubert and P. Arabie, Journal of Classification 1985

Properties of the Hubert-Arabie adjusted Rand index D. Steinley, Psychological Methods 2004

Wikipedia entry for the Rand index

Minimum adjusted Rand index for two clusterings of a given size, 2022, J. E. Chacón and A. I. Rastrojo

Given the knowledge of the ground truth class assignments labels_true and our clustering algorithm assignments of the same samples labels_pred, the Mutual Information is a function that measures the agreement of the two assignments, ignoring permutations. Two different normalized versions of this measure are available, Normalized Mutual Information (NMI) and Adjusted Mutual Information (AMI). NMI is often used in the literature, while AMI was proposed more recently and is normalized against chance:

One can permute 0 and 1 in the predicted labels, rename 2 to 3 and get the same score:

All, mutual_info_score, adjusted_mutual_info_score and normalized_mutual_info_score are symmetric: swapping the argument does not change the score. Thus they can be used as a consensus measure:

Perfect labeling is scored 1.0:

This is not true for mutual_info_score, which is therefore harder to judge:

Bad (e.g. independent labelings) have non-positive scores:

Random (uniform) label assignments have an AMI score close to 0.0 for any value of n_clusters and n_samples (which is not the case for raw Mutual Information or the V-measure for instance).

Upper bound of 1: Values close to zero indicate two label assignments that are largely independent, while values close to one indicate significant agreement. Further, an AMI of exactly 1 indicates that the two label assignments are equal (with or without permutation).

Contrary to inertia, MI-based measures require the knowledge of the ground truth classes while almost never available in practice or requires manual assignment by human annotators (as in the supervised learning setting).

However MI-based measures can also be useful in purely unsupervised setting as a building block for a Consensus Index that can be used for clustering model selection.

NMI and MI are not adjusted against chance.

Adjustment for chance in clustering performance evaluation: Analysis of the impact of the dataset size on the value of clustering measures for random assignments. This example also includes the Adjusted Rand Index.

Assume two label assignments (of the same N objects), \(U\) and \(V\). Their entropy is the amount of uncertainty for a partition set, defined by:

where \(P(i) = |U_i| / N\) is the probability that an object picked at random from \(U\) falls into class \(U_i\). Likewise for \(V\):

With \(P'(j) = |V_j| / N\). The mutual information (MI) between \(U\) and \(V\) is calculated by:

where \(P(i, j) = |U_i \cap V_j| / N\) is the probability that an object picked at random falls into both classes \(U_i\) and \(V_j\).

It also can be expressed in set cardinality formulation:

The normalized mutual information is defined as

This value of the mutual information and also the normalized variant is not adjusted for chance and will tend to increase as the number of different labels (clusters) increases, regardless of the actual amount of “mutual information” between the label assignments.

The expected value for the mutual information can be calculated using the following equation [VEB2009]. In this equation, \(a_i = |U_i|\) (the number of elements in \(U_i\)) and \(b_j = |V_j|\) (the number of elements in \(V_j\)).

Using the expected value, the adjusted mutual information can then be calculated using a similar form to that of the adjusted Rand index:

For normalized mutual information and adjusted mutual information, the normalizing value is typically some generalized mean of the entropies of each clustering. Various generalized means exist, and no firm rules exist for preferring one over the others. The decision is largely a field-by-field basis; for instance, in community detection, the arithmetic mean is most common. Each normalizing method provides “qualitatively similar behaviours” [YAT2016]. In our implementation, this is controlled by the average_method parameter.

Vinh et al. (2010) named variants of NMI and AMI by their averaging method [VEB2010]. Their ‘sqrt’ and ‘sum’ averages are the geometric and arithmetic means; we use these more broadly common names.

Strehl, Alexander, and Joydeep Ghosh (2002). “Cluster ensembles - a knowledge reuse framework for combining multiple partitions”. Journal of Machine Learning Research 3: 583-617. doi:10.1162/153244303321897735.

Wikipedia entry for the (normalized) Mutual Information

Wikipedia entry for the Adjusted Mutual Information

Vinh, Epps, and Bailey, (2009). “Information theoretic measures for clusterings comparison”. Proceedings of the 26th Annual International Conference on Machine Learning - ICML ‘09. doi:10.1145/1553374.1553511. ISBN 9781605585161.

Vinh, Epps, and Bailey, (2010). “Information Theoretic Measures for Clusterings Comparison: Variants, Properties, Normalization and Correction for Chance”. JMLR <https://jmlr.csail.mit.edu/papers/volume11/vinh10a/vinh10a.pdf>

Yang, Algesheimer, and Tessone, (2016). “A comparative analysis of community detection algorithms on artificial networks”. Scientific Reports 6: 30750. doi:10.1038/srep30750.

Given the knowledge of the ground truth class assignments of the samples, it is possible to define some intuitive metric using conditional entropy analysis.

In particular Rosenberg and Hirschberg (2007) define the following two desirable objectives for any cluster assignment:

homogeneity: each cluster contains only members of a single class.

completeness: all members of a given class are assigned to the same cluster.

We can turn those concept as scores homogeneity_score and completeness_score. Both are bounded below by 0.0 and above by 1.0 (higher is better):

Their harmonic mean called V-measure is computed by v_measure_score:

This function’s formula is as follows:

beta defaults to a value of 1.0, but for using a value less than 1 for beta:

more weight will be attributed to homogeneity, and using a value greater than 1:

more weight will be attributed to completeness.

The V-measure is actually equivalent to the mutual information (NMI) discussed above, with the aggregation function being the arithmetic mean [B2011].

Homogeneity, completeness and V-measure can be computed at once using homogeneity_completeness_v_measure as follows:

The following clustering assignment is slightly better, since it is homogeneous but not complete:

v_measure_score is symmetric: it can be used to evaluate the agreement of two independent assignments on the same dataset.

This is not the case for completeness_score and homogeneity_score: both are bound by the relationship:

Bounded scores: 0.0 is as bad as it can be, 1.0 is a perfect score.

Intuitive interpretation: clustering with bad V-measure can be qualitatively analyzed in terms of homogeneity and completeness to better feel what ‘kind’ of mistakes is done by the assignment.

No assumption is made on the cluster structure: can be used to compare clustering algorithms such as k-means which assumes isotropic blob shapes with results of spectral clustering algorithms which can find cluster with “folded” shapes.

The previously introduced metrics are not normalized with regards to random labeling: this means that depending on the number of samples, clusters and ground truth classes, a completely random labeling will not always yield the same values for homogeneity, completeness and hence v-measure. In particular random labeling won’t yield zero scores especially when the number of clusters is large.

This problem can safely be ignored when the number of samples is more than a thousand and the number of clusters is less than 10. For smaller sample sizes or larger number of clusters it is safer to use an adjusted index such as the Adjusted Rand Index (ARI).

These metrics require the knowledge of the ground truth classes while almost never available in practice or requires manual assignment by human annotators (as in the supervised learning setting).

Adjustment for chance in clustering performance evaluation: Analysis of the impact of the dataset size on the value of clustering measures for random assignments.

Homogeneity and completeness scores are formally given by:

where \(H(C|K)\) is the conditional entropy of the classes given the cluster assignments and is given by:

and \(H(C)\) is the entropy of the classes and is given by:

with \(n\) the total number of samples, \(n_c\) and \(n_k\) the number of samples respectively belonging to class \(c\) and cluster \(k\), and finally \(n_{c,k}\) the number of samples from class \(c\) assigned to cluster \(k\).

The conditional entropy of clusters given class \(H(K|C)\) and the entropy of clusters \(H(K)\) are defined in a symmetric manner.

Rosenberg and Hirschberg further define V-measure as the harmonic mean of homogeneity and completeness:

V-Measure: A conditional entropy-based external cluster evaluation measure Andrew Rosenberg and Julia Hirschberg, 2007

Identification and Characterization of Events in Social Media, Hila Becker, PhD Thesis.

The original Fowlkes-Mallows index (FMI) was intended to measure the similarity between two clustering results, which is inherently an unsupervised comparison. The supervised adaptation of the Fowlkes-Mallows index (as implemented in sklearn.metrics.fowlkes_mallows_score) can be used when the ground truth class assignments of the samples are known. The FMI is defined as the geometric mean of the pairwise precision and recall:

In the above formula:

TP (True Positive): The number of pairs of points that are clustered together both in the true labels and in the predicted labels.

FP (False Positive): The number of pairs of points that are clustered together in the predicted labels but not in the true labels.

FN (False Negative): The number of pairs of points that are clustered together in the true labels but not in the predicted labels.

The score ranges from 0 to 1. A high value indicates a good similarity between two clusters.

One can permute 0 and 1 in the predicted labels, rename 2 to 3 and get the same score:

Perfect labeling is scored 1.0:

Bad (e.g. independent labelings) have zero scores:

Random (uniform) label assignments have a FMI score close to 0.0 for any value of n_clusters and n_samples (which is not the case for raw Mutual Information or the V-measure for instance).

Upper-bounded at 1: Values close to zero indicate two label assignments that are largely independent, while values close to one indicate significant agreement. Further, values of exactly 0 indicate purely independent label assignments and a FMI of exactly 1 indicates that the two label assignments are equal (with or without permutation).

No assumption is made on the cluster structure: can be used to compare clustering algorithms such as k-means which assumes isotropic blob shapes with results of spectral clustering algorithms which can find cluster with “folded” shapes.

Contrary to inertia, FMI-based measures require the knowledge of the ground truth classes while almost never available in practice or requires manual assignment by human annotators (as in the supervised learning setting).

E. B. Fowkles and C. L. Mallows, 1983. “A method for comparing two hierarchical clusterings”. Journal of the American Statistical Association. https://www.tandfonline.com/doi/abs/10.1080/01621459.1983.10478008

Wikipedia entry for the Fowlkes-Mallows Index

If the ground truth labels are not known, evaluation must be performed using the model itself. The Silhouette Coefficient (sklearn.metrics.silhouette_score) is an example of such an evaluation, where a higher Silhouette Coefficient score relates to a model with better defined clusters. The Silhouette Coefficient is defined for each sample and is composed of two scores:

a: The mean distance between a sample and all other points in the same class.

b: The mean distance between a sample and all other points in the next nearest cluster.

The Silhouette Coefficient s for a single sample is then given as:

The Silhouette Coefficient for a set of samples is given as the mean of the Silhouette Coefficient for each sample.

In normal usage, the Silhouette Coefficient is applied to the results of a cluster analysis.

The score is bounded between -1 for incorrect clustering and +1 for highly dense clustering. Scores around zero indicate overlapping clusters.

The score is higher when clusters are dense and well separated, which relates to a standard concept of a cluster.

The Silhouette Coefficient is generally higher for convex clusters than other concepts of clusters, such as density based clusters like those obtained through DBSCAN.

Selecting the number of clusters with silhouette analysis on KMeans clustering : In this example the silhouette analysis is used to choose an optimal value for n_clusters.

Peter J. Rousseeuw (1987). “Silhouettes: a Graphical Aid to the Interpretation and Validation of Cluster Analysis”. Computational and Applied Mathematics 20: 53-65.

If the ground truth labels are not known, the Calinski-Harabasz index (sklearn.metrics.calinski_harabasz_score) - also known as the Variance Ratio Criterion - can be used to evaluate the model, where a higher Calinski-Harabasz score relates to a model with better defined clusters.

The index is the ratio of the sum of between-clusters dispersion and of within-cluster dispersion for all clusters (where dispersion is defined as the sum of distances squared):

In normal usage, the Calinski-Harabasz index is applied to the results of a cluster analysis:

The score is higher when clusters are dense and well separated, which relates to a standard concept of a cluster.

The score is fast to compute.

The Calinski-Harabasz index is generally higher for convex clusters than other concepts of clusters, such as density based clusters like those obtained through DBSCAN.

For a set of data \(E\) of size \(n_E\) which has been clustered into \(k\) clusters, the Calinski-Harabasz score \(s\) is defined as the ratio of the between-clusters dispersion mean and the within-cluster dispersion:

where \(\mathrm{tr}(B_k)\) is trace of the between group dispersion matrix and \(\mathrm{tr}(W_k)\) is the trace of the within-cluster dispersion matrix defined by:

with \(C_q\) the set of points in cluster \(q\), \(c_q\) the center of cluster \(q\), \(c_E\) the center of \(E\), and \(n_q\) the number of points in cluster \(q\).

Caliński, T., & Harabasz, J. (1974). “A Dendrite Method for Cluster Analysis”. Communications in Statistics-theory and Methods 3: 1-27.

If the ground truth labels are not known, the Davies-Bouldin index (sklearn.metrics.davies_bouldin_score) can be used to evaluate the model, where a lower Davies-Bouldin index relates to a model with better separation between the clusters.

This index signifies the average ‘similarity’ between clusters, where the similarity is a measure that compares the distance between clusters with the size of the clusters themselves.

Zero is the lowest possible score. Values closer to zero indicate a better partition.

In normal usage, the Davies-Bouldin index is applied to the results of a cluster analysis as follows:

The computation of Davies-Bouldin is simpler than that of Silhouette scores.

The index is solely based on quantities and features inherent to the dataset as its computation only uses point-wise distances.

The Davies-Bouldin index is generally higher for convex clusters than other concepts of clusters, such as density-based clusters like those obtained from DBSCAN.

The usage of centroid distance limits the distance metric to Euclidean space.

The index is defined as the average similarity between each cluster \(C_i\) for \(i=1, ..., k\) and its most similar one \(C_j\). In the context of this index, similarity is defined as a measure \(R_{ij}\) that trades off:

\(s_i\), the average distance between each point of cluster \(i\) and the centroid of that cluster – also known as cluster diameter.

\(d_{ij}\), the distance between cluster centroids \(i\) and \(j\).

A simple choice to construct \(R_{ij}\) so that it is nonnegative and symmetric is:

Then the Davies-Bouldin index is defined as:

Davies, David L.; Bouldin, Donald W. (1979). “A Cluster Separation Measure” IEEE Transactions on Pattern Analysis and Machine Intelligence. PAMI-1 (2): 224-227.

Halkidi, Maria; Batistakis, Yannis; Vazirgiannis, Michalis (2001). “On Clustering Validation Techniques” Journal of Intelligent Information Systems, 17(2-3), 107-145.

Wikipedia entry for Davies-Bouldin index.

Contingency matrix (sklearn.metrics.cluster.contingency_matrix) reports the intersection cardinality for every true/predicted cluster pair. The contingency matrix provides sufficient statistics for all clustering metrics where the samples are independent and identically distributed and one doesn’t need to account for some instances not being clustered.

The first row of the output array indicates that there are three samples whose true cluster is “a”. Of them, two are in predicted cluster 0, one is in 1, and none is in 2. And the second row indicates that there are three samples whose true cluster is “b”. Of them, none is in predicted cluster 0, one is in 1 and two are in 2.

A confusion matrix for classification is a square contingency matrix where the order of rows and columns correspond to a list of classes.

Allows to examine the spread of each true cluster across predicted clusters and vice versa.

The contingency table calculated is typically utilized in the calculation of a similarity statistic (like the others listed in this document) between the two clusterings.

Contingency matrix is easy to interpret for a small number of clusters, but becomes very hard to interpret for a large number of clusters.

It doesn’t give a single metric to use as an objective for clustering optimisation.

Wikipedia entry for contingency matrix

The pair confusion matrix (sklearn.metrics.cluster.pair_confusion_matrix) is a 2x2 similarity matrix

between two clusterings computed by considering all pairs of samples and counting pairs that are assigned into the same or into different clusters under the true and predicted clusterings.

It has the following entries:

\(C_{00}\) : number of pairs with both clusterings having the samples not clustered together

\(C_{10}\) : number of pairs with the true label clustering having the samples clustered together but the other clustering not having the samples clustered together

\(C_{01}\) : number of pairs with the true label clustering not having the samples clustered together but the other clustering having the samples clustered together

\(C_{11}\) : number of pairs with both clusterings having the samples clustered together

Considering a pair of samples that is clustered together a positive pair, then as in binary classification the count of true negatives is \(C_{00}\), false negatives is \(C_{10}\), true positives is \(C_{11}\) and false positives is \(C_{01}\).

Perfectly matching labelings have all non-zero entries on the diagonal regardless of actual label values:

Labelings that assign all classes members to the same clusters are complete but may not always be pure, hence penalized, and have some off-diagonal non-zero entries:

The matrix is not symmetric:

If classes members are completely split across different clusters, the assignment is totally incomplete, hence the matrix has all zero diagonal entries:

“Comparing Partitions” L. Hubert and P. Arabie, Journal of Classification 1985

**Examples:**

Example 1 (unknown):
```unknown
similarity = np.exp(-beta * distance / distance.std())
```

Example 2 (sql):
```sql
>>> from sklearn.cluster import SpectralClustering
>>> sc = SpectralClustering(3, affinity='precomputed', n_init=100,
...                         assign_labels='discretize')
>>> sc.fit_predict(adjacency_matrix)
```

Example 3 (python):
```python
>>> from sklearn import metrics
>>> labels_true = [0, 0, 0, 1, 1, 1]
>>> labels_pred = [0, 0, 1, 1, 2, 2]
>>> metrics.rand_score(labels_true, labels_pred)
0.66
```

Example 4 (unknown):
```unknown
>>> metrics.adjusted_rand_score(labels_true, labels_pred)
0.24
```

---

## MDS#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.manifold.MDS.html

**Contents:**
- MDS#
- Gallery examples#

Multidimensional scaling.

Read more in the User Guide.

Number of dimensions in which to immerse the dissimilarities.

If True, perform metric MDS; otherwise, perform nonmetric MDS. When False (i.e. non-metric MDS), dissimilarities with 0 are considered as missing values.

Changed in version 1.8: The parameter metric was renamed into metric_mds.

Number of times the SMACOF algorithm will be run with different initializations. The final results will be the best output of the runs, determined by the run with the smallest final stress.

Changed in version 1.9: The default value for n_init will change from 4 to 1 in version 1.9.

The initialization approach. If random, random initialization is used. If classical_mds, then classical MDS is run and used as initialization for MDS (in this case, the value of n_init is ignored).

Added in version 1.8.

Changed in version 1.10: The default value for init will change to classical_mds.

Maximum number of iterations of the SMACOF algorithm for a single run.

The tolerance with respect to stress (normalized by the sum of squared embedding distances) at which to declare convergence.

Changed in version 1.7: The default value for eps has changed from 1e-3 to 1e-6, as a result of a bugfix in the computation of the convergence criterion.

The number of jobs to use for the computation. If multiple initializations are used (n_init), each run of the algorithm is computed in parallel.

None means 1 unless in a joblib.parallel_backend context. -1 means using all processors. See Glossary for more details.

Determines the random number generator used to initialize the centers. Pass an int for reproducible results across multiple function calls. See Glossary.

Dissimilarity measure to use:

Pairwise Euclidean distances between points in the dataset.

Pre-computed dissimilarities are passed directly to fit and fit_transform.

Deprecated since version 1.8: dissimilarity was renamed metric in 1.8 and will be removed in 1.10.

Metric to use for dissimilarity computation. Default is “euclidean”.

If metric is a string, it must be one of the options allowed by scipy.spatial.distance.pdist for its metric parameter, or a metric listed in sklearn.metrics.pairwise.distance_metrics

If metric is “precomputed”, X is assumed to be a distance matrix and must be square during fit.

If metric is a callable function, it takes two arrays representing 1D vectors as inputs and must return one value indicating the distance between those vectors. This works for Scipy’s metrics, but is less efficient than passing the metric name as a string.

Changed in version 1.8: Prior to 1.8, metric=True/False was used to select metric/non-metric MDS, which is now the role of metric_mds. The support for True and False will be dropped in version 1.10, use metric_mds instead.

Additional keyword arguments for the dissimilarity computation.

Added in version 1.8.

Whether to return normalized stress value (Stress-1) instead of raw stress. By default, metric MDS returns raw stress while non-metric MDS returns normalized stress.

Added in version 1.2.

Changed in version 1.4: The default value changed from False to "auto" in version 1.4.

Changed in version 1.7: Normalized stress is now supported for metric MDS as well.

Stores the position of the dataset in the embedding space.

The final value of the stress (sum of squared distance of the disparities and the distances for all constrained points). If normalized_stress=True, returns Stress-1. A value of 0 indicates “perfect” fit, 0.025 excellent, 0.05 good, 0.1 fair, and 0.2 poor [1].

Pairwise dissimilarities between the points. Symmetric matrix that:

either uses a custom dissimilarity matrix by setting dissimilarity to ‘precomputed’;

or constructs a dissimilarity matrix from data using Euclidean distances.

Number of features seen during fit.

Added in version 0.24.

Names of features seen during fit. Defined only when X has feature names that are all strings.

Added in version 1.0.

The number of iterations corresponding to the best stress.

Principal component analysis that is a linear dimensionality reduction method.

Non-linear dimensionality reduction using kernels and PCA.

T-distributed Stochastic Neighbor Embedding.

Manifold learning based on Isometric Mapping.

Manifold learning using Locally Linear Embedding.

Spectral embedding for non-linear dimensionality.

“Nonmetric multidimensional scaling: a numerical method” Kruskal, J. Psychometrika, 29 (1964)

“Multidimensional scaling by optimizing goodness of fit to a nonmetric hypothesis” Kruskal, J. Psychometrika, 29, (1964)

“Modern Multidimensional Scaling - Theory and Applications” Borg, I.; Groenen P. Springer Series in Statistics (1997)

For a more detailed example of usage, see Multi-dimensional scaling.

For a comparison of manifold learning techniques, see Comparison of Manifold Learning methods.

Compute the position of the points in the embedding space.

Input data. If metric=='precomputed', the input should be the dissimilarity matrix.

Not used, present for API consistency by convention.

Starting configuration of the embedding to initialize the SMACOF algorithm. By default, the algorithm is initialized with a randomly chosen array.

Fit the data from X, and returns the embedded coordinates.

Input data. If metric=='precomputed', the input should be the dissimilarity matrix.

Not used, present for API consistency by convention.

Starting configuration of the embedding to initialize the SMACOF algorithm. By default, the algorithm is initialized with a randomly chosen array.

X transformed in the new space.

Get metadata routing of this object.

Please check User Guide on how the routing mechanism works.

A MetadataRequest encapsulating routing information.

Get parameters for this estimator.

If True, will return the parameters for this estimator and contained subobjects that are estimators.

Parameter names mapped to their values.

Configure whether metadata should be requested to be passed to the fit method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to fit if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to fit.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Added in version 1.3.

Metadata routing for init parameter in fit.

Set the parameters of this estimator.

The method works on simple estimators as well as on nested objects (such as Pipeline). The latter have parameters of the form <component>__<parameter> so that it’s possible to update each component of a nested object.

Estimator parameters.

Comparison of Manifold Learning methods

Manifold learning on handwritten digits: Locally Linear Embedding, Isomap…

Manifold Learning methods on a severed sphere

Multi-dimensional scaling

**Examples:**

Example 1 (sql):
```sql
>>> from sklearn.datasets import load_digits
>>> from sklearn.manifold import MDS
>>> X, _ = load_digits(return_X_y=True)
>>> X.shape
(1797, 64)
>>> embedding = MDS(n_components=2, n_init=1, init="random")
>>> X_transformed = embedding.fit_transform(X[:100])
>>> X_transformed.shape
(100, 2)
```

---

## SelectFpr#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectFpr.html

**Contents:**
- SelectFpr#

Filter: Select the pvalues below alpha based on a FPR test.

FPR test stands for False Positive Rate test. It controls the total amount of false detections.

Read more in the User Guide.

Function taking two arrays X and y, and returning a pair of arrays (scores, pvalues). Default is f_classif (see below “See Also”). The default function only works with classification tasks.

Features with p-values less than alpha are selected.

p-values of feature scores.

Number of features seen during fit.

Added in version 0.24.

Names of features seen during fit. Defined only when X has feature names that are all strings.

Added in version 1.0.

ANOVA F-value between label/feature for classification tasks.

Chi-squared stats of non-negative features for classification tasks.

Mutual information for a discrete target.

F-value between label/feature for regression tasks.

Mutual information for a continuous target.

Select features based on percentile of the highest scores.

Select features based on the k highest scores.

Select features based on an estimated false discovery rate.

Select features based on family-wise error rate.

Univariate feature selector with configurable mode.

Run score function on (X, y) and get the appropriate features.

The training input samples.

The target values (class labels in classification, real numbers in regression). If the selector is unsupervised then y can be set to None.

Returns the instance itself.

Fit to data, then transform it.

Fits transformer to X and y with optional parameters fit_params and returns a transformed version of X.

Target values (None for unsupervised transformations).

Additional fit parameters. Pass only if the estimator accepts additional params in its fit method.

Mask feature names according to selected features.

If input_features is None, then feature_names_in_ is used as feature names in. If feature_names_in_ is not defined, then the following input feature names are generated: ["x0", "x1", ..., "x(n_features_in_ - 1)"].

If input_features is an array-like, then input_features must match feature_names_in_ if feature_names_in_ is defined.

Transformed feature names.

Get metadata routing of this object.

Please check User Guide on how the routing mechanism works.

A MetadataRequest encapsulating routing information.

Get parameters for this estimator.

If True, will return the parameters for this estimator and contained subobjects that are estimators.

Parameter names mapped to their values.

Get a mask, or integer index, of the features selected.

If True, the return value will be an array of integers, rather than a boolean mask.

An index that selects the retained features from a feature vector. If indices is False, this is a boolean array of shape [# input features], in which an element is True iff its corresponding feature is selected for retention. If indices is True, this is an integer array of shape [# output features] whose values are indices into the input feature vector.

Reverse the transformation operation.

X with columns of zeros inserted where features would have been removed by transform.

Set output container.

See Introducing the set_output API for an example on how to use the API.

Configure output of transform and fit_transform.

"default": Default output format of a transformer

"pandas": DataFrame output

"polars": Polars output

None: Transform configuration is unchanged

Added in version 1.4: "polars" option was added.

Set the parameters of this estimator.

The method works on simple estimators as well as on nested objects (such as Pipeline). The latter have parameters of the form <component>__<parameter> so that it’s possible to update each component of a nested object.

Estimator parameters.

Reduce X to the selected features.

The input samples with only the selected features.

**Examples:**

Example 1 (sql):
```sql
>>> from sklearn.datasets import load_breast_cancer
>>> from sklearn.feature_selection import SelectFpr, chi2
>>> X, y = load_breast_cancer(return_X_y=True)
>>> X.shape
(569, 30)
>>> X_new = SelectFpr(chi2, alpha=0.01).fit_transform(X, y)
>>> X_new.shape
(569, 16)
```

---

## HuberRegressor#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.HuberRegressor.html

**Contents:**
- HuberRegressor#
- Gallery examples#

L2-regularized linear regression model that is robust to outliers.

The Huber Regressor optimizes the squared loss for the samples where |(y - Xw - c) / sigma| < epsilon and the absolute loss for the samples where |(y - Xw - c) / sigma| > epsilon, where the model coefficients w, the intercept c and the scale sigma are parameters to be optimized. The parameter sigma makes sure that if y is scaled up or down by a certain factor, one does not need to rescale epsilon to achieve the same robustness. Note that this does not take into account the fact that the different features of X may be of different scales.

The Huber loss function has the advantage of not being heavily influenced by the outliers while not completely ignoring their effect.

Read more in the User Guide

Added in version 0.18.

The parameter epsilon controls the number of samples that should be classified as outliers. The smaller the epsilon, the more robust it is to outliers. Epsilon must be in the range [1, inf).

Maximum number of iterations that scipy.optimize.minimize(method="L-BFGS-B") should run for.

Strength of the squared L2 regularization. Note that the penalty is equal to alpha * ||w||^2. Must be in the range [0, inf).

This is useful if the stored attributes of a previously used model has to be reused. If set to False, then the coefficients will be rewritten for every call to fit. See the Glossary.

Whether or not to fit the intercept. This can be set to False if the data is already centered around the origin.

The iteration will stop when max{|proj g_i | i = 1, ..., n} <= tol where pg_i is the i-th component of the projected gradient.

Features got by optimizing the L2-regularized Huber loss.

The value by which |y - Xw - c| is scaled down.

Number of features seen during fit.

Added in version 0.24.

Names of features seen during fit. Defined only when X has feature names that are all strings.

Added in version 1.0.

Number of iterations that scipy.optimize.minimize(method="L-BFGS-B") has run for.

Changed in version 0.20: In SciPy <= 1.0.0 the number of lbfgs iterations may exceed max_iter. n_iter_ will now report at most max_iter.

A boolean mask which is set to True where the samples are identified as outliers.

RANSAC (RANdom SAmple Consensus) algorithm.

Theil-Sen Estimator robust multivariate regression model.

Fitted by minimizing a regularized empirical loss with SGD.

Peter J. Huber, Elvezio M. Ronchetti, Robust Statistics Concomitant scale estimates, p. 172

Art B. Owen (2006), A robust hybrid of lasso and ridge regression.

Fit the model according to the given training data.

Training vector, where n_samples is the number of samples and n_features is the number of features.

Target vector relative to X.

Weight given to each sample.

Fitted HuberRegressor estimator.

Get metadata routing of this object.

Please check User Guide on how the routing mechanism works.

A MetadataRequest encapsulating routing information.

Get parameters for this estimator.

If True, will return the parameters for this estimator and contained subobjects that are estimators.

Parameter names mapped to their values.

Predict using the linear model.

Returns predicted values.

Return coefficient of determination on test data.

The coefficient of determination, \(R^2\), is defined as \((1 - \frac{u}{v})\), where \(u\) is the residual sum of squares ((y_true - y_pred)** 2).sum() and \(v\) is the total sum of squares ((y_true - y_true.mean()) ** 2).sum(). The best possible score is 1.0 and it can be negative (because the model can be arbitrarily worse). A constant model that always predicts the expected value of y, disregarding the input features, would get a \(R^2\) score of 0.0.

Test samples. For some estimators this may be a precomputed kernel matrix or a list of generic objects instead with shape (n_samples, n_samples_fitted), where n_samples_fitted is the number of samples used in the fitting for the estimator.

\(R^2\) of self.predict(X) w.r.t. y.

The \(R^2\) score used when calling score on a regressor uses multioutput='uniform_average' from version 0.23 to keep consistent with default value of r2_score. This influences the score method of all the multioutput regressors (except for MultiOutputRegressor).

Configure whether metadata should be requested to be passed to the fit method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to fit if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to fit.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Added in version 1.3.

Metadata routing for sample_weight parameter in fit.

Set the parameters of this estimator.

The method works on simple estimators as well as on nested objects (such as Pipeline). The latter have parameters of the form <component>__<parameter> so that it’s possible to update each component of a nested object.

Estimator parameters.

Configure whether metadata should be requested to be passed to the score method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to score if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to score.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Added in version 1.3.

Metadata routing for sample_weight parameter in score.

HuberRegressor vs Ridge on dataset with strong outliers

Ridge coefficients as a function of the L2 Regularization

Robust linear estimator fitting

**Examples:**

Example 1 (python):
```python
>>> import numpy as np
>>> from sklearn.linear_model import HuberRegressor, LinearRegression
>>> from sklearn.datasets import make_regression
>>> rng = np.random.RandomState(0)
>>> X, y, coef = make_regression(
...     n_samples=200, n_features=2, noise=4.0, coef=True, random_state=0)
>>> X[:4] = rng.uniform(10, 20, (4, 2))
>>> y[:4] = rng.uniform(10, 20, 4)
>>> huber = HuberRegressor().fit(X, y)
>>> huber.score(X, y)
-7.284
>>> huber.predict(X[:1,])
array([806.7200])
>>> linear = LinearRegression().fit(X, y)
>>> print("True coefficients:", coef)
True coefficients: [20.4923...  34.1698...]
>>> print("Huber coefficients:", huber.coef_)
Huber coefficients: [17.7906... 31.0106...]
>>> print("Linear Regression coefficients:", linear.coef_)
Linear Regression coefficients: [-1.9221...  7.0226...]
```

---

## permutation_importance#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.inspection.permutation_importance.html

**Contents:**
- permutation_importance#
- Gallery examples#

Permutation importance for feature evaluation [BRE].

The estimator is required to be a fitted estimator. X can be the data set used to train the estimator or a hold-out set. The permutation importance of a feature is calculated as follows. First, a baseline metric, defined by scoring, is evaluated on a (potentially different) dataset defined by the X. Next, a feature column from the validation set is permuted and the metric is evaluated again. The permutation importance is defined to be the difference between the baseline metric and metric from permutating the feature column.

Read more in the User Guide.

An estimator that has already been fitted and is compatible with scorer.

Data on which permutation importance will be computed.

Targets for supervised or None for unsupervised.

Scorer to use. If scoring represents a single score, one can use:

str: see String name scorers for options.

callable: a scorer callable object (e.g., function) with signature scorer(estimator, X, y). See Callable scorers for details.

None: the estimator’s default evaluation criterion is used.

If scoring represents multiple scores, one can use:

a list or tuple of unique strings;

a callable returning a dictionary where the keys are the metric names and the values are the metric scores;

a dictionary with metric names as keys and callables a values.

Passing multiple scores to scoring is more efficient than calling permutation_importance for each of the scores as it reuses predictions to avoid redundant computation.

Number of times to permute a feature.

Number of jobs to run in parallel. The computation is done by computing permutation score for each columns and parallelized over the columns. None means 1 unless in a joblib.parallel_backend context. -1 means using all processors. See Glossary for more details.

Pseudo-random number generator to control the permutations of each feature. Pass an int to get reproducible results across function calls. See Glossary.

Sample weights used in scoring.

Added in version 0.24.

The number of samples to draw from X to compute feature importance in each repeat (without replacement).

If int, then draw max_samples samples.

If float, then draw max_samples * X.shape[0] samples.

If max_samples is equal to 1.0 or X.shape[0], all samples will be used.

While using this option may provide less accurate importance estimates, it keeps the method tractable when evaluating feature importance on large datasets. In combination with n_repeats, this allows to control the computational speed vs statistical accuracy trade-off of this method.

Added in version 1.0.

Dictionary-like object, with the following attributes.

Mean of feature importance over n_repeats.

Standard deviation over n_repeats.

Raw permutation importance scores.

If there are multiple scoring metrics in the scoring parameter result is a dict with scorer names as keys (e.g. ‘roc_auc’) and Bunch objects like above as values.

L. Breiman, “Random Forests”, Machine Learning, 45(1), 5-32, 2001.

Feature importances with a forest of trees

Gradient Boosting regression

Permutation Importance vs Random Forest Feature Importance (MDI)

Permutation Importance with Multicollinear or Correlated Features

Release Highlights for scikit-learn 0.22

**Examples:**

Example 1 (sql):
```sql
>>> from sklearn.linear_model import LogisticRegression
>>> from sklearn.inspection import permutation_importance
>>> X = [[1, 9, 9],[1, 9, 9],[1, 9, 9],
...      [0, 9, 9],[0, 9, 9],[0, 9, 9]]
>>> y = [1, 1, 1, 0, 0, 0]
>>> clf = LogisticRegression().fit(X, y)
>>> result = permutation_importance(clf, X, y, n_repeats=10,
...                                 random_state=0)
>>> result.importances_mean
array([0.4666, 0.       , 0.       ])
>>> result.importances_std
array([0.2211, 0.       , 0.       ])
```

---

## l1_min_c#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.svm.l1_min_c.html

**Contents:**
- l1_min_c#
- Gallery examples#

Return the lowest bound for C.

The lower bound for C is computed such that for C in (l1_min_C, infinity) the model is guaranteed not to be empty. This applies to l1 penalized classifiers, such as sklearn.svm.LinearSVC with penalty=’l1’ and sklearn.linear_model.LogisticRegression with l1_ratio=1.

This value is valid if class_weight parameter in fit() is not set.

For an example of how to use this function, see Regularization path of L1- Logistic Regression.

Training vector, where n_samples is the number of samples and n_features is the number of features.

Target vector relative to X.

Specifies the loss function. With ‘squared_hinge’ it is the squared hinge loss (a.k.a. L2 loss). With ‘log’ it is the loss of logistic regression models.

Specifies if the intercept should be fitted by the model. It must match the fit() method parameter.

When fit_intercept is True, instance vector x becomes [x, intercept_scaling], i.e. a “synthetic” feature with constant value equals to intercept_scaling is appended to the instance vector. It must match the fit() method parameter.

Regularization path of L1- Logistic Regression

**Examples:**

Example 1 (python):
```python
>>> from sklearn.svm import l1_min_c
>>> from sklearn.datasets import make_classification
>>> X, y = make_classification(n_samples=100, n_features=20, random_state=42)
>>> print(f"{l1_min_c(X, y, loss='squared_hinge', fit_intercept=True):.4f}")
0.0044
```

---

## RandomizedSearchCV#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html

**Contents:**
- RandomizedSearchCV#
- Gallery examples#

Randomized search on hyper parameters.

RandomizedSearchCV implements a “fit” and a “score” method. It also implements “score_samples”, “predict”, “predict_proba”, “decision_function”, “transform” and “inverse_transform” if they are implemented in the estimator used.

The parameters of the estimator used to apply these methods are optimized by cross-validated search over parameter settings.

In contrast to GridSearchCV, not all parameter values are tried out, but rather a fixed number of parameter settings is sampled from the specified distributions. The number of parameter settings that are tried is given by n_iter.

If all parameters are presented as a list, sampling without replacement is performed. If at least one parameter is given as a distribution, sampling with replacement is used. It is highly recommended to use continuous distributions for continuous parameters.

Read more in the User Guide.

Added in version 0.14.

An object of that type is instantiated for each grid point. This is assumed to implement the scikit-learn estimator interface. Either estimator needs to provide a score function, or scoring must be passed.

Dictionary with parameters names (str) as keys and distributions or lists of parameters to try. Distributions must provide a rvs method for sampling (such as those from scipy.stats.distributions). If a list is given, it is sampled uniformly. If a list of dicts is given, first a dict is sampled uniformly, and then a parameter is sampled using that dict as above.

Number of parameter settings that are sampled. n_iter trades off runtime vs quality of the solution.

Strategy to evaluate the performance of the cross-validated model on the test set.

If scoring represents a single score, one can use:

a single string (see String name scorers);

a callable (see Callable scorers) that returns a single value;

None, the estimator’s default evaluation criterion is used.

If scoring represents multiple scores, one can use:

a list or tuple of unique strings;

a callable returning a dictionary where the keys are the metric names and the values are the metric scores;

a dictionary with metric names as keys and callables as values.

See Specifying multiple metrics for evaluation for an example.

If None, the estimator’s score method is used.

Number of jobs to run in parallel. None means 1 unless in a joblib.parallel_backend context. -1 means using all processors. See Glossary for more details.

Changed in version v0.20: n_jobs default changed from 1 to None

Refit an estimator using the best found parameters on the whole dataset.

For multiple metric evaluation, this needs to be a str denoting the scorer that would be used to find the best parameters for refitting the estimator at the end.

Where there are considerations other than maximum score in choosing a best estimator, refit can be set to a function which returns the selected best_index_ given the cv_results_. In that case, the best_estimator_ and best_params_ will be set according to the returned best_index_ while the best_score_ attribute will not be available.

The refitted estimator is made available at the best_estimator_ attribute and permits using predict directly on this RandomizedSearchCV instance.

Also for multiple metric evaluation, the attributes best_index_, best_score_ and best_params_ will only be available if refit is set and all of them will be determined w.r.t this specific scorer.

See scoring parameter to know more about multiple metric evaluation.

See this example for an example of how to use refit=callable to balance model complexity and cross-validated score.

Changed in version 0.20: Support for callable added.

Determines the cross-validation splitting strategy. Possible inputs for cv are:

None, to use the default 5-fold cross validation,

integer, to specify the number of folds in a (Stratified)KFold,

An iterable yielding (train, test) splits as arrays of indices.

For integer/None inputs, if the estimator is a classifier and y is either binary or multiclass, StratifiedKFold is used. In all other cases, KFold is used. These splitters are instantiated with shuffle=False so the splits will be the same across calls.

Refer User Guide for the various cross-validation strategies that can be used here.

Changed in version 0.22: cv default value if None changed from 3-fold to 5-fold.

Controls the verbosity: the higher, the more messages.

>1 : the computation time for each fold and parameter candidate is displayed;

>2 : the score is also displayed;

>3 : the fold and candidate parameter indexes are also displayed together with the starting time of the computation.

Controls the number of jobs that get dispatched during parallel execution. Reducing this number can be useful to avoid an explosion of memory consumption when more jobs get dispatched than CPUs can process. This parameter can be:

None, in which case all the jobs are immediately created and spawned. Use this for lightweight and fast-running jobs, to avoid delays due to on-demand spawning of the jobs

An int, giving the exact number of total jobs that are spawned

A str, giving an expression as a function of n_jobs, as in ‘2*n_jobs’

Pseudo random number generator state used for random uniform sampling from lists of possible values instead of scipy.stats distributions. Pass an int for reproducible output across multiple function calls. See Glossary.

Value to assign to the score if an error occurs in estimator fitting. If set to ‘raise’, the error is raised. If a numeric value is given, FitFailedWarning is raised. This parameter does not affect the refit step, which will always raise the error.

If False, the cv_results_ attribute will not include training scores. Computing training scores is used to get insights on how different parameter settings impact the overfitting/underfitting trade-off. However computing the scores on the training set can be computationally expensive and is not strictly required to select the parameters that yield the best generalization performance.

Added in version 0.19.

Changed in version 0.21: Default value was changed from True to False

A dict with keys as column headers and values as columns, that can be imported into a pandas DataFrame.

For instance the below given table

will be represented by a cv_results_ dict of:

For an example of analysing cv_results_, see Statistical comparison of models using grid search.

The key 'params' is used to store a list of parameter settings dicts for all the parameter candidates.

The mean_fit_time, std_fit_time, mean_score_time and std_score_time are all in seconds.

For multi-metric evaluation, the scores for all the scorers are available in the cv_results_ dict at the keys ending with that scorer’s name ('_<scorer_name>') instead of '_score' shown above. (‘split0_test_precision’, ‘mean_train_precision’ etc.)

Estimator that was chosen by the search, i.e. estimator which gave highest score (or smallest loss if specified) on the left out data. Not available if refit=False.

For multi-metric evaluation, this attribute is present only if refit is specified.

See refit parameter for more information on allowed values.

Mean cross-validated score of the best_estimator.

For multi-metric evaluation, this is not available if refit is False. See refit parameter for more information.

This attribute is not available if refit is a function.

Parameter setting that gave the best results on the hold out data.

For multi-metric evaluation, this is not available if refit is False. See refit parameter for more information.

The index (of the cv_results_ arrays) which corresponds to the best candidate parameter setting.

The dict at search.cv_results_['params'][search.best_index_] gives the parameter setting for the best model, that gives the highest mean score (search.best_score_).

For multi-metric evaluation, this is not available if refit is False. See refit parameter for more information.

Scorer function used on the held out data to choose the best parameters for the model.

For multi-metric evaluation, this attribute holds the validated scoring dict which maps the scorer key to the scorer callable.

The number of cross-validation splits (folds/iterations).

Seconds used for refitting the best model on the whole dataset.

This is present only if refit is not False.

Added in version 0.20.

Whether or not the scorers compute several metrics.

Number of features seen during fit.

Names of features seen during fit. Only defined if best_estimator_ is defined (see the documentation for the refit parameter for more details) and that best_estimator_ exposes feature_names_in_ when fit.

Added in version 1.0.

Does exhaustive search over a grid of parameters.

A generator over parameter settings, constructed from param_distributions.

The parameters selected are those that maximize the score of the held-out data, according to the scoring parameter.

If n_jobs was set to a value higher than one, the data is copied for each parameter setting(and not n_jobs times). This is done for efficiency reasons if individual jobs take very little time, but may raise errors if the dataset is large and not enough memory is available. A workaround in this case is to set pre_dispatch. Then, the memory is copied only pre_dispatch many times. A reasonable value for pre_dispatch is 2 * n_jobs.

Call decision_function on the estimator with the best found parameters.

Only available if refit=True and the underlying estimator supports decision_function.

Must fulfill the input assumptions of the underlying estimator.

Result of the decision function for X based on the estimator with the best found parameters.

Run fit with all sets of parameters.

Training vectors, where n_samples is the number of samples and n_features is the number of features. For precomputed kernel or distance matrix, the expected shape of X is (n_samples, n_samples).

Target relative to X for classification or regression; None for unsupervised learning.

Parameters passed to the fit method of the estimator, the scorer, and the CV splitter.

If a fit parameter is an array-like whose length is equal to num_samples then it will be split by cross-validation along with X and y. For example, the sample_weight parameter is split because len(sample_weights) = len(X). However, this behavior does not apply to groups which is passed to the splitter configured via the cv parameter of the constructor. Thus, groups is used to perform the split and determines which samples are assigned to the each side of the a split.

Instance of fitted estimator.

Get metadata routing of this object.

Please check User Guide on how the routing mechanism works.

Added in version 1.4.

A MetadataRouter encapsulating routing information.

Get parameters for this estimator.

If True, will return the parameters for this estimator and contained subobjects that are estimators.

Parameter names mapped to their values.

Call inverse_transform on the estimator with the best found params.

Only available if the underlying estimator implements inverse_transform and refit=True.

Must fulfill the input assumptions of the underlying estimator.

Result of the inverse_transform function for X based on the estimator with the best found parameters.

Call predict on the estimator with the best found parameters.

Only available if refit=True and the underlying estimator supports predict.

Must fulfill the input assumptions of the underlying estimator.

The predicted labels or values for X based on the estimator with the best found parameters.

Call predict_log_proba on the estimator with the best found parameters.

Only available if refit=True and the underlying estimator supports predict_log_proba.

Must fulfill the input assumptions of the underlying estimator.

Predicted class log-probabilities for X based on the estimator with the best found parameters. The order of the classes corresponds to that in the fitted attribute classes_.

Call predict_proba on the estimator with the best found parameters.

Only available if refit=True and the underlying estimator supports predict_proba.

Must fulfill the input assumptions of the underlying estimator.

Predicted class probabilities for X based on the estimator with the best found parameters. The order of the classes corresponds to that in the fitted attribute classes_.

Return the score on the given data, if the estimator has been refit.

This uses the score defined by scoring where provided, and the best_estimator_.score method otherwise.

Input data, where n_samples is the number of samples and n_features is the number of features.

Target relative to X for classification or regression; None for unsupervised learning.

Parameters to be passed to the underlying scorer(s).

Added in version 1.4: Only available if enable_metadata_routing=True. See Metadata Routing User Guide for more details.

The score defined by scoring if provided, and the best_estimator_.score method otherwise.

Call score_samples on the estimator with the best found parameters.

Only available if refit=True and the underlying estimator supports score_samples.

Added in version 0.24.

Data to predict on. Must fulfill input requirements of the underlying estimator.

The best_estimator_.score_samples method.

Set the parameters of this estimator.

The method works on simple estimators as well as on nested objects (such as Pipeline). The latter have parameters of the form <component>__<parameter> so that it’s possible to update each component of a nested object.

Estimator parameters.

Call transform on the estimator with the best found parameters.

Only available if the underlying estimator supports transform and refit=True.

Must fulfill the input assumptions of the underlying estimator.

X transformed in the new space based on the estimator with the best found parameters.

Faces recognition example using eigenfaces and SVMs

Column Transformer with Mixed Types

Comparison of kernel ridge and Gaussian process regression

Sample pipeline for text feature extraction and evaluation

Comparing randomized search and grid search for hyperparameter estimation

Release Highlights for scikit-learn 0.24

**Examples:**

Example 1 (json):
```json
{
'param_kernel' : masked_array(data = ['rbf', 'rbf', 'rbf'],
                              mask = False),
'param_gamma'  : masked_array(data = [0.1 0.2 0.3], mask = False),
'split0_test_score'  : [0.80, 0.84, 0.70],
'split1_test_score'  : [0.82, 0.50, 0.70],
'mean_test_score'    : [0.81, 0.67, 0.70],
'std_test_score'     : [0.01, 0.24, 0.00],
'rank_test_score'    : [1, 3, 2],
'split0_train_score' : [0.80, 0.92, 0.70],
'split1_train_score' : [0.82, 0.55, 0.70],
'mean_train_score'   : [0.81, 0.74, 0.70],
'std_train_score'    : [0.01, 0.19, 0.00],
'mean_fit_time'      : [0.73, 0.63, 0.43],
'std_fit_time'       : [0.01, 0.02, 0.01],
'mean_score_time'    : [0.01, 0.06, 0.04],
'std_score_time'     : [0.00, 0.00, 0.00],
'params'             : [{'kernel' : 'rbf', 'gamma' : 0.1}, ...],
}
```

Example 2 (json):
```json
>>> from sklearn.datasets import load_iris
>>> from sklearn.linear_model import LogisticRegression
>>> from sklearn.model_selection import RandomizedSearchCV
>>> from scipy.stats import uniform
>>> iris = load_iris()
>>> logistic = LogisticRegression(solver='saga', tol=1e-2, max_iter=200,
...                               random_state=0)
>>> distributions = dict(C=uniform(loc=0, scale=4),
...                      l1_ratio=[0, 1])
>>> clf = RandomizedSearchCV(logistic, distributions, random_state=0)
>>> search = clf.fit(iris.data, iris.target)
>>> search.best_params_
{'C': np.float64(2.195...), 'l1_ratio': 1}
```

---

## RFE#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFE.html

**Contents:**
- RFE#
- Gallery examples#

Feature ranking with recursive feature elimination.

Given an external estimator that assigns weights to features (e.g., the coefficients of a linear model), the goal of recursive feature elimination (RFE) is to select features by recursively considering smaller and smaller sets of features. First, the estimator is trained on the initial set of features and the importance of each feature is obtained either through any specific attribute or callable. Then, the least important features are pruned from current set of features. That procedure is recursively repeated on the pruned set until the desired number of features to select is eventually reached.

Read more in the User Guide.

A supervised learning estimator with a fit method that provides information about feature importance (e.g. coef_, feature_importances_).

The number of features to select. If None, half of the features are selected. If integer, the parameter is the absolute number of features to select. If float between 0 and 1, it is the fraction of features to select.

Changed in version 0.24: Added float values for fractions.

If greater than or equal to 1, then step corresponds to the (integer) number of features to remove at each iteration. If within (0.0, 1.0), then step corresponds to the percentage (rounded down) of features to remove at each iteration.

Controls verbosity of output.

If ‘auto’, uses the feature importance either through a coef_ or feature_importances_ attributes of estimator.

Also accepts a string that specifies an attribute name/path for extracting feature importance (implemented with attrgetter). For example, give regressor_.coef_ in case of TransformedTargetRegressor or named_steps.clf.feature_importances_ in case of class:~sklearn.pipeline.Pipeline with its last step named clf.

If callable, overrides the default feature importance getter. The callable is passed with the fitted estimator and it should return importance for each feature.

Added in version 0.24.

Classes labels available when estimator is a classifier.

The fitted estimator used to select features.

The number of selected features.

Number of features seen during fit. Only defined if the underlying estimator exposes such an attribute when fit.

Added in version 0.24.

Names of features seen during fit. Defined only when X has feature names that are all strings.

Added in version 1.0.

The feature ranking, such that ranking_[i] corresponds to the ranking position of the i-th feature. Selected (i.e., estimated best) features are assigned rank 1.

The mask of selected features.

Recursive feature elimination with built-in cross-validated selection of the best number of features.

Feature selection based on thresholds of importance weights.

Sequential cross-validation based feature selection. Does not rely on importance weights.

Allows NaN/Inf in the input if the underlying estimator does as well.

Guyon, I., Weston, J., Barnhill, S., & Vapnik, V., “Gene selection for cancer classification using support vector machines”, Mach. Learn., 46(1-3), 389–422, 2002.

The following example shows how to retrieve the 5 most informative features in the Friedman #1 dataset.

Compute the decision function of X.

The input samples. Internally, it will be converted to dtype=np.float32 and if a sparse matrix is provided to a sparse csr_matrix.

The decision function of the input samples. The order of the classes corresponds to that in the attribute classes_. Regression and binary classification produce an array of shape [n_samples].

Fit the RFE model and then the underlying estimator on the selected features.

The training input samples.

If enable_metadata_routing=False (default): Parameters directly passed to the fit method of the underlying estimator.

If enable_metadata_routing=True: Parameters safely routed to the fit method of the underlying estimator.

Changed in version 1.6: See Metadata Routing User Guide for more details.

Fit to data, then transform it.

Fits transformer to X and y with optional parameters fit_params and returns a transformed version of X.

Target values (None for unsupervised transformations).

Additional fit parameters. Pass only if the estimator accepts additional params in its fit method.

Mask feature names according to selected features.

If input_features is None, then feature_names_in_ is used as feature names in. If feature_names_in_ is not defined, then the following input feature names are generated: ["x0", "x1", ..., "x(n_features_in_ - 1)"].

If input_features is an array-like, then input_features must match feature_names_in_ if feature_names_in_ is defined.

Transformed feature names.

Get metadata routing of this object.

Please check User Guide on how the routing mechanism works.

Added in version 1.6.

A MetadataRouter encapsulating routing information.

Get parameters for this estimator.

If True, will return the parameters for this estimator and contained subobjects that are estimators.

Parameter names mapped to their values.

Get a mask, or integer index, of the features selected.

If True, the return value will be an array of integers, rather than a boolean mask.

An index that selects the retained features from a feature vector. If indices is False, this is a boolean array of shape [# input features], in which an element is True iff its corresponding feature is selected for retention. If indices is True, this is an integer array of shape [# output features] whose values are indices into the input feature vector.

Reverse the transformation operation.

X with columns of zeros inserted where features would have been removed by transform.

Reduce X to the selected features and predict using the estimator.

Parameters to route to the predict method of the underlying estimator.

Added in version 1.6: Only available if enable_metadata_routing=True, which can be set by using sklearn.set_config(enable_metadata_routing=True). See Metadata Routing User Guide for more details.

The predicted target values.

Predict class log-probabilities for X.

The class log-probabilities of the input samples. The order of the classes corresponds to that in the attribute classes_.

Predict class probabilities for X.

The input samples. Internally, it will be converted to dtype=np.float32 and if a sparse matrix is provided to a sparse csr_matrix.

The class probabilities of the input samples. The order of the classes corresponds to that in the attribute classes_.

Reduce X to the selected features and return the score of the estimator.

If enable_metadata_routing=False (default): Parameters directly passed to the score method of the underlying estimator.

If enable_metadata_routing=True: Parameters safely routed to the score method of the underlying estimator.

Added in version 1.0.

Changed in version 1.6: See Metadata Routing User Guide for more details.

Score of the underlying base estimator computed with the selected features returned by rfe.transform(X) and y.

Set output container.

See Introducing the set_output API for an example on how to use the API.

Configure output of transform and fit_transform.

"default": Default output format of a transformer

"pandas": DataFrame output

"polars": Polars output

None: Transform configuration is unchanged

Added in version 1.4: "polars" option was added.

Set the parameters of this estimator.

The method works on simple estimators as well as on nested objects (such as Pipeline). The latter have parameters of the form <component>__<parameter> so that it’s possible to update each component of a nested object.

Estimator parameters.

Reduce X to the selected features.

The input samples with only the selected features.

Recursive feature elimination

**Examples:**

Example 1 (sql):
```sql
>>> from sklearn.datasets import make_friedman1
>>> from sklearn.feature_selection import RFE
>>> from sklearn.svm import SVR
>>> X, y = make_friedman1(n_samples=50, n_features=10, random_state=0)
>>> estimator = SVR(kernel="linear")
>>> selector = RFE(estimator, n_features_to_select=5, step=1)
>>> selector = selector.fit(X, y)
>>> selector.support_
array([ True,  True,  True,  True,  True, False, False, False, False,
       False])
>>> selector.ranking_
array([1, 1, 1, 1, 1, 6, 4, 3, 2, 5])
```

---

## cross_val_predict#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_predict.html

**Contents:**
- cross_val_predict#
- Gallery examples#

Generate cross-validated estimates for each input data point.

The data is split according to the cv parameter. Each sample belongs to exactly one test set, and its prediction is computed with an estimator fitted on the corresponding training set.

Passing these predictions into an evaluation metric may not be a valid way to measure generalization performance. Results can differ from cross_validate and cross_val_score unless all tests sets have equal size and the metric decomposes over samples.

Read more in the User Guide.

The estimator instance to use to fit the data. It must implement a fit method and the method given by the method parameter.

The data to fit. Can be, for example a list, or an array at least 2d.

The target variable to try to predict in the case of supervised learning.

Group labels for the samples used while splitting the dataset into train/test set. Only used in conjunction with a “Group” cv instance (e.g., GroupKFold).

Changed in version 1.4: groups can only be passed if metadata routing is not enabled via sklearn.set_config(enable_metadata_routing=True). When routing is enabled, pass groups alongside other metadata via the params argument instead. E.g.: cross_val_predict(..., params={'groups': groups}).

Determines the cross-validation splitting strategy. Possible inputs for cv are:

None, to use the default 5-fold cross validation,

int, to specify the number of folds in a (Stratified)KFold,

An iterable that generates (train, test) splits as arrays of indices.

For int/None inputs, if the estimator is a classifier and y is either binary or multiclass, StratifiedKFold is used. In all other cases, KFold is used. These splitters are instantiated with shuffle=False so the splits will be the same across calls.

Refer User Guide for the various cross-validation strategies that can be used here.

Changed in version 0.22: cv default value if None changed from 3-fold to 5-fold.

Number of jobs to run in parallel. Training the estimator and predicting are parallelized over the cross-validation splits. None means 1 unless in a joblib.parallel_backend context. -1 means using all processors. See Glossary for more details.

Parameters to pass to the underlying estimator’s fit and the CV splitter.

Added in version 1.4.

Controls the number of jobs that get dispatched during parallel execution. Reducing this number can be useful to avoid an explosion of memory consumption when more jobs get dispatched than CPUs can process. This parameter can be:

None, in which case all the jobs are immediately created and spawned. Use this for lightweight and fast-running jobs, to avoid delays due to on-demand spawning of the jobs

An int, giving the exact number of total jobs that are spawned

A str, giving an expression as a function of n_jobs, as in ‘2*n_jobs’

The method to be invoked by estimator.

This is the result of calling method. Shape:

When method is ‘predict’ and in special case where method is ‘decision_function’ and the target is binary: (n_samples,)

When method is one of {‘predict_proba’, ‘predict_log_proba’, ‘decision_function’} (unless special case above): (n_samples, n_classes)

If estimator is multioutput, an extra dimension ‘n_outputs’ is added to the end of each shape above.

Calculate score for each CV split.

Calculate one or more scores and timings for each CV split.

In the case that one or more classes are absent in a training portion, a default score needs to be assigned to all instances for that class if method produces columns per class, as in {‘decision_function’, ‘predict_proba’, ‘predict_log_proba’}. For predict_proba this value is 0. In order to ensure finite output, we approximate negative infinity by the minimum finite float value for the dtype in other cases.

For a detailed example of using cross_val_predict to visualize prediction errors, please see Plotting Cross-Validated Predictions.

Combine predictors using stacking

Plotting Cross-Validated Predictions

**Examples:**

Example 1 (python):
```python
>>> from sklearn import datasets, linear_model
>>> from sklearn.model_selection import cross_val_predict
>>> diabetes = datasets.load_diabetes()
>>> X = diabetes.data[:150]
>>> y = diabetes.target[:150]
>>> lasso = linear_model.Lasso()
>>> y_pred = cross_val_predict(lasso, X, y, cv=3)
```

---

## ShrunkCovariance#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.covariance.ShrunkCovariance.html

**Contents:**
- ShrunkCovariance#
- Gallery examples#

Covariance estimator with shrinkage.

Read more in the User Guide.

Specify if the estimated precision is stored.

If True, data will not be centered before computation. Useful when working with data whose mean is almost, but not exactly zero. If False, data will be centered before computation.

Coefficient in the convex combination used for the computation of the shrunk estimate. Range is [0, 1].

Estimated covariance matrix

Estimated location, i.e. the estimated mean.

Estimated pseudo inverse matrix. (stored only if store_precision is True)

Number of features seen during fit.

Added in version 0.24.

Names of features seen during fit. Defined only when X has feature names that are all strings.

Added in version 1.0.

An object for detecting outliers in a Gaussian distributed dataset.

Maximum likelihood covariance estimator.

Sparse inverse covariance estimation with an l1-penalized estimator.

Sparse inverse covariance with cross-validated choice of the l1 penalty.

LedoitWolf Estimator.

Minimum Covariance Determinant (robust estimator of covariance).

Oracle Approximating Shrinkage Estimator.

The regularized covariance is given by:

(1 - shrinkage) * cov + shrinkage * mu * np.identity(n_features)

where mu = trace(cov) / n_features

Compute the Mean Squared Error between two covariance estimators.

The covariance to compare with.

The type of norm used to compute the error. Available error types: - ‘frobenius’ (default): sqrt(tr(A^t.A)) - ‘spectral’: sqrt(max(eigenvalues(A^t.A)) where A is the error (comp_cov - self.covariance_).

If True (default), the squared error norm is divided by n_features. If False, the squared error norm is not rescaled.

Whether to compute the squared error norm or the error norm. If True (default), the squared error norm is returned. If False, the error norm is returned.

The Mean Squared Error (in the sense of the Frobenius norm) between self and comp_cov covariance estimators.

Fit the shrunk covariance model to X.

Training data, where n_samples is the number of samples and n_features is the number of features.

Not used, present for API consistency by convention.

Returns the instance itself.

Get metadata routing of this object.

Please check User Guide on how the routing mechanism works.

A MetadataRequest encapsulating routing information.

Get parameters for this estimator.

If True, will return the parameters for this estimator and contained subobjects that are estimators.

Parameter names mapped to their values.

Getter for the precision matrix.

The precision matrix associated to the current covariance object.

Compute the squared Mahalanobis distances of given observations.

For a detailed example of how outliers affects the Mahalanobis distance, see Robust covariance estimation and Mahalanobis distances relevance.

The observations, the Mahalanobis distances of the which we compute. Observations are assumed to be drawn from the same distribution than the data used in fit.

Squared Mahalanobis distances of the observations.

Compute the log-likelihood of X_test under the estimated Gaussian model.

The Gaussian model is defined by its mean and covariance matrix which are represented respectively by self.location_ and self.covariance_.

Test data of which we compute the likelihood, where n_samples is the number of samples and n_features is the number of features. X_test is assumed to be drawn from the same distribution than the data used in fit (including centering).

Not used, present for API consistency by convention.

The log-likelihood of X_test with self.location_ and self.covariance_ as estimators of the Gaussian model mean and covariance matrix respectively.

Set the parameters of this estimator.

The method works on simple estimators as well as on nested objects (such as Pipeline). The latter have parameters of the form <component>__<parameter> so that it’s possible to update each component of a nested object.

Estimator parameters.

Shrinkage covariance estimation: LedoitWolf vs OAS and max-likelihood

Model selection with Probabilistic PCA and Factor Analysis (FA)

**Examples:**

Example 1 (sql):
```sql
>>> import numpy as np
>>> from sklearn.covariance import ShrunkCovariance
>>> from sklearn.datasets import make_gaussian_quantiles
>>> real_cov = np.array([[.8, .3],
...                      [.3, .4]])
>>> rng = np.random.RandomState(0)
>>> X = rng.multivariate_normal(mean=[0, 0],
...                                   cov=real_cov,
...                                   size=500)
>>> cov = ShrunkCovariance().fit(X)
>>> cov.covariance_
array([[0.7387, 0.2536],
       [0.2536, 0.4110]])
>>> cov.location_
array([0.0622, 0.0193])
```

---

## BayesianRidge#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.BayesianRidge.html

**Contents:**
- BayesianRidge#
- Gallery examples#

Bayesian ridge regression.

Fit a Bayesian ridge model. See the Notes section for details on this implementation and the optimization of the regularization parameters lambda (precision of the weights) and alpha (precision of the noise).

Read more in the User Guide. For an intuitive visualization of how the sinusoid is approximated by a polynomial using different pairs of initial values, see Curve Fitting with Bayesian Ridge Regression.

Maximum number of iterations over the complete dataset before stopping independently of any early stopping criterion.

Changed in version 1.3.

Stop the algorithm if w has converged.

Hyper-parameter : shape parameter for the Gamma distribution prior over the alpha parameter.

Hyper-parameter : inverse scale parameter (rate parameter) for the Gamma distribution prior over the alpha parameter.

Hyper-parameter : shape parameter for the Gamma distribution prior over the lambda parameter.

Hyper-parameter : inverse scale parameter (rate parameter) for the Gamma distribution prior over the lambda parameter.

Initial value for alpha (precision of the noise). If not set, alpha_init is 1/Var(y).

Added in version 0.22.

Initial value for lambda (precision of the weights). If not set, lambda_init is 1.

Added in version 0.22.

If True, compute the log marginal likelihood at each iteration of the optimization.

Whether to calculate the intercept for this model. The intercept is not treated as a probabilistic parameter and thus has no associated variance. If set to False, no intercept will be used in calculations (i.e. data is expected to be centered).

If True, X will be copied; else, it may be overwritten.

Verbose mode when fitting the model.

Coefficients of the regression model (mean of distribution)

Independent term in decision function. Set to 0.0 if fit_intercept = False.

Estimated precision of the noise.

Estimated precision of the weights.

Estimated variance-covariance matrix of the weights

If computed_score is True, value of the log marginal likelihood (to be maximized) at each iteration of the optimization. The array starts with the value of the log marginal likelihood obtained for the initial values of alpha and lambda and ends with the value obtained for the estimated alpha and lambda.

The actual number of iterations to reach the stopping criterion.

If fit_intercept=True, offset subtracted for centering data to a zero mean. Set to np.zeros(n_features) otherwise.

Set to np.ones(n_features).

Number of features seen during fit.

Added in version 0.24.

Names of features seen during fit. Defined only when X has feature names that are all strings.

Added in version 1.0.

Bayesian ARD regression.

There exist several strategies to perform Bayesian ridge regression. This implementation is based on the algorithm described in Appendix A of (Tipping, 2001) where updates of the regularization parameters are done as suggested in (MacKay, 1992). Note that according to A New View of Automatic Relevance Determination (Wipf and Nagarajan, 2008) these update rules do not guarantee that the marginal likelihood is increasing between two consecutive iterations of the optimization.

D. J. C. MacKay, Bayesian Interpolation, Computation and Neural Systems, Vol. 4, No. 3, 1992.

M. E. Tipping, Sparse Bayesian Learning and the Relevance Vector Machine, Journal of Machine Learning Research, Vol. 1, 2001.

Target values. Will be cast to X’s dtype if necessary.

Individual weights for each sample.

Added in version 0.20: parameter sample_weight support to BayesianRidge.

Returns the instance itself.

Get metadata routing of this object.

Please check User Guide on how the routing mechanism works.

A MetadataRequest encapsulating routing information.

Get parameters for this estimator.

If True, will return the parameters for this estimator and contained subobjects that are estimators.

Parameter names mapped to their values.

Predict using the linear model.

In addition to the mean of the predictive distribution, also its standard deviation can be returned.

Whether to return the standard deviation of posterior prediction.

Mean of predictive distribution of query points.

Standard deviation of predictive distribution of query points.

Return coefficient of determination on test data.

The coefficient of determination, \(R^2\), is defined as \((1 - \frac{u}{v})\), where \(u\) is the residual sum of squares ((y_true - y_pred)** 2).sum() and \(v\) is the total sum of squares ((y_true - y_true.mean()) ** 2).sum(). The best possible score is 1.0 and it can be negative (because the model can be arbitrarily worse). A constant model that always predicts the expected value of y, disregarding the input features, would get a \(R^2\) score of 0.0.

Test samples. For some estimators this may be a precomputed kernel matrix or a list of generic objects instead with shape (n_samples, n_samples_fitted), where n_samples_fitted is the number of samples used in the fitting for the estimator.

\(R^2\) of self.predict(X) w.r.t. y.

The \(R^2\) score used when calling score on a regressor uses multioutput='uniform_average' from version 0.23 to keep consistent with default value of r2_score. This influences the score method of all the multioutput regressors (except for MultiOutputRegressor).

Configure whether metadata should be requested to be passed to the fit method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to fit if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to fit.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Added in version 1.3.

Metadata routing for sample_weight parameter in fit.

Set the parameters of this estimator.

The method works on simple estimators as well as on nested objects (such as Pipeline). The latter have parameters of the form <component>__<parameter> so that it’s possible to update each component of a nested object.

Estimator parameters.

Configure whether metadata should be requested to be passed to the predict method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to predict if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to predict.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Added in version 1.3.

Metadata routing for return_std parameter in predict.

Configure whether metadata should be requested to be passed to the score method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to score if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to score.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Added in version 1.3.

Metadata routing for sample_weight parameter in score.

Feature agglomeration vs. univariate selection

Imputing missing values with variants of IterativeImputer

Imputing missing values before building an estimator

Comparing Linear Bayesian Regressors

Curve Fitting with Bayesian Ridge Regression

L1-based models for Sparse Signals

**Examples:**

Example 1 (python):
```python
>>> from sklearn import linear_model
>>> clf = linear_model.BayesianRidge()
>>> clf.fit([[0,0], [1, 1], [2, 2]], [0, 1, 2])
BayesianRidge()
>>> clf.predict([[1, 1]])
array([1.])
```

---

## DBSCAN#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.cluster.DBSCAN.html

**Contents:**
- DBSCAN#
- Gallery examples#

Perform DBSCAN clustering from vector array or distance matrix.

DBSCAN - Density-Based Spatial Clustering of Applications with Noise. Finds core samples of high density and expands clusters from them. This algorithm is particularly good for data which contains clusters of similar density and can find clusters of arbitrary shape.

Unlike K-means, DBSCAN does not require specifying the number of clusters in advance and can identify outliers as noise points.

This implementation has a worst case memory complexity of \(O({n}^2)\), which can occur when the eps param is large and min_samples is low, while the original DBSCAN only uses linear memory. For further details, see the Notes below.

Read more in the User Guide.

The maximum distance between two samples for one to be considered as in the neighborhood of the other. This is not a maximum bound on the distances of points within a cluster. This is the most important DBSCAN parameter to choose appropriately for your data set and distance function. Smaller values generally lead to more clusters.

The number of samples (or total weight) in a neighborhood for a point to be considered as a core point. This includes the point itself. If min_samples is set to a higher value, DBSCAN will find denser clusters, whereas if it is set to a lower value, the found clusters will be more sparse.

The metric to use when calculating distance between instances in a feature array. If metric is a string or callable, it must be one of the options allowed by sklearn.metrics.pairwise_distances for its metric parameter. If metric is “precomputed”, X is assumed to be a distance matrix and must be square. X may be a sparse graph, in which case only “nonzero” elements may be considered neighbors for DBSCAN.

Added in version 0.17: metric precomputed to accept precomputed sparse matrix.

Additional keyword arguments for the metric function.

Added in version 0.19.

The algorithm to be used by the NearestNeighbors module to compute pointwise distances and find nearest neighbors. ‘auto’ will attempt to decide the most appropriate algorithm based on the values passed to fit method. See NearestNeighbors documentation for details.

Leaf size passed to BallTree or cKDTree. This can affect the speed of the construction and query, as well as the memory required to store the tree. The optimal value depends on the nature of the problem.

The power of the Minkowski metric to be used to calculate distance between points. If None, then p=2 (equivalent to the Euclidean distance). When p=1, this is equivalent to Manhattan distance.

The number of parallel jobs to run. None means 1 unless in a joblib.parallel_backend context. -1 means using all processors. See Glossary for more details.

Indices of core samples.

Copy of each core sample found by training.

Cluster labels for each point in the dataset given to fit(). Noisy samples are given the label -1. Non-negative integers indicate cluster membership.

Number of features seen during fit.

Added in version 0.24.

Names of features seen during fit. Defined only when X has feature names that are all strings.

Added in version 1.0.

A similar clustering at multiple values of eps. Our implementation is optimized for memory usage.

This implementation bulk-computes all neighborhood queries, which increases the memory complexity to O(n.d) where d is the average number of neighbors, while original DBSCAN had memory complexity O(n). It may attract a higher memory complexity when querying these nearest neighborhoods, depending on the algorithm.

One way to avoid the query complexity is to pre-compute sparse neighborhoods in chunks using NearestNeighbors.radius_neighbors_graph with mode='distance', then using metric='precomputed' here.

Another way to reduce memory and computation time is to remove (near-)duplicate points and use sample_weight instead.

OPTICS provides a similar clustering with lower memory usage.

Ester, M., H. P. Kriegel, J. Sander, and X. Xu, “A Density-Based Algorithm for Discovering Clusters in Large Spatial Databases with Noise”. In: Proceedings of the 2nd International Conference on Knowledge Discovery and Data Mining, Portland, OR, AAAI Press, pp. 226-231. 1996

Schubert, E., Sander, J., Ester, M., Kriegel, H. P., & Xu, X. (2017). “DBSCAN revisited, revisited: why and how you should (still) use DBSCAN.” ACM Transactions on Database Systems (TODS), 42(3), 19.

For an example, see Demo of DBSCAN clustering algorithm.

For a comparison of DBSCAN with other clustering algorithms, see Comparing different clustering algorithms on toy datasets

Perform DBSCAN clustering from features, or distance matrix.

Training instances to cluster, or distances between instances if metric='precomputed'. If a sparse matrix is provided, it will be converted into a sparse csr_matrix.

Not used, present here for API consistency by convention.

Weight of each sample, such that a sample with a weight of at least min_samples is by itself a core sample; a sample with a negative weight may inhibit its eps-neighbor from being core. Note that weights are absolute, and default to 1.

Returns a fitted instance of self.

Compute clusters from a data or distance matrix and predict labels.

This method fits the model and returns the cluster labels in a single step. It is equivalent to calling fit(X).labels_.

Training instances to cluster, or distances between instances if metric='precomputed'. If a sparse matrix is provided, it will be converted into a sparse csr_matrix.

Not used, present here for API consistency by convention.

Weight of each sample, such that a sample with a weight of at least min_samples is by itself a core sample; a sample with a negative weight may inhibit its eps-neighbor from being core. Note that weights are absolute, and default to 1.

Cluster labels. Noisy samples are given the label -1. Non-negative integers indicate cluster membership.

Get metadata routing of this object.

Please check User Guide on how the routing mechanism works.

A MetadataRequest encapsulating routing information.

Get parameters for this estimator.

If True, will return the parameters for this estimator and contained subobjects that are estimators.

Parameter names mapped to their values.

Configure whether metadata should be requested to be passed to the fit method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to fit if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to fit.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Added in version 1.3.

Metadata routing for sample_weight parameter in fit.

Set the parameters of this estimator.

The method works on simple estimators as well as on nested objects (such as Pipeline). The latter have parameters of the form <component>__<parameter> so that it’s possible to update each component of a nested object.

Estimator parameters.

Comparing different clustering algorithms on toy datasets

Demo of DBSCAN clustering algorithm

Demo of HDBSCAN clustering algorithm

**Examples:**

Example 1 (sql):
```sql
>>> from sklearn.cluster import DBSCAN
>>> import numpy as np
>>> X = np.array([[1, 2], [2, 2], [2, 3],
...               [8, 7], [8, 8], [25, 80]])
>>> clustering = DBSCAN(eps=3, min_samples=2).fit(X)
>>> clustering.labels_
array([ 0,  0,  0,  1,  1, -1])
>>> clustering
DBSCAN(eps=3, min_samples=2)
```

---

## PairwiseKernel#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.gaussian_process.kernels.PairwiseKernel.html

**Contents:**
- PairwiseKernel#

Wrapper for kernels in sklearn.metrics.pairwise.

A thin wrapper around the functionality of the kernels in sklearn.metrics.pairwise.

kernels support only isotropic distances. The parameter gamma is considered to be a hyperparameter and may be optimized. The other kernel parameters are set directly at initialization and are kept fixed.

Added in version 0.18.

Parameter gamma of the pairwise kernel specified by metric. It should be positive.

The lower and upper bound on ‘gamma’. If set to “fixed”, ‘gamma’ cannot be changed during hyperparameter tuning.

The metric to use when calculating kernel between instances in a feature array. If metric is a string, it must be one of the metrics in pairwise.PAIRWISE_KERNEL_FUNCTIONS. If metric is “precomputed”, X is assumed to be a kernel matrix. Alternatively, if metric is a callable function, it is called on each pair of instances (rows) and the resulting value recorded. The callable should take two arrays from X as input and return a value indicating the distance between them.

All entries of this dict (if any) are passed as keyword arguments to the pairwise kernel function.

Return the kernel k(X, Y) and optionally its gradient.

Left argument of the returned kernel k(X, Y)

Right argument of the returned kernel k(X, Y). If None, k(X, X) if evaluated instead.

Determines whether the gradient with respect to the log of the kernel hyperparameter is computed. Only supported when Y is None.

The gradient of the kernel k(X, X) with respect to the log of the hyperparameter of the kernel. Only returned when eval_gradient is True.

Returns the log-transformed bounds on the theta.

The log-transformed bounds on the kernel’s hyperparameters theta

Returns a clone of self with given hyperparameters theta.

Returns the diagonal of the kernel k(X, X).

The result of this method is identical to np.diag(self(X)); however, it can be evaluated more efficiently since only the diagonal is evaluated.

Left argument of the returned kernel k(X, Y)

Diagonal of kernel k(X, X)

Get parameters of this kernel.

If True, will return the parameters for this estimator and contained subobjects that are estimators.

Parameter names mapped to their values.

Returns a list of all hyperparameter specifications.

Returns whether the kernel is stationary.

Returns the number of non-fixed hyperparameters of the kernel.

Returns whether the kernel is defined on fixed-length feature vectors or generic objects. Defaults to True for backward compatibility.

Set the parameters of this kernel.

The method works on simple kernels as well as on nested kernels. The latter have parameters of the form <component>__<parameter> so that it’s possible to update each component of a nested object.

Returns the (flattened, log-transformed) non-fixed hyperparameters.

Note that theta are typically the log-transformed values of the kernel’s hyperparameters as this representation of the search space is more amenable for hyperparameter search, as hyperparameters like length-scales naturally live on a log-scale.

The non-fixed, log-transformed hyperparameters of the kernel

**Examples:**

Example 1 (json):
```json
>>> from sklearn.datasets import load_iris
>>> from sklearn.gaussian_process import GaussianProcessClassifier
>>> from sklearn.gaussian_process.kernels import PairwiseKernel
>>> X, y = load_iris(return_X_y=True)
>>> kernel = PairwiseKernel(metric='rbf')
>>> gpc = GaussianProcessClassifier(kernel=kernel,
...         random_state=0).fit(X, y)
>>> gpc.score(X, y)
0.9733
>>> gpc.predict_proba(X[:2,:])
array([[0.8880, 0.05663, 0.05532],
       [0.8676, 0.07073, 0.06165]])
```

---

## SelectFromModel#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectFromModel.html

**Contents:**
- SelectFromModel#
- Gallery examples#

Meta-transformer for selecting features based on importance weights.

Added in version 0.17.

Read more in the User Guide.

The base estimator from which the transformer is built. This can be both a fitted (if prefit is set to True) or a non-fitted estimator. The estimator should have a feature_importances_ or coef_ attribute after fitting. Otherwise, the importance_getter parameter should be used.

The threshold value to use for feature selection. Features whose absolute importance value is greater or equal are kept while the others are discarded. If “median” (resp. “mean”), then the threshold value is the median (resp. the mean) of the feature importances. A scaling factor (e.g., “1.25*mean”) may also be used. If None and if the estimator has a parameter penalty set to l1, either explicitly or implicitly (e.g, Lasso), the threshold used is 1e-5. Otherwise, “mean” is used by default.

Whether a prefit model is expected to be passed into the constructor directly or not. If True, estimator must be a fitted estimator. If False, estimator is fitted and updated by calling fit and partial_fit, respectively.

Order of the norm used to filter the vectors of coefficients below threshold in the case where the coef_ attribute of the estimator is of dimension 2.

The maximum number of features to select.

If an integer, then it specifies the maximum number of features to allow.

If a callable, then it specifies how to calculate the maximum number of features allowed. The callable will receive X as input: max_features(X).

If None, then all features are kept.

To only select based on max_features, set threshold=-np.inf.

Added in version 0.20.

Changed in version 1.1: max_features accepts a callable.

If ‘auto’, uses the feature importance either through a coef_ attribute or feature_importances_ attribute of estimator.

Also accepts a string that specifies an attribute name/path for extracting feature importance (implemented with attrgetter). For example, give regressor_.coef_ in case of TransformedTargetRegressor or named_steps.clf.feature_importances_ in case of Pipeline with its last step named clf.

If callable, overrides the default feature importance getter. The callable is passed with the fitted estimator and it should return importance for each feature.

Added in version 0.24.

The base estimator from which the transformer is built. This attribute exist only when fit has been called.

If prefit=True, it is a deep copy of estimator.

If prefit=False, it is a clone of estimator and fit on the data passed to fit or partial_fit.

Number of features seen during fit.

Maximum number of features calculated during fit. Only defined if the max_features is not None.

If max_features is an int, then max_features_ = max_features.

If max_features is a callable, then max_features_ = max_features(X).

Added in version 1.1.

Names of features seen during fit. Defined only when X has feature names that are all strings.

Added in version 1.0.

Threshold value used for feature selection.

Recursive feature elimination based on importance weights.

Recursive feature elimination with built-in cross-validated selection of the best number of features.

Sequential cross-validation based feature selection. Does not rely on importance weights.

Allows NaN/Inf in the input if the underlying estimator does as well.

Using a callable to create a selector that can use no more than half of the input features.

Fit the SelectFromModel meta-transformer.

The training input samples.

The target values (integers that correspond to classes in classification, real numbers in regression).

If enable_metadata_routing=False (default): Parameters directly passed to the fit method of the sub-estimator. They are ignored if prefit=True.

If enable_metadata_routing=True: Parameters safely routed to the fit method of the sub-estimator. They are ignored if prefit=True.

Changed in version 1.4: See Metadata Routing User Guide for more details.

Fit to data, then transform it.

Fits transformer to X and y with optional parameters fit_params and returns a transformed version of X.

Target values (None for unsupervised transformations).

Additional fit parameters. Pass only if the estimator accepts additional params in its fit method.

Mask feature names according to selected features.

If input_features is None, then feature_names_in_ is used as feature names in. If feature_names_in_ is not defined, then the following input feature names are generated: ["x0", "x1", ..., "x(n_features_in_ - 1)"].

If input_features is an array-like, then input_features must match feature_names_in_ if feature_names_in_ is defined.

Transformed feature names.

Get metadata routing of this object.

Please check User Guide on how the routing mechanism works.

Added in version 1.4.

A MetadataRouter encapsulating routing information.

Get parameters for this estimator.

If True, will return the parameters for this estimator and contained subobjects that are estimators.

Parameter names mapped to their values.

Get a mask, or integer index, of the features selected.

If True, the return value will be an array of integers, rather than a boolean mask.

An index that selects the retained features from a feature vector. If indices is False, this is a boolean array of shape [# input features], in which an element is True iff its corresponding feature is selected for retention. If indices is True, this is an integer array of shape [# output features] whose values are indices into the input feature vector.

Reverse the transformation operation.

X with columns of zeros inserted where features would have been removed by transform.

Fit the SelectFromModel meta-transformer only once.

The training input samples.

The target values (integers that correspond to classes in classification, real numbers in regression).

If enable_metadata_routing=False (default): Parameters directly passed to the partial_fit method of the sub-estimator.

If enable_metadata_routing=True: Parameters passed to the partial_fit method of the sub-estimator. They are ignored if prefit=True.

Changed in version 1.4: **partial_fit_params are routed to the sub-estimator, if enable_metadata_routing=True is set via set_config, which allows for aliasing.

See Metadata Routing User Guide for more details.

Set output container.

See Introducing the set_output API for an example on how to use the API.

Configure output of transform and fit_transform.

"default": Default output format of a transformer

"pandas": DataFrame output

"polars": Polars output

None: Transform configuration is unchanged

Added in version 1.4: "polars" option was added.

Set the parameters of this estimator.

The method works on simple estimators as well as on nested objects (such as Pipeline). The latter have parameters of the form <component>__<parameter> so that it’s possible to update each component of a nested object.

Estimator parameters.

Reduce X to the selected features.

The input samples with only the selected features.

Model-based and sequential feature selection

**Examples:**

Example 1 (csharp):
```csharp
>>> from sklearn.feature_selection import SelectFromModel
>>> from sklearn.linear_model import LogisticRegression
>>> X = [[ 0.87, -1.34,  0.31 ],
...      [-2.79, -0.02, -0.85 ],
...      [-1.34, -0.48, -2.55 ],
...      [ 1.92,  1.48,  0.65 ]]
>>> y = [0, 1, 0, 1]
>>> selector = SelectFromModel(estimator=LogisticRegression()).fit(X, y)
>>> selector.estimator_.coef_
array([[-0.3252,  0.8345,  0.4976]])
>>> selector.threshold_
np.float64(0.55249)
>>> selector.get_support()
array([False,  True, False])
>>> selector.transform(X)
array([[-1.34],
       [-0.02],
       [-0.48],
       [ 1.48]])
```

Example 2 (python):
```python
>>> def half_callable(X):
...     return round(len(X[0]) / 2)
>>> half_selector = SelectFromModel(estimator=LogisticRegression(),
...                                 max_features=half_callable)
>>> _ = half_selector.fit(X, y)
>>> half_selector.max_features_
2
```

---

## 5.2. Permutation feature importance#

**URL:** https://scikit-learn.org/stable/modules/permutation_importance.html

**Contents:**
- 5.2. Permutation feature importance#
- 5.2.1. Outline of the permutation importance algorithm#
- 5.2.2. Relation to impurity-based importance in trees#
- 5.2.3. Misleading values on strongly correlated features#

Permutation feature importance is a model inspection technique that measures the contribution of each feature to a fitted model’s statistical performance on a given tabular dataset. This technique is particularly useful for non-linear or opaque estimators, and involves randomly shuffling the values of a single feature and observing the resulting degradation of the model’s score [1]. By breaking the relationship between the feature and the target, we determine how much the model relies on such particular feature.

In the following figures, we observe the effect of permuting features on the correlation between the feature and the target and consequently on the model’s statistical performance.

On the top figure, we observe that permuting a predictive feature breaks the correlation between the feature and the target, and consequently the model’s statistical performance decreases. On the bottom figure, we observe that permuting a non-predictive feature does not significantly degrade the model’s statistical performance.

One key advantage of permutation feature importance is that it is model-agnostic, i.e. it can be applied to any fitted estimator. Moreover, it can be calculated multiple times with different permutations of the feature, further providing a measure of the variance in the estimated feature importances for the specific trained model.

The figure below shows the permutation feature importance of a RandomForestClassifier trained on an augmented version of the titanic dataset that contains a random_cat and a random_num features, i.e. a categorical and a numerical feature that are not correlated in any way with the target variable:

Features that are deemed of low importance for a bad model (low cross-validation score) could be very important for a good model. Therefore it is always important to evaluate the predictive power of a model using a held-out set (or better with cross-validation) prior to computing importances. Permutation importance does not reflect the intrinsic predictive value of a feature by itself but how important this feature is for a particular model.

The permutation_importance function calculates the feature importance of estimators for a given dataset. The n_repeats parameter sets the number of times a feature is randomly shuffled and returns a sample of feature importances.

Let’s consider the following trained regression model:

Its validation performance, measured via the \(R^2\) score, is significantly larger than the chance level. This makes it possible to use the permutation_importance function to probe which features are most predictive:

Note that the importance values for the top features represent a large fraction of the reference score of 0.356.

Permutation importances can be computed either on the training set or on a held-out testing or validation set. Using a held-out set makes it possible to highlight which features contribute the most to the generalization power of the inspected model. Features that are important on the training set but not on the held-out set might cause the model to overfit.

The permutation feature importance depends on the score function that is specified with the scoring argument. This argument accepts multiple scorers, which is more computationally efficient than sequentially calling permutation_importance several times with a different scorer, as it reuses model predictions.

In the example below we use a list of metrics, but more input formats are possible, as documented in Using multiple metric evaluation.

The ranking of the features is approximately the same for different metrics even if the scales of the importance values are very different. However, this is not guaranteed and different metrics might lead to significantly different feature importances, in particular for models trained for imbalanced classification problems, for which the choice of the classification metric can be critical.

Inputs: fitted predictive model \(m\), tabular dataset (training or validation) \(D\).

Compute the reference score \(s\) of the model \(m\) on data \(D\) (for instance the accuracy for a classifier or the \(R^2\) for a regressor).

For each feature \(j\) (column of \(D\)):

For each repetition \(k\) in \({1, ..., K}\):

Randomly shuffle column \(j\) of dataset \(D\) to generate a corrupted version of the data named \(\tilde{D}_{k,j}\).

Compute the score \(s_{k,j}\) of model \(m\) on corrupted data \(\tilde{D}_{k,j}\).

Compute importance \(i_j\) for feature \(f_j\) defined as:

Tree-based models provide an alternative measure of feature importances based on the mean decrease in impurity (MDI). Impurity is quantified by the splitting criterion of the decision trees (Gini, Log Loss or Mean Squared Error). However, this method can give high importance to features that may not be predictive on unseen data when the model is overfitting. Permutation-based feature importance, on the other hand, avoids this issue, since it can be computed on unseen data.

Furthermore, impurity-based feature importance for trees is strongly biased and favor high cardinality features (typically numerical features) over low cardinality features such as binary features or categorical variables with a small number of possible categories.

Permutation-based feature importances do not exhibit such a bias. Additionally, the permutation feature importance may be computed with any performance metric on the model predictions and can be used to analyze any model class (not just tree-based models).

The following example highlights the limitations of impurity-based feature importance in contrast to permutation-based feature importance: Permutation Importance vs Random Forest Feature Importance (MDI).

When two features are correlated and one of the features is permuted, the model still has access to the latter through its correlated feature. This results in a lower reported importance value for both features, though they might actually be important.

The figure below shows the permutation feature importance of a RandomForestClassifier trained using the Breast cancer Wisconsin (diagnostic) dataset, which contains strongly correlated features. A naive interpretation would suggest that all features are unimportant:

One way to handle the issue is to cluster features that are correlated and only keep one feature from each cluster.

For more details on such strategy, see the example Permutation Importance with Multicollinear or Correlated Features.

Permutation Importance vs Random Forest Feature Importance (MDI)

Permutation Importance with Multicollinear or Correlated Features

L. Breiman, “Random Forests”, Machine Learning, 45(1), 5-32, 2001.

**Examples:**

Example 1 (sql):
```sql
>>> from sklearn.datasets import load_diabetes
>>> from sklearn.model_selection import train_test_split
>>> from sklearn.linear_model import Ridge
>>> diabetes = load_diabetes()
>>> X_train, X_val, y_train, y_val = train_test_split(
...     diabetes.data, diabetes.target, random_state=0)
...
>>> model = Ridge(alpha=1e-2).fit(X_train, y_train)
>>> model.score(X_val, y_val)
0.356...
```

Example 2 (python):
```python
>>> from sklearn.inspection import permutation_importance
>>> r = permutation_importance(model, X_val, y_val,
...                            n_repeats=30,
...                            random_state=0)
...
>>> for i in r.importances_mean.argsort()[::-1]:
...     if r.importances_mean[i] - 2 * r.importances_std[i] > 0:
...         print(f"{diabetes.feature_names[i]:<8}"
...               f"{r.importances_mean[i]:.3f}"
...               f" +/- {r.importances_std[i]:.3f}")
...
s5      0.204 +/- 0.050
bmi     0.176 +/- 0.048
bp      0.088 +/- 0.033
sex     0.056 +/- 0.023
```

Example 3 (python):
```python
>>> scoring = ['r2', 'neg_mean_absolute_percentage_error', 'neg_mean_squared_error']
>>> r_multi = permutation_importance(
...     model, X_val, y_val, n_repeats=30, random_state=0, scoring=scoring)
...
>>> for metric in r_multi:
...     print(f"{metric}")
...     r = r_multi[metric]
...     for i in r.importances_mean.argsort()[::-1]:
...         if r.importances_mean[i] - 2 * r.importances_std[i] > 0:
...             print(f"    {diabetes.feature_names[i]:<8}"
...                   f"{r.importances_mean[i]:.3f}"
...                   f" +/- {r.importances_std[i]:.3f}")
...
r2
    s5      0.204 +/- 0.050
    bmi     0.176 +/- 0.048
    bp      0.088 +/- 0.033
    sex     0.056 +/- 0.023
neg_mean_absolute_percentage_error
    s5      0.081 +/- 0.020
    bmi     0.064 +/- 0.015
    bp      0.029 +/- 0.010
neg_mean_squared_error
    s5      1013.866 +/- 246.445
    bmi     872.726 +/- 240.298
    bp      438.663 +/- 163.022
    sex     277.376 +/- 115.123
```

---

## MiniBatchKMeans#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.cluster.MiniBatchKMeans.html

**Contents:**
- MiniBatchKMeans#
- Gallery examples#

Mini-Batch K-Means clustering.

Read more in the User Guide.

The number of clusters to form as well as the number of centroids to generate.

Method for initialization:

‘k-means++’ : selects initial cluster centroids using sampling based on an empirical probability distribution of the points’ contribution to the overall inertia. This technique speeds up convergence. The algorithm implemented is “greedy k-means++”. It differs from the vanilla k-means++ by making several trials at each sampling step and choosing the best centroid among them.

‘random’: choose n_clusters observations (rows) at random from data for the initial centroids.

If an array is passed, it should be of shape (n_clusters, n_features) and gives the initial centers.

If a callable is passed, it should take arguments X, n_clusters and a random state and return an initialization.

For an evaluation of the impact of initialization, see the example Empirical evaluation of the impact of k-means initialization.

Maximum number of iterations over the complete dataset before stopping independently of any early stopping criterion heuristics.

Size of the mini batches. For faster computations, you can set batch_size > 256 * number_of_cores to enable parallelism on all cores.

Changed in version 1.0: batch_size default changed from 100 to 1024.

Compute label assignment and inertia for the complete dataset once the minibatch optimization has converged in fit.

Determines random number generation for centroid initialization and random reassignment. Use an int to make the randomness deterministic. See Glossary.

Control early stopping based on the relative center changes as measured by a smoothed, variance-normalized of the mean center squared position changes. This early stopping heuristics is closer to the one used for the batch variant of the algorithms but induces a slight computational and memory overhead over the inertia heuristic.

To disable convergence detection based on normalized center change, set tol to 0.0 (default).

Control early stopping based on the consecutive number of mini batches that does not yield an improvement on the smoothed inertia.

To disable convergence detection based on inertia, set max_no_improvement to None.

Number of samples to randomly sample for speeding up the initialization (sometimes at the expense of accuracy): the only algorithm is initialized by running a batch KMeans on a random subset of the data. This needs to be larger than n_clusters.

If None, the heuristic is init_size = 3 * batch_size if 3 * batch_size < n_clusters, else init_size = 3 * n_clusters.

Number of random initializations that are tried. In contrast to KMeans, the algorithm is only run once, using the best of the n_init initializations as measured by inertia. Several runs are recommended for sparse high-dimensional problems (see Clustering sparse data with k-means).

When n_init='auto', the number of runs depends on the value of init: 3 if using init='random' or init is a callable; 1 if using init='k-means++' or init is an array-like.

Added in version 1.2: Added ‘auto’ option for n_init.

Changed in version 1.4: Default value for n_init changed to 'auto' in version.

Control the fraction of the maximum number of counts for a center to be reassigned. A higher value means that low count centers are more easily reassigned, which means that the model will take longer to converge, but should converge in a better clustering. However, too high a value may cause convergence issues, especially with a small batch size.

Coordinates of cluster centers.

Labels of each point (if compute_labels is set to True).

The value of the inertia criterion associated with the chosen partition if compute_labels is set to True. If compute_labels is set to False, it’s an approximation of the inertia based on an exponentially weighted average of the batch inertiae. The inertia is defined as the sum of square distances of samples to their cluster center, weighted by the sample weights if provided.

Number of iterations over the full dataset.

Number of minibatches processed.

Added in version 1.0.

Number of features seen during fit.

Added in version 0.24.

Names of features seen during fit. Defined only when X has feature names that are all strings.

Added in version 1.0.

The classic implementation of the clustering method based on the Lloyd’s algorithm. It consumes the whole set of input data at each iteration.

See https://www.eecs.tufts.edu/~dsculley/papers/fastkmeans.pdf

When there are too few points in the dataset, some centers may be duplicated, which means that a proper clustering in terms of the number of requesting clusters and the number of returned clusters will not always match. One solution is to set reassignment_ratio=0, which prevents reassignments of clusters that are too small.

See Compare BIRCH and MiniBatchKMeans for a comparison with BIRCH.

For a comparison of Mini-Batch K-Means clustering with other clustering algorithms, see Comparing different clustering algorithms on toy datasets

Compute the centroids on X by chunking it into mini-batches.

Training instances to cluster. It must be noted that the data will be converted to C ordering, which will cause a memory copy if the given data is not C-contiguous. If a sparse matrix is passed, a copy will be made if it’s not in CSR format.

Not used, present here for API consistency by convention.

The weights for each observation in X. If None, all observations are assigned equal weight. sample_weight is not used during initialization if init is a callable or a user provided array.

Added in version 0.20.

Compute cluster centers and predict cluster index for each sample.

Convenience method; equivalent to calling fit(X) followed by predict(X).

New data to transform.

Not used, present here for API consistency by convention.

The weights for each observation in X. If None, all observations are assigned equal weight.

Index of the cluster each sample belongs to.

Compute clustering and transform X to cluster-distance space.

Equivalent to fit(X).transform(X), but more efficiently implemented.

New data to transform.

Not used, present here for API consistency by convention.

The weights for each observation in X. If None, all observations are assigned equal weight.

X transformed in the new space.

Get output feature names for transformation.

The feature names out will prefixed by the lowercased class name. For example, if the transformer outputs 3 features, then the feature names out are: ["class_name0", "class_name1", "class_name2"].

Only used to validate feature names with the names seen in fit.

Transformed feature names.

Get metadata routing of this object.

Please check User Guide on how the routing mechanism works.

A MetadataRequest encapsulating routing information.

Get parameters for this estimator.

If True, will return the parameters for this estimator and contained subobjects that are estimators.

Parameter names mapped to their values.

Update k means estimate on a single mini-batch X.

Training instances to cluster. It must be noted that the data will be converted to C ordering, which will cause a memory copy if the given data is not C-contiguous. If a sparse matrix is passed, a copy will be made if it’s not in CSR format.

Not used, present here for API consistency by convention.

The weights for each observation in X. If None, all observations are assigned equal weight. sample_weight is not used during initialization if init is a callable or a user provided array.

Return updated estimator.

Predict the closest cluster each sample in X belongs to.

In the vector quantization literature, cluster_centers_ is called the code book and each value returned by predict is the index of the closest code in the code book.

Index of the cluster each sample belongs to.

Opposite of the value of X on the K-means objective.

Not used, present here for API consistency by convention.

The weights for each observation in X. If None, all observations are assigned equal weight.

Opposite of the value of X on the K-means objective.

Configure whether metadata should be requested to be passed to the fit method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to fit if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to fit.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Added in version 1.3.

Metadata routing for sample_weight parameter in fit.

Set output container.

See Introducing the set_output API for an example on how to use the API.

Configure output of transform and fit_transform.

"default": Default output format of a transformer

"pandas": DataFrame output

"polars": Polars output

None: Transform configuration is unchanged

Added in version 1.4: "polars" option was added.

Set the parameters of this estimator.

The method works on simple estimators as well as on nested objects (such as Pipeline). The latter have parameters of the form <component>__<parameter> so that it’s possible to update each component of a nested object.

Estimator parameters.

Configure whether metadata should be requested to be passed to the partial_fit method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to partial_fit if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to partial_fit.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Added in version 1.3.

Metadata routing for sample_weight parameter in partial_fit.

Configure whether metadata should be requested to be passed to the score method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to score if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to score.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Added in version 1.3.

Metadata routing for sample_weight parameter in score.

Transform X to a cluster-distance space.

In the new space, each dimension is the distance to the cluster centers. Note that even if X is sparse, the array returned by transform will typically be dense.

New data to transform.

X transformed in the new space.

Biclustering documents with the Spectral Co-clustering algorithm

Compare BIRCH and MiniBatchKMeans

Comparing different clustering algorithms on toy datasets

Online learning of a dictionary of parts of faces

Empirical evaluation of the impact of k-means initialization

Comparison of the K-Means and MiniBatchKMeans clustering algorithms

Faces dataset decompositions

Clustering text documents using k-means

**Examples:**

Example 1 (json):
```json
>>> from sklearn.cluster import MiniBatchKMeans
>>> import numpy as np
>>> X = np.array([[1, 2], [1, 4], [1, 0],
...               [4, 2], [4, 0], [4, 4],
...               [4, 5], [0, 1], [2, 2],
...               [3, 2], [5, 5], [1, -1]])
>>> # manually fit on batches
>>> kmeans = MiniBatchKMeans(n_clusters=2,
...                          random_state=0,
...                          batch_size=6,
...                          n_init="auto")
>>> kmeans = kmeans.partial_fit(X[0:6,:])
>>> kmeans = kmeans.partial_fit(X[6:12,:])
>>> kmeans.cluster_centers_
array([[3.375, 3.  ],
       [0.75 , 0.5 ]])
>>> kmeans.predict([[0, 0], [4, 4]])
array([1, 0], dtype=int32)
>>> # fit on the whole data
>>> kmeans = MiniBatchKMeans(n_clusters=2,
...                          random_state=0,
...                          batch_size=6,
...                          max_iter=10,
...                          n_init="auto").fit(X)
>>> kmeans.cluster_centers_
array([[3.55102041, 2.48979592],
       [1.06896552, 1.        ]])
>>> kmeans.predict([[0, 0], [4, 4]])
array([1, 0], dtype=int32)
```

---

## QuadraticDiscriminantAnalysis#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.discriminant_analysis.QuadraticDiscriminantAnalysis.html

**Contents:**
- QuadraticDiscriminantAnalysis#
- Gallery examples#

Quadratic Discriminant Analysis.

A classifier with a quadratic decision boundary, generated by fitting class conditional densities to the data and using Bayes’ rule.

The model fits a Gaussian density to each class.

Added in version 0.17.

For a comparison between QuadraticDiscriminantAnalysis and LinearDiscriminantAnalysis, see Linear and Quadratic Discriminant Analysis with covariance ellipsoid.

Read more in the User Guide.

‘svd’: Singular value decomposition (default). Does not compute the covariance matrix, therefore this solver is recommended for data with a large number of features.

‘eigen’: Eigenvalue decomposition. Can be combined with shrinkage or custom covariance estimator.

None: no shrinkage (default).

‘auto’: automatic shrinkage using the Ledoit-Wolf lemma.

float between 0 and 1: fixed shrinkage parameter.

Enabling shrinkage is expected to improve the model when some classes have a relatively small number of training data points compared to the number of features by mitigating overfitting during the covariance estimation step.

This should be left to None if covariance_estimator is used. Note that shrinkage works only with ‘eigen’ solver.

Class priors. By default, the class proportions are inferred from the training data.

Regularizes the per-class covariance estimates by transforming S2 as S2 = (1 - reg_param) * S2 + reg_param * np.eye(n_features), where S2 corresponds to the scaling_ attribute of a given class.

If True, the class covariance matrices are explicitly computed and stored in the self.covariance_ attribute.

Added in version 0.17.

Absolute threshold for the covariance matrix to be considered rank deficient after applying some regularization (see reg_param) to each Sk where Sk represents covariance matrix for k-th class. This parameter does not affect the predictions. It controls when a warning is raised if the covariance matrix is not full rank.

Added in version 0.17.

If not None, covariance_estimator is used to estimate the covariance matrices instead of relying on the empirical covariance estimator (with potential shrinkage). The object should have a fit method and a covariance_ attribute like the estimators in sklearn.covariance. If None the shrinkage parameter drives the estimate.

This should be left to None if shrinkage is used. Note that covariance_estimator works only with the ‘eigen’ solver.

For each class, gives the covariance matrix estimated using the samples of that class. The estimations are unbiased. Only present if store_covariance is True.

Class priors (sum to 1).

For each class k an array of shape (n_features, n_k), where n_k = min(n_features, number of elements in class k) It is the rotation of the Gaussian distribution, i.e. its principal axis. It corresponds to V, the matrix of eigenvectors coming from the SVD of Xk = U S Vt where Xk is the centered matrix of samples from class k.

For each class, contains the scaling of the Gaussian distributions along its principal axes, i.e. the variance in the rotated coordinate system. It corresponds to S^2 / (n_samples - 1), where S is the diagonal matrix of singular values from the SVD of Xk, where Xk is the centered matrix of samples from class k.

Number of features seen during fit.

Added in version 0.24.

Names of features seen during fit. Defined only when X has feature names that are all strings.

Added in version 1.0.

Linear Discriminant Analysis.

Apply decision function to an array of samples.

The decision function is equal (up to a constant factor) to the log-posterior of the model, i.e. log p(y = k | x). In a binary classification setting this instead corresponds to the difference log p(y = 1 | x) - log p(y = 0 | x). See Mathematical formulation of the LDA and QDA classifiers.

Array of samples (test vectors).

Decision function values related to each class, per sample. In the two-class case, the shape is (n_samples,), giving the log likelihood ratio of the positive class.

Fit the model according to the given training data and parameters.

Changed in version 0.19: store_covariances has been moved to main constructor as store_covariance.

Changed in version 0.19: tol has been moved to main constructor.

Training vector, where n_samples is the number of samples and n_features is the number of features.

Target values (integers).

Get metadata routing of this object.

Please check User Guide on how the routing mechanism works.

A MetadataRequest encapsulating routing information.

Get parameters for this estimator.

If True, will return the parameters for this estimator and contained subobjects that are estimators.

Parameter names mapped to their values.

Perform classification on an array of vectors X.

Returns the class label for each sample.

Input vectors, where n_samples is the number of samples and n_features is the number of features.

Class label for each sample.

Estimate log class probabilities.

Estimated log probabilities.

Estimate class probabilities.

Probability estimate of the sample for each class in the model, where classes are ordered as they are in self.classes_.

Return accuracy on provided data and labels.

In multi-label classification, this is the subset accuracy which is a harsh metric since you require for each sample that each label set be correctly predicted.

Mean accuracy of self.predict(X) w.r.t. y.

Set the parameters of this estimator.

The method works on simple estimators as well as on nested objects (such as Pipeline). The latter have parameters of the form <component>__<parameter> so that it’s possible to update each component of a nested object.

Estimator parameters.

Configure whether metadata should be requested to be passed to the score method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to score if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to score.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Added in version 1.3.

Metadata routing for sample_weight parameter in score.

Classifier comparison

Linear and Quadratic Discriminant Analysis with covariance ellipsoid

**Examples:**

Example 1 (python):
```python
>>> from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis
>>> import numpy as np
>>> X = np.array([[-1, -1], [-2, -1], [-3, -2], [1, 1], [2, 1], [3, 2]])
>>> y = np.array([1, 1, 1, 2, 2, 2])
>>> clf = QuadraticDiscriminantAnalysis()
>>> clf.fit(X, y)
QuadraticDiscriminantAnalysis()
>>> print(clf.predict([[-0.8, -1]]))
[1]
```

---

## f_regression#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.f_regression.html

**Contents:**
- f_regression#
- Gallery examples#

Univariate linear regression tests returning F-statistic and p-values.

Quick linear model for testing the effect of a single regressor, sequentially for many regressors.

This is done in 2 steps:

The cross correlation between each regressor and the target is computed using r_regression as:

It is converted to an F score and then to a p-value.

f_regression is derived from r_regression and will rank features in the same order if all the features are positively correlated with the target.

Note however that contrary to f_regression, r_regression values lie in [-1, 1] and can thus be negative. f_regression is therefore recommended as a feature selection criterion to identify potentially predictive feature for a downstream classifier, irrespective of the sign of the association with the target variable.

Furthermore f_regression returns p-values while r_regression does not.

Read more in the User Guide.

Whether or not to center the data matrix X and the target vector y. By default, X and y will be centered.

Whether or not to force the F-statistics and associated p-values to be finite. There are two cases where the F-statistic is expected to not be finite:

when the target y or some features in X are constant. In this case, the Pearson’s R correlation is not defined leading to obtain np.nan values in the F-statistic and p-value. When force_finite=True, the F-statistic is set to 0.0 and the associated p-value is set to 1.0.

when a feature in X is perfectly correlated (or anti-correlated) with the target y. In this case, the F-statistic is expected to be np.inf. When force_finite=True, the F-statistic is set to np.finfo(dtype).max and the associated p-value is set to 0.0.

Added in version 1.1.

F-statistic for each feature.

P-values associated with the F-statistic.

Pearson’s R between label/feature for regression tasks.

ANOVA F-value between label/feature for classification tasks.

Chi-squared stats of non-negative features for classification tasks.

Select features based on the k highest scores.

Select features based on a false positive rate test.

Select features based on an estimated false discovery rate.

Select features based on family-wise error rate.

Select features based on percentile of the highest scores.

Feature agglomeration vs. univariate selection

Comparison of F-test and mutual information

**Examples:**

Example 1 (unknown):
```unknown
E[(X[:, i] - mean(X[:, i])) * (y - mean(y))] / (std(X[:, i]) * std(y))
```

Example 2 (sql):
```sql
>>> from sklearn.datasets import make_regression
>>> from sklearn.feature_selection import f_regression
>>> X, y = make_regression(
...     n_samples=50, n_features=3, n_informative=1, noise=1e-4, random_state=42
... )
>>> f_statistic, p_values = f_regression(X, y)
>>> f_statistic
array([1.21, 2.67e13, 2.66])
>>> p_values
array([0.276, 1.54e-283, 0.11])
```

---

## FastICA#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.FastICA.html

**Contents:**
- FastICA#
- Gallery examples#

FastICA: a fast algorithm for Independent Component Analysis.

The implementation is based on [1].

Read more in the User Guide.

Number of components to use. If None is passed, all are used.

Specify which algorithm to use for FastICA.

Specify the whitening strategy to use.

If ‘arbitrary-variance’, a whitening with variance arbitrary is used.

If ‘unit-variance’, the whitening matrix is rescaled to ensure that each recovered source has unit variance.

If False, the data is already considered to be whitened, and no whitening is performed.

Changed in version 1.3: The default value of whiten changed to ‘unit-variance’ in 1.3.

The functional form of the G function used in the approximation to neg-entropy. Could be either ‘logcosh’, ‘exp’, or ‘cube’. You can also provide your own function. It should return a tuple containing the value of the function, and of its derivative, in the point. The derivative should be averaged along its last dimension. Example:

Arguments to send to the functional form. If empty or None and if fun=’logcosh’, fun_args will take value {‘alpha’ : 1.0}.

Maximum number of iterations during fit.

A positive scalar giving the tolerance at which the un-mixing matrix is considered to have converged.

Initial un-mixing array. If w_init=None, then an array of values drawn from a normal distribution is used.

The solver to use for whitening.

“svd” is more stable numerically if the problem is degenerate, and often faster when n_samples <= n_features.

“eigh” is generally more memory efficient when n_samples >= n_features, and can be faster when n_samples >= 50 * n_features.

Added in version 1.2.

Used to initialize w_init when not specified, with a normal distribution. Pass an int, for reproducible results across multiple function calls. See Glossary.

The linear operator to apply to the data to get the independent sources. This is equal to the unmixing matrix when whiten is False, and equal to np.dot(unmixing_matrix, self.whitening_) when whiten is True.

The pseudo-inverse of components_. It is the linear operator that maps independent sources to the data.

The mean over features. Only set if self.whiten is True.

Number of features seen during fit.

Added in version 0.24.

Names of features seen during fit. Defined only when X has feature names that are all strings.

Added in version 1.0.

If the algorithm is “deflation”, n_iter is the maximum number of iterations run across all components. Else they are just the number of iterations taken to converge.

Only set if whiten is ‘True’. This is the pre-whitening matrix that projects data onto the first n_components principal components.

Principal component analysis (PCA).

Incremental principal components analysis (IPCA).

Kernel Principal component analysis (KPCA).

Mini-batch Sparse Principal Components Analysis.

Sparse Principal Components Analysis (SparsePCA).

A. Hyvarinen and E. Oja, Independent Component Analysis: Algorithms and Applications, Neural Networks, 13(4-5), 2000, pp. 411-430.

Training data, where n_samples is the number of samples and n_features is the number of features.

Not used, present for API consistency by convention.

Returns the instance itself.

Fit the model and recover the sources from X.

Training data, where n_samples is the number of samples and n_features is the number of features.

Not used, present for API consistency by convention.

Estimated sources obtained by transforming the data with the estimated unmixing matrix.

Get output feature names for transformation.

The feature names out will prefixed by the lowercased class name. For example, if the transformer outputs 3 features, then the feature names out are: ["class_name0", "class_name1", "class_name2"].

Only used to validate feature names with the names seen in fit.

Transformed feature names.

Get metadata routing of this object.

Please check User Guide on how the routing mechanism works.

A MetadataRequest encapsulating routing information.

Get parameters for this estimator.

If True, will return the parameters for this estimator and contained subobjects that are estimators.

Parameter names mapped to their values.

Transform the sources back to the mixed data (apply mixing matrix).

Sources, where n_samples is the number of samples and n_components is the number of components.

If False, data passed to fit are overwritten. Defaults to True.

Reconstructed data obtained with the mixing matrix.

Configure whether metadata should be requested to be passed to the inverse_transform method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to inverse_transform if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to inverse_transform.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Added in version 1.3.

Metadata routing for copy parameter in inverse_transform.

Set output container.

See Introducing the set_output API for an example on how to use the API.

Configure output of transform and fit_transform.

"default": Default output format of a transformer

"pandas": DataFrame output

"polars": Polars output

None: Transform configuration is unchanged

Added in version 1.4: "polars" option was added.

Set the parameters of this estimator.

The method works on simple estimators as well as on nested objects (such as Pipeline). The latter have parameters of the form <component>__<parameter> so that it’s possible to update each component of a nested object.

Estimator parameters.

Configure whether metadata should be requested to be passed to the transform method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to transform if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to transform.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Added in version 1.3.

Metadata routing for copy parameter in transform.

Recover the sources from X (apply the unmixing matrix).

Data to transform, where n_samples is the number of samples and n_features is the number of features.

If False, data passed to fit can be overwritten. Defaults to True.

Estimated sources obtained by transforming the data with the estimated unmixing matrix.

Faces dataset decompositions

Blind source separation using FastICA

FastICA on 2D point clouds

**Examples:**

Example 1 (python):
```python
def my_g(x):
    return x ** 3, (3 * x ** 2).mean(axis=-1)
```

Example 2 (sql):
```sql
>>> from sklearn.datasets import load_digits
>>> from sklearn.decomposition import FastICA
>>> X, _ = load_digits(return_X_y=True)
>>> transformer = FastICA(n_components=7,
...         random_state=0,
...         whiten='unit-variance')
>>> X_transformed = transformer.fit_transform(X)
>>> X_transformed.shape
(1797, 7)
```

---

## 3.1. Cross-validation: evaluating estimator performance#

**URL:** https://scikit-learn.org/stable/modules/cross_validation.html

**Contents:**
- 3.1. Cross-validation: evaluating estimator performance#
- 3.1.1. Computing cross-validated metrics#
  - 3.1.1.1. The cross_validate function and multiple metric evaluation#
  - 3.1.1.2. Obtaining predictions by cross-validation#
- 3.1.2. Cross validation iterators#
  - 3.1.2.1. Cross-validation iterators for i.i.d. data#
    - 3.1.2.1.1. K-fold#
    - 3.1.2.1.2. Repeated K-Fold#
    - 3.1.2.1.3. Leave One Out (LOO)#
    - 3.1.2.1.4. Leave P Out (LPO)#

Learning the parameters of a prediction function and testing it on the same data is a methodological mistake: a model that would just repeat the labels of the samples that it has just seen would have a perfect score but would fail to predict anything useful on yet-unseen data. This situation is called overfitting. To avoid it, it is common practice when performing a (supervised) machine learning experiment to hold out part of the available data as a test set X_test, y_test. Note that the word “experiment” is not intended to denote academic use only, because even in commercial settings machine learning usually starts out experimentally. Here is a flowchart of typical cross validation workflow in model training. The best parameters can be determined by grid search techniques.

In scikit-learn a random split into training and test sets can be quickly computed with the train_test_split helper function. Let’s load the iris data set to fit a linear support vector machine on it:

We can now quickly sample a training set while holding out 40% of the data for testing (evaluating) our classifier:

When evaluating different settings (“hyperparameters”) for estimators, such as the C setting that must be manually set for an SVM, there is still a risk of overfitting on the test set because the parameters can be tweaked until the estimator performs optimally. This way, knowledge about the test set can “leak” into the model and evaluation metrics no longer report on generalization performance. To solve this problem, yet another part of the dataset can be held out as a so-called “validation set”: training proceeds on the training set, after which evaluation is done on the validation set, and when the experiment seems to be successful, final evaluation can be done on the test set.

However, by partitioning the available data into three sets, we drastically reduce the number of samples which can be used for learning the model, and the results can depend on a particular random choice for the pair of (train, validation) sets.

A solution to this problem is a procedure called cross-validation (CV for short). A test set should still be held out for final evaluation, but the validation set is no longer needed when doing CV. In the basic approach, called k-fold CV, the training set is split into k smaller sets (other approaches are described below, but generally follow the same principles). The following procedure is followed for each of the k “folds”:

A model is trained using \(k-1\) of the folds as training data;

the resulting model is validated on the remaining part of the data (i.e., it is used as a test set to compute a performance measure such as accuracy).

The performance measure reported by k-fold cross-validation is then the average of the values computed in the loop. This approach can be computationally expensive, but does not waste too much data (as is the case when fixing an arbitrary validation set), which is a major advantage in problems such as inverse inference where the number of samples is very small.

The simplest way to use cross-validation is to call the cross_val_score helper function on the estimator and the dataset.

The following example demonstrates how to estimate the accuracy of a linear kernel support vector machine on the iris dataset by splitting the data, fitting a model and computing the score 5 consecutive times (with different splits each time):

The mean score and the standard deviation are hence given by:

By default, the score computed at each CV iteration is the score method of the estimator. It is possible to change this by using the scoring parameter:

See The scoring parameter: defining model evaluation rules for details. In the case of the Iris dataset, the samples are balanced across target classes hence the accuracy and the F1-score are almost equal.

When the cv argument is an integer, cross_val_score uses the KFold or StratifiedKFold strategies by default, the latter being used if the estimator derives from ClassifierMixin.

It is also possible to use other cross validation strategies by passing a cross validation iterator instead, for instance:

Another option is to use an iterable yielding (train, test) splits as arrays of indices, for example:

Just as it is important to test a predictor on data held-out from training, preprocessing (such as standardization, feature selection, etc.) and similar data transformations similarly should be learnt from a training set and applied to held-out data for prediction:

A Pipeline makes it easier to compose estimators, providing this behavior under cross-validation:

See Pipelines and composite estimators.

The cross_validate function differs from cross_val_score in two ways:

It allows specifying multiple metrics for evaluation.

It returns a dict containing fit-times, score-times (and optionally training scores, fitted estimators, train-test split indices) in addition to the test score.

For single metric evaluation, where the scoring parameter is a string, callable or None, the keys will be - ['test_score', 'fit_time', 'score_time']

And for multiple metric evaluation, the return value is a dict with the following keys - ['test_<scorer1_name>', 'test_<scorer2_name>', 'test_<scorer...>', 'fit_time', 'score_time']

return_train_score is set to False by default to save computation time. To evaluate the scores on the training set as well you need to set it to True. You may also retain the estimator fitted on each training set by setting return_estimator=True. Similarly, you may set return_indices=True to retain the training and testing indices used to split the dataset into train and test sets for each cv split.

The multiple metrics can be specified either as a list, tuple or set of predefined scorer names:

Or as a dict mapping scorer name to a predefined or custom scoring function:

Here is an example of cross_validate using a single metric:

The function cross_val_predict has a similar interface to cross_val_score, but returns, for each element in the input, the prediction that was obtained for that element when it was in the test set. Only cross-validation strategies that assign all elements to a test set exactly once can be used (otherwise, an exception is raised).

Note on inappropriate usage of cross_val_predict

The result of cross_val_predict may be different from those obtained using cross_val_score as the elements are grouped in different ways. The function cross_val_score takes an average over cross-validation folds, whereas cross_val_predict simply returns the labels (or probabilities) from several distinct models undistinguished. Thus, cross_val_predict is not an appropriate measure of generalization error.

Visualization of predictions obtained from different models.

Model blending: When predictions of one supervised estimator are used to train another estimator in ensemble methods.

The available cross validation iterators are introduced in the following section.

Receiver Operating Characteristic (ROC) with cross validation,

Recursive feature elimination with cross-validation,

Custom refit strategy of a grid search with cross-validation,

Sample pipeline for text feature extraction and evaluation,

Plotting Cross-Validated Predictions,

Nested versus non-nested cross-validation.

The following sections list utilities to generate indices that can be used to generate dataset splits according to different cross validation strategies.

Assuming that some data is Independent and Identically Distributed (i.i.d.) is making the assumption that all samples stem from the same generative process and that the generative process is assumed to have no memory of past generated samples.

The following cross-validators can be used in such cases.

While i.i.d. data is a common assumption in machine learning theory, it rarely holds in practice. If one knows that the samples have been generated using a time-dependent process, it is safer to use a time-series aware cross-validation scheme. Similarly, if we know that the generative process has a group structure (samples collected from different subjects, experiments, measurement devices), it is safer to use group-wise cross-validation.

KFold divides all the samples in \(k\) groups of samples, called folds (if \(k = n\), this is equivalent to the Leave One Out strategy), of equal sizes (if possible). The prediction function is learned using \(k - 1\) folds, and the fold left out is used for test.

Example of 2-fold cross-validation on a dataset with 4 samples:

Here is a visualization of the cross-validation behavior. Note that KFold is not affected by classes or groups.

Each fold is constituted by two arrays: the first one is related to the training set, and the second one to the test set. Thus, one can create the training/test sets using numpy indexing:

RepeatedKFold repeats KFold \(n\) times, producing different splits in each repetition.

Example of 2-fold K-Fold repeated 2 times:

Similarly, RepeatedStratifiedKFold repeats StratifiedKFold \(n\) times with different randomization in each repetition.

LeaveOneOut (or LOO) is a simple cross-validation. Each learning set is created by taking all the samples except one, the test set being the sample left out. Thus, for \(n\) samples, we have \(n\) different training sets and \(n\) different test sets. This cross-validation procedure does not waste much data as only one sample is removed from the training set:

Potential users of LOO for model selection should weigh a few known caveats. When compared with \(k\)-fold cross validation, one builds \(n\) models from \(n\) samples instead of \(k\) models, where \(n > k\). Moreover, each is trained on \(n - 1\) samples rather than \((k-1) n / k\). In both ways, assuming \(k\) is not too large and \(k < n\), LOO is more computationally expensive than \(k\)-fold cross validation.

In terms of accuracy, LOO often results in high variance as an estimator for the test error. Intuitively, since \(n - 1\) of the \(n\) samples are used to build each model, models constructed from folds are virtually identical to each other and to the model built from the entire training set.

However, if the learning curve is steep for the training size in question, then 5 or 10-fold cross validation can overestimate the generalization error.

As a general rule, most authors and empirical evidence suggest that 5 or 10-fold cross validation should be preferred to LOO.

http://www.faqs.org/faqs/ai-faq/neural-nets/part3/section-12.html;

T. Hastie, R. Tibshirani, J. Friedman, The Elements of Statistical Learning, Springer 2009

L. Breiman, P. Spector Submodel selection and evaluation in regression: The X-random case, International Statistical Review 1992;

R. Kohavi, A Study of Cross-Validation and Bootstrap for Accuracy Estimation and Model Selection, Intl. Jnt. Conf. AI

R. Bharat Rao, G. Fung, R. Rosales, On the Dangers of Cross-Validation. An Experimental Evaluation, SIAM 2008;

G. James, D. Witten, T. Hastie, R. Tibshirani, An Introduction to Statistical Learning, Springer 2013.

LeavePOut is very similar to LeaveOneOut as it creates all the possible training/test sets by removing \(p\) samples from the complete set. For \(n\) samples, this produces \({n \choose p}\) train-test pairs. Unlike LeaveOneOut and KFold, the test sets will overlap for \(p > 1\).

Example of Leave-2-Out on a dataset with 4 samples:

The ShuffleSplit iterator will generate a user defined number of independent train / test dataset splits. Samples are first shuffled and then split into a pair of train and test sets.

It is possible to control the randomness for reproducibility of the results by explicitly seeding the random_state pseudo random number generator.

Here is a usage example:

Here is a visualization of the cross-validation behavior. Note that ShuffleSplit is not affected by classes or groups.

ShuffleSplit is thus a good alternative to KFold cross validation that allows a finer control on the number of iterations and the proportion of samples on each side of the train / test split.

Some classification tasks can naturally exhibit rare classes: for instance, there could be orders of magnitude more negative observations than positive observations (e.g. medical screening, fraud detection, etc). As a result, cross-validation splitting can generate train or validation folds without any occurrence of a particular class. This typically leads to undefined classification metrics (e.g. ROC AUC), exceptions raised when attempting to call fit or missing columns in the output of the predict_proba or decision_function methods of multiclass classifiers trained on different folds.

To mitigate such problems, splitters such as StratifiedKFold and StratifiedShuffleSplit implement stratified sampling to ensure that relative class frequencies are approximately preserved in each fold.

Stratified sampling was introduced in scikit-learn to workaround the aforementioned engineering problems rather than solve a statistical one.

Stratification makes cross-validation folds more homogeneous, and as a result hides some of the variability inherent to fitting models with a limited number of observations.

As a result, stratification can artificially shrink the spread of the metric measured across cross-validation iterations: the inter-fold variability does no longer reflect the uncertainty in the performance of classifiers in the presence of rare classes.

StratifiedKFold is a variation of K-fold which returns stratified folds: each set contains approximately the same percentage of samples of each target class as the complete set.

Here is an example of stratified 3-fold cross-validation on a dataset with 50 samples from two unbalanced classes. We show the number of samples in each class and compare with KFold.

We can see that StratifiedKFold preserves the class ratios (approximately 1 / 10) in both train and test datasets.

Here is a visualization of the cross-validation behavior.

RepeatedStratifiedKFold can be used to repeat Stratified K-Fold n times with different randomization in each repetition.

StratifiedShuffleSplit is a variation of ShuffleSplit, which returns stratified splits, i.e. which creates splits by preserving the same percentage for each target class as in the complete set.

Here is a visualization of the cross-validation behavior.

For some datasets, a pre-defined split of the data into training- and validation fold or into several cross-validation folds already exists. Using PredefinedSplit it is possible to use these folds e.g. when searching for hyperparameters.

For example, when using a validation set, set the test_fold to 0 for all samples that are part of the validation set, and to -1 for all other samples.

The i.i.d. assumption is broken if the underlying generative process yields groups of dependent samples.

Such a grouping of data is domain specific. An example would be when there is medical data collected from multiple patients, with multiple samples taken from each patient. And such data is likely to be dependent on the individual group. In our example, the patient id for each sample will be its group identifier.

In this case we would like to know if a model trained on a particular set of groups generalizes well to the unseen groups. To measure this, we need to ensure that all the samples in the validation fold come from groups that are not represented at all in the paired training fold.

The following cross-validation splitters can be used to do that. The grouping identifier for the samples is specified via the groups parameter.

GroupKFold is a variation of K-fold which ensures that the same group is not represented in both testing and training sets. For example if the data is obtained from different subjects with several samples per-subject and if the model is flexible enough to learn from highly person specific features it could fail to generalize to new subjects. GroupKFold makes it possible to detect this kind of overfitting situations.

Imagine you have three subjects, each with an associated number from 1 to 3:

Each subject is in a different testing fold, and the same subject is never in both testing and training. Notice that the folds do not have exactly the same size due to the imbalance in the data. If class proportions must be balanced across folds, StratifiedGroupKFold is a better option.

Here is a visualization of the cross-validation behavior.

Similar to KFold, the test sets from GroupKFold will form a complete partition of all the data.

While GroupKFold attempts to place the same number of samples in each fold when shuffle=False, when shuffle=True it attempts to place an equal number of distinct groups in each fold (but does not account for group sizes).

StratifiedGroupKFold is a cross-validation scheme that combines both StratifiedKFold and GroupKFold. The idea is to try to preserve the distribution of classes in each split while keeping each group within a single split. That might be useful when you have an unbalanced dataset so that using just GroupKFold might produce skewed splits.

With the current implementation full shuffle is not possible in most scenarios. When shuffle=True, the following happens:

All groups are shuffled.

Groups are sorted by standard deviation of classes using stable sort.

Sorted groups are iterated over and assigned to folds.

That means that only groups with the same standard deviation of class distribution will be shuffled, which might be useful when each group has only a single class.

The algorithm greedily assigns each group to one of n_splits test sets, choosing the test set that minimises the variance in class distribution across test sets. Group assignment proceeds from groups with highest to lowest variance in class frequency, i.e. large groups peaked on one or few classes are assigned first.

This split is suboptimal in a sense that it might produce imbalanced splits even if perfect stratification is possible. If you have relatively close distribution of classes in each group, using GroupKFold is better.

Here is a visualization of cross-validation behavior for uneven groups:

LeaveOneGroupOut is a cross-validation scheme where each split holds out samples belonging to one specific group. Group information is provided via an array that encodes the group of each sample.

Each training set is thus constituted by all the samples except the ones related to a specific group. This is the same as LeavePGroupsOut with n_groups=1 and the same as GroupKFold with n_splits equal to the number of unique labels passed to the groups parameter.

For example, in the cases of multiple experiments, LeaveOneGroupOut can be used to create a cross-validation based on the different experiments: we create a training set using the samples of all the experiments except one:

Another common application is to use time information: for instance the groups could be the year of collection of the samples and thus allow for cross-validation against time-based splits.

LeavePGroupsOut is similar to LeaveOneGroupOut, but removes samples related to \(P\) groups for each training/test set. All possible combinations of \(P\) groups are left out, meaning test sets will overlap for \(P>1\).

Example of Leave-2-Group Out:

The GroupShuffleSplit iterator behaves as a combination of ShuffleSplit and LeavePGroupsOut, and generates a sequence of randomized partitions in which a subset of groups are held out for each split. Each train/test split is performed independently meaning there is no guaranteed relationship between successive test sets.

Here is a usage example:

Here is a visualization of the cross-validation behavior.

This class is useful when the behavior of LeavePGroupsOut is desired, but the number of groups is large enough that generating all possible partitions with \(P\) groups withheld would be prohibitively expensive. In such a scenario, GroupShuffleSplit provides a random sample (with replacement) of the train / test splits generated by LeavePGroupsOut.

The above group cross-validation functions may also be useful for splitting a dataset into training and testing subsets. Note that the convenience function train_test_split is a wrapper around ShuffleSplit and thus only allows for stratified splitting (using the class labels) and cannot account for groups.

To perform the train and test split, use the indices for the train and test subsets yielded by the generator output by the split() method of the cross-validation splitter. For example:

Time series data is characterized by the correlation between observations that are near in time (autocorrelation). However, classical cross-validation techniques such as KFold and ShuffleSplit assume the samples are independent and identically distributed, and would result in unreasonable correlation between training and testing instances (yielding poor estimates of generalization error) on time series data. Therefore, it is very important to evaluate our model for time series data on the “future” observations least like those that are used to train the model. To achieve this, one solution is provided by TimeSeriesSplit.

TimeSeriesSplit is a variation of k-fold which returns first \(k\) folds as train set and the \((k+1)\) th fold as test set. Note that unlike standard cross-validation methods, successive training sets are supersets of those that come before them. Also, it adds all surplus data to the first training partition, which is always used to train the model.

This class can be used to cross-validate time series data samples that are observed at fixed time intervals. Indeed, the folds must represent the same duration, in order to have comparable metrics across folds.

Example of 3-split time series cross-validation on a dataset with 6 samples:

Here is a visualization of the cross-validation behavior.

If the data ordering is not arbitrary (e.g. samples with the same class label are contiguous), shuffling it first may be essential to get a meaningful cross-validation result. However, the opposite may be true if the samples are not independently and identically distributed. For example, if samples correspond to news articles, and are ordered by their time of publication, then shuffling the data will likely lead to a model that is overfit and an inflated validation score: it will be tested on samples that are artificially similar (close in time) to training samples.

Some cross validation iterators, such as KFold, have an inbuilt option to shuffle the data indices before splitting them. Note that:

This consumes less memory than shuffling the data directly.

By default no shuffling occurs, including for the (stratified) K fold cross-validation performed by specifying cv=some_integer to cross_val_score, grid search, etc. Keep in mind that train_test_split still returns a random split.

The random_state parameter defaults to None, meaning that the shuffling will be different every time KFold(..., shuffle=True) is iterated. However, GridSearchCV will use the same shuffling for each set of parameters validated by a single call to its fit method.

To get identical results for each split, set random_state to an integer.

For more details on how to control the randomness of cv splitters and avoid common pitfalls, see Controlling randomness.

Cross validation iterators can also be used to directly perform model selection using Grid Search for the optimal hyperparameters of the model. This is the topic of the next section: Tuning the hyper-parameters of an estimator.

permutation_test_score offers another way to evaluate the performance of a predictor. It provides a permutation-based p-value, which represents how likely an observed performance of the estimator would be obtained by chance. The null hypothesis in this test is that the estimator fails to leverage any statistical dependency between the features and the targets to make correct predictions on left-out data. permutation_test_score generates a null distribution by calculating n_permutations different permutations of the data. In each permutation the target values are randomly shuffled, thereby removing any dependency between the features and the targets. The p-value output is the fraction of permutations whose cross-validation score is better or equal than the true score without permuting targets. For reliable results n_permutations should typically be larger than 100 and cv between 3-10 folds.

A low p-value provides evidence that the dataset contains some real dependency between features and targets and that the estimator was able to utilize this dependency to obtain good results. A high p-value, in reverse, could be due to either one of these:

a lack of dependency between features and targets (i.e., there is no systematic relationship and any observed patterns are likely due to random chance)

or because the estimator was not able to use the dependency in the data (for instance because it underfit).

In the latter case, using a more appropriate estimator that is able to use the structure in the data, would result in a lower p-value.

Cross-validation provides information about how well an estimator generalizes by estimating the range of its expected scores. However, an estimator trained on a high dimensional dataset with no structure may still perform better than expected on cross-validation, just by chance. This can typically happen with small datasets with less than a few hundred samples. permutation_test_score provides information on whether the estimator has found a real dependency between features and targets and can help in evaluating the performance of the estimator.

It is important to note that this test has been shown to produce low p-values even if there is only weak structure in the data because in the corresponding permutated datasets there is absolutely no structure. This test is therefore only able to show whether the model reliably outperforms random guessing.

Finally, permutation_test_score is computed using brute force and internally fits (n_permutations + 1) * n_cv models. It is therefore only tractable with small datasets for which fitting an individual model is very fast. Using the n_jobs parameter parallelizes the computation and thus speeds it up.

Test with permutations the significance of a classification score

Ojala and Garriga. Permutation Tests for Studying Classifier Performance. J. Mach. Learn. Res. 2010.

**Examples:**

Example 1 (python):
```python
>>> import numpy as np
>>> from sklearn.model_selection import train_test_split
>>> from sklearn import datasets
>>> from sklearn import svm

>>> X, y = datasets.load_iris(return_X_y=True)
>>> X.shape, y.shape
((150, 4), (150,))
```

Example 2 (unknown):
```unknown
>>> X_train, X_test, y_train, y_test = train_test_split(
...     X, y, test_size=0.4, random_state=0)

>>> X_train.shape, y_train.shape
((90, 4), (90,))
>>> X_test.shape, y_test.shape
((60, 4), (60,))

>>> clf = svm.SVC(kernel='linear', C=1).fit(X_train, y_train)
>>> clf.score(X_test, y_test)
0.96
```

Example 3 (sql):
```sql
>>> from sklearn.model_selection import cross_val_score
>>> clf = svm.SVC(kernel='linear', C=1, random_state=42)
>>> scores = cross_val_score(clf, X, y, cv=5)
>>> scores
array([0.96, 1. , 0.96, 0.96, 1. ])
```

Example 4 (unknown):
```unknown
>>> print("%0.2f accuracy with a standard deviation of %0.2f" % (scores.mean(), scores.std()))
0.98 accuracy with a standard deviation of 0.02
```

---

## cosine_distances#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise.cosine_distances.html

**Contents:**
- cosine_distances#

Compute cosine distance between samples in X and Y.

Cosine distance is defined as 1.0 minus the cosine similarity.

Read more in the User Guide.

Returns the cosine distance between samples in X and Y.

Compute cosine similarity between samples in X and Y.

**Examples:**

Example 1 (sql):
```sql
>>> from sklearn.metrics.pairwise import cosine_distances
>>> X = [[0, 0, 0], [1, 1, 1]]
>>> Y = [[1, 0, 0], [1, 1, 0]]
>>> cosine_distances(X, Y)
array([[1.   , 1.   ],
       [0.422, 0.183]])
```

---

## 2.1. Gaussian mixture models#

**URL:** https://scikit-learn.org/stable/modules/mixture.html

**Contents:**
- 2.1. Gaussian mixture models#
- 2.1.1. Gaussian Mixture#
- 2.1.2. Variational Bayesian Gaussian Mixture#
  - 2.1.2.1. The Dirichlet Process#

sklearn.mixture is a package which enables one to learn Gaussian Mixture Models (diagonal, spherical, tied and full covariance matrices supported), sample them, and estimate them from data. Facilities to help determine the appropriate number of components are also provided.

Two-component Gaussian mixture model: data points, and equi-probability surfaces of the model.#

A Gaussian mixture model is a probabilistic model that assumes all the data points are generated from a mixture of a finite number of Gaussian distributions with unknown parameters. One can think of mixture models as generalizing k-means clustering to incorporate information about the covariance structure of the data as well as the centers of the latent Gaussians.

Scikit-learn implements different classes to estimate Gaussian mixture models, that correspond to different estimation strategies, detailed below.

The GaussianMixture object implements the expectation-maximization (EM) algorithm for fitting mixture-of-Gaussian models. It can also draw confidence ellipsoids for multivariate models, and compute the Bayesian Information Criterion to assess the number of clusters in the data. A GaussianMixture.fit method is provided that learns a Gaussian Mixture Model from training data. Given test data, it can assign to each sample the Gaussian it most probably belongs to using the GaussianMixture.predict method.

The GaussianMixture comes with different options to constrain the covariance of the difference classes estimated: spherical, diagonal, tied or full covariance.

See GMM covariances for an example of using the Gaussian mixture as clustering on the iris dataset.

See Density Estimation for a Gaussian mixture for an example on plotting the density estimation.

It is the fastest algorithm for learning mixture models

As this algorithm maximizes only the likelihood, it will not bias the means towards zero, or bias the cluster sizes to have specific structures that might or might not apply.

When one has insufficiently many points per mixture, estimating the covariance matrices becomes difficult, and the algorithm is known to diverge and find solutions with infinite likelihood unless one regularizes the covariances artificially.

This algorithm will always use all the components it has access to, needing held-out data or information theoretical criteria to decide how many components to use in the absence of external cues.

The BIC criterion can be used to select the number of components in a Gaussian Mixture in an efficient way. In theory, it recovers the true number of components only in the asymptotic regime (i.e. if much data is available and assuming that the data was actually generated i.i.d. from a mixture of Gaussian distributions). Note that using a Variational Bayesian Gaussian mixture avoids the specification of the number of components for a Gaussian mixture model.

See Gaussian Mixture Model Selection for an example of model selection performed with classical Gaussian mixture.

The main difficulty in learning Gaussian mixture models from unlabeled data is that one usually doesn’t know which points came from which latent component (if one has access to this information it gets very easy to fit a separate Gaussian distribution to each set of points). Expectation-maximization is a well-founded statistical algorithm to get around this problem by an iterative process. First one assumes random components (randomly centered on data points, learned from k-means, or even just normally distributed around the origin) and computes for each point a probability of being generated by each component of the model. Then, one tweaks the parameters to maximize the likelihood of the data given those assignments. Repeating this process is guaranteed to always converge to a local optimum.

There is a choice of four initialization methods (as well as inputting user defined initial means) to generate the initial centers for the model components:

This applies a traditional k-means clustering algorithm. This can be computationally expensive compared to other initialization methods.

This uses the initialization method of k-means clustering: k-means++. This will pick the first center at random from the data. Subsequent centers will be chosen from a weighted distribution of the data favouring points further away from existing centers. k-means++ is the default initialization for k-means so will be quicker than running a full k-means but can still take a significant amount of time for large data sets with many components.

This will pick random data points from the input data as the initial centers. This is a very fast method of initialization but can produce non-convergent results if the chosen points are too close to each other.

Centers are chosen as a small perturbation away from the mean of all data. This method is simple but can lead to the model taking longer to converge.

See GMM Initialization Methods for an example of using different initializations in Gaussian Mixture.

The BayesianGaussianMixture object implements a variant of the Gaussian mixture model with variational inference algorithms. The API is similar to the one defined by GaussianMixture.

Estimation algorithm: variational inference

Variational inference is an extension of expectation-maximization that maximizes a lower bound on model evidence (including priors) instead of data likelihood. The principle behind variational methods is the same as expectation-maximization (that is both are iterative algorithms that alternate between finding the probabilities for each point to be generated by each mixture and fitting the mixture to these assigned points), but variational methods add regularization by integrating information from prior distributions. This avoids the singularities often found in expectation-maximization solutions but introduces some subtle biases to the model. Inference is often notably slower, but not usually as much so as to render usage unpractical.

Due to its Bayesian nature, the variational algorithm needs more hyperparameters than expectation-maximization, the most important of these being the concentration parameter weight_concentration_prior. Specifying a low value for the concentration prior will make the model put most of the weight on a few components and set the remaining components’ weights very close to zero. High values of the concentration prior will allow a larger number of components to be active in the mixture.

The parameters implementation of the BayesianGaussianMixture class proposes two types of prior for the weights distribution: a finite mixture model with Dirichlet distribution and an infinite mixture model with the Dirichlet Process. In practice Dirichlet Process inference algorithm is approximated and uses a truncated distribution with a fixed maximum number of components (called the Stick-breaking representation). The number of components actually used almost always depends on the data.

The next figure compares the results obtained for the different types of the weight concentration prior (parameter weight_concentration_prior_type) for different values of weight_concentration_prior. Here, we can see the value of the weight_concentration_prior parameter has a strong impact on the effective number of active components obtained. We can also notice that large values for the concentration weight prior lead to more uniform weights when the type of prior is ‘dirichlet_distribution’ while this is not necessarily the case for the ‘dirichlet_process’ type (used by default).

The examples below compare Gaussian mixture models with a fixed number of components, to the variational Gaussian mixture models with a Dirichlet process prior. Here, a classical Gaussian mixture is fitted with 5 components on a dataset composed of 2 clusters. We can see that the variational Gaussian mixture with a Dirichlet process prior is able to limit itself to only 2 components whereas the Gaussian mixture fits the data with a fixed number of components that has to be set a priori by the user. In this case the user has selected n_components=5 which does not match the true generative distribution of this toy dataset. Note that with very little observations, the variational Gaussian mixture models with a Dirichlet process prior can take a conservative stand, and fit only one component.

On the following figure we are fitting a dataset not well-depicted by a Gaussian mixture. Adjusting the weight_concentration_prior, parameter of the BayesianGaussianMixture controls the number of components used to fit this data. We also present on the last two plots a random sampling generated from the two resulting mixtures.

See Gaussian Mixture Model Ellipsoids for an example on plotting the confidence ellipsoids for both GaussianMixture and BayesianGaussianMixture.

Gaussian Mixture Model Sine Curve shows using GaussianMixture and BayesianGaussianMixture to fit a sine wave.

See Concentration Prior Type Analysis of Variation Bayesian Gaussian Mixture for an example plotting the confidence ellipsoids for the BayesianGaussianMixture with different weight_concentration_prior_type for different values of the parameter weight_concentration_prior.

When weight_concentration_prior is small enough and n_components is larger than what is found necessary by the model, the Variational Bayesian mixture model has a natural tendency to set some mixture weights values close to zero. This makes it possible to let the model choose a suitable number of effective components automatically. Only an upper bound of this number needs to be provided. Note however that the “ideal” number of active components is very application specific and is typically ill-defined in a data exploration setting.

Unlike finite models, which will almost always use all components as much as they can, and hence will produce wildly different solutions for different numbers of components, the variational inference with a Dirichlet process prior (weight_concentration_prior_type='dirichlet_process') won’t change much with changes to the parameters, leading to more stability and less tuning.

Due to the incorporation of prior information, variational solutions have less pathological special cases than expectation-maximization solutions.

The extra parametrization necessary for variational inference makes inference slower, although not by much.

This algorithm needs an extra hyperparameter that might need experimental tuning via cross-validation.

There are many implicit biases in the inference algorithms (and also in the Dirichlet process if used), and whenever there is a mismatch between these biases and the data it might be possible to fit better models using a finite mixture.

Here we describe variational inference algorithms on Dirichlet process mixture. The Dirichlet process is a prior probability distribution on clusterings with an infinite, unbounded, number of partitions. Variational techniques let us incorporate this prior structure on Gaussian mixture models at almost no penalty in inference time, comparing with a finite Gaussian mixture model.

An important question is how can the Dirichlet process use an infinite, unbounded number of clusters and still be consistent. While a full explanation doesn’t fit this manual, one can think of its stick breaking process analogy to help understanding it. The stick breaking process is a generative story for the Dirichlet process. We start with a unit-length stick and in each step we break off a portion of the remaining stick. Each time, we associate the length of the piece of the stick to the proportion of points that falls into a group of the mixture. At the end, to represent the infinite mixture, we associate the last remaining piece of the stick to the proportion of points that don’t fall into all the other groups. The length of each piece is a random variable with probability proportional to the concentration parameter. Smaller values of the concentration will divide the unit-length into larger pieces of the stick (defining more concentrated distribution). Larger concentration values will create smaller pieces of the stick (increasing the number of components with non zero weights).

Variational inference techniques for the Dirichlet process still work with a finite approximation to this infinite mixture model, but instead of having to specify a priori how many components one wants to use, one just specifies the concentration parameter and an upper bound on the number of mixture components (this upper bound, assuming it is higher than the “true” number of components, affects only algorithmic complexity, not the actual number of components used).

---

## LatentDirichletAllocation#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.LatentDirichletAllocation.html

**Contents:**
- LatentDirichletAllocation#
- Gallery examples#

Latent Dirichlet Allocation with online variational Bayes algorithm.

The implementation is based on [1] and [2].

Added in version 0.17.

Read more in the User Guide.

Changed in version 0.19: n_topics was renamed to n_components

Prior of document topic distribution theta. If the value is None, defaults to 1 / n_components. In [1], this is called alpha.

Prior of topic word distribution beta. If the value is None, defaults to 1 / n_components. In [1], this is called eta.

Method used to update _component. Only used in fit method. In general, if the data size is large, the online update will be much faster than the batch update.

‘batch’: Batch variational Bayes method. Use all training data in each EM update. Old components_ will be overwritten in each iteration.

‘online’: Online variational Bayes method. In each EM update, use mini-batch of training data to update the components_ variable incrementally. The learning rate is controlled by the learning_decay and the learning_offset parameters.

Changed in version 0.20: The default learning method is now "batch".

It is a parameter that control learning rate in the online learning method. The value should be set between (0.5, 1.0] to guarantee asymptotic convergence. When the value is 0.0 and batch_size is n_samples, the update method is same as batch learning. In the literature, this is called kappa.

A (positive) parameter that downweights early iterations in online learning. It should be greater than 1.0. In the literature, this is called tau_0.

The maximum number of passes over the training data (aka epochs). It only impacts the behavior in the fit method, and not the partial_fit method.

Number of documents to use in each EM iteration. Only used in online learning.

How often to evaluate perplexity. Only used in fit method. set it to 0 or negative number to not evaluate perplexity in training at all. Evaluating perplexity can help you check convergence in training process, but it will also increase total training time. Evaluating perplexity in every iteration might increase training time up to two-fold.

Total number of documents. Only used in the partial_fit method.

Perplexity tolerance. Only used when evaluate_every is greater than 0.

Stopping tolerance for updating document topic distribution in E-step.

Max number of iterations for updating document topic distribution in the E-step.

The number of jobs to use in the E-step. None means 1 unless in a joblib.parallel_backend context. -1 means using all processors. See Glossary for more details.

Pass an int for reproducible results across multiple function calls. See Glossary.

Variational parameters for topic word distribution. Since the complete conditional for topic word distribution is a Dirichlet, components_[i, j] can be viewed as pseudocount that represents the number of times word j was assigned to topic i. It can also be viewed as distribution over the words for each topic after normalization: model.components_ / model.components_.sum(axis=1)[:, np.newaxis].

Exponential value of expectation of log topic word distribution. In the literature, this is exp(E[log(beta)]).

Number of iterations of the EM step.

Number of features seen during fit.

Added in version 0.24.

Names of features seen during fit. Defined only when X has feature names that are all strings.

Added in version 1.0.

Number of passes over the dataset.

Final perplexity score on training set.

Prior of document topic distribution theta. If the value is None, it is 1 / n_components.

RandomState instance that is generated either from a seed, the random number generator or by np.random.

Prior of topic word distribution beta. If the value is None, it is 1 / n_components.

A classifier with a linear decision boundary, generated by fitting class conditional densities to the data and using Bayes’ rule.

“Online Learning for Latent Dirichlet Allocation”, Matthew D. Hoffman, David M. Blei, Francis Bach, 2010. blei-lab/onlineldavb

“Stochastic Variational Inference”, Matthew D. Hoffman, David M. Blei, Chong Wang, John Paisley, 2013. https://jmlr.org/papers/volume14/hoffman13a/hoffman13a.pdf

Learn model for the data X with variational Bayes method.

When learning_method is ‘online’, use mini-batch update. Otherwise, use batch update.

Document word matrix.

Not used, present here for API consistency by convention.

Fit to data, then transform it.

Fits transformer to X and y and returns a transformed version of X.

Target values (None for unsupervised transformations).

Whether to normalize the document topic distribution in transform.

Get output feature names for transformation.

The feature names out will prefixed by the lowercased class name. For example, if the transformer outputs 3 features, then the feature names out are: ["class_name0", "class_name1", "class_name2"].

Only used to validate feature names with the names seen in fit.

Transformed feature names.

Get metadata routing of this object.

Please check User Guide on how the routing mechanism works.

A MetadataRequest encapsulating routing information.

Get parameters for this estimator.

If True, will return the parameters for this estimator and contained subobjects that are estimators.

Parameter names mapped to their values.

Online VB with Mini-Batch update.

Document word matrix.

Not used, present here for API consistency by convention.

Partially fitted estimator.

Calculate approximate perplexity for data X.

Perplexity is defined as exp(-1. * log-likelihood per word)

Changed in version 0.19: doc_topic_distr argument has been deprecated and is ignored because user no longer has access to unnormalized distribution

Document word matrix.

Do sub-sampling or not.

Calculate approximate log-likelihood as score.

Document word matrix.

Not used, present here for API consistency by convention.

Use approximate bound as score.

Set output container.

See Introducing the set_output API for an example on how to use the API.

Configure output of transform and fit_transform.

"default": Default output format of a transformer

"pandas": DataFrame output

"polars": Polars output

None: Transform configuration is unchanged

Added in version 1.4: "polars" option was added.

Set the parameters of this estimator.

The method works on simple estimators as well as on nested objects (such as Pipeline). The latter have parameters of the form <component>__<parameter> so that it’s possible to update each component of a nested object.

Estimator parameters.

Configure whether metadata should be requested to be passed to the transform method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to transform if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to transform.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Added in version 1.3.

Metadata routing for normalize parameter in transform.

Transform data X according to the fitted model.

Changed in version 0.18: doc_topic_distr is now normalized.

Document word matrix.

Whether to normalize the document topic distribution.

Document topic distribution for X.

Topic extraction with Non-negative Matrix Factorization and Latent Dirichlet Allocation

**Examples:**

Example 1 (csharp):
```csharp
>>> from sklearn.decomposition import LatentDirichletAllocation
>>> from sklearn.datasets import make_multilabel_classification
>>> # This produces a feature matrix of token counts, similar to what
>>> # CountVectorizer would produce on text.
>>> X, _ = make_multilabel_classification(random_state=0)
>>> lda = LatentDirichletAllocation(n_components=5,
...     random_state=0)
>>> lda.fit(X)
LatentDirichletAllocation(...)
>>> # get topics for some given samples:
>>> lda.transform(X[-2:])
array([[0.00360392, 0.25499205, 0.0036211 , 0.64236448, 0.09541846],
       [0.15297572, 0.00362644, 0.44412786, 0.39568399, 0.003586  ]])
```

---

## consensus_score#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.metrics.consensus_score.html

**Contents:**
- consensus_score#
- Gallery examples#

The similarity of two sets of biclusters.

Similarity between individual biclusters is computed. Then the best matching between sets is found by solving a linear sum assignment problem, using a modified Jonker-Volgenant algorithm. The final score is the sum of similarities divided by the size of the larger set.

Read more in the User Guide.

Tuple of row and column indicators for a set of biclusters.

Another set of biclusters like a.

May be the string “jaccard” to use the Jaccard coefficient, or any function that takes four arguments, each of which is a 1d indicator vector: (a_rows, a_columns, b_rows, b_columns).

Consensus score, a non-negative value, sum of similarities divided by size of larger set.

Solve the linear sum assignment problem.

Hochreiter, Bodenhofer, et. al., 2010. FABIA: factor analysis for bicluster acquisition.

A demo of the Spectral Biclustering algorithm

A demo of the Spectral Co-Clustering algorithm

**Examples:**

Example 1 (sql):
```sql
>>> from sklearn.metrics import consensus_score
>>> a = ([[True, False], [False, True]], [[False, True], [True, False]])
>>> b = ([[False, True], [True, False]], [[True, False], [False, True]])
>>> consensus_score(a, b, similarity='jaccard')
1.0
```

---

## empirical_covariance#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.covariance.empirical_covariance.html

**Contents:**
- empirical_covariance#
- Gallery examples#

Compute the Maximum likelihood covariance estimator.

Data from which to compute the covariance estimate.

If True, data will not be centered before computation. Useful when working with data whose mean is almost, but not exactly zero. If False, data will be centered before computation.

Empirical covariance (Maximum Likelihood Estimator).

Shrinkage covariance estimation: LedoitWolf vs OAS and max-likelihood

**Examples:**

Example 1 (sql):
```sql
>>> from sklearn.covariance import empirical_covariance
>>> X = [[1,1,1],[1,1,1],[1,1,1],
...      [0,0,0],[0,0,0],[0,0,0]]
>>> empirical_covariance(X)
array([[0.25, 0.25, 0.25],
       [0.25, 0.25, 0.25],
       [0.25, 0.25, 0.25]])
```

---

## TransformedTargetRegressor#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.compose.TransformedTargetRegressor.html

**Contents:**
- TransformedTargetRegressor#
- Gallery examples#

Meta-estimator to regress on a transformed target.

Useful for applying a non-linear transformation to the target y in regression problems. This transformation can be given as a Transformer such as the QuantileTransformer or as a function and its inverse such as np.log and np.exp.

The computation during fit is:

The computation during predict is:

Read more in the User Guide.

Added in version 0.20.

Regressor object such as derived from RegressorMixin. This regressor will automatically be cloned each time prior to fitting. If regressor is None, LinearRegression is created and used.

Estimator object such as derived from TransformerMixin. Cannot be set at the same time as func and inverse_func. If transformer is None as well as func and inverse_func, the transformer will be an identity transformer. Note that the transformer will be cloned during fitting. Also, the transformer is restricting y to be a numpy array.

Function to apply to y before passing to fit. Cannot be set at the same time as transformer. If func is None, the function used will be the identity function. If func is set, inverse_func also needs to be provided. The function needs to return a 2-dimensional array.

Function to apply to the prediction of the regressor. Cannot be set at the same time as transformer. The inverse function is used to return predictions to the same space of the original training labels. If inverse_func is set, func also needs to be provided. The inverse function needs to return a 2-dimensional array.

Whether to check that transform followed by inverse_transform or func followed by inverse_func leads to the original targets.

Transformer used in fit and predict.

Number of features seen during fit.

Names of features seen during fit. Defined only when X has feature names that are all strings.

Added in version 1.0.

Construct a transformer from an arbitrary callable.

Internally, the target y is always converted into a 2-dimensional array to be used by scikit-learn transformers. At the time of prediction, the output will be reshaped to a have the same number of dimensions as y.

For a more detailed example use case refer to Effect of transforming the targets in regression model.

Fit the model according to the given training data.

Training vector, where n_samples is the number of samples and n_features is the number of features.

If enable_metadata_routing=False (default): Parameters directly passed to the fit method of the underlying regressor.

If enable_metadata_routing=True: Parameters safely routed to the fit method of the underlying regressor.

Changed in version 1.6: See Metadata Routing User Guide for more details.

Get metadata routing of this object.

Please check User Guide on how the routing mechanism works.

Added in version 1.6.

A MetadataRouter encapsulating routing information.

Get parameters for this estimator.

If True, will return the parameters for this estimator and contained subobjects that are estimators.

Parameter names mapped to their values.

Predict using the base regressor, applying inverse.

The regressor is used to predict and the inverse_func or inverse_transform is applied before returning the prediction.

If enable_metadata_routing=False (default): Parameters directly passed to the predict method of the underlying regressor.

If enable_metadata_routing=True: Parameters safely routed to the predict method of the underlying regressor.

Changed in version 1.6: See Metadata Routing User Guide for more details.

Return coefficient of determination on test data.

The coefficient of determination, \(R^2\), is defined as \((1 - \frac{u}{v})\), where \(u\) is the residual sum of squares ((y_true - y_pred)** 2).sum() and \(v\) is the total sum of squares ((y_true - y_true.mean()) ** 2).sum(). The best possible score is 1.0 and it can be negative (because the model can be arbitrarily worse). A constant model that always predicts the expected value of y, disregarding the input features, would get a \(R^2\) score of 0.0.

Test samples. For some estimators this may be a precomputed kernel matrix or a list of generic objects instead with shape (n_samples, n_samples_fitted), where n_samples_fitted is the number of samples used in the fitting for the estimator.

\(R^2\) of self.predict(X) w.r.t. y.

The \(R^2\) score used when calling score on a regressor uses multioutput='uniform_average' from version 0.23 to keep consistent with default value of r2_score. This influences the score method of all the multioutput regressors (except for MultiOutputRegressor).

Set the parameters of this estimator.

The method works on simple estimators as well as on nested objects (such as Pipeline). The latter have parameters of the form <component>__<parameter> so that it’s possible to update each component of a nested object.

Estimator parameters.

Configure whether metadata should be requested to be passed to the score method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to score if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to score.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Added in version 1.3.

Metadata routing for sample_weight parameter in score.

Effect of transforming the targets in regression model

Common pitfalls in the interpretation of coefficients of linear models

Poisson regression and non-normal loss

**Examples:**

Example 1 (unknown):
```unknown
regressor.fit(X, func(y))
```

Example 2 (csharp):
```csharp
regressor.fit(X, transformer.transform(y))
```

Example 3 (unknown):
```unknown
inverse_func(regressor.predict(X))
```

Example 4 (unknown):
```unknown
transformer.inverse_transform(regressor.predict(X))
```

---

## GaussianProcessClassifier#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.gaussian_process.GaussianProcessClassifier.html

**Contents:**
- GaussianProcessClassifier#
- Gallery examples#

Gaussian process classification (GPC) based on Laplace approximation.

The implementation is based on Algorithm 3.1, 3.2, and 5.1 from [RW2006].

Internally, the Laplace approximation is used for approximating the non-Gaussian posterior by a Gaussian.

Currently, the implementation is restricted to using the logistic link function. For multi-class classification, several binary one-versus rest classifiers are fitted. Note that this class thus does not implement a true multi-class Laplace approximation.

Read more in the User Guide.

Added in version 0.18.

The kernel specifying the covariance function of the GP. If None is passed, the kernel “1.0 * RBF(1.0)” is used as default. Note that the kernel’s hyperparameters are optimized during fitting. Also kernel cannot be a CompoundKernel.

Can either be one of the internally supported optimizers for optimizing the kernel’s parameters, specified by a string, or an externally defined optimizer passed as a callable. If a callable is passed, it must have the signature:

Per default, the ‘L-BFGS-B’ algorithm from scipy.optimize.minimize is used. If None is passed, the kernel’s parameters are kept fixed. Available internal optimizers are:

The number of restarts of the optimizer for finding the kernel’s parameters which maximize the log-marginal likelihood. The first run of the optimizer is performed from the kernel’s initial parameters, the remaining ones (if any) from thetas sampled log-uniform randomly from the space of allowed theta-values. If greater than 0, all bounds must be finite. Note that n_restarts_optimizer=0 implies that one run is performed.

The maximum number of iterations in Newton’s method for approximating the posterior during predict. Smaller values will reduce computation time at the cost of worse results.

If warm-starts are enabled, the solution of the last Newton iteration on the Laplace approximation of the posterior mode is used as initialization for the next call of _posterior_mode(). This can speed up convergence when _posterior_mode is called several times on similar problems as in hyperparameter optimization. See the Glossary.

If True, a persistent copy of the training data is stored in the object. Otherwise, just a reference to the training data is stored, which might cause predictions to change if the data is modified externally.

Determines random number generation used to initialize the centers. Pass an int for reproducible results across multiple function calls. See Glossary.

Specifies how multi-class classification problems are handled. Supported are ‘one_vs_rest’ and ‘one_vs_one’. In ‘one_vs_rest’, one binary Gaussian process classifier is fitted for each class, which is trained to separate this class from the rest. In ‘one_vs_one’, one binary Gaussian process classifier is fitted for each pair of classes, which is trained to separate these two classes. The predictions of these binary predictors are combined into multi-class predictions. Note that ‘one_vs_one’ does not support predicting probability estimates.

The number of jobs to use for the computation: the specified multiclass problems are computed in parallel. None means 1 unless in a joblib.parallel_backend context. -1 means using all processors. See Glossary for more details.

The estimator instance that defines the likelihood function using the observed data.

Return the kernel of the base estimator.

The log-marginal-likelihood of self.kernel_.theta

The number of classes in the training data

Number of features seen during fit.

Added in version 0.24.

Names of features seen during fit. Defined only when X has feature names that are all strings.

Added in version 1.0.

Gaussian process regression (GPR).

Carl E. Rasmussen and Christopher K.I. Williams, “Gaussian Processes for Machine Learning”, MIT Press 2006

For a comparison of the GaussianProcessClassifier with other classifiers see: Plot classification probability.

Fit Gaussian process classification model.

Feature vectors or other representations of training data.

Target values, must be binary.

Returns an instance of self.

Get metadata routing of this object.

Please check User Guide on how the routing mechanism works.

A MetadataRequest encapsulating routing information.

Get parameters for this estimator.

If True, will return the parameters for this estimator and contained subobjects that are estimators.

Parameter names mapped to their values.

Compute the mean and variance of the latent function.

Based on algorithm 3.2 of [RW2006], this function returns the latent mean (Line 4) and variance (Line 6) of the Gaussian process classification model.

Note that this function is only supported for binary classification.

Added in version 1.7.

Query points where the GP is evaluated for classification.

Mean of the latent function values at the query points.

Variance of the latent function values at the query points.

Return log-marginal likelihood of theta for training data.

In the case of multi-class classification, the mean log-marginal likelihood of the one-versus-rest classifiers are returned.

Kernel hyperparameters for which the log-marginal likelihood is evaluated. In the case of multi-class classification, theta may be the hyperparameters of the compound kernel or of an individual kernel. In the latter case, all individual kernel get assigned the same theta values. If None, the precomputed log_marginal_likelihood of self.kernel_.theta is returned.

If True, the gradient of the log-marginal likelihood with respect to the kernel hyperparameters at position theta is returned additionally. Note that gradient computation is not supported for non-binary classification. If True, theta must not be None.

If True, the kernel attribute is copied. If False, the kernel attribute is modified, but may result in a performance improvement.

Log-marginal likelihood of theta for training data.

Gradient of the log-marginal likelihood with respect to the kernel hyperparameters at position theta. Only returned when eval_gradient is True.

Perform classification on an array of test vectors X.

Query points where the GP is evaluated for classification.

Predicted target values for X, values are from classes_.

Return probability estimates for the test vector X.

Query points where the GP is evaluated for classification.

Returns the probability of the samples for each class in the model. The columns correspond to the classes in sorted order, as they appear in the attribute classes_.

Return accuracy on provided data and labels.

In multi-label classification, this is the subset accuracy which is a harsh metric since you require for each sample that each label set be correctly predicted.

Mean accuracy of self.predict(X) w.r.t. y.

Set the parameters of this estimator.

The method works on simple estimators as well as on nested objects (such as Pipeline). The latter have parameters of the form <component>__<parameter> so that it’s possible to update each component of a nested object.

Estimator parameters.

Configure whether metadata should be requested to be passed to the score method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to score if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to score.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Added in version 1.3.

Metadata routing for sample_weight parameter in score.

Plot classification probability

Classifier comparison

Probabilistic predictions with Gaussian process classification (GPC)

Gaussian process classification (GPC) on iris dataset

Iso-probability lines for Gaussian Processes classification (GPC)

Illustration of Gaussian process classification (GPC) on the XOR dataset

Gaussian processes on discrete data structures

**Examples:**

Example 1 (python):
```python
def optimizer(obj_func, initial_theta, bounds):
    # * 'obj_func' is the objective function to be maximized, which
    #   takes the hyperparameters theta as parameter and an
    #   optional flag eval_gradient, which determines if the
    #   gradient is returned additionally to the function value
    # * 'initial_theta': the initial value for theta, which can be
    #   used by local optimizers
    # * 'bounds': the bounds on the values of theta
    ....
    # Returned are the best found hyperparameters theta and
    # the corresponding value of the target function.
    return theta_opt, func_min
```

Example 2 (unknown):
```unknown
'fmin_l_bfgs_b'
```

Example 3 (json):
```json
>>> from sklearn.datasets import load_iris
>>> from sklearn.gaussian_process import GaussianProcessClassifier
>>> from sklearn.gaussian_process.kernels import RBF
>>> X, y = load_iris(return_X_y=True)
>>> kernel = 1.0 * RBF(1.0)
>>> gpc = GaussianProcessClassifier(kernel=kernel,
...         random_state=0).fit(X, y)
>>> gpc.score(X, y)
0.9866...
>>> gpc.predict_proba(X[:2,:])
array([[0.83548752, 0.03228706, 0.13222543],
       [0.79064206, 0.06525643, 0.14410151]])
```

---

## KernelPCA#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.KernelPCA.html

**Contents:**
- KernelPCA#
- Gallery examples#

Kernel Principal component analysis (KPCA).

Non-linear dimensionality reduction through the use of kernels [1], see also Pairwise metrics, Affinities and Kernels.

It uses the scipy.linalg.eigh LAPACK implementation of the full SVD or the scipy.sparse.linalg.eigsh ARPACK implementation of the truncated SVD, depending on the shape of the input data and the number of components to extract. It can also use a randomized truncated SVD by the method proposed in [3], see eigen_solver.

For a usage example and comparison between Principal Components Analysis (PCA) and its kernelized version (KPCA), see Kernel PCA.

For a usage example in denoising images using KPCA, see Image denoising using kernel PCA.

Read more in the User Guide.

Number of components. If None, all non-zero components are kept.

Kernel coefficient for rbf, poly and sigmoid kernels. Ignored by other kernels. If gamma is None, then it is set to 1/n_features.

Degree for poly kernels. Ignored by other kernels.

Independent term in poly and sigmoid kernels. Ignored by other kernels.

Parameters (keyword arguments) and values for kernel passed as callable object. Ignored by other kernels.

Hyperparameter of the ridge regression that learns the inverse transform (when fit_inverse_transform=True).

Learn the inverse transform for non-precomputed kernels (i.e. learn to find the pre-image of a point). This method is based on [2].

Select eigensolver to use. If n_components is much less than the number of training samples, randomized (or arpack to a smaller extent) may be more efficient than the dense eigensolver. Randomized SVD is performed according to the method of Halko et al [3].

the solver is selected by a default policy based on n_samples (the number of training samples) and n_components: if the number of components to extract is less than 10 (strict) and the number of samples is more than 200 (strict), the ‘arpack’ method is enabled. Otherwise the exact full eigenvalue decomposition is computed and optionally truncated afterwards (‘dense’ method).

run exact full eigenvalue decomposition calling the standard LAPACK solver via scipy.linalg.eigh, and select the components by postprocessing

run SVD truncated to n_components calling ARPACK solver using scipy.sparse.linalg.eigsh. It requires strictly 0 < n_components < n_samples

run randomized SVD by the method of Halko et al. [3]. The current implementation selects eigenvalues based on their module; therefore using this method can lead to unexpected results if the kernel is not positive semi-definite. See also [4].

Changed in version 1.0: 'randomized' was added.

Convergence tolerance for arpack. If 0, optimal value will be chosen by arpack.

Maximum number of iterations for arpack. If None, optimal value will be chosen by arpack.

Number of iterations for the power method computed by svd_solver == ‘randomized’. When ‘auto’, it is set to 7 when n_components < 0.1 * min(X.shape), other it is set to 4.

Added in version 1.0.

If True, then all components with zero eigenvalues are removed, so that the number of components in the output may be < n_components (and sometimes even zero due to numerical instability). When n_components is None, this parameter is ignored and components with zero eigenvalues are removed regardless.

Used when eigen_solver == ‘arpack’ or ‘randomized’. Pass an int for reproducible results across multiple function calls. See Glossary.

Added in version 0.18.

If True, input X is copied and stored by the model in the X_fit_ attribute. If no further changes will be done to X, setting copy_X=False saves memory by storing a reference.

Added in version 0.18.

The number of parallel jobs to run. None means 1 unless in a joblib.parallel_backend context. -1 means using all processors. See Glossary for more details.

Added in version 0.18.

Eigenvalues of the centered kernel matrix in decreasing order. If n_components and remove_zero_eig are not set, then all values are stored.

Eigenvectors of the centered kernel matrix. If n_components and remove_zero_eig are not set, then all components are stored.

Inverse transform matrix. Only available when fit_inverse_transform is True.

Projection of the fitted data on the kernel principal components. Only available when fit_inverse_transform is True.

The data used to fit the model. If copy_X=False, then X_fit_ is a reference. This attribute is used for the calls to transform.

Number of features seen during fit.

Added in version 0.24.

Names of features seen during fit. Defined only when X has feature names that are all strings.

Added in version 1.0.

Kernel coefficient for rbf, poly and sigmoid kernels. When gamma is explicitly provided, this is just the same as gamma. When gamma is None, this is the actual value of kernel coefficient.

Added in version 1.3.

A fast algorithm for Independent Component Analysis.

Incremental Principal Component Analysis.

Non-Negative Matrix Factorization.

Principal Component Analysis.

Sparse Principal Component Analysis.

Dimensionality reduction using truncated SVD.

Schölkopf, Bernhard, Alexander Smola, and Klaus-Robert Müller. “Kernel principal component analysis.” International conference on artificial neural networks. Springer, Berlin, Heidelberg, 1997.

Bakır, Gökhan H., Jason Weston, and Bernhard Schölkopf. “Learning to find pre-images.” Advances in neural information processing systems 16 (2004): 449-456.

Halko, Nathan, Per-Gunnar Martinsson, and Joel A. Tropp. “Finding structure with randomness: Probabilistic algorithms for constructing approximate matrix decompositions.” SIAM review 53.2 (2011): 217-288.

Martinsson, Per-Gunnar, Vladimir Rokhlin, and Mark Tygert. “A randomized algorithm for the decomposition of matrices.” Applied and Computational Harmonic Analysis 30.1 (2011): 47-68.

Fit the model from data in X.

Training vector, where n_samples is the number of samples and n_features is the number of features.

Not used, present for API consistency by convention.

Returns the instance itself.

Fit the model from data in X and transform X.

Training vector, where n_samples is the number of samples and n_features is the number of features.

Not used, present for API consistency by convention.

Parameters (keyword arguments) and values passed to the fit_transform instance.

Get output feature names for transformation.

The feature names out will prefixed by the lowercased class name. For example, if the transformer outputs 3 features, then the feature names out are: ["class_name0", "class_name1", "class_name2"].

Only used to validate feature names with the names seen in fit.

Transformed feature names.

Get metadata routing of this object.

Please check User Guide on how the routing mechanism works.

A MetadataRequest encapsulating routing information.

Get parameters for this estimator.

If True, will return the parameters for this estimator and contained subobjects that are estimators.

Parameter names mapped to their values.

Transform X back to original space.

inverse_transform approximates the inverse transformation using a learned pre-image. The pre-image is learned by kernel ridge regression of the original data on their low-dimensional representation vectors.

When users want to compute inverse transformation for ‘linear’ kernel, it is recommended that they use PCA instead. Unlike PCA, KernelPCA’s inverse_transform does not reconstruct the mean of data when ‘linear’ kernel is used due to the use of centered kernel.

Training vector, where n_samples is the number of samples and n_features is the number of features.

Original data, where n_samples is the number of samples and n_features is the number of features.

Bakır, Gökhan H., Jason Weston, and Bernhard Schölkopf. “Learning to find pre-images.” Advances in neural information processing systems 16 (2004): 449-456.

Set output container.

See Introducing the set_output API for an example on how to use the API.

Configure output of transform and fit_transform.

"default": Default output format of a transformer

"pandas": DataFrame output

"polars": Polars output

None: Transform configuration is unchanged

Added in version 1.4: "polars" option was added.

Set the parameters of this estimator.

The method works on simple estimators as well as on nested objects (such as Pipeline). The latter have parameters of the form <component>__<parameter> so that it’s possible to update each component of a nested object.

Estimator parameters.

Training vector, where n_samples is the number of samples and n_features is the number of features.

Projection of X in the first principal components, where n_samples is the number of samples and n_components is the number of the components.

Image denoising using kernel PCA

**Examples:**

Example 1 (sql):
```sql
>>> from sklearn.datasets import load_digits
>>> from sklearn.decomposition import KernelPCA
>>> X, _ = load_digits(return_X_y=True)
>>> transformer = KernelPCA(n_components=7, kernel='linear')
>>> X_transformed = transformer.fit_transform(X)
>>> X_transformed.shape
(1797, 7)
```

---

## OneVsRestClassifier#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.multiclass.OneVsRestClassifier.html

**Contents:**
- OneVsRestClassifier#
- Gallery examples#

One-vs-the-rest (OvR) multiclass strategy.

Also known as one-vs-all, this strategy consists in fitting one classifier per class. For each classifier, the class is fitted against all the other classes. In addition to its computational efficiency (only n_classes classifiers are needed), one advantage of this approach is its interpretability. Since each class is represented by one and one classifier only, it is possible to gain knowledge about the class by inspecting its corresponding classifier. This is the most commonly used strategy for multiclass classification and is a fair default choice.

OneVsRestClassifier can also be used for multilabel classification. To use this feature, provide an indicator matrix for the target y when calling .fit. In other words, the target labels should be formatted as a 2D binary (0/1) matrix, where [i, j] == 1 indicates the presence of label j in sample i. This estimator uses the binary relevance method to perform multilabel classification, which involves training one binary classifier independently for each label.

Read more in the User Guide.

A regressor or a classifier that implements fit. When a classifier is passed, decision_function will be used in priority and it will fallback to predict_proba if it is not available. When a regressor is passed, predict is used.

The number of jobs to use for the computation: the n_classes one-vs-rest problems are computed in parallel.

None means 1 unless in a joblib.parallel_backend context. -1 means using all processors. See Glossary for more details.

Changed in version 0.20: n_jobs default changed from 1 to None

The verbosity level, if non zero, progress messages are printed. Below 50, the output is sent to stderr. Otherwise, the output is sent to stdout. The frequency of the messages increases with the verbosity level, reporting all iterations at 10. See joblib.Parallel for more details.

Added in version 1.1.

Estimators used for predictions.

Object used to transform multiclass labels to binary labels and vice-versa.

Whether this is a multilabel classifier.

Number of features seen during fit. Only defined if the underlying estimator exposes such an attribute when fit.

Added in version 0.24.

Names of features seen during fit. Only defined if the underlying estimator exposes such an attribute when fit.

Added in version 1.0.

One-vs-one multiclass strategy.

(Error-Correcting) Output-Code multiclass strategy.

Alternate way of extending an estimator for multilabel classification.

Transform iterable of iterables to binary indicator matrix.

Decision function for the OneVsRestClassifier.

Return the distance of each sample from the decision boundary for each class. This can only be used with estimators which implement the decision_function method.

Result of calling decision_function on the final estimator.

Changed in version 0.19: output shape changed to (n_samples,) to conform to scikit-learn conventions for binary classification.

Fit underlying estimators.

Multi-class targets. An indicator matrix turns on multilabel classification.

Parameters passed to the estimator.fit method of each sub-estimator.

Added in version 1.4: Only available if enable_metadata_routing=True. See Metadata Routing User Guide for more details.

Instance of fitted estimator.

Get metadata routing of this object.

Please check User Guide on how the routing mechanism works.

Added in version 1.4.

A MetadataRouter encapsulating routing information.

Get parameters for this estimator.

If True, will return the parameters for this estimator and contained subobjects that are estimators.

Parameter names mapped to their values.

Partially fit underlying estimators.

Should be used when memory is inefficient to train all data. Chunks of data can be passed in several iterations.

Multi-class targets. An indicator matrix turns on multilabel classification.

Classes across all calls to partial_fit. Can be obtained via np.unique(y_all), where y_all is the target vector of the entire dataset. This argument is only required in the first call of partial_fit and can be omitted in the subsequent calls.

Parameters passed to the estimator.partial_fit method of each sub-estimator.

Added in version 1.4: Only available if enable_metadata_routing=True. See Metadata Routing User Guide for more details.

Instance of partially fitted estimator.

Predict multi-class targets using underlying estimators.

Predicted multi-class targets.

Probability estimates.

The returned estimates for all classes are ordered by label of classes.

Note that in the multilabel case, each sample can have any number of labels. This returns the marginal probability that the given sample has the label in question. For example, it is entirely consistent that two labels both have a 90% probability of applying to a given sample.

In the single label multiclass case, the rows of the returned matrix sum to 1.

Returns the probability of the sample for each class in the model, where classes are ordered as they are in self.classes_.

Return accuracy on provided data and labels.

In multi-label classification, this is the subset accuracy which is a harsh metric since you require for each sample that each label set be correctly predicted.

Mean accuracy of self.predict(X) w.r.t. y.

Set the parameters of this estimator.

The method works on simple estimators as well as on nested objects (such as Pipeline). The latter have parameters of the form <component>__<parameter> so that it’s possible to update each component of a nested object.

Estimator parameters.

Configure whether metadata should be requested to be passed to the partial_fit method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to partial_fit if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to partial_fit.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Added in version 1.3.

Metadata routing for classes parameter in partial_fit.

Configure whether metadata should be requested to be passed to the score method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to score if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to score.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Added in version 1.3.

Metadata routing for sample_weight parameter in score.

Decision Boundaries of Multinomial and One-vs-Rest Logistic Regression

Multiclass sparse logistic regression on 20newgroups

Multilabel classification

Multiclass Receiver Operating Characteristic (ROC)

Overview of multiclass training meta-estimators

Multilabel classification using a classifier chain

**Examples:**

Example 1 (sql):
```sql
>>> import numpy as np
>>> from sklearn.multiclass import OneVsRestClassifier
>>> from sklearn.svm import SVC
>>> X = np.array([
...     [10, 10],
...     [8, 10],
...     [-5, 5.5],
...     [-5.4, 5.5],
...     [-20, -20],
...     [-15, -20]
... ])
>>> y = np.array([0, 0, 1, 1, 2, 2])
>>> clf = OneVsRestClassifier(SVC()).fit(X, y)
>>> clf.predict([[-19, -20], [9, 9], [-5, 5]])
array([2, 0, 1])
```

---

## FeatureAgglomeration#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.cluster.FeatureAgglomeration.html

**Contents:**
- FeatureAgglomeration#
- Gallery examples#

Agglomerate features.

Recursively merges pair of clusters of features.

Refer to Feature agglomeration vs. univariate selection for an example comparison of FeatureAgglomeration strategy with a univariate feature selection strategy (based on ANOVA).

Read more in the User Guide.

The number of clusters to find. It must be None if distance_threshold is not None.

Metric used to compute the linkage. Can be “euclidean”, “l1”, “l2”, “manhattan”, “cosine”, or “precomputed”. If linkage is “ward”, only “euclidean” is accepted. If “precomputed”, a distance matrix is needed as input for the fit method.

Added in version 1.2.

Used to cache the output of the computation of the tree. By default, no caching is done. If a string is given, it is the path to the caching directory.

Connectivity matrix. Defines for each feature the neighboring features following a given structure of the data. This can be a connectivity matrix itself or a callable that transforms the data into a connectivity matrix, such as derived from kneighbors_graph. Default is None, i.e, the hierarchical clustering algorithm is unstructured.

Stop early the construction of the tree at n_clusters. This is useful to decrease computation time if the number of clusters is not small compared to the number of features. This option is useful only when specifying a connectivity matrix. Note also that when varying the number of clusters and using caching, it may be advantageous to compute the full tree. It must be True if distance_threshold is not None. By default compute_full_tree is “auto”, which is equivalent to True when distance_threshold is not None or that n_clusters is inferior to the maximum between 100 or 0.02 * n_samples. Otherwise, “auto” is equivalent to False.

Which linkage criterion to use. The linkage criterion determines which distance to use between sets of features. The algorithm will merge the pairs of cluster that minimize this criterion.

“ward” minimizes the variance of the clusters being merged.

“complete” or maximum linkage uses the maximum distances between all features of the two sets.

“average” uses the average of the distances of each feature of the two sets.

“single” uses the minimum of the distances between all features of the two sets.

This combines the values of agglomerated features into a single value, and should accept an array of shape [M, N] and the keyword argument axis=1, and reduce it to an array of size [M].

The linkage distance threshold at or above which clusters will not be merged. If not None, n_clusters must be None and compute_full_tree must be True.

Added in version 0.21.

Computes distances between clusters even if distance_threshold is not used. This can be used to make dendrogram visualization, but introduces a computational and memory overhead.

Added in version 0.24.

The number of clusters found by the algorithm. If distance_threshold=None, it will be equal to the given n_clusters.

Cluster labels for each feature.

Number of leaves in the hierarchical tree.

The estimated number of connected components in the graph.

Added in version 0.21: n_connected_components_ was added to replace n_components_.

Number of features seen during fit.

Added in version 0.24.

Names of features seen during fit. Defined only when X has feature names that are all strings.

Added in version 1.0.

The children of each non-leaf node. Values less than n_features correspond to leaves of the tree which are the original samples. A node i greater than or equal to n_features is a non-leaf node and has children children_[i - n_features]. Alternatively at the i-th iteration, children[i][0] and children[i][1] are merged to form node n_features + i.

Distances between nodes in the corresponding place in children_. Only computed if distance_threshold is used or compute_distances is set to True.

Agglomerative clustering samples instead of features.

Hierarchical clustering with ward linkage.

Fit the hierarchical clustering on the data.

Not used, present here for API consistency by convention.

Returns the transformer.

Fit and return the result of each sample’s clustering assignment.

Fit to data, then transform it.

Fits transformer to X and y with optional parameters fit_params and returns a transformed version of X.

Target values (None for unsupervised transformations).

Additional fit parameters. Pass only if the estimator accepts additional params in its fit method.

Get output feature names for transformation.

The feature names out will prefixed by the lowercased class name. For example, if the transformer outputs 3 features, then the feature names out are: ["class_name0", "class_name1", "class_name2"].

Only used to validate feature names with the names seen in fit.

Transformed feature names.

Get metadata routing of this object.

Please check User Guide on how the routing mechanism works.

A MetadataRequest encapsulating routing information.

Get parameters for this estimator.

If True, will return the parameters for this estimator and contained subobjects that are estimators.

Parameter names mapped to their values.

Inverse the transformation and return a vector of size n_features.

The values to be assigned to each cluster of samples.

A vector of size n_samples with the values of X assigned to each of the cluster of samples.

Set output container.

See Introducing the set_output API for an example on how to use the API.

Configure output of transform and fit_transform.

"default": Default output format of a transformer

"pandas": DataFrame output

"polars": Polars output

None: Transform configuration is unchanged

Added in version 1.4: "polars" option was added.

Set the parameters of this estimator.

The method works on simple estimators as well as on nested objects (such as Pipeline). The latter have parameters of the form <component>__<parameter> so that it’s possible to update each component of a nested object.

Estimator parameters.

Transform a new matrix using the built clustering.

An M by N array of M observations in N dimensions or a length M array of M one-dimensional observations.

The pooled values for each feature cluster.

Feature agglomeration

Feature agglomeration vs. univariate selection

**Examples:**

Example 1 (csharp):
```csharp
>>> import numpy as np
>>> from sklearn import datasets, cluster
>>> digits = datasets.load_digits()
>>> images = digits.images
>>> X = np.reshape(images, (len(images), -1))
>>> agglo = cluster.FeatureAgglomeration(n_clusters=32)
>>> agglo.fit(X)
FeatureAgglomeration(n_clusters=32)
>>> X_reduced = agglo.transform(X)
>>> X_reduced.shape
(1797, 32)
```

---

## CalibratedClassifierCV#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.calibration.CalibratedClassifierCV.html

**Contents:**
- CalibratedClassifierCV#
- Gallery examples#

Calibrate probabilities using isotonic, sigmoid, or temperature scaling.

This class uses cross-validation to both estimate the parameters of a classifier and subsequently calibrate a classifier. With ensemble=True, for each cv split it fits a copy of the base estimator to the training subset, and calibrates it using the testing subset. For prediction, predicted probabilities are averaged across these individual calibrated classifiers. When ensemble=False, cross-validation is used to obtain unbiased predictions, via cross_val_predict, which are then used for calibration. For prediction, the base estimator, trained using all the data, is used. This is the prediction method implemented when probabilities=True for SVC and NuSVC estimators (see User Guide for details).

Already fitted classifiers can be calibrated by wrapping the model in a FrozenEstimator. In this case all provided data is used for calibration. The user has to take care manually that data for model fitting and calibration are disjoint.

The calibration is based on the decision_function method of the estimator if it exists, else on predict_proba.

Read more in the User Guide. In order to learn more on the CalibratedClassifierCV class, see the following calibration examples: Probability calibration of classifiers, Probability Calibration curves, and Probability Calibration for 3-class classification.

The classifier whose output need to be calibrated to provide more accurate predict_proba outputs. The default classifier is a LinearSVC.

Added in version 1.2.

The method to use for calibration. Can be:

‘sigmoid’, which corresponds to Platt’s method (i.e. a binary logistic regression model).

‘isotonic’, which is a non-parametric approach.

‘temperature’, temperature scaling.

Sigmoid and isotonic calibration methods natively support only binary classifiers and extend to multi-class classification using a One-vs-Rest (OvR) strategy with post-hoc renormalization, i.e., adjusting the probabilities after calibration to ensure they sum up to 1.

In contrast, temperature scaling naturally supports multi-class calibration by applying softmax(classifier_logits/T) with a value of T (temperature) that optimizes the log loss.

For very uncalibrated classifiers on very imbalanced datasets, sigmoid calibration might be preferred because it fits an additional intercept parameter. This helps shift decision boundaries appropriately when the classifier being calibrated is biased towards the majority class.

Isotonic calibration is not recommended when the number of calibration samples is too low (≪1000) since it then tends to overfit.

Changed in version 1.8: Added option ‘temperature’.

Determines the cross-validation splitting strategy. Possible inputs for cv are:

None, to use the default 5-fold cross-validation,

integer, to specify the number of folds.

An iterable yielding (train, test) splits as arrays of indices.

For integer/None inputs, if y is binary or multiclass, StratifiedKFold is used. If y is neither binary nor multiclass, KFold is used.

Refer to the User Guide for the various cross-validation strategies that can be used here.

Changed in version 0.22: cv default value if None changed from 3-fold to 5-fold.

Number of jobs to run in parallel. None means 1 unless in a joblib.parallel_backend context. -1 means using all processors.

Base estimator clones are fitted in parallel across cross-validation iterations.

See Glossary for more details.

Added in version 0.24.

Determines how the calibrator is fitted.

“auto” will use False if the estimator is a FrozenEstimator, and True otherwise.

If True, the estimator is fitted using training data, and calibrated using testing data, for each cv fold. The final estimator is an ensemble of n_cv fitted classifier and calibrator pairs, where n_cv is the number of cross-validation folds. The output is the average predicted probabilities of all pairs.

If False, cv is used to compute unbiased predictions, via cross_val_predict, which are then used for calibration. At prediction time, the classifier used is the estimator trained on all the data. Note that this method is also internally implemented in sklearn.svm estimators with the probabilities=True parameter.

Added in version 0.24.

Changed in version 1.6: "auto" option is added and is the default.

Number of features seen during fit. Only defined if the underlying estimator exposes such an attribute when fit.

Added in version 0.24.

Names of features seen during fit. Only defined if the underlying estimator exposes such an attribute when fit.

Added in version 1.0.

The list of classifier and calibrator pairs.

When ensemble=True, n_cv fitted estimator and calibrator pairs. n_cv is the number of cross-validation folds.

When ensemble=False, the estimator, fitted on all the data, and fitted calibrator.

Changed in version 0.24: Single calibrated classifier case when ensemble=False.

Compute true and predicted probabilities for a calibration curve.

B. Zadrozny & C. Elkan. Obtaining calibrated probability estimates from decision trees and naive Bayesian classifiers, ICML 2001.

B. Zadrozny & C. Elkan. Transforming Classifier Scores into Accurate Multiclass Probability Estimates, KDD 2002.

J. Platt. Probabilistic Outputs for Support Vector Machines and Comparisons to Regularized Likelihood Methods, 1999.

A. Niculescu-Mizil & R. Caruana. Predicting Good Probabilities with Supervised Learning, ICML 2005.

Chuan Guo, Geoff Pleiss, Yu Sun, Kilian Q. Weinberger. On Calibration of Modern Neural Networks. Proceedings of the 34th International Conference on Machine Learning, PMLR 70:1321-1330, 2017.

Fit the calibrated model.

Sample weights. If None, then samples are equally weighted.

Parameters to pass to the fit method of the underlying classifier.

Returns an instance of self.

Get metadata routing of this object.

Please check User Guide on how the routing mechanism works.

A MetadataRouter encapsulating routing information.

Get parameters for this estimator.

If True, will return the parameters for this estimator and contained subobjects that are estimators.

Parameter names mapped to their values.

Predict the target of new samples.

The predicted class is the class that has the highest probability, and can thus be different from the prediction of the uncalibrated classifier.

The samples, as accepted by estimator.predict.

Calibrated probabilities of classification.

This function returns calibrated probabilities of classification according to each class on an array of test vectors X.

The samples, as accepted by estimator.predict_proba.

The predicted probas.

Return accuracy on provided data and labels.

In multi-label classification, this is the subset accuracy which is a harsh metric since you require for each sample that each label set be correctly predicted.

Mean accuracy of self.predict(X) w.r.t. y.

Configure whether metadata should be requested to be passed to the fit method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to fit if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to fit.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Added in version 1.3.

Metadata routing for sample_weight parameter in fit.

Set the parameters of this estimator.

The method works on simple estimators as well as on nested objects (such as Pipeline). The latter have parameters of the form <component>__<parameter> so that it’s possible to update each component of a nested object.

Estimator parameters.

Configure whether metadata should be requested to be passed to the score method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to score if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to score.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Added in version 1.3.

Metadata routing for sample_weight parameter in score.

Probability calibration of classifiers

Probability Calibration curves

Probability Calibration for 3-class classification

Examples of Using FrozenEstimator

Release Highlights for scikit-learn 1.8

**Examples:**

Example 1 (json):
```json
>>> from sklearn.datasets import make_classification
>>> from sklearn.naive_bayes import GaussianNB
>>> from sklearn.calibration import CalibratedClassifierCV
>>> X, y = make_classification(n_samples=100, n_features=2,
...                            n_redundant=0, random_state=42)
>>> base_clf = GaussianNB()
>>> calibrated_clf = CalibratedClassifierCV(base_clf, cv=3)
>>> calibrated_clf.fit(X, y)
CalibratedClassifierCV(...)
>>> len(calibrated_clf.calibrated_classifiers_)
3
>>> calibrated_clf.predict_proba(X)[:5, :]
array([[0.110, 0.889],
       [0.072, 0.927],
       [0.928, 0.072],
       [0.928, 0.072],
       [0.072, 0.928]])
>>> from sklearn.model_selection import train_test_split
>>> X, y = make_classification(n_samples=100, n_features=2,
...                            n_redundant=0, random_state=42)
>>> X_train, X_calib, y_train, y_calib = train_test_split(
...        X, y, random_state=42
... )
>>> base_clf = GaussianNB()
>>> base_clf.fit(X_train, y_train)
GaussianNB()
>>> from sklearn.frozen import FrozenEstimator
>>> calibrated_clf = CalibratedClassifierCV(FrozenEstimator(base_clf))
>>> calibrated_clf.fit(X_calib, y_calib)
CalibratedClassifierCV(...)
>>> len(calibrated_clf.calibrated_classifiers_)
1
>>> calibrated_clf.predict_proba([[-0.5, 0.5]])
array([[0.936, 0.063]])
```

---

## FactorAnalysis#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.FactorAnalysis.html

**Contents:**
- FactorAnalysis#
- Gallery examples#

Factor Analysis (FA).

A simple linear generative model with Gaussian latent variables.

The observations are assumed to be caused by a linear transformation of lower dimensional latent factors and added Gaussian noise. Without loss of generality the factors are distributed according to a Gaussian with zero mean and unit covariance. The noise is also zero mean and has an arbitrary diagonal covariance matrix.

If we would restrict the model further, by assuming that the Gaussian noise is even isotropic (all diagonal entries are the same) we would obtain PCA.

FactorAnalysis performs a maximum likelihood estimate of the so-called loading matrix, the transformation of the latent variables to the observed ones, using SVD based approach.

Read more in the User Guide.

Added in version 0.13.

Dimensionality of latent space, the number of components of X that are obtained after transform. If None, n_components is set to the number of features.

Stopping tolerance for log-likelihood increase.

Whether to make a copy of X. If False, the input X gets overwritten during fitting.

Maximum number of iterations.

The initial guess of the noise variance for each feature. If None, it defaults to np.ones(n_features).

Which SVD method to use. If ‘lapack’ use standard SVD from scipy.linalg, if ‘randomized’ use fast randomized_svd function. Defaults to ‘randomized’. For most applications ‘randomized’ will be sufficiently precise while providing significant speed gains. Accuracy can also be improved by setting higher values for iterated_power. If this is not sufficient, for maximum precision you should choose ‘lapack’.

Number of iterations for the power method. 3 by default. Only used if svd_method equals ‘randomized’.

If not None, apply the indicated rotation. Currently, varimax and quartimax are implemented. See “The varimax criterion for analytic rotation in factor analysis” H. F. Kaiser, 1958.

Added in version 0.24.

Only used when svd_method equals ‘randomized’. Pass an int for reproducible results across multiple function calls. See Glossary.

Components with maximum variance.

The log likelihood at each iteration.

The estimated noise variance for each feature.

Number of iterations run.

Per-feature empirical mean, estimated from the training set.

Number of features seen during fit.

Added in version 0.24.

Names of features seen during fit. Defined only when X has feature names that are all strings.

Added in version 1.0.

Principal component analysis is also a latent linear variable model which however assumes equal noise variance for each feature. This extra assumption makes probabilistic PCA faster as it can be computed in closed form.

Independent component analysis, a latent variable model with non-Gaussian latent variables.

David Barber, Bayesian Reasoning and Machine Learning, Algorithm 21.1.

Christopher M. Bishop: Pattern Recognition and Machine Learning, Chapter 12.2.4.

Fit the FactorAnalysis model to X using SVD based approach.

FactorAnalysis class instance.

Fit to data, then transform it.

Fits transformer to X and y with optional parameters fit_params and returns a transformed version of X.

Target values (None for unsupervised transformations).

Additional fit parameters. Pass only if the estimator accepts additional params in its fit method.

Compute data covariance with the FactorAnalysis model.

cov = components_.T * components_ + diag(noise_variance)

Estimated covariance of data.

Get output feature names for transformation.

The feature names out will prefixed by the lowercased class name. For example, if the transformer outputs 3 features, then the feature names out are: ["class_name0", "class_name1", "class_name2"].

Only used to validate feature names with the names seen in fit.

Transformed feature names.

Get metadata routing of this object.

Please check User Guide on how the routing mechanism works.

A MetadataRequest encapsulating routing information.

Get parameters for this estimator.

If True, will return the parameters for this estimator and contained subobjects that are estimators.

Parameter names mapped to their values.

Compute data precision matrix with the FactorAnalysis model.

Estimated precision of data.

Compute the average log-likelihood of the samples.

Average log-likelihood of the samples under the current model.

Compute the log-likelihood of each sample.

Log-likelihood of each sample under the current model.

Set output container.

See Introducing the set_output API for an example on how to use the API.

Configure output of transform and fit_transform.

"default": Default output format of a transformer

"pandas": DataFrame output

"polars": Polars output

None: Transform configuration is unchanged

Added in version 1.4: "polars" option was added.

Set the parameters of this estimator.

The method works on simple estimators as well as on nested objects (such as Pipeline). The latter have parameters of the form <component>__<parameter> so that it’s possible to update each component of a nested object.

Estimator parameters.

Apply dimensionality reduction to X using the model.

Compute the expected mean of the latent variables. See Barber, 21.2.33 (or Bishop, 12.66).

The latent variables of X.

Faces dataset decompositions

Model selection with Probabilistic PCA and Factor Analysis (FA)

Factor Analysis (with rotation) to visualize patterns

**Examples:**

Example 1 (sql):
```sql
>>> from sklearn.datasets import load_digits
>>> from sklearn.decomposition import FactorAnalysis
>>> X, _ = load_digits(return_X_y=True)
>>> transformer = FactorAnalysis(n_components=7, random_state=0)
>>> X_transformed = transformer.fit_transform(X)
>>> X_transformed.shape
(1797, 7)
```

---

## SpectralEmbedding#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.manifold.SpectralEmbedding.html

**Contents:**
- SpectralEmbedding#
- Gallery examples#

Spectral embedding for non-linear dimensionality reduction.

Forms an affinity matrix given by the specified function and applies spectral decomposition to the corresponding graph laplacian. The resulting transformation is given by the value of the eigenvectors for each data point.

Note : Laplacian Eigenmaps is the actual algorithm implemented here.

Read more in the User Guide.

The dimension of the projected subspace.

‘nearest_neighbors’ : construct the affinity matrix by computing a graph of nearest neighbors.

‘rbf’ : construct the affinity matrix by computing a radial basis function (RBF) kernel.

‘precomputed’ : interpret X as a precomputed affinity matrix.

‘precomputed_nearest_neighbors’ : interpret X as a sparse graph of precomputed nearest neighbors, and constructs the affinity matrix by selecting the n_neighbors nearest neighbors.

callable : use passed in function as affinity the function takes in data matrix (n_samples, n_features) and return affinity matrix (n_samples, n_samples).

Kernel coefficient for rbf kernel. If None, gamma will be set to 1/n_features.

A pseudo random number generator used for the initialization of the lobpcg eigen vectors decomposition when eigen_solver == 'amg', and for the K-Means initialization. Use an int to make the results deterministic across calls (See Glossary).

When using eigen_solver == 'amg', it is necessary to also fix the global numpy seed with np.random.seed(int) to get deterministic results. See pyamg/pyamg#139 for further information.

The eigenvalue decomposition strategy to use. AMG requires pyamg to be installed. It can be faster on very large, sparse problems. If None, then 'arpack' is used.

Stopping criterion for eigendecomposition of the Laplacian matrix. If eigen_tol="auto" then the passed tolerance will depend on the eigen_solver:

If eigen_solver="arpack", then eigen_tol=0.0;

If eigen_solver="lobpcg" or eigen_solver="amg", then eigen_tol=None which configures the underlying lobpcg solver to automatically resolve the value according to their heuristics. See, scipy.sparse.linalg.lobpcg for details.

Note that when using eigen_solver="lobpcg" or eigen_solver="amg" values of tol<1e-5 may lead to convergence issues and should be avoided.

Added in version 1.2.

Number of nearest neighbors for nearest_neighbors graph building. If None, n_neighbors will be set to max(n_samples/10, 1).

The number of parallel jobs to run. None means 1 unless in a joblib.parallel_backend context. -1 means using all processors. See Glossary for more details.

Spectral embedding of the training matrix.

Affinity_matrix constructed from samples or precomputed.

Number of features seen during fit.

Added in version 0.24.

Names of features seen during fit. Defined only when X has feature names that are all strings.

Added in version 1.0.

Number of nearest neighbors effectively used.

Non-linear dimensionality reduction through Isometric Mapping.

A Tutorial on Spectral Clustering, 2007 Ulrike von Luxburg

On Spectral Clustering: Analysis and an algorithm, 2001 Andrew Y. Ng, Michael I. Jordan, Yair Weiss

Normalized cuts and image segmentation, 2000 Jianbo Shi, Jitendra Malik

Fit the model from data in X.

Training vector, where n_samples is the number of samples and n_features is the number of features.

If affinity is “precomputed” X : {array-like, sparse matrix}, shape (n_samples, n_samples), Interpret X as precomputed adjacency graph computed from samples.

Not used, present for API consistency by convention.

Returns the instance itself.

Fit the model from data in X and transform X.

Training vector, where n_samples is the number of samples and n_features is the number of features.

If affinity is “precomputed” X : {array-like, sparse matrix} of shape (n_samples, n_samples), Interpret X as precomputed adjacency graph computed from samples.

Not used, present for API consistency by convention.

Spectral embedding of the training matrix.

Get metadata routing of this object.

Please check User Guide on how the routing mechanism works.

A MetadataRequest encapsulating routing information.

Get parameters for this estimator.

If True, will return the parameters for this estimator and contained subobjects that are estimators.

Parameter names mapped to their values.

Set the parameters of this estimator.

The method works on simple estimators as well as on nested objects (such as Pipeline). The latter have parameters of the form <component>__<parameter> so that it’s possible to update each component of a nested object.

Estimator parameters.

Various Agglomerative Clustering on a 2D embedding of digits

Comparison of Manifold Learning methods

Manifold learning on handwritten digits: Locally Linear Embedding, Isomap…

Manifold Learning methods on a severed sphere

**Examples:**

Example 1 (sql):
```sql
>>> from sklearn.datasets import load_digits
>>> from sklearn.manifold import SpectralEmbedding
>>> X, _ = load_digits(return_X_y=True)
>>> X.shape
(1797, 64)
>>> embedding = SpectralEmbedding(n_components=2)
>>> X_transformed = embedding.fit_transform(X[:100])
>>> X_transformed.shape
(100, 2)
```

---

## Pipeline#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html

**Contents:**
- Pipeline#
- Gallery examples#

A sequence of data transformers with an optional final predictor.

Pipeline allows you to sequentially apply a list of transformers to preprocess the data and, if desired, conclude the sequence with a final predictor for predictive modeling.

Intermediate steps of the pipeline must be transformers, that is, they must implement fit and transform methods. The final estimator only needs to implement fit. The transformers in the pipeline can be cached using memory argument.

The purpose of the pipeline is to assemble several steps that can be cross-validated together while setting different parameters. For this, it enables setting parameters of the various steps using their names and the parameter name separated by a '__', as in the example below. A step’s estimator may be replaced entirely by setting the parameter with its name to another estimator, or a transformer removed by setting it to 'passthrough' or None.

For an example use case of Pipeline combined with GridSearchCV, refer to Selecting dimensionality reduction with Pipeline and GridSearchCV. The example Pipelining: chaining a PCA and a logistic regression shows how to grid search on a pipeline using '__' as a separator in the parameter names.

Read more in the User Guide.

Added in version 0.5.

List of (name of step, estimator) tuples that are to be chained in sequential order. To be compatible with the scikit-learn API, all steps must define fit. All non-last steps must also define transform. See Combining Estimators for more details.

The names of the metadata parameters that should be transformed by the pipeline before passing it to the step consuming it.

This enables transforming some input arguments to fit (other than X) to be transformed by the steps of the pipeline up to the step which requires them. Requirement is defined via metadata routing. For instance, this can be used to pass a validation set through the pipeline.

You can only set this if metadata routing is enabled, which you can enable using sklearn.set_config(enable_metadata_routing=True).

Added in version 1.6.

Used to cache the fitted transformers of the pipeline. The last step will never be cached, even if it is a transformer. By default, no caching is performed. If a string is given, it is the path to the caching directory. Enabling caching triggers a clone of the transformers before fitting. Therefore, the transformer instance given to the pipeline cannot be inspected directly. Use the attribute named_steps or steps to inspect estimators within the pipeline. Caching the transformers is advantageous when fitting is time consuming. See Caching nearest neighbors for an example on how to enable caching.

If True, the time elapsed while fitting each step will be printed as it is completed.

Access the steps by name.

Number of features seen during first step fit method.

Names of features seen during first step fit method.

Convenience function for simplified pipeline construction.

Transform the data, and apply decision_function with the final estimator.

Call transform of each transformer in the pipeline. The transformed data are finally passed to the final estimator that calls decision_function method. Only valid if the final estimator implements decision_function.

Data to predict on. Must fulfill input requirements of first step of the pipeline.

Parameters requested and accepted by steps. Each step must have requested certain metadata for these parameters to be forwarded to them.

Added in version 1.4: Only available if enable_metadata_routing=True. See Metadata Routing User Guide for more details.

Result of calling decision_function on the final estimator.

Fit all the transformers one after the other and sequentially transform the data. Finally, fit the transformed data using the final estimator.

Training data. Must fulfill input requirements of first step of the pipeline.

Training targets. Must fulfill label requirements for all steps of the pipeline.

If enable_metadata_routing=False (default): Parameters passed to the fit method of each step, where each parameter name is prefixed such that parameter p for step s has key s__p.

If enable_metadata_routing=True: Parameters requested and accepted by steps. Each step must have requested certain metadata for these parameters to be forwarded to them.

Changed in version 1.4: Parameters are now passed to the transform method of the intermediate steps as well, if requested, and if enable_metadata_routing=True is set via set_config.

See Metadata Routing User Guide for more details.

Pipeline with fitted steps.

Transform the data, and apply fit_predict with the final estimator.

Call fit_transform of each transformer in the pipeline. The transformed data are finally passed to the final estimator that calls fit_predict method. Only valid if the final estimator implements fit_predict.

Training data. Must fulfill input requirements of first step of the pipeline.

Training targets. Must fulfill label requirements for all steps of the pipeline.

If enable_metadata_routing=False (default): Parameters to the predict called at the end of all transformations in the pipeline.

If enable_metadata_routing=True: Parameters requested and accepted by steps. Each step must have requested certain metadata for these parameters to be forwarded to them.

Added in version 0.20.

Changed in version 1.4: Parameters are now passed to the transform method of the intermediate steps as well, if requested, and if enable_metadata_routing=True.

See Metadata Routing User Guide for more details.

Note that while this may be used to return uncertainties from some models with return_std or return_cov, uncertainties that are generated by the transformations in the pipeline are not propagated to the final estimator.

Result of calling fit_predict on the final estimator.

Fit the model and transform with the final estimator.

Fit all the transformers one after the other and sequentially transform the data. Only valid if the final estimator either implements fit_transform or fit and transform.

Training data. Must fulfill input requirements of first step of the pipeline.

Training targets. Must fulfill label requirements for all steps of the pipeline.

If enable_metadata_routing=False (default): Parameters passed to the fit method of each step, where each parameter name is prefixed such that parameter p for step s has key s__p.

If enable_metadata_routing=True: Parameters requested and accepted by steps. Each step must have requested certain metadata for these parameters to be forwarded to them.

Changed in version 1.4: Parameters are now passed to the transform method of the intermediate steps as well, if requested, and if enable_metadata_routing=True.

See Metadata Routing User Guide for more details.

Get output feature names for transformation.

Transform input features using the pipeline.

Transformed feature names.

Get metadata routing of this object.

Please check User Guide on how the routing mechanism works.

A MetadataRouter encapsulating routing information.

Get parameters for this estimator.

Returns the parameters given in the constructor as well as the estimators contained within the steps of the Pipeline.

If True, will return the parameters for this estimator and contained subobjects that are estimators.

Parameter names mapped to their values.

Apply inverse_transform for each step in a reverse order.

All estimators in the pipeline must support inverse_transform.

Data samples, where n_samples is the number of samples and n_features is the number of features. Must fulfill input requirements of last step of pipeline’s inverse_transform method.

Parameters requested and accepted by steps. Each step must have requested certain metadata for these parameters to be forwarded to them.

Added in version 1.4: Only available if enable_metadata_routing=True. See Metadata Routing User Guide for more details.

Inverse transformed data, that is, data in the original feature space.

Access the steps by name.

Read-only attribute to access any step by given name. Keys are steps names and values are the steps objects.

Transform the data, and apply predict with the final estimator.

Call transform of each transformer in the pipeline. The transformed data are finally passed to the final estimator that calls predict method. Only valid if the final estimator implements predict.

Data to predict on. Must fulfill input requirements of first step of the pipeline.

If enable_metadata_routing=False (default): Parameters to the predict called at the end of all transformations in the pipeline.

If enable_metadata_routing=True: Parameters requested and accepted by steps. Each step must have requested certain metadata for these parameters to be forwarded to them.

Added in version 0.20.

Changed in version 1.4: Parameters are now passed to the transform method of the intermediate steps as well, if requested, and if enable_metadata_routing=True is set via set_config.

See Metadata Routing User Guide for more details.

Note that while this may be used to return uncertainties from some models with return_std or return_cov, uncertainties that are generated by the transformations in the pipeline are not propagated to the final estimator.

Result of calling predict on the final estimator.

Transform the data, and apply predict_log_proba with the final estimator.

Call transform of each transformer in the pipeline. The transformed data are finally passed to the final estimator that calls predict_log_proba method. Only valid if the final estimator implements predict_log_proba.

Data to predict on. Must fulfill input requirements of first step of the pipeline.

If enable_metadata_routing=False (default): Parameters to the predict_log_proba called at the end of all transformations in the pipeline.

If enable_metadata_routing=True: Parameters requested and accepted by steps. Each step must have requested certain metadata for these parameters to be forwarded to them.

Added in version 0.20.

Changed in version 1.4: Parameters are now passed to the transform method of the intermediate steps as well, if requested, and if enable_metadata_routing=True.

See Metadata Routing User Guide for more details.

Result of calling predict_log_proba on the final estimator.

Transform the data, and apply predict_proba with the final estimator.

Call transform of each transformer in the pipeline. The transformed data are finally passed to the final estimator that calls predict_proba method. Only valid if the final estimator implements predict_proba.

Data to predict on. Must fulfill input requirements of first step of the pipeline.

If enable_metadata_routing=False (default): Parameters to the predict_proba called at the end of all transformations in the pipeline.

If enable_metadata_routing=True: Parameters requested and accepted by steps. Each step must have requested certain metadata for these parameters to be forwarded to them.

Added in version 0.20.

Changed in version 1.4: Parameters are now passed to the transform method of the intermediate steps as well, if requested, and if enable_metadata_routing=True.

See Metadata Routing User Guide for more details.

Result of calling predict_proba on the final estimator.

Transform the data, and apply score with the final estimator.

Call transform of each transformer in the pipeline. The transformed data are finally passed to the final estimator that calls score method. Only valid if the final estimator implements score.

Data to predict on. Must fulfill input requirements of first step of the pipeline.

Targets used for scoring. Must fulfill label requirements for all steps of the pipeline.

If not None, this argument is passed as sample_weight keyword argument to the score method of the final estimator.

Parameters requested and accepted by steps. Each step must have requested certain metadata for these parameters to be forwarded to them.

Added in version 1.4: Only available if enable_metadata_routing=True. See Metadata Routing User Guide for more details.

Result of calling score on the final estimator.

Transform the data, and apply score_samples with the final estimator.

Call transform of each transformer in the pipeline. The transformed data are finally passed to the final estimator that calls score_samples method. Only valid if the final estimator implements score_samples.

Data to predict on. Must fulfill input requirements of first step of the pipeline.

Result of calling score_samples on the final estimator.

Set the output container when "transform" and "fit_transform" are called.

Calling set_output will set the output of all estimators in steps.

Configure output of transform and fit_transform.

"default": Default output format of a transformer

"pandas": DataFrame output

"polars": Polars output

None: Transform configuration is unchanged

Added in version 1.4: "polars" option was added.

Set the parameters of this estimator.

Valid parameter keys can be listed with get_params(). Note that you can directly set the parameters of the estimators contained in steps.

Parameters of this estimator or parameters of estimators contained in steps. Parameters of the steps may be set using its name and the parameter name separated by a ‘__’.

Pipeline class instance.

Configure whether metadata should be requested to be passed to the score method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to score if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to score.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Added in version 1.3.

Metadata routing for sample_weight parameter in score.

Transform the data, and apply transform with the final estimator.

Call transform of each transformer in the pipeline. The transformed data are finally passed to the final estimator that calls transform method. Only valid if the final estimator implements transform.

This also works where final estimator is None in which case all prior transformations are applied.

Data to transform. Must fulfill input requirements of first step of the pipeline.

Parameters requested and accepted by steps. Each step must have requested certain metadata for these parameters to be forwarded to them.

Added in version 1.4: Only available if enable_metadata_routing=True. See Metadata Routing User Guide for more details.

Feature agglomeration vs. univariate selection

Column Transformer with Heterogeneous Data Sources

Column Transformer with Mixed Types

Selecting dimensionality reduction with Pipeline and GridSearchCV

Pipelining: chaining a PCA and a logistic regression

Concatenating multiple feature extraction methods

Recursive feature elimination

Permutation Importance vs Random Forest Feature Importance (MDI)

Poisson regression and non-normal loss

Explicit feature map approximation for RBF kernels

Balance model complexity and cross-validated score

Sample pipeline for text feature extraction and evaluation

Underfitting vs. Overfitting

Caching nearest neighbors

Nearest Neighbors Classification

Comparing Nearest Neighbors with and without Neighborhood Components Analysis

Restricted Boltzmann Machine features for digit classification

Target Encoder’s Internal Cross fitting

Release Highlights for scikit-learn 1.7

Semi-supervised Classification on a Text Dataset

SVM-Anova: SVM with univariate feature selection

**Examples:**

Example 1 (sql):
```sql
>>> from sklearn.svm import SVC
>>> from sklearn.preprocessing import StandardScaler
>>> from sklearn.datasets import make_classification
>>> from sklearn.model_selection import train_test_split
>>> from sklearn.pipeline import Pipeline
>>> X, y = make_classification(random_state=0)
>>> X_train, X_test, y_train, y_test = train_test_split(X, y,
...                                                     random_state=0)
>>> pipe = Pipeline([('scaler', StandardScaler()), ('svc', SVC())])
>>> # The pipeline can be used as any other estimator
>>> # and avoids leaking the test set into the train set
>>> pipe.fit(X_train, y_train).score(X_test, y_test)
0.88
>>> # An estimator's parameter can be set using '__' syntax
>>> pipe.set_params(svc__C=10).fit(X_train, y_train).score(X_test, y_test)
0.76
```

---

## 7.4. Imputation of missing values#

**URL:** https://scikit-learn.org/stable/modules/impute.html

**Contents:**
- 7.4. Imputation of missing values#
- 7.4.1. Univariate vs. Multivariate Imputation#
- 7.4.2. Univariate feature imputation#
- 7.4.3. Multivariate feature imputation#
  - 7.4.3.1. Flexibility of IterativeImputer#
  - 7.4.3.2. Multiple vs. Single Imputation#
- 7.4.4. Nearest neighbors imputation#
- 7.4.5. Keeping the number of features constant#
- 7.4.6. Marking imputed values#
- 7.4.7. Estimators that handle NaN values#

For various reasons, many real world datasets contain missing values, often encoded as blanks, NaNs or other placeholders. Such datasets however are incompatible with scikit-learn estimators which assume that all values in an array are numerical, and that all have and hold meaning. A basic strategy to use incomplete datasets is to discard entire rows and/or columns containing missing values. However, this comes at the price of losing data which may be valuable (even though incomplete). A better strategy is to impute the missing values, i.e., to infer them from the known part of the data. See the glossary entry on imputation.

One type of imputation algorithm is univariate, which imputes values in the i-th feature dimension using only non-missing values in that feature dimension (e.g. SimpleImputer). By contrast, multivariate imputation algorithms use the entire set of available feature dimensions to estimate the missing values (e.g. IterativeImputer).

The SimpleImputer class provides basic strategies for imputing missing values. Missing values can be imputed with a provided constant value, or using the statistics (mean, median or most frequent) of each column in which the missing values are located. This class also allows for different missing values encodings.

The following snippet demonstrates how to replace missing values, encoded as np.nan, using the mean value of the columns (axis 0) that contain the missing values:

The SimpleImputer class also supports sparse matrices:

Note that this format is not meant to be used to implicitly store missing values in the matrix because it would densify it at transform time. Missing values encoded by 0 must be used with dense input.

The SimpleImputer class also supports categorical data represented as string values or pandas categoricals when using the 'most_frequent' or 'constant' strategy:

For another example on usage, see Imputing missing values before building an estimator.

A more sophisticated approach is to use the IterativeImputer class, which models each feature with missing values as a function of other features, and uses that estimate for imputation. It does so in an iterated round-robin fashion: at each step, a feature column is designated as output y and the other feature columns are treated as inputs X. A regressor is fit on (X, y) for known y. Then, the regressor is used to predict the missing values of y. This is done for each feature in an iterative fashion, and then is repeated for max_iter imputation rounds. The results of the final imputation round are returned.

This estimator is still experimental for now: default parameters or details of behaviour might change without any deprecation cycle. Resolving the following issues would help stabilize IterativeImputer: convergence criteria (#14338) and default estimators (#13286). To use it, you need to explicitly import enable_iterative_imputer.

Both SimpleImputer and IterativeImputer can be used in a Pipeline as a way to build a composite estimator that supports imputation. See Imputing missing values before building an estimator.

There are many well-established imputation packages in the R data science ecosystem: Amelia, mi, mice, missForest, etc. missForest is popular, and turns out to be a particular instance of different sequential imputation algorithms that can all be implemented with IterativeImputer by passing in different regressors to be used for predicting missing feature values. In the case of missForest, this regressor is a Random Forest. See Imputing missing values with variants of IterativeImputer.

In the statistics community, it is common practice to perform multiple imputations, generating, for example, m separate imputations for a single feature matrix. Each of these m imputations is then put through the subsequent analysis pipeline (e.g. feature engineering, clustering, regression, classification). The m final analysis results (e.g. held-out validation errors) allow the data scientist to obtain understanding of how analytic results may differ as a consequence of the inherent uncertainty caused by the missing values. The above practice is called multiple imputation.

Our implementation of IterativeImputer was inspired by the R MICE package (Multivariate Imputation by Chained Equations) [1], but differs from it by returning a single imputation instead of multiple imputations. However, IterativeImputer can also be used for multiple imputations by applying it repeatedly to the same dataset with different random seeds when sample_posterior=True. See [2], chapter 4 for more discussion on multiple vs. single imputations.

It is still an open problem as to how useful single vs. multiple imputation is in the context of prediction and classification when the user is not interested in measuring uncertainty due to missing values.

Note that a call to the transform method of IterativeImputer is not allowed to change the number of samples. Therefore multiple imputations cannot be achieved by a single call to transform.

Stef van Buuren, Karin Groothuis-Oudshoorn (2011). “mice: Multivariate Imputation by Chained Equations in R”. Journal of Statistical Software 45: 1-67.

Roderick J A Little and Donald B Rubin (1986). “Statistical Analysis with Missing Data”. John Wiley & Sons, Inc., New York, NY, USA.

The KNNImputer class provides imputation for filling in missing values using the k-Nearest Neighbors approach. By default, a euclidean distance metric that supports missing values, nan_euclidean_distances, is used to find the nearest neighbors. Each missing feature is imputed using values from n_neighbors nearest neighbors that have a value for the feature. The feature of the neighbors are averaged uniformly or weighted by distance to each neighbor. If a sample has more than one feature missing, then the neighbors for that sample can be different depending on the particular feature being imputed. When the number of available neighbors is less than n_neighbors and there are no defined distances to the training set, the training set average for that feature is used during imputation. If there is at least one neighbor with a defined distance, the weighted or unweighted average of the remaining neighbors will be used during imputation. If a feature is always missing in training, it is removed during transform. For more information on the methodology, see ref. [OL2001].

The following snippet demonstrates how to replace missing values, encoded as np.nan, using the mean feature value of the two nearest neighbors of samples with missing values:

For another example on usage, see Imputing missing values before building an estimator.

Olga Troyanskaya, Michael Cantor, Gavin Sherlock, Pat Brown, Trevor Hastie, Robert Tibshirani, David Botstein and Russ B. Altman, Missing value estimation methods for DNA microarrays, BIOINFORMATICS Vol. 17 no. 6, 2001 Pages 520-525.

By default, the scikit-learn imputers will drop fully empty features, i.e. columns containing only missing values. For instance:

The first feature in X containing only np.nan was dropped after the imputation. While this feature will not help in predictive setting, dropping the columns will change the shape of X which could be problematic when using imputers in a more complex machine-learning pipeline. The parameter keep_empty_features offers the option to keep the empty features by imputing with a constant value. In most of the cases, this constant value is zero:

The MissingIndicator transformer is useful to transform a dataset into corresponding binary matrix indicating the presence of missing values in the dataset. This transformation is useful in conjunction with imputation. When using imputation, preserving the information about which values had been missing can be informative. Note that both the SimpleImputer and IterativeImputer have the boolean parameter add_indicator (False by default) which when set to True provides a convenient way of stacking the output of the MissingIndicator transformer with the output of the imputer.

NaN is usually used as the placeholder for missing values. However, it enforces the data type to be float. The parameter missing_values allows to specify other placeholder such as integer. In the following example, we will use -1 as missing values:

The features parameter is used to choose the features for which the mask is constructed. By default, it is 'missing-only' which returns the imputer mask of the features containing missing values at fit time:

The features parameter can be set to 'all' to return all features whether or not they contain missing values:

When using the MissingIndicator in a Pipeline, be sure to use the FeatureUnion or ColumnTransformer to add the indicator features to the regular features. First we obtain the iris dataset, and add some missing values to it.

Now we create a FeatureUnion. All features will be imputed using SimpleImputer, in order to enable classifiers to work with this data. Additionally, it adds the indicator variables from MissingIndicator.

Of course, we cannot use the transformer to make any predictions. We should wrap this in a Pipeline with a classifier (e.g., a DecisionTreeClassifier) to be able to make predictions.

Some estimators are designed to handle NaN values without preprocessing. Below is the list of these estimators, classified by type (cluster, regressor, classifier, transform):

DecisionTreeRegressor

HistGradientBoostingRegressor

RandomForestRegressor

DecisionTreeClassifier

HistGradientBoostingClassifier

RandomForestClassifier

**Examples:**

Example 1 (csharp):
```csharp
>>> import numpy as np
>>> from sklearn.impute import SimpleImputer
>>> imp = SimpleImputer(missing_values=np.nan, strategy='mean')
>>> imp.fit([[1, 2], [np.nan, 3], [7, 6]])
SimpleImputer()
>>> X = [[np.nan, 2], [6, np.nan], [7, 6]]
>>> print(imp.transform(X))
[[4.          2.        ]
 [6.          3.666]
 [7.          6.        ]]
```

Example 2 (csharp):
```csharp
>>> import scipy.sparse as sp
>>> X = sp.csc_matrix([[1, 2], [0, -1], [8, 4]])
>>> imp = SimpleImputer(missing_values=-1, strategy='mean')
>>> imp.fit(X)
SimpleImputer(missing_values=-1)
>>> X_test = sp.csc_matrix([[-1, 2], [6, -1], [7, 6]])
>>> print(imp.transform(X_test).toarray())
[[3. 2.]
 [6. 3.]
 [7. 6.]]
```

Example 3 (python):
```python
>>> import pandas as pd
>>> df = pd.DataFrame([["a", "x"],
...                    [np.nan, "y"],
...                    ["a", np.nan],
...                    ["b", "y"]], dtype="category")
...
>>> imp = SimpleImputer(strategy="most_frequent")
>>> print(imp.fit_transform(df))
[['a' 'x']
 ['a' 'y']
 ['a' 'y']
 ['b' 'y']]
```

Example 4 (csharp):
```csharp
>>> import numpy as np
>>> from sklearn.experimental import enable_iterative_imputer
>>> from sklearn.impute import IterativeImputer
>>> imp = IterativeImputer(max_iter=10, random_state=0)
>>> imp.fit([[1, 2], [3, 6], [4, 8], [np.nan, 3], [7, np.nan]])
IterativeImputer(random_state=0)
>>> X_test = [[np.nan, 2], [6, np.nan], [np.nan, 6]]
>>> # the model learns that the second feature is double the first
>>> print(np.round(imp.transform(X_test)))
[[ 1.  2.]
 [ 6. 12.]
 [ 3.  6.]]
```

---

## Ridge#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html

**Contents:**
- Ridge#
- Gallery examples#

Linear least squares with l2 regularization.

Minimizes the objective function:

This model solves a regression model where the loss function is the linear least squares function and regularization is given by the l2-norm. Also known as Ridge Regression or Tikhonov regularization. This estimator has built-in support for multi-variate regression (i.e., when y is a 2d-array of shape (n_samples, n_targets)).

Read more in the User Guide.

Constant that multiplies the L2 term, controlling regularization strength. alpha must be a non-negative float i.e. in [0, inf).

When alpha = 0, the objective is equivalent to ordinary least squares, solved by the LinearRegression object. For numerical reasons, using alpha = 0 with the Ridge object is not advised. Instead, you should use the LinearRegression object.

If an array is passed, penalties are assumed to be specific to the targets. Hence they must correspond in number.

Whether to fit the intercept for this model. If set to false, no intercept will be used in calculations (i.e. X and y are expected to be centered).

If True, X will be copied; else, it may be overwritten.

Maximum number of iterations for conjugate gradient solver. For ‘sparse_cg’ and ‘lsqr’ solvers, the default value is determined by scipy.sparse.linalg. For ‘sag’ solver, the default value is 1000. For ‘lbfgs’ solver, the default value is 15000.

The precision of the solution (coef_) is determined by tol which specifies a different convergence criterion for each solver:

‘svd’: tol has no impact.

‘cholesky’: tol has no impact.

‘sparse_cg’: norm of residuals smaller than tol.

‘lsqr’: tol is set as atol and btol of scipy.sparse.linalg.lsqr, which control the norm of the residual vector in terms of the norms of matrix and coefficients.

‘sag’ and ‘saga’: relative change of coef smaller than tol.

‘lbfgs’: maximum of the absolute (projected) gradient=max|residuals| smaller than tol.

Changed in version 1.2: Default value changed from 1e-3 to 1e-4 for consistency with other linear models.

Solver to use in the computational routines:

‘auto’ chooses the solver automatically based on the type of data.

‘svd’ uses a Singular Value Decomposition of X to compute the Ridge coefficients. It is the most stable solver, in particular more stable for singular matrices than ‘cholesky’ at the cost of being slower.

‘cholesky’ uses the standard scipy.linalg.solve function to obtain a closed-form solution.

‘sparse_cg’ uses the conjugate gradient solver as found in scipy.sparse.linalg.cg. As an iterative algorithm, this solver is more appropriate than ‘cholesky’ for large-scale data (possibility to set tol and max_iter).

‘lsqr’ uses the dedicated regularized least-squares routine scipy.sparse.linalg.lsqr. It is the fastest and uses an iterative procedure.

‘sag’ uses a Stochastic Average Gradient descent, and ‘saga’ uses its improved, unbiased version named SAGA. Both methods also use an iterative procedure, and are often faster than other solvers when both n_samples and n_features are large. Note that ‘sag’ and ‘saga’ fast convergence is only guaranteed on features with approximately the same scale. You can preprocess the data with a scaler from sklearn.preprocessing.

‘lbfgs’ uses L-BFGS-B algorithm implemented in scipy.optimize.minimize. It can be used only when positive is True.

All solvers except ‘svd’ support both dense and sparse data. However, only ‘lsqr’, ‘sag’, ‘sparse_cg’, and ‘lbfgs’ support sparse input when fit_intercept is True.

Added in version 0.17: Stochastic Average Gradient descent solver.

Added in version 0.19: SAGA solver.

When set to True, forces the coefficients to be positive. Only ‘lbfgs’ solver is supported in this case.

Used when solver == ‘sag’ or ‘saga’ to shuffle the data. See Glossary for details.

Added in version 0.17: random_state to support Stochastic Average Gradient.

Independent term in decision function. Set to 0.0 if fit_intercept = False.

Actual number of iterations for each target. Available only for ‘sag’ and ‘lsqr’ solvers. Other solvers will return None.

Added in version 0.17.

Number of features seen during fit.

Added in version 0.24.

Names of features seen during fit. Defined only when X has feature names that are all strings.

Added in version 1.0.

The solver that was used at fit time by the computational routines.

Added in version 1.5.

Ridge regression with built-in cross validation.

Kernel ridge regression combines ridge regression with the kernel trick.

Regularization improves the conditioning of the problem and reduces the variance of the estimates. Larger values specify stronger regularization. Alpha corresponds to 1 / (2C) in other linear models such as LogisticRegression or LinearSVC.

Fit Ridge regression model.

Individual weights for each sample. If given a float, every sample will have the same weight.

Get metadata routing of this object.

Please check User Guide on how the routing mechanism works.

A MetadataRequest encapsulating routing information.

Get parameters for this estimator.

If True, will return the parameters for this estimator and contained subobjects that are estimators.

Parameter names mapped to their values.

Predict using the linear model.

Returns predicted values.

Return coefficient of determination on test data.

The coefficient of determination, \(R^2\), is defined as \((1 - \frac{u}{v})\), where \(u\) is the residual sum of squares ((y_true - y_pred)** 2).sum() and \(v\) is the total sum of squares ((y_true - y_true.mean()) ** 2).sum(). The best possible score is 1.0 and it can be negative (because the model can be arbitrarily worse). A constant model that always predicts the expected value of y, disregarding the input features, would get a \(R^2\) score of 0.0.

Test samples. For some estimators this may be a precomputed kernel matrix or a list of generic objects instead with shape (n_samples, n_samples_fitted), where n_samples_fitted is the number of samples used in the fitting for the estimator.

\(R^2\) of self.predict(X) w.r.t. y.

The \(R^2\) score used when calling score on a regressor uses multioutput='uniform_average' from version 0.23 to keep consistent with default value of r2_score. This influences the score method of all the multioutput regressors (except for MultiOutputRegressor).

Configure whether metadata should be requested to be passed to the fit method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to fit if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to fit.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Added in version 1.3.

Metadata routing for sample_weight parameter in fit.

Set the parameters of this estimator.

The method works on simple estimators as well as on nested objects (such as Pipeline). The latter have parameters of the form <component>__<parameter> so that it’s possible to update each component of a nested object.

Estimator parameters.

Configure whether metadata should be requested to be passed to the score method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to score if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to score.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Added in version 1.3.

Metadata routing for sample_weight parameter in score.

Compressive sensing: tomography reconstruction with L1 prior (Lasso)

Comparison of kernel ridge and Gaussian process regression

Imputing missing values with variants of IterativeImputer

Common pitfalls in the interpretation of coefficients of linear models

HuberRegressor vs Ridge on dataset with strong outliers

L1-based models for Sparse Signals

Ordinary Least Squares and Ridge Regression

Poisson regression and non-normal loss

Polynomial and Spline interpolation

Ridge coefficients as a function of the L2 Regularization

Plot Ridge coefficients as a function of the regularization

Target Encoder’s Internal Cross fitting

**Examples:**

Example 1 (unknown):
```unknown
||y - Xw||^2_2 + alpha * ||w||^2_2
```

Example 2 (sql):
```sql
>>> from sklearn.linear_model import Ridge
>>> import numpy as np
>>> n_samples, n_features = 10, 5
>>> rng = np.random.RandomState(0)
>>> y = rng.randn(n_samples)
>>> X = rng.randn(n_samples, n_features)
>>> clf = Ridge(alpha=1.0)
>>> clf.fit(X, y)
Ridge()
```

---

## mutual_info_classif#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.mutual_info_classif.html

**Contents:**
- mutual_info_classif#
- Gallery examples#

Estimate mutual information for a discrete target variable.

Mutual information (MI) [1] between two random variables is a non-negative value, which measures the dependency between the variables. It is equal to zero if and only if two random variables are independent, and higher values mean higher dependency.

The function relies on nonparametric methods based on entropy estimation from k-nearest neighbors distances as described in [2] and [3]. Both methods are based on the idea originally proposed in [4].

It can be used for univariate features selection, read more in the User Guide.

If bool, then determines whether to consider all features discrete or continuous. If array, then it should be either a boolean mask with shape (n_features,) or array with indices of discrete features. If ‘auto’, it is assigned to False for dense X and to True for sparse X.

Number of neighbors to use for MI estimation for continuous variables, see [2] and [3]. Higher values reduce variance of the estimation, but could introduce a bias.

Whether to make a copy of the given data. If set to False, the initial data will be overwritten.

Determines random number generation for adding small noise to continuous variables in order to remove repeated values. Pass an int for reproducible results across multiple function calls. See Glossary.

The number of jobs to use for computing the mutual information. The parallelization is done on the columns of X. None means 1 unless in a joblib.parallel_backend context. -1 means using all processors. See Glossary for more details.

Added in version 1.5.

Estimated mutual information between each feature and the target in nat units.

The term “discrete features” is used instead of naming them “categorical”, because it describes the essence more accurately. For example, pixel intensities of an image are discrete features (but hardly categorical) and you will get better results if mark them as such. Also note, that treating a continuous variable as discrete and vice versa will usually give incorrect results, so be attentive about that.

True mutual information can’t be negative. If its estimate turns out to be negative, it is replaced by zero.

Mutual Information on Wikipedia.

A. Kraskov, H. Stogbauer and P. Grassberger, “Estimating mutual information”. Phys. Rev. E 69, 2004.

B. C. Ross “Mutual Information between Discrete and Continuous Data Sets”. PLoS ONE 9(2), 2014.

L. F. Kozachenko, N. N. Leonenko, “Sample Estimate of the Entropy of a Random Vector:, Probl. Peredachi Inf., 23:2 (1987), 9-16

Selecting dimensionality reduction with Pipeline and GridSearchCV

**Examples:**

Example 1 (sql):
```sql
>>> from sklearn.datasets import make_classification
>>> from sklearn.feature_selection import mutual_info_classif
>>> X, y = make_classification(
...     n_samples=100, n_features=10, n_informative=2, n_clusters_per_class=1,
...     shuffle=False, random_state=42
... )
>>> mutual_info_classif(X, y)
array([0.589, 0.107, 0.196, 0.0968 , 0.,
       0.   , 0.   , 0.   , 0.     , 0.])
```

---

## shrunk_covariance#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.covariance.shrunk_covariance.html

**Contents:**
- shrunk_covariance#

Calculate covariance matrices shrunk on the diagonal.

Read more in the User Guide.

Covariance matrices to be shrunk, at least 2D ndarray.

Coefficient in the convex combination used for the computation of the shrunk estimate. Range is [0, 1].

Shrunk covariance matrices.

The regularized (shrunk) covariance is given by:

where mu = trace(cov) / n_features.

**Examples:**

Example 1 (unknown):
```unknown
(1 - shrinkage) * cov + shrinkage * mu * np.identity(n_features)
```

Example 2 (sql):
```sql
>>> import numpy as np
>>> from sklearn.datasets import make_gaussian_quantiles
>>> from sklearn.covariance import empirical_covariance, shrunk_covariance
>>> real_cov = np.array([[.8, .3], [.3, .4]])
>>> rng = np.random.RandomState(0)
>>> X = rng.multivariate_normal(mean=[0, 0], cov=real_cov, size=500)
>>> shrunk_covariance(empirical_covariance(X))
array([[0.739, 0.254],
       [0.254, 0.411]])
```

---

## RandomForestRegressor#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html

**Contents:**
- RandomForestRegressor#
- Gallery examples#

A random forest regressor.

A random forest is a meta estimator that fits a number of decision tree regressors on various sub-samples of the dataset and uses averaging to improve the predictive accuracy and control over-fitting. Trees in the forest use the best split strategy, i.e. equivalent to passing splitter="best" to the underlying DecisionTreeRegressor. The sub-sample size is controlled with the max_samples parameter if bootstrap=True (default), otherwise the whole dataset is used to build each tree.

This estimator has native support for missing values (NaNs). During training, the tree grower learns at each split point whether samples with missing values should go to the left or right child, based on the potential gain. When predicting, samples with missing values are assigned to the left or right child consequently. If no missing values were encountered for a given feature during training, then samples with missing values are mapped to whichever child has the most samples.

For a comparison between tree-based ensemble models see the example Comparing Random Forests and Histogram Gradient Boosting models.

Read more in the User Guide.

The number of trees in the forest.

Changed in version 0.22: The default value of n_estimators changed from 10 to 100 in 0.22.

The function to measure the quality of a split. Supported criteria are “squared_error” for the mean squared error, which is equal to variance reduction as feature selection criterion and minimizes the L2 loss using the mean of each terminal node, “friedman_mse”, which uses mean squared error with Friedman’s improvement score for potential splits, “absolute_error” for the mean absolute error, which minimizes the L1 loss using the median of each terminal node, and “poisson” which uses reduction in Poisson deviance to find splits. Training using “absolute_error” is significantly slower than when using “squared_error”.

Added in version 0.18: Mean Absolute Error (MAE) criterion.

Added in version 1.0: Poisson criterion.

The maximum depth of the tree. If None, then nodes are expanded until all leaves are pure or until all leaves contain less than min_samples_split samples.

The minimum number of samples required to split an internal node:

If int, then consider min_samples_split as the minimum number.

If float, then min_samples_split is a fraction and ceil(min_samples_split * n_samples) are the minimum number of samples for each split.

Changed in version 0.18: Added float values for fractions.

The minimum number of samples required to be at a leaf node. A split point at any depth will only be considered if it leaves at least min_samples_leaf training samples in each of the left and right branches. This may have the effect of smoothing the model, especially in regression.

If int, then consider min_samples_leaf as the minimum number.

If float, then min_samples_leaf is a fraction and ceil(min_samples_leaf * n_samples) are the minimum number of samples for each node.

Changed in version 0.18: Added float values for fractions.

The minimum weighted fraction of the sum total of weights (of all the input samples) required to be at a leaf node. Samples have equal weight when sample_weight is not provided.

The number of features to consider when looking for the best split:

If int, then consider max_features features at each split.

If float, then max_features is a fraction and max(1, int(max_features * n_features_in_)) features are considered at each split.

If “sqrt”, then max_features=sqrt(n_features).

If “log2”, then max_features=log2(n_features).

If None or 1.0, then max_features=n_features.

The default of 1.0 is equivalent to bagged trees and more randomness can be achieved by setting smaller values, e.g. 0.3.

Changed in version 1.1: The default of max_features changed from "auto" to 1.0.

Note: the search for a split does not stop until at least one valid partition of the node samples is found, even if it requires to effectively inspect more than max_features features.

Grow trees with max_leaf_nodes in best-first fashion. Best nodes are defined as relative reduction in impurity. If None then unlimited number of leaf nodes.

A node will be split if this split induces a decrease of the impurity greater than or equal to this value.

The weighted impurity decrease equation is the following:

where N is the total number of samples, N_t is the number of samples at the current node, N_t_L is the number of samples in the left child, and N_t_R is the number of samples in the right child.

N, N_t, N_t_R and N_t_L all refer to the weighted sum, if sample_weight is passed.

Added in version 0.19.

Whether bootstrap samples are used when building trees. If False, the whole dataset is used to build each tree.

Whether to use out-of-bag samples to estimate the generalization score. By default, r2_score is used. Provide a callable with signature metric(y_true, y_pred) to use a custom metric. Only available if bootstrap=True.

For an illustration of out-of-bag (OOB) error estimation, see the example OOB Errors for Random Forests.

The number of jobs to run in parallel. fit, predict, decision_path and apply are all parallelized over the trees. None means 1 unless in a joblib.parallel_backend context. -1 means using all processors. See Glossary for more details.

Controls both the randomness of the bootstrapping of the samples used when building trees (if bootstrap=True) and the sampling of the features to consider when looking for the best split at each node (if max_features < n_features). See Glossary for details.

Controls the verbosity when fitting and predicting.

When set to True, reuse the solution of the previous call to fit and add more estimators to the ensemble, otherwise, just fit a whole new forest. See Glossary and Fitting additional trees for details.

Complexity parameter used for Minimal Cost-Complexity Pruning. The subtree with the largest cost complexity that is smaller than ccp_alpha will be chosen. By default, no pruning is performed. See Minimal Cost-Complexity Pruning for details. See Post pruning decision trees with cost complexity pruning for an example of such pruning.

Added in version 0.22.

If bootstrap is True, the number of samples to draw from X to train each base estimator.

If None (default), then draw X.shape[0] samples.

If int, then draw max_samples samples.

If float, then draw max(round(n_samples * max_samples), 1) samples. Thus, max_samples should be in the interval (0.0, 1.0].

Added in version 0.22.

1: monotonically increasing

-1: monotonically decreasing

If monotonic_cst is None, no constraints are applied.

multioutput regressions (i.e. when n_outputs_ > 1),

regressions trained on data with missing values.

Read more in the User Guide.

Added in version 1.4.

The child estimator template used to create the collection of fitted sub-estimators.

Added in version 1.2: base_estimator_ was renamed to estimator_.

The collection of fitted sub-estimators.

The impurity-based feature importances.

Number of features seen during fit.

Added in version 0.24.

Names of features seen during fit. Defined only when X has feature names that are all strings.

Added in version 1.0.

The number of outputs when fit is performed.

Score of the training dataset obtained using an out-of-bag estimate. This attribute exists only when oob_score is True.

Prediction computed with out-of-bag estimate on the training set. This attribute exists only when oob_score is True.

The subset of drawn samples for each base estimator.

A decision tree regressor.

Ensemble of extremely randomized tree regressors.

A Histogram-based Gradient Boosting Regression Tree, very fast for big datasets (n_samples >= 10_000).

The default values for the parameters controlling the size of the trees (e.g. max_depth, min_samples_leaf, etc.) lead to fully grown and unpruned trees which can potentially be very large on some data sets. To reduce memory consumption, the complexity and size of the trees should be controlled by setting those parameter values.

The features are always randomly permuted at each split. Therefore, the best found split may vary, even with the same training data, max_features=n_features and bootstrap=False, if the improvement of the criterion is identical for several splits enumerated during the search of the best split. To obtain a deterministic behaviour during fitting, random_state has to be fixed.

The default value max_features=1.0 uses n_features rather than n_features / 3. The latter was originally suggested in [1], whereas the former was more recently justified empirically in [2].

L. Breiman, “Random Forests”, Machine Learning, 45(1), 5-32, 2001.

P. Geurts, D. Ernst., and L. Wehenkel, “Extremely randomized trees”, Machine Learning, 63(1), 3-42, 2006.

Apply trees in the forest to X, return leaf indices.

The input samples. Internally, its dtype will be converted to dtype=np.float32. If a sparse matrix is provided, it will be converted into a sparse csr_matrix.

For each datapoint x in X and for each tree in the forest, return the index of the leaf x ends up in.

Return the decision path in the forest.

Added in version 0.18.

The input samples. Internally, its dtype will be converted to dtype=np.float32. If a sparse matrix is provided, it will be converted into a sparse csr_matrix.

Return a node indicator matrix where non zero elements indicates that the samples goes through the nodes. The matrix is of CSR format.

The columns from indicator[n_nodes_ptr[i]:n_nodes_ptr[i+1]] gives the indicator value for the i-th estimator.

Build a forest of trees from the training set (X, y).

The training input samples. Internally, its dtype will be converted to dtype=np.float32. If a sparse matrix is provided, it will be converted into a sparse csc_matrix.

The target values (class labels in classification, real numbers in regression).

Sample weights. If None, then samples are equally weighted. Splits that would create child nodes with net zero or negative weight are ignored while searching for a split in each node. In the case of classification, splits are also ignored if they would result in any single class carrying a negative weight in either child node.

Get metadata routing of this object.

Please check User Guide on how the routing mechanism works.

A MetadataRequest encapsulating routing information.

Get parameters for this estimator.

If True, will return the parameters for this estimator and contained subobjects that are estimators.

Parameter names mapped to their values.

Predict regression target for X.

The predicted regression target of an input sample is computed as the mean predicted regression targets of the trees in the forest.

The input samples. Internally, its dtype will be converted to dtype=np.float32. If a sparse matrix is provided, it will be converted into a sparse csr_matrix.

The predicted values.

Return coefficient of determination on test data.

The coefficient of determination, \(R^2\), is defined as \((1 - \frac{u}{v})\), where \(u\) is the residual sum of squares ((y_true - y_pred)** 2).sum() and \(v\) is the total sum of squares ((y_true - y_true.mean()) ** 2).sum(). The best possible score is 1.0 and it can be negative (because the model can be arbitrarily worse). A constant model that always predicts the expected value of y, disregarding the input features, would get a \(R^2\) score of 0.0.

Test samples. For some estimators this may be a precomputed kernel matrix or a list of generic objects instead with shape (n_samples, n_samples_fitted), where n_samples_fitted is the number of samples used in the fitting for the estimator.

\(R^2\) of self.predict(X) w.r.t. y.

The \(R^2\) score used when calling score on a regressor uses multioutput='uniform_average' from version 0.23 to keep consistent with default value of r2_score. This influences the score method of all the multioutput regressors (except for MultiOutputRegressor).

Configure whether metadata should be requested to be passed to the fit method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to fit if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to fit.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Added in version 1.3.

Metadata routing for sample_weight parameter in fit.

Set the parameters of this estimator.

The method works on simple estimators as well as on nested objects (such as Pipeline). The latter have parameters of the form <component>__<parameter> so that it’s possible to update each component of a nested object.

Estimator parameters.

Configure whether metadata should be requested to be passed to the score method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to score if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to score.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Added in version 1.3.

Metadata routing for sample_weight parameter in score.

Comparing Random Forests and Histogram Gradient Boosting models

Comparing random forests and the multi-output meta estimator

Combine predictors using stacking

Plot individual and voting regression predictions

Imputing missing values with variants of IterativeImputer

Imputing missing values before building an estimator

Release Highlights for scikit-learn 0.24

Release Highlights for scikit-learn 1.4

**Examples:**

Example 1 (yaml):
```yaml
N_t / N * (impurity - N_t_R / N_t * right_impurity
                    - N_t_L / N_t * left_impurity)
```

Example 2 (python):
```python
>>> from sklearn.ensemble import RandomForestRegressor
>>> from sklearn.datasets import make_regression
>>> X, y = make_regression(n_features=4, n_informative=2,
...                        random_state=0, shuffle=False)
>>> regr = RandomForestRegressor(max_depth=2, random_state=0)
>>> regr.fit(X, y)
RandomForestRegressor(...)
>>> print(regr.predict([[0, 0, 0, 0]]))
[-8.32987858]
```

---

## 

**URL:** https://scikit-learn.org/stable/_sources/modules/biclustering.rst.txt

---

## StackingRegressor#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.StackingRegressor.html

**Contents:**
- StackingRegressor#
- Gallery examples#

Stack of estimators with a final regressor.

Stacked generalization consists in stacking the output of individual estimator and use a regressor to compute the final prediction. Stacking allows to use the strength of each individual estimator by using their output as input of a final estimator.

Note that estimators_ are fitted on the full X while final_estimator_ is trained using cross-validated predictions of the base estimators using cross_val_predict.

Read more in the User Guide.

Added in version 0.22.

Base estimators which will be stacked together. Each element of the list is defined as a tuple of string (i.e. name) and an estimator instance. An estimator can be set to ‘drop’ using set_params.

A regressor which will be used to combine the base estimators. The default regressor is a RidgeCV.

Determines the cross-validation splitting strategy used in cross_val_predict to train final_estimator. Possible inputs for cv are:

None, to use the default 5-fold cross validation,

integer, to specify the number of folds in a (Stratified) KFold,

An object to be used as a cross-validation generator,

An iterable yielding train, test splits,

"prefit", to assume the estimators are prefit. In this case, the estimators will not be refitted.

For integer/None inputs, if the estimator is a classifier and y is either binary or multiclass, StratifiedKFold is used. In all other cases, KFold is used. These splitters are instantiated with shuffle=False so the splits will be the same across calls.

Refer User Guide for the various cross-validation strategies that can be used here.

If “prefit” is passed, it is assumed that all estimators have been fitted already. The final_estimator_ is trained on the estimators predictions on the full training set and are not cross validated predictions. Please note that if the models have been trained on the same data to train the stacking model, there is a very high risk of overfitting.

Added in version 1.1: The ‘prefit’ option was added in 1.1

A larger number of split will provide no benefits if the number of training samples is large enough. Indeed, the training time will increase. cv is not used for model evaluation but for prediction.

The number of jobs to run in parallel for fit of all estimators. None means 1 unless in a joblib.parallel_backend context. -1 means using all processors. See Glossary for more details.

When False, only the predictions of estimators will be used as training data for final_estimator. When True, the final_estimator is trained on the predictions as well as the original training data.

The elements of the estimators parameter, having been fitted on the training data. If an estimator has been set to 'drop', it will not appear in estimators_. When cv="prefit", estimators_ is set to estimators and is not fitted again.

Attribute to access any fitted sub-estimators by name.

Number of features seen during fit.

Names of features seen during fit. Only defined if the underlying estimators expose such an attribute when fit.

Added in version 1.0.

The regressor fit on the output of estimators_ and responsible for final predictions.

The method used by each base estimator.

Stack of estimators with a final classifier.

Wolpert, David H. “Stacked generalization.” Neural networks 5.2 (1992): 241-259.

Training vectors, where n_samples is the number of samples and n_features is the number of features.

Parameters to pass to the underlying estimators.

Added in version 1.6: Only available if enable_metadata_routing=True, which can be set by using sklearn.set_config(enable_metadata_routing=True). See Metadata Routing User Guide for more details.

Returns a fitted instance.

Fit the estimators and return the predictions for X for each estimator.

Training vectors, where n_samples is the number of samples and n_features is the number of features.

Parameters to pass to the underlying estimators.

Added in version 1.6: Only available if enable_metadata_routing=True, which can be set by using sklearn.set_config(enable_metadata_routing=True). See Metadata Routing User Guide for more details.

Prediction outputs for each estimator.

Get output feature names for transformation.

Input features. The input feature names are only used when passthrough is True.

If input_features is None, then feature_names_in_ is used as feature names in. If feature_names_in_ is not defined, then names are generated: [x0, x1, ..., x(n_features_in_ - 1)].

If input_features is an array-like, then input_features must match feature_names_in_ if feature_names_in_ is defined.

If passthrough is False, then only the names of estimators are used to generate the output feature names.

Transformed feature names.

Get metadata routing of this object.

Please check User Guide on how the routing mechanism works.

Added in version 1.6.

A MetadataRouter encapsulating routing information.

Get the parameters of an estimator from the ensemble.

Returns the parameters given in the constructor as well as the estimators contained within the estimators parameter.

Setting it to True gets the various estimators and the parameters of the estimators as well.

Parameter and estimator names mapped to their values or parameter names mapped to their values.

Dictionary to access any fitted sub-estimators by name.

Predict target for X.

Training vectors, where n_samples is the number of samples and n_features is the number of features.

Parameters to the predict called by the final_estimator. Note that this may be used to return uncertainties from some estimators with return_std or return_cov. Be aware that it will only account for uncertainty in the final estimator.

If enable_metadata_routing=False (default): Parameters directly passed to the predict method of the final_estimator.

If enable_metadata_routing=True: Parameters safely routed to the predict method of the final_estimator. See Metadata Routing User Guide for more details.

Changed in version 1.6: **predict_params can be routed via metadata routing API.

Return coefficient of determination on test data.

The coefficient of determination, \(R^2\), is defined as \((1 - \frac{u}{v})\), where \(u\) is the residual sum of squares ((y_true - y_pred)** 2).sum() and \(v\) is the total sum of squares ((y_true - y_true.mean()) ** 2).sum(). The best possible score is 1.0 and it can be negative (because the model can be arbitrarily worse). A constant model that always predicts the expected value of y, disregarding the input features, would get a \(R^2\) score of 0.0.

Test samples. For some estimators this may be a precomputed kernel matrix or a list of generic objects instead with shape (n_samples, n_samples_fitted), where n_samples_fitted is the number of samples used in the fitting for the estimator.

\(R^2\) of self.predict(X) w.r.t. y.

The \(R^2\) score used when calling score on a regressor uses multioutput='uniform_average' from version 0.23 to keep consistent with default value of r2_score. This influences the score method of all the multioutput regressors (except for MultiOutputRegressor).

Set output container.

See Introducing the set_output API for an example on how to use the API.

Configure output of transform and fit_transform.

"default": Default output format of a transformer

"pandas": DataFrame output

"polars": Polars output

None: Transform configuration is unchanged

Added in version 1.4: "polars" option was added.

Set the parameters of an estimator from the ensemble.

Valid parameter keys can be listed with get_params(). Note that you can directly set the parameters of the estimators contained in estimators.

Specific parameters using e.g. set_params(parameter_name=new_value). In addition, to setting the parameters of the estimator, the individual estimator of the estimators can also be set, or can be removed by setting them to ‘drop’.

Configure whether metadata should be requested to be passed to the score method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to score if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to score.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Added in version 1.3.

Metadata routing for sample_weight parameter in score.

Return the predictions for X for each estimator.

Training vectors, where n_samples is the number of samples and n_features is the number of features.

Prediction outputs for each estimator.

Combine predictors using stacking

**Examples:**

Example 1 (sql):
```sql
>>> from sklearn.datasets import load_diabetes
>>> from sklearn.linear_model import RidgeCV
>>> from sklearn.svm import LinearSVR
>>> from sklearn.ensemble import RandomForestRegressor
>>> from sklearn.ensemble import StackingRegressor
>>> X, y = load_diabetes(return_X_y=True)
>>> estimators = [
...     ('lr', RidgeCV()),
...     ('svr', LinearSVR(random_state=42))
... ]
>>> reg = StackingRegressor(
...     estimators=estimators,
...     final_estimator=RandomForestRegressor(n_estimators=10,
...                                           random_state=42)
... )
>>> from sklearn.model_selection import train_test_split
>>> X_train, X_test, y_train, y_test = train_test_split(
...     X, y, random_state=42
... )
>>> reg.fit(X_train, y_train).score(X_test, y_test)
0.3...
```

---

## LassoLarsIC#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LassoLarsIC.html

**Contents:**
- LassoLarsIC#
- Gallery examples#

Lasso model fit with Lars using BIC or AIC for model selection.

The optimization objective for Lasso is:

AIC is the Akaike information criterion [2] and BIC is the Bayes Information criterion [3]. Such criteria are useful to select the value of the regularization parameter by making a trade-off between the goodness of fit and the complexity of the model. A good model should explain well the data while being simple.

Read more in the User Guide.

The type of criterion to use.

Whether to calculate the intercept for this model. If set to false, no intercept will be used in calculations (i.e. data is expected to be centered).

Sets the verbosity amount.

Whether to use a precomputed Gram matrix to speed up calculations. If set to 'auto' let us decide. The Gram matrix can also be passed as argument.

Maximum number of iterations to perform. Can be used for early stopping.

The machine-precision regularization in the computation of the Cholesky diagonal factors. Increase this for very ill-conditioned systems. Unlike the tol parameter in some iterative optimization-based algorithms, this parameter does not control the tolerance of the optimization.

If True, X will be copied; else, it may be overwritten.

Restrict coefficients to be >= 0. Be aware that you might want to remove fit_intercept which is set True by default. Under the positive restriction the model coefficients do not converge to the ordinary-least-squares solution for small values of alpha. Only coefficients up to the smallest alpha value (alphas_[alphas_ > 0.].min() when fit_path=True) reached by the stepwise Lars-Lasso algorithm are typically in congruence with the solution of the coordinate descent Lasso estimator. As a consequence using LassoLarsIC only makes sense for problems where a sparse solution is expected and/or reached.

The estimated noise variance of the data. If None, an unbiased estimate is computed by an OLS model. However, it is only possible in the case where n_samples > n_features + fit_intercept.

Added in version 1.1.

parameter vector (w in the formulation formula)

independent term in decision function.

the alpha parameter chosen by the information criterion

Maximum of covariances (in absolute value) at each iteration. n_alphas is either max_iter, n_features or the number of nodes in the path with alpha >= alpha_min, whichever is smaller. If a list, it will be of length n_targets.

number of iterations run by lars_path to find the grid of alphas.

The value of the information criteria (‘aic’, ‘bic’) across all alphas. The alpha which has the smallest information criterion is chosen, as specified in [1].

The estimated noise variance from the data used to compute the criterion.

Added in version 1.1.

Number of features seen during fit.

Added in version 0.24.

Names of features seen during fit. Defined only when X has feature names that are all strings.

Added in version 1.0.

Compute Least Angle Regression or Lasso path using LARS algorithm.

Compute Lasso path with coordinate descent.

Linear Model trained with L1 prior as regularizer (aka the Lasso).

Lasso linear model with iterative fitting along a regularization path.

Lasso model fit with Least Angle Regression a.k.a. Lars.

Cross-validated Lasso, using the LARS algorithm.

The number of degrees of freedom is computed as in [1].

To have more details regarding the mathematical formulation of the AIC and BIC criteria, please refer to User Guide.

Zou, Hui, Trevor Hastie, and Robert Tibshirani. “On the degrees of freedom of the lasso.” The Annals of Statistics 35.5 (2007): 2173-2192.

Wikipedia entry on the Akaike information criterion

Wikipedia entry on the Bayesian information criterion

For a detailed example of using this class, see Lasso model selection via information criteria.

Fit the model using X, y as training data.

Target values. Will be cast to X’s dtype if necessary.

If provided, this parameter will override the choice of copy_X made at instance creation. If True, X will be copied; else, it may be overwritten.

Returns an instance of self.

Get metadata routing of this object.

Please check User Guide on how the routing mechanism works.

A MetadataRequest encapsulating routing information.

Get parameters for this estimator.

If True, will return the parameters for this estimator and contained subobjects that are estimators.

Parameter names mapped to their values.

Predict using the linear model.

Returns predicted values.

Return coefficient of determination on test data.

The coefficient of determination, \(R^2\), is defined as \((1 - \frac{u}{v})\), where \(u\) is the residual sum of squares ((y_true - y_pred)** 2).sum() and \(v\) is the total sum of squares ((y_true - y_true.mean()) ** 2).sum(). The best possible score is 1.0 and it can be negative (because the model can be arbitrarily worse). A constant model that always predicts the expected value of y, disregarding the input features, would get a \(R^2\) score of 0.0.

Test samples. For some estimators this may be a precomputed kernel matrix or a list of generic objects instead with shape (n_samples, n_samples_fitted), where n_samples_fitted is the number of samples used in the fitting for the estimator.

\(R^2\) of self.predict(X) w.r.t. y.

The \(R^2\) score used when calling score on a regressor uses multioutput='uniform_average' from version 0.23 to keep consistent with default value of r2_score. This influences the score method of all the multioutput regressors (except for MultiOutputRegressor).

Configure whether metadata should be requested to be passed to the fit method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to fit if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to fit.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Added in version 1.3.

Metadata routing for copy_X parameter in fit.

Set the parameters of this estimator.

The method works on simple estimators as well as on nested objects (such as Pipeline). The latter have parameters of the form <component>__<parameter> so that it’s possible to update each component of a nested object.

Estimator parameters.

Configure whether metadata should be requested to be passed to the score method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to score if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to score.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Added in version 1.3.

Metadata routing for sample_weight parameter in score.

Lasso model selection via information criteria

Lasso model selection: AIC-BIC / cross-validation

**Examples:**

Example 1 (unknown):
```unknown
(1 / (2 * n_samples)) * ||y - Xw||^2_2 + alpha * ||w||_1
```

Example 2 (python):
```python
>>> from sklearn import linear_model
>>> reg = linear_model.LassoLarsIC(criterion='bic')
>>> X = [[-2, 2], [-1, 1], [0, 0], [1, 1], [2, 2]]
>>> y = [-2.2222, -1.1111, 0, -1.1111, -2.2222]
>>> reg.fit(X, y)
LassoLarsIC(criterion='bic')
>>> print(reg.coef_)
[ 0.  -1.11]
```

---

## MiniBatchSparsePCA#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.MiniBatchSparsePCA.html

**Contents:**
- MiniBatchSparsePCA#
- Gallery examples#

Mini-batch Sparse Principal Components Analysis.

Finds the set of sparse components that can optimally reconstruct the data. The amount of sparseness is controllable by the coefficient of the L1 penalty, given by the parameter alpha.

For an example comparing sparse PCA to PCA, see Faces dataset decompositions

Read more in the User Guide.

Number of sparse atoms to extract. If None, then n_components is set to n_features.

Sparsity controlling parameter. Higher values lead to sparser components.

Amount of ridge shrinkage to apply in order to improve conditioning when calling the transform method.

Maximum number of iterations over the complete dataset before stopping independently of any early stopping criterion heuristics.

Added in version 1.2.

Callable that gets invoked every five iterations.

The number of features to take in each mini batch.

Controls the verbosity; the higher, the more messages. Defaults to 0.

Whether to shuffle the data before splitting it in batches.

Number of parallel jobs to run. None means 1 unless in a joblib.parallel_backend context. -1 means using all processors. See Glossary for more details.

Method to be used for optimization. lars: uses the least angle regression method to solve the lasso problem (linear_model.lars_path) cd: uses the coordinate descent method to compute the Lasso solution (linear_model.Lasso). Lars will be faster if the estimated components are sparse.

Used for random shuffling when shuffle is set to True, during online dictionary learning. Pass an int for reproducible results across multiple function calls. See Glossary.

Control early stopping based on the norm of the differences in the dictionary between 2 steps.

To disable early stopping based on changes in the dictionary, set tol to 0.0.

Added in version 1.1.

Control early stopping based on the consecutive number of mini batches that does not yield an improvement on the smoothed cost function.

To disable convergence detection based on cost function, set max_no_improvement to None.

Added in version 1.1.

Sparse components extracted from the data.

Estimated number of components.

Added in version 0.23.

Number of iterations run.

Per-feature empirical mean, estimated from the training set. Equal to X.mean(axis=0).

Number of features seen during fit.

Added in version 0.24.

Names of features seen during fit. Defined only when X has feature names that are all strings.

Added in version 1.0.

Find a dictionary that sparsely encodes data.

Incremental principal components analysis.

Principal component analysis.

Sparse Principal Components Analysis.

Dimensionality reduction using truncated SVD.

Fit the model from data in X.

Training vector, where n_samples is the number of samples and n_features is the number of features.

Not used, present here for API consistency by convention.

Returns the instance itself.

Fit to data, then transform it.

Fits transformer to X and y with optional parameters fit_params and returns a transformed version of X.

Target values (None for unsupervised transformations).

Additional fit parameters. Pass only if the estimator accepts additional params in its fit method.

Get output feature names for transformation.

The feature names out will prefixed by the lowercased class name. For example, if the transformer outputs 3 features, then the feature names out are: ["class_name0", "class_name1", "class_name2"].

Only used to validate feature names with the names seen in fit.

Transformed feature names.

Get metadata routing of this object.

Please check User Guide on how the routing mechanism works.

A MetadataRequest encapsulating routing information.

Get parameters for this estimator.

If True, will return the parameters for this estimator and contained subobjects that are estimators.

Parameter names mapped to their values.

Transform data from the latent space to the original space.

This inversion is an approximation due to the loss of information induced by the forward decomposition.

Added in version 1.2.

Data in the latent space.

Reconstructed data in the original space.

Set output container.

See Introducing the set_output API for an example on how to use the API.

Configure output of transform and fit_transform.

"default": Default output format of a transformer

"pandas": DataFrame output

"polars": Polars output

None: Transform configuration is unchanged

Added in version 1.4: "polars" option was added.

Set the parameters of this estimator.

The method works on simple estimators as well as on nested objects (such as Pipeline). The latter have parameters of the form <component>__<parameter> so that it’s possible to update each component of a nested object.

Estimator parameters.

Least Squares projection of the data onto the sparse components.

To avoid instability issues in case the system is under-determined, regularization can be applied (Ridge regression) via the ridge_alpha parameter.

Note that Sparse PCA components orthogonality is not enforced as in PCA hence one cannot use a simple linear projection.

Test data to be transformed, must have the same number of features as the data used to train the model.

Faces dataset decompositions

**Examples:**

Example 1 (csharp):
```csharp
>>> import numpy as np
>>> from sklearn.datasets import make_friedman1
>>> from sklearn.decomposition import MiniBatchSparsePCA
>>> X, _ = make_friedman1(n_samples=200, n_features=30, random_state=0)
>>> transformer = MiniBatchSparsePCA(n_components=5, batch_size=50,
...                                  max_iter=10, random_state=0)
>>> transformer.fit(X)
MiniBatchSparsePCA(...)
>>> X_transformed = transformer.transform(X)
>>> X_transformed.shape
(200, 5)
>>> # most values in the components_ are zero (sparsity)
>>> np.mean(transformer.components_ == 0)
np.float64(0.9)
```

---

## calinski_harabasz_score#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.metrics.calinski_harabasz_score.html

**Contents:**
- calinski_harabasz_score#

Compute the Calinski and Harabasz score.

It is also known as the Variance Ratio Criterion.

The score is defined as ratio of the sum of between-cluster dispersion and of within-cluster dispersion.

Read more in the User Guide.

A list of n_features-dimensional data points. Each row corresponds to a single data point.

Predicted labels for each sample.

The resulting Calinski-Harabasz score.

T. Calinski and J. Harabasz, 1974. “A dendrite method for cluster analysis”. Communications in Statistics

**Examples:**

Example 1 (sql):
```sql
>>> from sklearn.datasets import make_blobs
>>> from sklearn.cluster import KMeans
>>> from sklearn.metrics import calinski_harabasz_score
>>> X, _ = make_blobs(random_state=0)
>>> kmeans = KMeans(n_clusters=3, random_state=0,).fit(X)
>>> calinski_harabasz_score(X, kmeans.labels_)
114.8...
```

---

## CategoricalNB#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.CategoricalNB.html

**Contents:**
- CategoricalNB#

Naive Bayes classifier for categorical features.

The categorical Naive Bayes classifier is suitable for classification with discrete features that are categorically distributed. The categories of each feature are drawn from a categorical distribution.

Read more in the User Guide.

Additive (Laplace/Lidstone) smoothing parameter (set alpha=0 and force_alpha=True, for no smoothing).

If False and alpha is less than 1e-10, it will set alpha to 1e-10. If True, alpha will remain unchanged. This may cause numerical errors if alpha is too close to 0.

Added in version 1.2.

Changed in version 1.4: The default value of force_alpha changed to True.

Whether to learn class prior probabilities or not. If false, a uniform prior will be used.

Prior probabilities of the classes. If specified, the priors are not adjusted according to the data.

Minimum number of categories per feature.

integer: Sets the minimum number of categories per feature to n_categories for each features.

array-like: shape (n_features,) where n_categories[i] holds the minimum number of categories for the ith column of the input.

None (default): Determines the number of categories automatically from the training data.

Added in version 0.24.

Holds arrays of shape (n_classes, n_categories of respective feature) for each feature. Each array provides the number of samples encountered for each class and category of the specific feature.

Number of samples encountered for each class during fitting. This value is weighted by the sample weight when provided.

Smoothed empirical log probability for each class.

Class labels known to the classifier

Holds arrays of shape (n_classes, n_categories of respective feature) for each feature. Each array provides the empirical log probability of categories given the respective feature and class, P(x_i|y).

Number of features seen during fit.

Added in version 0.24.

Names of features seen during fit. Defined only when X has feature names that are all strings.

Added in version 1.0.

Number of categories for each feature. This value is inferred from the data or set by the minimum number of categories.

Added in version 0.24.

Naive Bayes classifier for multivariate Bernoulli models.

Complement Naive Bayes classifier.

Gaussian Naive Bayes.

Naive Bayes classifier for multinomial models.

Fit Naive Bayes classifier according to X, y.

Training vectors, where n_samples is the number of samples and n_features is the number of features. Here, each feature of X is assumed to be from a different categorical distribution. It is further assumed that all categories of each feature are represented by the numbers 0, …, n - 1, where n refers to the total number of categories for the given feature. This can, for instance, be achieved with the help of OrdinalEncoder.

Weights applied to individual samples (1. for unweighted).

Returns the instance itself.

Get metadata routing of this object.

Please check User Guide on how the routing mechanism works.

A MetadataRequest encapsulating routing information.

Get parameters for this estimator.

If True, will return the parameters for this estimator and contained subobjects that are estimators.

Parameter names mapped to their values.

Incremental fit on a batch of samples.

This method is expected to be called several times consecutively on different chunks of a dataset so as to implement out-of-core or online learning.

This is especially useful when the whole dataset is too big to fit in memory at once.

This method has some performance overhead hence it is better to call partial_fit on chunks of data that are as large as possible (as long as fitting in the memory budget) to hide the overhead.

Training vectors, where n_samples is the number of samples and n_features is the number of features. Here, each feature of X is assumed to be from a different categorical distribution. It is further assumed that all categories of each feature are represented by the numbers 0, …, n - 1, where n refers to the total number of categories for the given feature. This can, for instance, be achieved with the help of OrdinalEncoder.

List of all the classes that can possibly appear in the y vector.

Must be provided at the first call to partial_fit, can be omitted in subsequent calls.

Weights applied to individual samples (1. for unweighted).

Returns the instance itself.

Perform classification on an array of test vectors X.

Predicted target values for X.

Return joint log probability estimates for the test vector X.

For each row x of X and class y, the joint log probability is given by log P(x, y) = log P(y) + log P(x|y), where log P(y) is the class prior probability and log P(x|y) is the class-conditional probability.

Returns the joint log-probability of the samples for each class in the model. The columns correspond to the classes in sorted order, as they appear in the attribute classes_.

Return log-probability estimates for the test vector X.

Returns the log-probability of the samples for each class in the model. The columns correspond to the classes in sorted order, as they appear in the attribute classes_.

Return probability estimates for the test vector X.

Returns the probability of the samples for each class in the model. The columns correspond to the classes in sorted order, as they appear in the attribute classes_.

Return accuracy on provided data and labels.

In multi-label classification, this is the subset accuracy which is a harsh metric since you require for each sample that each label set be correctly predicted.

Mean accuracy of self.predict(X) w.r.t. y.

Configure whether metadata should be requested to be passed to the fit method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to fit if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to fit.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Added in version 1.3.

Metadata routing for sample_weight parameter in fit.

Set the parameters of this estimator.

The method works on simple estimators as well as on nested objects (such as Pipeline). The latter have parameters of the form <component>__<parameter> so that it’s possible to update each component of a nested object.

Estimator parameters.

Configure whether metadata should be requested to be passed to the partial_fit method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to partial_fit if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to partial_fit.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Added in version 1.3.

Metadata routing for classes parameter in partial_fit.

Metadata routing for sample_weight parameter in partial_fit.

Configure whether metadata should be requested to be passed to the score method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to score if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to score.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Added in version 1.3.

Metadata routing for sample_weight parameter in score.

**Examples:**

Example 1 (json):
```json
>>> import numpy as np
>>> rng = np.random.RandomState(1)
>>> X = rng.randint(5, size=(6, 100))
>>> y = np.array([1, 2, 3, 4, 5, 6])
>>> from sklearn.naive_bayes import CategoricalNB
>>> clf = CategoricalNB()
>>> clf.fit(X, y)
CategoricalNB()
>>> print(clf.predict(X[2:3]))
[3]
```

---

## MultiTaskLasso#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.MultiTaskLasso.html

**Contents:**
- MultiTaskLasso#
- Gallery examples#

Multi-task Lasso model trained with L1/L2 mixed-norm as regularizer.

The optimization objective for Lasso is:

i.e. the sum of norm of each row.

Read more in the User Guide.

Constant that multiplies the L1/L2 term. Defaults to 1.0.

Whether to calculate the intercept for this model. If set to false, no intercept will be used in calculations (i.e. data is expected to be centered).

If True, X will be copied; else, it may be overwritten.

The maximum number of iterations.

The tolerance for the optimization: if the updates are smaller or equal to tol, the optimization code checks the dual gap for optimality and continues until it is smaller or equal to tol.

When set to True, reuse the solution of the previous call to fit as initialization, otherwise, just erase the previous solution. See the Glossary.

The seed of the pseudo random number generator that selects a random feature to update. Used when selection == ‘random’. Pass an int for reproducible output across multiple function calls. See Glossary.

If set to ‘random’, a random coefficient is updated every iteration rather than looping over features sequentially by default. This (setting to ‘random’) often leads to significantly faster convergence especially when tol is higher than 1e-4.

Parameter vector (W in the cost function formula). Note that coef_ stores the transpose of W, W.T.

Independent term in decision function.

Number of iterations run by the coordinate descent solver to reach the specified tolerance.

The dual gaps at the end of the optimization for each alpha.

The tolerance scaled scaled by the variance of the target y.

Sparse representation of the fitted coef_.

Number of features seen during fit.

Added in version 0.24.

Names of features seen during fit. Defined only when X has feature names that are all strings.

Added in version 1.0.

Linear Model trained with L1 prior as regularizer (aka the Lasso).

Multi-task L1 regularized linear model with built-in cross-validation.

Multi-task L1/L2 ElasticNet with built-in cross-validation.

The algorithm used to fit the model is coordinate descent.

To avoid unnecessary memory duplication the X and y arguments of the fit method should be directly passed as Fortran-contiguous numpy arrays.

Fit MultiTaskElasticNet model with coordinate descent.

Target. Will be cast to X’s dtype if necessary.

Coordinate descent is an algorithm that considers each column of data at a time hence it will automatically convert the X input as a Fortran-contiguous numpy array if necessary.

To avoid memory re-allocation it is advised to allocate the initial data in memory directly using that format.

Get metadata routing of this object.

Please check User Guide on how the routing mechanism works.

A MetadataRequest encapsulating routing information.

Get parameters for this estimator.

If True, will return the parameters for this estimator and contained subobjects that are estimators.

Parameter names mapped to their values.

Compute elastic net path with coordinate descent.

The elastic net optimization function varies for mono and multi-outputs.

For mono-output tasks it is:

For multi-output tasks it is:

i.e. the sum of norm of each row.

Read more in the User Guide.

Training data. Pass directly as Fortran-contiguous data to avoid unnecessary memory duplication. If y is mono-output then X can be sparse.

Number between 0 and 1 passed to elastic net (scaling between l1 and l2 penalties). l1_ratio=1 corresponds to the Lasso.

Length of the path. eps=1e-3 means that alpha_min / alpha_max = 1e-3.

Number of alphas along the regularization path.

List of alphas where to compute the models. If None alphas are set automatically.

Whether to use a precomputed Gram matrix to speed up calculations. If set to 'auto' let us decide. The Gram matrix can also be passed as argument.

Xy = np.dot(X.T, y) that can be precomputed. It is useful only when the Gram matrix is precomputed.

If True, X will be copied; else, it may be overwritten.

The initial values of the coefficients.

Whether to return the number of iterations or not.

If set to True, forces coefficients to be positive. (Only allowed when y.ndim == 1).

If set to False, the input validation checks are skipped (including the Gram matrix when provided). It is assumed that they are handled by the caller.

Keyword arguments passed to the coordinate descent solver.

The alphas along the path where models are computed.

Coefficients along the path.

The dual gaps at the end of the optimization for each alpha.

The number of iterations taken by the coordinate descent optimizer to reach the specified tolerance for each alpha. (Is returned when return_n_iter is set to True).

Multi-task ElasticNet model trained with L1/L2 mixed-norm as regularizer.

Multi-task L1/L2 ElasticNet with built-in cross-validation.

Linear regression with combined L1 and L2 priors as regularizer.

Elastic Net model with iterative fitting along a regularization path.

For an example, see examples/linear_model/plot_lasso_lasso_lars_elasticnet_path.py.

The underlying coordinate descent solver uses gap safe screening rules to speedup fitting time, see User Guide on coordinate descent.

Predict using the linear model.

Returns predicted values.

Return coefficient of determination on test data.

The coefficient of determination, \(R^2\), is defined as \((1 - \frac{u}{v})\), where \(u\) is the residual sum of squares ((y_true - y_pred)** 2).sum() and \(v\) is the total sum of squares ((y_true - y_true.mean()) ** 2).sum(). The best possible score is 1.0 and it can be negative (because the model can be arbitrarily worse). A constant model that always predicts the expected value of y, disregarding the input features, would get a \(R^2\) score of 0.0.

Test samples. For some estimators this may be a precomputed kernel matrix or a list of generic objects instead with shape (n_samples, n_samples_fitted), where n_samples_fitted is the number of samples used in the fitting for the estimator.

\(R^2\) of self.predict(X) w.r.t. y.

The \(R^2\) score used when calling score on a regressor uses multioutput='uniform_average' from version 0.23 to keep consistent with default value of r2_score. This influences the score method of all the multioutput regressors (except for MultiOutputRegressor).

Configure whether metadata should be requested to be passed to the fit method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to fit if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to fit.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Added in version 1.3.

Metadata routing for sample_weight parameter in fit.

Set the parameters of this estimator.

The method works on simple estimators as well as on nested objects (such as Pipeline). The latter have parameters of the form <component>__<parameter> so that it’s possible to update each component of a nested object.

Estimator parameters.

Configure whether metadata should be requested to be passed to the score method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to score if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to score.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Added in version 1.3.

Metadata routing for sample_weight parameter in score.

Joint feature selection with multi-task Lasso

**Examples:**

Example 1 (unknown):
```unknown
(1 / (2 * n_samples)) * ||Y - XW||^2_Fro + alpha * ||W||_21
```

Example 2 (unknown):
```unknown
||W||_21 = \sum_i \sqrt{\sum_j w_{ij}^2}
```

Example 3 (python):
```python
>>> from sklearn import linear_model
>>> clf = linear_model.MultiTaskLasso(alpha=0.1)
>>> clf.fit([[0, 1], [1, 2], [2, 4]], [[0, 0], [1, 1], [2, 3]])
MultiTaskLasso(alpha=0.1)
>>> print(clf.coef_)
[[0.         0.60809415]
[0.         0.94592424]]
>>> print(clf.intercept_)
[-0.41888636 -0.87382323]
```

Example 4 (unknown):
```unknown
1 / (2 * n_samples) * ||y - Xw||^2_2
+ alpha * l1_ratio * ||w||_1
+ 0.5 * alpha * (1 - l1_ratio) * ||w||^2_2
```

---

## GridSearchCV#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html

**Contents:**
- GridSearchCV#
- Gallery examples#

Exhaustive search over specified parameter values for an estimator.

Important members are fit, predict.

GridSearchCV implements a “fit” and a “score” method. It also implements “score_samples”, “predict”, “predict_proba”, “decision_function”, “transform” and “inverse_transform” if they are implemented in the estimator used.

The parameters of the estimator used to apply these methods are optimized by cross-validated grid-search over a parameter grid.

Read more in the User Guide.

This is assumed to implement the scikit-learn estimator interface. Either estimator needs to provide a score function, or scoring must be passed.

Dictionary with parameters names (str) as keys and lists of parameter settings to try as values, or a list of such dictionaries, in which case the grids spanned by each dictionary in the list are explored. This enables searching over any sequence of parameter settings.

Strategy to evaluate the performance of the cross-validated model on the test set.

If scoring represents a single score, one can use:

a single string (see String name scorers);

a callable (see Callable scorers) that returns a single value;

None, the estimator’s default evaluation criterion is used.

If scoring represents multiple scores, one can use:

a list or tuple of unique strings;

a callable returning a dictionary where the keys are the metric names and the values are the metric scores;

a dictionary with metric names as keys and callables as values.

See Specifying multiple metrics for evaluation for an example.

Number of jobs to run in parallel. None means 1 unless in a joblib.parallel_backend context. -1 means using all processors. See Glossary for more details.

Changed in version v0.20: n_jobs default changed from 1 to None

Refit an estimator using the best found parameters on the whole dataset.

For multiple metric evaluation, this needs to be a str denoting the scorer that would be used to find the best parameters for refitting the estimator at the end.

Where there are considerations other than maximum score in choosing a best estimator, refit can be set to a function which returns the selected best_index_ given cv_results_. In that case, the best_estimator_ and best_params_ will be set according to the returned best_index_ while the best_score_ attribute will not be available.

The refitted estimator is made available at the best_estimator_ attribute and permits using predict directly on this GridSearchCV instance.

Also for multiple metric evaluation, the attributes best_index_, best_score_ and best_params_ will only be available if refit is set and all of them will be determined w.r.t this specific scorer.

See scoring parameter to know more about multiple metric evaluation.

See Custom refit strategy of a grid search with cross-validation to see how to design a custom selection strategy using a callable via refit.

See this example for an example of how to use refit=callable to balance model complexity and cross-validated score.

Changed in version 0.20: Support for callable added.

Determines the cross-validation splitting strategy. Possible inputs for cv are:

None, to use the default 5-fold cross validation,

integer, to specify the number of folds in a (Stratified)KFold,

An iterable yielding (train, test) splits as arrays of indices.

For integer/None inputs, if the estimator is a classifier and y is either binary or multiclass, StratifiedKFold is used. In all other cases, KFold is used. These splitters are instantiated with shuffle=False so the splits will be the same across calls.

Refer User Guide for the various cross-validation strategies that can be used here.

Changed in version 0.22: cv default value if None changed from 3-fold to 5-fold.

Controls the verbosity: the higher, the more messages.

>1 : the computation time for each fold and parameter candidate is displayed;

>2 : the score is also displayed;

>3 : the fold and candidate parameter indexes are also displayed together with the starting time of the computation.

Controls the number of jobs that get dispatched during parallel execution. Reducing this number can be useful to avoid an explosion of memory consumption when more jobs get dispatched than CPUs can process. This parameter can be:

None, in which case all the jobs are immediately created and spawned. Use this for lightweight and fast-running jobs, to avoid delays due to on-demand spawning of the jobs

An int, giving the exact number of total jobs that are spawned

A str, giving an expression as a function of n_jobs, as in ‘2*n_jobs’

Value to assign to the score if an error occurs in estimator fitting. If set to ‘raise’, the error is raised. If a numeric value is given, FitFailedWarning is raised. This parameter does not affect the refit step, which will always raise the error.

If False, the cv_results_ attribute will not include training scores. Computing training scores is used to get insights on how different parameter settings impact the overfitting/underfitting trade-off. However computing the scores on the training set can be computationally expensive and is not strictly required to select the parameters that yield the best generalization performance.

Added in version 0.19.

Changed in version 0.21: Default value was changed from True to False

A dict with keys as column headers and values as columns, that can be imported into a pandas DataFrame.

For instance the below given table

will be represented by a cv_results_ dict of:

For an example of visualization and interpretation of GridSearch results, see Statistical comparison of models using grid search.

The key 'params' is used to store a list of parameter settings dicts for all the parameter candidates.

The mean_fit_time, std_fit_time, mean_score_time and std_score_time are all in seconds.

For multi-metric evaluation, the scores for all the scorers are available in the cv_results_ dict at the keys ending with that scorer’s name ('_<scorer_name>') instead of '_score' shown above. (‘split0_test_precision’, ‘mean_train_precision’ etc.)

Estimator that was chosen by the search, i.e. estimator which gave highest score (or smallest loss if specified) on the left out data. Not available if refit=False.

See refit parameter for more information on allowed values.

Mean cross-validated score of the best_estimator

For multi-metric evaluation, this is present only if refit is specified.

This attribute is not available if refit is a function.

Parameter setting that gave the best results on the hold out data.

For multi-metric evaluation, this is present only if refit is specified.

The index (of the cv_results_ arrays) which corresponds to the best candidate parameter setting.

The dict at search.cv_results_['params'][search.best_index_] gives the parameter setting for the best model, that gives the highest mean score (search.best_score_).

For multi-metric evaluation, this is present only if refit is specified.

Scorer function used on the held out data to choose the best parameters for the model.

For multi-metric evaluation, this attribute holds the validated scoring dict which maps the scorer key to the scorer callable.

The number of cross-validation splits (folds/iterations).

Seconds used for refitting the best model on the whole dataset.

This is present only if refit is not False.

Added in version 0.20.

Whether or not the scorers compute several metrics.

Number of features seen during fit.

Names of features seen during fit. Only defined if best_estimator_ is defined (see the documentation for the refit parameter for more details) and that best_estimator_ exposes feature_names_in_ when fit.

Added in version 1.0.

Generates all the combinations of a hyperparameter grid.

Utility function to split the data into a development set usable for fitting a GridSearchCV instance and an evaluation set for its final evaluation.

Make a scorer from a performance metric or loss function.

The parameters selected are those that maximize the score of the left out data, unless an explicit score is passed in which case it is used instead.

If n_jobs was set to a value higher than one, the data is copied for each point in the grid (and not n_jobs times). This is done for efficiency reasons if individual jobs take very little time, but may raise errors if the dataset is large and not enough memory is available. A workaround in this case is to set pre_dispatch. Then, the memory is copied only pre_dispatch many times. A reasonable value for pre_dispatch is 2 * n_jobs.

Call decision_function on the estimator with the best found parameters.

Only available if refit=True and the underlying estimator supports decision_function.

Must fulfill the input assumptions of the underlying estimator.

Result of the decision function for X based on the estimator with the best found parameters.

Run fit with all sets of parameters.

Training vectors, where n_samples is the number of samples and n_features is the number of features. For precomputed kernel or distance matrix, the expected shape of X is (n_samples, n_samples).

Target relative to X for classification or regression; None for unsupervised learning.

Parameters passed to the fit method of the estimator, the scorer, and the CV splitter.

If a fit parameter is an array-like whose length is equal to num_samples then it will be split by cross-validation along with X and y. For example, the sample_weight parameter is split because len(sample_weights) = len(X). However, this behavior does not apply to groups which is passed to the splitter configured via the cv parameter of the constructor. Thus, groups is used to perform the split and determines which samples are assigned to the each side of the a split.

Instance of fitted estimator.

Get metadata routing of this object.

Please check User Guide on how the routing mechanism works.

Added in version 1.4.

A MetadataRouter encapsulating routing information.

Get parameters for this estimator.

If True, will return the parameters for this estimator and contained subobjects that are estimators.

Parameter names mapped to their values.

Call inverse_transform on the estimator with the best found params.

Only available if the underlying estimator implements inverse_transform and refit=True.

Must fulfill the input assumptions of the underlying estimator.

Result of the inverse_transform function for X based on the estimator with the best found parameters.

Call predict on the estimator with the best found parameters.

Only available if refit=True and the underlying estimator supports predict.

Must fulfill the input assumptions of the underlying estimator.

The predicted labels or values for X based on the estimator with the best found parameters.

Call predict_log_proba on the estimator with the best found parameters.

Only available if refit=True and the underlying estimator supports predict_log_proba.

Must fulfill the input assumptions of the underlying estimator.

Predicted class log-probabilities for X based on the estimator with the best found parameters. The order of the classes corresponds to that in the fitted attribute classes_.

Call predict_proba on the estimator with the best found parameters.

Only available if refit=True and the underlying estimator supports predict_proba.

Must fulfill the input assumptions of the underlying estimator.

Predicted class probabilities for X based on the estimator with the best found parameters. The order of the classes corresponds to that in the fitted attribute classes_.

Return the score on the given data, if the estimator has been refit.

This uses the score defined by scoring where provided, and the best_estimator_.score method otherwise.

Input data, where n_samples is the number of samples and n_features is the number of features.

Target relative to X for classification or regression; None for unsupervised learning.

Parameters to be passed to the underlying scorer(s).

Added in version 1.4: Only available if enable_metadata_routing=True. See Metadata Routing User Guide for more details.

The score defined by scoring if provided, and the best_estimator_.score method otherwise.

Call score_samples on the estimator with the best found parameters.

Only available if refit=True and the underlying estimator supports score_samples.

Added in version 0.24.

Data to predict on. Must fulfill input requirements of the underlying estimator.

The best_estimator_.score_samples method.

Set the parameters of this estimator.

The method works on simple estimators as well as on nested objects (such as Pipeline). The latter have parameters of the form <component>__<parameter> so that it’s possible to update each component of a nested object.

Estimator parameters.

Call transform on the estimator with the best found parameters.

Only available if the underlying estimator supports transform and refit=True.

Must fulfill the input assumptions of the underlying estimator.

X transformed in the new space based on the estimator with the best found parameters.

Feature agglomeration vs. univariate selection

Column Transformer with Mixed Types

Selecting dimensionality reduction with Pipeline and GridSearchCV

Pipelining: chaining a PCA and a logistic regression

Concatenating multiple feature extraction methods

Shrinkage covariance estimation: LedoitWolf vs OAS and max-likelihood

Model selection with Probabilistic PCA and Factor Analysis (FA)

Comparing Random Forests and Histogram Gradient Boosting models

Comparison of kernel ridge regression and SVR

Gaussian Mixture Model Selection

Post-tuning the decision threshold for cost-sensitive learning

Custom refit strategy of a grid search with cross-validation

Balance model complexity and cross-validated score

Statistical comparison of models using grid search

Sample pipeline for text feature extraction and evaluation

Demonstration of multi-metric evaluation on cross_val_score and GridSearchCV

Nested versus non-nested cross-validation

Comparing randomized search and grid search for hyperparameter estimation

Comparison between grid search and successive halving

Overview of multiclass training meta-estimators

Caching nearest neighbors

Kernel Density Estimation

Feature discretization

Release Highlights for scikit-learn 0.24

Release Highlights for scikit-learn 1.4

Plot classification boundaries with different SVM Kernels

**Examples:**

Example 1 (json):
```json
{
'param_kernel': masked_array(data = ['poly', 'poly', 'rbf', 'rbf'],
                             mask = [False False False False]...)
'param_gamma': masked_array(data = [-- -- 0.1 0.2],
                            mask = [ True  True False False]...),
'param_degree': masked_array(data = [2.0 3.0 -- --],
                             mask = [False False  True  True]...),
'split0_test_score'  : [0.80, 0.70, 0.80, 0.93],
'split1_test_score'  : [0.82, 0.50, 0.70, 0.78],
'mean_test_score'    : [0.81, 0.60, 0.75, 0.85],
'std_test_score'     : [0.01, 0.10, 0.05, 0.08],
'rank_test_score'    : [2, 4, 3, 1],
'split0_train_score' : [0.80, 0.92, 0.70, 0.93],
'split1_train_score' : [0.82, 0.55, 0.70, 0.87],
'mean_train_score'   : [0.81, 0.74, 0.70, 0.90],
'std_train_score'    : [0.01, 0.19, 0.00, 0.03],
'mean_fit_time'      : [0.73, 0.63, 0.43, 0.49],
'std_fit_time'       : [0.01, 0.02, 0.01, 0.01],
'mean_score_time'    : [0.01, 0.06, 0.04, 0.04],
'std_score_time'     : [0.00, 0.00, 0.00, 0.01],
'params'             : [{'kernel': 'poly', 'degree': 2}, ...],
}
```

Example 2 (json):
```json
>>> from sklearn import svm, datasets
>>> from sklearn.model_selection import GridSearchCV
>>> iris = datasets.load_iris()
>>> parameters = {'kernel':('linear', 'rbf'), 'C':[1, 10]}
>>> svc = svm.SVC()
>>> clf = GridSearchCV(svc, parameters)
>>> clf.fit(iris.data, iris.target)
GridSearchCV(estimator=SVC(),
             param_grid={'C': [1, 10], 'kernel': ('linear', 'rbf')})
>>> sorted(clf.cv_results_.keys())
['mean_fit_time', 'mean_score_time', 'mean_test_score',...
 'param_C', 'param_kernel', 'params',...
 'rank_test_score', 'split0_test_score',...
 'split2_test_score', ...
 'std_fit_time', 'std_score_time', 'std_test_score']
```

---

## 

**URL:** https://scikit-learn.org/stable/_sources/modules/multiclass.rst.txt

---

## pair_confusion_matrix#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.metrics.cluster.pair_confusion_matrix.html

**Contents:**
- pair_confusion_matrix#

Pair confusion matrix arising from two clusterings.

The pair confusion matrix \(C\) computes a 2 by 2 similarity matrix between two clusterings by considering all pairs of samples and counting pairs that are assigned into the same or into different clusters under the true and predicted clusterings [1].

Considering a pair of samples that is clustered together a positive pair, then as in binary classification the count of true negatives is \(C_{00}\), false negatives is \(C_{10}\), true positives is \(C_{11}\) and false positives is \(C_{01}\).

Read more in the User Guide.

Ground truth class labels to be used as a reference.

Cluster labels to evaluate.

The contingency matrix.

Adjusted Mutual Information.

Hubert, L., Arabie, P. “Comparing partitions.” Journal of Classification 2, 193–218 (1985).

Perfectly matching labelings have all non-zero entries on the diagonal regardless of actual label values:

Labelings that assign all classes members to the same clusters are complete but may be not always pure, hence penalized, and have some off-diagonal non-zero entries:

Note that the matrix is not symmetric.

**Examples:**

Example 1 (sql):
```sql
>>> from sklearn.metrics.cluster import pair_confusion_matrix
>>> pair_confusion_matrix([0, 0, 1, 1], [1, 1, 0, 0])
array([[8, 0],
       [0, 4]]...
```

Example 2 (json):
```json
>>> pair_confusion_matrix([0, 0, 1, 2], [0, 0, 1, 1])
array([[8, 2],
       [0, 2]]...
```

---

## 7.7. Kernel Approximation#

**URL:** https://scikit-learn.org/stable/modules/kernel_approximation.html

**Contents:**
- 7.7. Kernel Approximation#
- 7.7.1. Nystroem Method for Kernel Approximation#
- 7.7.2. Radial Basis Function Kernel#
- 7.7.3. Additive Chi Squared Kernel#
- 7.7.4. Skewed Chi Squared Kernel#
- 7.7.5. Polynomial Kernel Approximation via Tensor Sketch#
- 7.7.6. Mathematical Details#

This submodule contains functions that approximate the feature mappings that correspond to certain kernels, as they are used for example in support vector machines (see Support Vector Machines). The following feature functions perform non-linear transformations of the input, which can serve as a basis for linear classification or other algorithms.

The advantage of using approximate explicit feature maps compared to the kernel trick, which makes use of feature maps implicitly, is that explicit mappings can be better suited for online learning and can significantly reduce the cost of learning with very large datasets. Standard kernelized SVMs do not scale well to large datasets, but using an approximate kernel map it is possible to use much more efficient linear SVMs. In particular, the combination of kernel map approximations with SGDClassifier can make non-linear learning on large datasets possible.

Since there has not been much empirical work using approximate embeddings, it is advisable to compare results against exact kernel methods when possible.

Polynomial regression: extending linear models with basis functions for an exact polynomial transformation.

The Nystroem method, as implemented in Nystroem is a general method for reduced rank approximations of kernels. It achieves this by subsampling without replacement rows/columns of the data on which the kernel is evaluated. While the computational complexity of the exact method is \(\mathcal{O}(n^3_{\text{samples}})\), the complexity of the approximation is \(\mathcal{O}(n^2_{\text{components}} \cdot n_{\text{samples}})\), where one can set \(n_{\text{components}} \ll n_{\text{samples}}\) without a significant decrease in performance [WS2001].

We can construct the eigendecomposition of the kernel matrix \(K\), based on the features of the data, and then split it into sampled and unsampled data points.

\(\Lambda\) is diagonal matrix of eigenvalues

\(U_1\) is orthonormal matrix of samples that were chosen

\(U_2\) is orthonormal matrix of samples that were not chosen

Given that \(U_1 \Lambda U_1^T\) can be obtained by orthonormalization of the matrix \(K_{11}\), and \(U_2 \Lambda U_1^T\) can be evaluated (as well as its transpose), the only remaining term to elucidate is \(U_2 \Lambda U_2^T\). To do this we can express it in terms of the already evaluated matrices:

During fit, the class Nystroem evaluates the basis \(U_1\), and computes the normalization constant, \(K_{11}^{-\frac12}\). Later, during transform, the kernel matrix is determined between the basis (given by the components_ attribute) and the new data points, X. This matrix is then multiplied by the normalization_ matrix for the final result.

By default Nystroem uses the rbf kernel, but it can use any kernel function or a precomputed kernel matrix. The number of samples used - which is also the dimensionality of the features computed - is given by the parameter n_components.

See the example entitled Time-related feature engineering, that shows an efficient machine learning pipeline that uses a Nystroem kernel.

See Explicit feature map approximation for RBF kernels for a comparison of Nystroem kernel with RBFSampler.

The RBFSampler constructs an approximate mapping for the radial basis function kernel, also known as Random Kitchen Sinks [RR2007]. This transformation can be used to explicitly model a kernel map, prior to applying a linear algorithm, for example a linear SVM:

The mapping relies on a Monte Carlo approximation to the kernel values. The fit function performs the Monte Carlo sampling, whereas the transform method performs the mapping of the data. Because of the inherent randomness of the process, results may vary between different calls to the fit function.

The fit function takes two arguments: n_components, which is the target dimensionality of the feature transform, and gamma, the parameter of the RBF-kernel. A higher n_components will result in a better approximation of the kernel and will yield results more similar to those produced by a kernel SVM. Note that “fitting” the feature function does not actually depend on the data given to the fit function. Only the dimensionality of the data is used. Details on the method can be found in [RR2007].

For a given value of n_components RBFSampler is often less accurate as Nystroem. RBFSampler is cheaper to compute, though, making use of larger feature spaces more efficient.

Comparing an exact RBF kernel (left) with the approximation (right)#

See Explicit feature map approximation for RBF kernels for a comparison of Nystroem kernel with RBFSampler.

The additive chi squared kernel is a kernel on histograms, often used in computer vision.

The additive chi squared kernel as used here is given by

This is not exactly the same as sklearn.metrics.pairwise.additive_chi2_kernel. The authors of [VZ2010] prefer the version above as it is always positive definite. Since the kernel is additive, it is possible to treat all components \(x_i\) separately for embedding. This makes it possible to sample the Fourier transform in regular intervals, instead of approximating using Monte Carlo sampling.

The class AdditiveChi2Sampler implements this component wise deterministic sampling. Each component is sampled \(n\) times, yielding \(2n+1\) dimensions per input dimension (the multiple of two stems from the real and complex part of the Fourier transform). In the literature, \(n\) is usually chosen to be 1 or 2, transforming the dataset to size n_samples * 5 * n_features (in the case of \(n=2\)).

The approximate feature map provided by AdditiveChi2Sampler can be combined with the approximate feature map provided by RBFSampler to yield an approximate feature map for the exponentiated chi squared kernel. See the [VZ2010] for details and [VVZ2010] for combination with the RBFSampler.

The skewed chi squared kernel is given by:

It has properties that are similar to the exponentiated chi squared kernel often used in computer vision, but allows for a simple Monte Carlo approximation of the feature map.

The usage of the SkewedChi2Sampler is the same as the usage described above for the RBFSampler. The only difference is in the free parameter, that is called \(c\). For a motivation for this mapping and the mathematical details see [LS2010].

The polynomial kernel is a popular type of kernel function given by:

x, y are the input vectors

d is the kernel degree

Intuitively, the feature space of the polynomial kernel of degree d consists of all possible degree-d products among input features, which enables learning algorithms using this kernel to account for interactions between features.

The TensorSketch [PP2013] method, as implemented in PolynomialCountSketch, is a scalable, input data independent method for polynomial kernel approximation. It is based on the concept of Count sketch [WIKICS] [CCF2002] , a dimensionality reduction technique similar to feature hashing, which instead uses several independent hash functions. TensorSketch obtains a Count Sketch of the outer product of two vectors (or a vector with itself), which can be used as an approximation of the polynomial kernel feature space. In particular, instead of explicitly computing the outer product, TensorSketch computes the Count Sketch of the vectors and then uses polynomial multiplication via the Fast Fourier Transform to compute the Count Sketch of their outer product.

Conveniently, the training phase of TensorSketch simply consists of initializing some random variables. It is thus independent of the input data, i.e. it only depends on the number of input features, but not the data values. In addition, this method can transform samples in \(\mathcal{O}(n_{\text{samples}}(n_{\text{features}} + n_{\text{components}} \log(n_{\text{components}})))\) time, where \(n_{\text{components}}\) is the desired output dimension, determined by n_components.

Scalable learning with polynomial kernel approximation

Kernel methods like support vector machines or kernelized PCA rely on a property of reproducing kernel Hilbert spaces. For any positive definite kernel function \(k\) (a so called Mercer kernel), it is guaranteed that there exists a mapping \(\phi\) into a Hilbert space \(\mathcal{H}\), such that

Where \(\langle \cdot, \cdot \rangle\) denotes the inner product in the Hilbert space.

If an algorithm, such as a linear support vector machine or PCA, relies only on the scalar product of data points \(x_i\), one may use the value of \(k(x_i, x_j)\), which corresponds to applying the algorithm to the mapped data points \(\phi(x_i)\). The advantage of using \(k\) is that the mapping \(\phi\) never has to be calculated explicitly, allowing for arbitrary large features (even infinite).

One drawback of kernel methods is, that it might be necessary to store many kernel values \(k(x_i, x_j)\) during optimization. If a kernelized classifier is applied to new data \(y_j\), \(k(x_i, y_j)\) needs to be computed to make predictions, possibly for many different \(x_i\) in the training set.

The classes in this submodule allow to approximate the embedding \(\phi\), thereby working explicitly with the representations \(\phi(x_i)\), which obviates the need to apply the kernel or store training examples.

“Using the Nyström method to speed up kernel machines” Williams, C.K.I.; Seeger, M. - 2001.

“Random features for large-scale kernel machines” Rahimi, A. and Recht, B. - Advances in neural information processing 2007,

“Random Fourier approximations for skewed multiplicative histogram kernels” Li, F., Ionescu, C., and Sminchisescu, C. - Pattern Recognition, DAGM 2010, Lecture Notes in Computer Science.

“Efficient additive kernels via explicit feature maps” Vedaldi, A. and Zisserman, A. - Computer Vision and Pattern Recognition 2010

“Generalized RBF feature maps for Efficient Detection” Vempati, S. and Vedaldi, A. and Zisserman, A. and Jawahar, CV - 2010

“Fast and scalable polynomial kernels via explicit feature maps” Pham, N., & Pagh, R. - 2013

“Finding frequent items in data streams” Charikar, M., Chen, K., & Farach-Colton - 2002

“Wikipedia: Count sketch”

**Examples:**

Example 1 (sql):
```sql
>>> from sklearn.kernel_approximation import RBFSampler
>>> from sklearn.linear_model import SGDClassifier
>>> X = [[0, 0], [1, 1], [1, 0], [0, 1]]
>>> y = [0, 0, 1, 1]
>>> rbf_feature = RBFSampler(gamma=1, random_state=1)
>>> X_features = rbf_feature.fit_transform(X)
>>> clf = SGDClassifier(max_iter=5)
>>> clf.fit(X_features, y)
SGDClassifier(max_iter=5)
>>> clf.score(X_features, y)
1.0
```

---

## LabelPropagation#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.semi_supervised.LabelPropagation.html

**Contents:**
- LabelPropagation#

Label Propagation classifier.

Read more in the User Guide.

String identifier for kernel function to use or the kernel function itself. Only ‘rbf’ and ‘knn’ strings are valid inputs. The function passed should take two inputs, each of shape (n_samples, n_features), and return a (n_samples, n_samples) shaped weight matrix.

Parameter for rbf kernel.

Parameter for knn kernel which need to be strictly positive.

Change maximum number of iterations allowed.

Convergence tolerance: threshold to consider the system at steady state.

The number of parallel jobs to run. None means 1 unless in a joblib.parallel_backend context. -1 means using all processors. See Glossary for more details.

The distinct labels used in classifying instances.

Categorical distribution for each item.

Label assigned to each item during fit.

Number of features seen during fit.

Added in version 0.24.

Names of features seen during fit. Defined only when X has feature names that are all strings.

Added in version 1.0.

Number of iterations run.

Alternate label propagation strategy more robust to noise.

Xiaojin Zhu and Zoubin Ghahramani. Learning from labeled and unlabeled data with label propagation. Technical Report CMU-CALD-02-107, Carnegie Mellon University, 2002 http://pages.cs.wisc.edu/~jerryzhu/pub/CMU-CALD-02-107.pdf

Fit a semi-supervised label propagation model to X.

Training data, where n_samples is the number of samples and n_features is the number of features.

Target class values with unlabeled points marked as -1. All unlabeled samples will be transductively assigned labels internally, which are stored in transduction_.

Returns the instance itself.

Get metadata routing of this object.

Please check User Guide on how the routing mechanism works.

A MetadataRequest encapsulating routing information.

Get parameters for this estimator.

If True, will return the parameters for this estimator and contained subobjects that are estimators.

Parameter names mapped to their values.

Perform inductive inference across the model.

Predictions for input data.

Predict probability for each possible outcome.

Compute the probability estimates for each single sample in X and each possible outcome seen during training (categorical distribution).

Normalized probability distributions across class labels.

Return accuracy on provided data and labels.

In multi-label classification, this is the subset accuracy which is a harsh metric since you require for each sample that each label set be correctly predicted.

Mean accuracy of self.predict(X) w.r.t. y.

Set the parameters of this estimator.

The method works on simple estimators as well as on nested objects (such as Pipeline). The latter have parameters of the form <component>__<parameter> so that it’s possible to update each component of a nested object.

Estimator parameters.

Configure whether metadata should be requested to be passed to the score method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to score if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to score.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Added in version 1.3.

Metadata routing for sample_weight parameter in score.

**Examples:**

Example 1 (python):
```python
>>> import numpy as np
>>> from sklearn import datasets
>>> from sklearn.semi_supervised import LabelPropagation
>>> label_prop_model = LabelPropagation()
>>> iris = datasets.load_iris()
>>> rng = np.random.RandomState(42)
>>> random_unlabeled_points = rng.rand(len(iris.target)) < 0.3
>>> labels = np.copy(iris.target)
>>> labels[random_unlabeled_points] = -1
>>> label_prop_model.fit(iris.data, labels)
LabelPropagation(...)
```

---

## SVR#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVR.html

**Contents:**
- SVR#
- Gallery examples#

Epsilon-Support Vector Regression.

The free parameters in the model are C and epsilon.

The implementation is based on libsvm. The fit time complexity is more than quadratic with the number of samples which makes it hard to scale to datasets with more than a couple of 10000 samples. For large datasets consider using LinearSVR or SGDRegressor instead, possibly after a Nystroem transformer or other Kernel Approximation.

Read more in the User Guide.

Specifies the kernel type to be used in the algorithm. If none is given, ‘rbf’ will be used. If a callable is given it is used to precompute the kernel matrix. For an intuitive visualization of different kernel types see Support Vector Regression (SVR) using linear and non-linear kernels

Degree of the polynomial kernel function (‘poly’). Must be non-negative. Ignored by all other kernels.

Kernel coefficient for ‘rbf’, ‘poly’ and ‘sigmoid’.

if gamma='scale' (default) is passed then it uses 1 / (n_features * X.var()) as value of gamma,

if ‘auto’, uses 1 / n_features

if float, must be non-negative.

Changed in version 0.22: The default value of gamma changed from ‘auto’ to ‘scale’.

Independent term in kernel function. It is only significant in ‘poly’ and ‘sigmoid’.

Tolerance for stopping criterion.

Regularization parameter. The strength of the regularization is inversely proportional to C. Must be strictly positive. The penalty is a squared l2. For an intuitive visualization of the effects of scaling the regularization parameter C, see Scaling the regularization parameter for SVCs.

Epsilon in the epsilon-SVR model. It specifies the epsilon-tube within which no penalty is associated in the training loss function with points predicted within a distance epsilon from the actual value. Must be non-negative.

Whether to use the shrinking heuristic. See the User Guide.

Specify the size of the kernel cache (in MB).

Enable verbose output. Note that this setting takes advantage of a per-process runtime setting in libsvm that, if enabled, may not work properly in a multithreaded context.

Hard limit on iterations within solver, or -1 for no limit.

Weights assigned to the features when kernel="linear".

Coefficients of the support vector in the decision function.

0 if correctly fitted, 1 otherwise (will raise warning)

Constants in decision function.

Number of features seen during fit.

Added in version 0.24.

Names of features seen during fit. Defined only when X has feature names that are all strings.

Added in version 1.0.

Number of iterations run by the optimization routine to fit the model.

Added in version 1.1.

Number of support vectors for each class.

Array dimensions of training vector X.

Indices of support vectors.

Support Vector Machine for regression implemented using libsvm using a parameter to control the number of support vectors.

Scalable Linear Support Vector Machine for regression implemented using liblinear.

LIBSVM: A Library for Support Vector Machines

Platt, John (1999). “Probabilistic Outputs for Support Vector Machines and Comparisons to Regularized Likelihood Methods”

Fit the SVM model according to the given training data.

Training vectors, where n_samples is the number of samples and n_features is the number of features. For kernel=”precomputed”, the expected shape of X is (n_samples, n_samples).

Target values (class labels in classification, real numbers in regression).

Per-sample weights. Rescale C per sample. Higher weights force the classifier to put more emphasis on these points.

If X and y are not C-ordered and contiguous arrays of np.float64 and X is not a scipy.sparse.csr_matrix, X and/or y may be copied.

If X is a dense array, then the other methods will not support sparse matrices as input.

Get metadata routing of this object.

Please check User Guide on how the routing mechanism works.

A MetadataRequest encapsulating routing information.

Get parameters for this estimator.

If True, will return the parameters for this estimator and contained subobjects that are estimators.

Parameter names mapped to their values.

Perform regression on samples in X.

For a one-class model, +1 (inlier) or -1 (outlier) is returned.

For kernel=”precomputed”, the expected shape of X is (n_samples_test, n_samples_train).

The predicted values.

Return coefficient of determination on test data.

The coefficient of determination, \(R^2\), is defined as \((1 - \frac{u}{v})\), where \(u\) is the residual sum of squares ((y_true - y_pred)** 2).sum() and \(v\) is the total sum of squares ((y_true - y_true.mean()) ** 2).sum(). The best possible score is 1.0 and it can be negative (because the model can be arbitrarily worse). A constant model that always predicts the expected value of y, disregarding the input features, would get a \(R^2\) score of 0.0.

Test samples. For some estimators this may be a precomputed kernel matrix or a list of generic objects instead with shape (n_samples, n_samples_fitted), where n_samples_fitted is the number of samples used in the fitting for the estimator.

\(R^2\) of self.predict(X) w.r.t. y.

The \(R^2\) score used when calling score on a regressor uses multioutput='uniform_average' from version 0.23 to keep consistent with default value of r2_score. This influences the score method of all the multioutput regressors (except for MultiOutputRegressor).

Configure whether metadata should be requested to be passed to the fit method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to fit if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to fit.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Added in version 1.3.

Metadata routing for sample_weight parameter in fit.

Set the parameters of this estimator.

The method works on simple estimators as well as on nested objects (such as Pipeline). The latter have parameters of the form <component>__<parameter> so that it’s possible to update each component of a nested object.

Estimator parameters.

Configure whether metadata should be requested to be passed to the score method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to score if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to score.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Added in version 1.3.

Metadata routing for sample_weight parameter in score.

Comparison of kernel ridge regression and SVR

Support Vector Regression (SVR) using linear and non-linear kernels

**Examples:**

Example 1 (sql):
```sql
>>> from sklearn.svm import SVR
>>> from sklearn.pipeline import make_pipeline
>>> from sklearn.preprocessing import StandardScaler
>>> import numpy as np
>>> n_samples, n_features = 10, 5
>>> rng = np.random.RandomState(0)
>>> y = rng.randn(n_samples)
>>> X = rng.randn(n_samples, n_features)
>>> regr = make_pipeline(StandardScaler(), SVR(C=1.0, epsilon=0.2))
>>> regr.fit(X, y)
Pipeline(steps=[('standardscaler', StandardScaler()),
                ('svr', SVR(epsilon=0.2))])
```

---

## PoissonRegressor#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.PoissonRegressor.html

**Contents:**
- PoissonRegressor#
- Gallery examples#

Generalized Linear Model with a Poisson distribution.

This regressor uses the ‘log’ link function.

Read more in the User Guide.

Added in version 0.23.

Constant that multiplies the L2 penalty term and determines the regularization strength. alpha = 0 is equivalent to unpenalized GLMs. In this case, the design matrix X must have full column rank (no collinearities). Values of alpha must be in the range [0.0, inf).

Specifies if a constant (a.k.a. bias or intercept) should be added to the linear predictor (X @ coef + intercept).

Algorithm to use in the optimization problem:

Calls scipy’s L-BFGS-B optimizer.

Uses Newton-Raphson steps (in arbitrary precision arithmetic equivalent to iterated reweighted least squares) with an inner Cholesky based solver. This solver is a good choice for n_samples >> n_features, especially with one-hot encoded categorical features with rare categories. Be aware that the memory usage of this solver has a quadratic dependency on n_features because it explicitly computes the Hessian matrix.

Added in version 1.2.

The maximal number of iterations for the solver. Values must be in the range [1, inf).

Stopping criterion. For the lbfgs solver, the iteration will stop when max{|g_j|, j = 1, ..., d} <= tol where g_j is the j-th component of the gradient (derivative) of the objective function. Values must be in the range (0.0, inf).

If set to True, reuse the solution of the previous call to fit as initialization for coef_ and intercept_ .

For the lbfgs solver set verbose to any positive number for verbosity. Values must be in the range [0, inf).

Estimated coefficients for the linear predictor (X @ coef_ + intercept_) in the GLM.

Intercept (a.k.a. bias) added to linear predictor.

Number of features seen during fit.

Added in version 0.24.

Names of features seen during fit. Defined only when X has feature names that are all strings.

Added in version 1.0.

Actual number of iterations used in the solver.

Generalized Linear Model with a Tweedie distribution.

Fit a Generalized Linear Model.

Get metadata routing of this object.

Please check User Guide on how the routing mechanism works.

A MetadataRequest encapsulating routing information.

Get parameters for this estimator.

If True, will return the parameters for this estimator and contained subobjects that are estimators.

Parameter names mapped to their values.

Predict using GLM with feature matrix X.

Returns predicted values.

Compute D^2, the percentage of deviance explained.

D^2 is a generalization of the coefficient of determination R^2. R^2 uses squared error and D^2 uses the deviance of this GLM, see the User Guide.

D^2 is defined as \(D^2 = 1-\frac{D(y_{true},y_{pred})}{D_{null}}\), \(D_{null}\) is the null deviance, i.e. the deviance of a model with intercept alone, which corresponds to \(y_{pred} = \bar{y}\). The mean \(\bar{y}\) is averaged by sample_weight. Best possible score is 1.0 and it can be negative (because the model can be arbitrarily worse).

True values of target.

D^2 of self.predict(X) w.r.t. y.

Configure whether metadata should be requested to be passed to the fit method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to fit if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to fit.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Added in version 1.3.

Metadata routing for sample_weight parameter in fit.

Set the parameters of this estimator.

The method works on simple estimators as well as on nested objects (such as Pipeline). The latter have parameters of the form <component>__<parameter> so that it’s possible to update each component of a nested object.

Estimator parameters.

Configure whether metadata should be requested to be passed to the score method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to score if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to score.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Added in version 1.3.

Metadata routing for sample_weight parameter in score.

Poisson regression and non-normal loss

Tweedie regression on insurance claims

Release Highlights for scikit-learn 0.23

**Examples:**

Example 1 (python):
```python
>>> from sklearn import linear_model
>>> clf = linear_model.PoissonRegressor()
>>> X = [[1, 2], [2, 3], [3, 4], [4, 3]]
>>> y = [12, 17, 22, 21]
>>> clf.fit(X, y)
PoissonRegressor()
>>> clf.score(X, y)
np.float64(0.990)
>>> clf.coef_
array([0.121, 0.158])
>>> clf.intercept_
np.float64(2.088)
>>> clf.predict([[1, 1], [3, 4]])
array([10.676, 21.875])
```

---

## LabelBinarizer#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelBinarizer.html

**Contents:**
- LabelBinarizer#
- Gallery examples#

Binarize labels in a one-vs-all fashion.

Several regression and binary classification algorithms are available in scikit-learn. A simple way to extend these algorithms to the multi-class classification case is to use the so-called one-vs-all scheme.

At learning time, this simply consists in learning one regressor or binary classifier per class. In doing so, one needs to convert multi-class labels to binary labels (belong or does not belong to the class). LabelBinarizer makes this process easy with the transform method.

At prediction time, one assigns the class for which the corresponding model gave the greatest confidence. LabelBinarizer makes this easy with the inverse_transform method.

Read more in the User Guide.

Value with which negative labels must be encoded.

Value with which positive labels must be encoded.

True if the returned array from transform is desired to be in sparse CSR format.

Holds the label for each class.

Represents the type of the target data as evaluated by type_of_target. Possible type are ‘continuous’, ‘continuous-multioutput’, ‘binary’, ‘multiclass’, ‘multiclass-multioutput’, ‘multilabel-indicator’, and ‘unknown’.

Function to perform the transform operation of LabelBinarizer with fixed classes.

Encode categorical features using a one-hot aka one-of-K scheme.

Binary targets transform to a column vector

Passing a 2D matrix for multilabel classification

Target values. The 2-d matrix should only contain 0 and 1, represents multilabel classification.

Returns the instance itself.

Fit label binarizer/transform multi-class labels to binary labels.

The output of transform is sometimes referred to as the 1-of-K coding scheme.

Target values. The 2-d matrix should only contain 0 and 1, represents multilabel classification. Sparse matrix can be CSR, CSC, COO, DOK, or LIL.

Shape will be (n_samples, 1) for binary problems. Sparse matrix will be of CSR format.

Get metadata routing of this object.

Please check User Guide on how the routing mechanism works.

A MetadataRequest encapsulating routing information.

Get parameters for this estimator.

If True, will return the parameters for this estimator and contained subobjects that are estimators.

Parameter names mapped to their values.

Transform binary labels back to multi-class labels.

Target values. All sparse matrices are converted to CSR before inverse transformation.

Threshold used in the binary and multi-label cases.

Use 0 when Y contains the output of decision_function (classifier). Use 0.5 when Y contains the output of predict_proba.

If None, the threshold is assumed to be half way between neg_label and pos_label.

Target values. Sparse matrix will be of CSR format.

In the case when the binary labels are fractional (probabilistic), inverse_transform chooses the class with the greatest value. Typically, this allows to use the output of a linear model’s decision_function method directly as the input of inverse_transform.

Configure whether metadata should be requested to be passed to the inverse_transform method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to inverse_transform if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to inverse_transform.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Added in version 1.3.

Metadata routing for threshold parameter in inverse_transform.

Set output container.

See Introducing the set_output API for an example on how to use the API.

Configure output of transform and fit_transform.

"default": Default output format of a transformer

"pandas": DataFrame output

"polars": Polars output

None: Transform configuration is unchanged

Added in version 1.4: "polars" option was added.

Set the parameters of this estimator.

The method works on simple estimators as well as on nested objects (such as Pipeline). The latter have parameters of the form <component>__<parameter> so that it’s possible to update each component of a nested object.

Estimator parameters.

Transform multi-class labels to binary labels.

The output of transform is sometimes referred to by some authors as the 1-of-K coding scheme.

Target values. The 2-d matrix should only contain 0 and 1, represents multilabel classification. Sparse matrix can be CSR, CSC, COO, DOK, or LIL.

Shape will be (n_samples, 1) for binary problems. Sparse matrix will be of CSR format.

Multiclass Receiver Operating Characteristic (ROC)

**Examples:**

Example 1 (csharp):
```csharp
>>> from sklearn.preprocessing import LabelBinarizer
>>> lb = LabelBinarizer()
>>> lb.fit([1, 2, 6, 4, 2])
LabelBinarizer()
>>> lb.classes_
array([1, 2, 4, 6])
>>> lb.transform([1, 6])
array([[1, 0, 0, 0],
       [0, 0, 0, 1]])
```

Example 2 (json):
```json
>>> lb = LabelBinarizer()
>>> lb.fit_transform(['yes', 'no', 'no', 'yes'])
array([[1],
       [0],
       [0],
       [1]])
```

Example 3 (csharp):
```csharp
>>> import numpy as np
>>> lb.fit(np.array([[0, 1, 1], [1, 0, 0]]))
LabelBinarizer()
>>> lb.classes_
array([0, 1, 2])
>>> lb.transform([0, 1, 2, 1])
array([[1, 0, 0],
       [0, 1, 0],
       [0, 0, 1],
       [0, 1, 0]])
```

---

## BallTree#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.BallTree.html

**Contents:**
- BallTree#

BallTree for fast generalized N-point problems

Read more in the User Guide.

n_samples is the number of points in the data set, and n_features is the dimension of the parameter space. Note: if X is a C-contiguous array of doubles then data will not be copied. Otherwise, an internal copy will be made.

Number of points at which to switch to brute-force. Changing leaf_size will not affect the results of a query, but can significantly impact the speed of a query and the memory required to store the constructed tree. The amount of memory needed to store the tree scales as approximately n_samples / leaf_size. For a specified leaf_size, a leaf node is guaranteed to satisfy leaf_size <= n_points <= 2 * leaf_size, except in the case that n_samples < leaf_size.

Metric to use for distance computation. Default is “minkowski”, which results in the standard Euclidean distance when p = 2. A list of valid metrics for BallTree is given by the attribute valid_metrics. See the documentation of scipy.spatial.distance and the metrics listed in distance_metrics for more information on any distance metric.

List of valid distance metrics.

Query for k-nearest neighbors

Pickle and Unpickle a tree. Note that the state of the tree is saved in the pickle operation: the tree needs not be rebuilt upon unpickling.

Query for neighbors within a given radius

Compute a gaussian kernel density estimate:

Compute a two-point auto-correlation function

Get data and node arrays.

Arrays for storing tree data, index, node data and node bounds.

number of distance computation calls

(number of trims, number of leaves, number of splits)

Compute the kernel density estimate at points X with the given kernel, using the distance metric specified at tree creation.

An array of points to query. Last dimension should match dimension of training data.

the bandwidth of the kernel

specify the kernel to use. Options are - ‘gaussian’ - ‘tophat’ - ‘epanechnikov’ - ‘exponential’ - ‘linear’ - ‘cosine’ Default is kernel = ‘gaussian’

Specify the desired absolute tolerance of the result. If the true result is K_true, then the returned result K_ret satisfies abs(K_true - K_ret) < atol + rtol * K_ret The default is zero (i.e. machine precision).

Specify the desired relative tolerance of the result. If the true result is K_true, then the returned result K_ret satisfies abs(K_true - K_ret) < atol + rtol * K_ret The default is 1e-8 (i.e. machine precision).

If True, use a breadth-first search. If False (default) use a depth-first search. Breadth-first is generally faster for compact kernels and/or high tolerances.

Return the logarithm of the result. This can be more accurate than returning the result itself for narrow kernels.

The array of (log)-density evaluations

query the tree for the k nearest neighbors

An array of points to query

The number of nearest neighbors to return

if True, return a tuple (d, i) of distances and indices if False, return array i

if True, use the dual tree formalism for the query: a tree is built for the query points, and the pair of trees is used to efficiently search this space. This can lead to better performance as the number of points grows large.

if True, then query the nodes in a breadth-first manner. Otherwise, query the nodes in a depth-first manner.

if True, then distances and indices of each point are sorted on return, so that the first column contains the closest points. Otherwise, neighbors are returned in an arbitrary order.

Each entry gives the list of distances to the neighbors of the corresponding point.

Each entry gives the list of indices of neighbors of the corresponding point.

query the tree for neighbors within a radius r

An array of points to query

r can be a single value, or an array of values of shape x.shape[:-1] if different radii are desired for each point.

if True, return distances to neighbors of each point if False, return only neighbors Note that unlike the query() method, setting return_distance=True here adds to the computation time. Not all distances need to be calculated explicitly for return_distance=False. Results are not sorted by default: see sort_results keyword.

if True, return only the count of points within distance r if False, return the indices of all points within distance r If return_distance==True, setting count_only=True will result in an error.

if True, the distances and indices will be sorted before being returned. If False, the results will not be sorted. If return_distance == False, setting sort_results = True will result in an error.

Each entry gives the number of neighbors within a distance r of the corresponding point.

Each element is a numpy integer array listing the indices of neighbors of the corresponding point. Note that unlike the results of a k-neighbors query, the returned neighbors are not sorted by distance by default.

Each element is a numpy double array listing the distances corresponding to indices in i.

Reset number of calls to 0.

Compute the two-point correlation function

An array of points to query. Last dimension should match dimension of training data.

A one-dimensional array of distances

If True, use a dualtree algorithm. Otherwise, use a single-tree algorithm. Dual tree algorithms can have better scaling for large N.

counts[i] contains the number of pairs of points with distance less than or equal to r[i]

**Examples:**

Example 1 (json):
```json
>>> import numpy as np
>>> from sklearn.neighbors import BallTree
>>> rng = np.random.RandomState(0)
>>> X = rng.random_sample((10, 3))  # 10 points in 3 dimensions
>>> tree = BallTree(X, leaf_size=2)
>>> dist, ind = tree.query(X[:1], k=3)
>>> print(ind)  # indices of 3 closest neighbors
[0 3 1]
>>> print(dist)  # distances to 3 closest neighbors
[ 0.          0.19662693  0.29473397]
```

Example 2 (json):
```json
>>> import numpy as np
>>> import pickle
>>> rng = np.random.RandomState(0)
>>> X = rng.random_sample((10, 3))  # 10 points in 3 dimensions
>>> tree = BallTree(X, leaf_size=2)
>>> s = pickle.dumps(tree)
>>> tree_copy = pickle.loads(s)
>>> dist, ind = tree_copy.query(X[:1], k=3)
>>> print(ind)  # indices of 3 closest neighbors
[0 3 1]
>>> print(dist)  # distances to 3 closest neighbors
[ 0.          0.19662693  0.29473397]
```

Example 3 (json):
```json
>>> import numpy as np
>>> rng = np.random.RandomState(0)
>>> X = rng.random_sample((10, 3))  # 10 points in 3 dimensions
>>> tree = BallTree(X, leaf_size=2)
>>> print(tree.query_radius(X[:1], r=0.3, count_only=True))
3
>>> ind = tree.query_radius(X[:1], r=0.3)
>>> print(ind)  # indices of neighbors within distance 0.3
[3 0 1]
```

Example 4 (typescript):
```typescript
>>> import numpy as np
>>> rng = np.random.RandomState(42)
>>> X = rng.random_sample((100, 3))
>>> tree = BallTree(X)
>>> tree.kernel_density(X[:3], h=0.1, kernel='gaussian')
array([ 6.94114649,  7.83281226,  7.2071716 ])
```

---

## KDTree#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KDTree.html

**Contents:**
- KDTree#

KDTree for fast generalized N-point problems

Read more in the User Guide.

n_samples is the number of points in the data set, and n_features is the dimension of the parameter space. Note: if X is a C-contiguous array of doubles then data will not be copied. Otherwise, an internal copy will be made.

Number of points at which to switch to brute-force. Changing leaf_size will not affect the results of a query, but can significantly impact the speed of a query and the memory required to store the constructed tree. The amount of memory needed to store the tree scales as approximately n_samples / leaf_size. For a specified leaf_size, a leaf node is guaranteed to satisfy leaf_size <= n_points <= 2 * leaf_size, except in the case that n_samples < leaf_size.

Metric to use for distance computation. Default is “minkowski”, which results in the standard Euclidean distance when p = 2. A list of valid metrics for KDTree is given by the attribute valid_metrics. See the documentation of scipy.spatial.distance and the metrics listed in distance_metrics for more information on any distance metric.

List of valid distance metrics.

Query for k-nearest neighbors

Pickle and Unpickle a tree. Note that the state of the tree is saved in the pickle operation: the tree needs not be rebuilt upon unpickling.

Query for neighbors within a given radius

Compute a gaussian kernel density estimate:

Compute a two-point auto-correlation function

Get data and node arrays.

Arrays for storing tree data, index, node data and node bounds.

number of distance computation calls

(number of trims, number of leaves, number of splits)

Compute the kernel density estimate at points X with the given kernel, using the distance metric specified at tree creation.

An array of points to query. Last dimension should match dimension of training data.

the bandwidth of the kernel

specify the kernel to use. Options are - ‘gaussian’ - ‘tophat’ - ‘epanechnikov’ - ‘exponential’ - ‘linear’ - ‘cosine’ Default is kernel = ‘gaussian’

Specify the desired absolute tolerance of the result. If the true result is K_true, then the returned result K_ret satisfies abs(K_true - K_ret) < atol + rtol * K_ret The default is zero (i.e. machine precision).

Specify the desired relative tolerance of the result. If the true result is K_true, then the returned result K_ret satisfies abs(K_true - K_ret) < atol + rtol * K_ret The default is 1e-8 (i.e. machine precision).

If True, use a breadth-first search. If False (default) use a depth-first search. Breadth-first is generally faster for compact kernels and/or high tolerances.

Return the logarithm of the result. This can be more accurate than returning the result itself for narrow kernels.

The array of (log)-density evaluations

query the tree for the k nearest neighbors

An array of points to query

The number of nearest neighbors to return

if True, return a tuple (d, i) of distances and indices if False, return array i

if True, use the dual tree formalism for the query: a tree is built for the query points, and the pair of trees is used to efficiently search this space. This can lead to better performance as the number of points grows large.

if True, then query the nodes in a breadth-first manner. Otherwise, query the nodes in a depth-first manner.

if True, then distances and indices of each point are sorted on return, so that the first column contains the closest points. Otherwise, neighbors are returned in an arbitrary order.

Each entry gives the list of distances to the neighbors of the corresponding point.

Each entry gives the list of indices of neighbors of the corresponding point.

query the tree for neighbors within a radius r

An array of points to query

r can be a single value, or an array of values of shape x.shape[:-1] if different radii are desired for each point.

if True, return distances to neighbors of each point if False, return only neighbors Note that unlike the query() method, setting return_distance=True here adds to the computation time. Not all distances need to be calculated explicitly for return_distance=False. Results are not sorted by default: see sort_results keyword.

if True, return only the count of points within distance r if False, return the indices of all points within distance r If return_distance==True, setting count_only=True will result in an error.

if True, the distances and indices will be sorted before being returned. If False, the results will not be sorted. If return_distance == False, setting sort_results = True will result in an error.

Each entry gives the number of neighbors within a distance r of the corresponding point.

Each element is a numpy integer array listing the indices of neighbors of the corresponding point. Note that unlike the results of a k-neighbors query, the returned neighbors are not sorted by distance by default.

Each element is a numpy double array listing the distances corresponding to indices in i.

Reset number of calls to 0.

Compute the two-point correlation function

An array of points to query. Last dimension should match dimension of training data.

A one-dimensional array of distances

If True, use a dualtree algorithm. Otherwise, use a single-tree algorithm. Dual tree algorithms can have better scaling for large N.

counts[i] contains the number of pairs of points with distance less than or equal to r[i]

**Examples:**

Example 1 (json):
```json
>>> import numpy as np
>>> from sklearn.neighbors import KDTree
>>> rng = np.random.RandomState(0)
>>> X = rng.random_sample((10, 3))  # 10 points in 3 dimensions
>>> tree = KDTree(X, leaf_size=2)
>>> dist, ind = tree.query(X[:1], k=3)
>>> print(ind)  # indices of 3 closest neighbors
[0 3 1]
>>> print(dist)  # distances to 3 closest neighbors
[ 0.          0.19662693  0.29473397]
```

Example 2 (json):
```json
>>> import numpy as np
>>> import pickle
>>> rng = np.random.RandomState(0)
>>> X = rng.random_sample((10, 3))  # 10 points in 3 dimensions
>>> tree = KDTree(X, leaf_size=2)
>>> s = pickle.dumps(tree)
>>> tree_copy = pickle.loads(s)
>>> dist, ind = tree_copy.query(X[:1], k=3)
>>> print(ind)  # indices of 3 closest neighbors
[0 3 1]
>>> print(dist)  # distances to 3 closest neighbors
[ 0.          0.19662693  0.29473397]
```

Example 3 (json):
```json
>>> import numpy as np
>>> rng = np.random.RandomState(0)
>>> X = rng.random_sample((10, 3))  # 10 points in 3 dimensions
>>> tree = KDTree(X, leaf_size=2)
>>> print(tree.query_radius(X[:1], r=0.3, count_only=True))
3
>>> ind = tree.query_radius(X[:1], r=0.3)
>>> print(ind)  # indices of neighbors within distance 0.3
[3 0 1]
```

Example 4 (typescript):
```typescript
>>> import numpy as np
>>> rng = np.random.RandomState(42)
>>> X = rng.random_sample((100, 3))
>>> tree = KDTree(X)
>>> tree.kernel_density(X[:3], h=0.1, kernel='gaussian')
array([ 6.94114649,  7.83281226,  7.2071716 ])
```

---

## VotingRegressor#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.VotingRegressor.html

**Contents:**
- VotingRegressor#
- Gallery examples#

Prediction voting regressor for unfitted estimators.

A voting regressor is an ensemble meta-estimator that fits several base regressors, each on the whole dataset. Then it averages the individual predictions to form a final prediction.

For a detailed example, refer to Plot individual and voting regression predictions.

Read more in the User Guide.

Added in version 0.21.

Invoking the fit method on the VotingRegressor will fit clones of those original estimators that will be stored in the class attribute self.estimators_. An estimator can be set to 'drop' using set_params.

Changed in version 0.21: 'drop' is accepted. Using None was deprecated in 0.22 and support was removed in 0.24.

Sequence of weights (float or int) to weight the occurrences of predicted values before averaging. Uses uniform weights if None.

The number of jobs to run in parallel for fit. None means 1 unless in a joblib.parallel_backend context. -1 means using all processors. See Glossary for more details.

If True, the time elapsed while fitting will be printed as it is completed.

Added in version 0.23.

The collection of fitted sub-estimators as defined in estimators that are not ‘drop’.

Attribute to access any fitted sub-estimators by name.

Added in version 0.20.

Number of features seen during fit.

Names of features seen during fit. Only defined if the underlying estimators expose such an attribute when fit.

Added in version 1.0.

Soft Voting/Majority Rule classifier.

In the following example, we drop the 'lr' estimator with set_params and fit the remaining two estimators:

Training vectors, where n_samples is the number of samples and n_features is the number of features.

Parameters to pass to the underlying estimators.

Added in version 1.5: Only available if enable_metadata_routing=True, which can be set by using sklearn.set_config(enable_metadata_routing=True). See Metadata Routing User Guide for more details.

Return class labels or probabilities for each estimator.

Return predictions for X for each estimator.

Target values (None for unsupervised transformations).

Additional fit parameters.

Get output feature names for transformation.

Not used, present here for API consistency by convention.

Transformed feature names.

Get metadata routing of this object.

Please check User Guide on how the routing mechanism works.

Added in version 1.5.

A MetadataRouter encapsulating routing information.

Get the parameters of an estimator from the ensemble.

Returns the parameters given in the constructor as well as the estimators contained within the estimators parameter.

Setting it to True gets the various estimators and the parameters of the estimators as well.

Parameter and estimator names mapped to their values or parameter names mapped to their values.

Dictionary to access any fitted sub-estimators by name.

Predict regression target for X.

The predicted regression target of an input sample is computed as the mean predicted regression targets of the estimators in the ensemble.

The predicted values.

Return coefficient of determination on test data.

The coefficient of determination, \(R^2\), is defined as \((1 - \frac{u}{v})\), where \(u\) is the residual sum of squares ((y_true - y_pred)** 2).sum() and \(v\) is the total sum of squares ((y_true - y_true.mean()) ** 2).sum(). The best possible score is 1.0 and it can be negative (because the model can be arbitrarily worse). A constant model that always predicts the expected value of y, disregarding the input features, would get a \(R^2\) score of 0.0.

Test samples. For some estimators this may be a precomputed kernel matrix or a list of generic objects instead with shape (n_samples, n_samples_fitted), where n_samples_fitted is the number of samples used in the fitting for the estimator.

\(R^2\) of self.predict(X) w.r.t. y.

The \(R^2\) score used when calling score on a regressor uses multioutput='uniform_average' from version 0.23 to keep consistent with default value of r2_score. This influences the score method of all the multioutput regressors (except for MultiOutputRegressor).

Set output container.

See Introducing the set_output API for an example on how to use the API.

Configure output of transform and fit_transform.

"default": Default output format of a transformer

"pandas": DataFrame output

"polars": Polars output

None: Transform configuration is unchanged

Added in version 1.4: "polars" option was added.

Set the parameters of an estimator from the ensemble.

Valid parameter keys can be listed with get_params(). Note that you can directly set the parameters of the estimators contained in estimators.

Specific parameters using e.g. set_params(parameter_name=new_value). In addition, to setting the parameters of the estimator, the individual estimator of the estimators can also be set, or can be removed by setting them to ‘drop’.

Configure whether metadata should be requested to be passed to the score method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to score if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to score.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Added in version 1.3.

Metadata routing for sample_weight parameter in score.

Return predictions for X for each estimator.

Values predicted by each regressor.

Plot individual and voting regression predictions

**Examples:**

Example 1 (python):
```python
>>> import numpy as np
>>> from sklearn.linear_model import LinearRegression
>>> from sklearn.ensemble import RandomForestRegressor
>>> from sklearn.ensemble import VotingRegressor
>>> from sklearn.neighbors import KNeighborsRegressor
>>> r1 = LinearRegression()
>>> r2 = RandomForestRegressor(n_estimators=10, random_state=1)
>>> r3 = KNeighborsRegressor()
>>> X = np.array([[1, 1], [2, 4], [3, 9], [4, 16], [5, 25], [6, 36]])
>>> y = np.array([2, 6, 12, 20, 30, 42])
>>> er = VotingRegressor([('lr', r1), ('rf', r2), ('r3', r3)])
>>> print(er.fit(X, y).predict(X))
[ 6.8  8.4 12.5 17.8 26  34]
```

Example 2 (unknown):
```unknown
>>> er = er.set_params(lr='drop')
>>> er = er.fit(X, y)
>>> len(er.estimators_)
2
```

---

## OPTICS#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.cluster.OPTICS.html

**Contents:**
- OPTICS#
- Gallery examples#

Estimate clustering structure from vector array.

OPTICS (Ordering Points To Identify the Clustering Structure), closely related to DBSCAN, finds core samples of high density and expands clusters from them [1]. Unlike DBSCAN, it keeps cluster hierarchy for a variable neighborhood radius. Better suited for usage on large datasets than the current scikit-learn implementation of DBSCAN.

Clusters are then extracted from the cluster-order using a DBSCAN-like method (cluster_method = ‘dbscan’) or an automatic technique proposed in [1] (cluster_method = ‘xi’).

This implementation deviates from the original OPTICS by first performing k-nearest-neighborhood searches on all points to identify core sizes of all points (instead of computing neighbors while looping through points). Reachability distances to only unprocessed points are then computed, to construct the cluster order, similar to the original OPTICS. Note that we do not employ a heap to manage the expansion candidates, so the time complexity will be O(n^2).

Read more in the User Guide.

The number of samples in a neighborhood for a point to be considered as a core point. Also, up and down steep regions can’t have more than min_samples consecutive non-steep points. Expressed as an absolute number or a fraction of the number of samples (rounded to be at least 2).

The maximum distance between two samples for one to be considered as in the neighborhood of the other. Default value of np.inf will identify clusters across all scales; reducing max_eps will result in shorter run times.

Metric to use for distance computation. Any metric from scikit-learn or scipy.spatial.distance can be used.

If metric is a callable function, it is called on each pair of instances (rows) and the resulting value recorded. The callable should take two arrays as input and return one value indicating the distance between them. This works for Scipy’s metrics, but is less efficient than passing the metric name as a string. If metric is “precomputed”, X is assumed to be a distance matrix and must be square.

Valid values for metric are:

from scikit-learn: [‘cityblock’, ‘cosine’, ‘euclidean’, ‘l1’, ‘l2’, ‘manhattan’]

from scipy.spatial.distance: [‘braycurtis’, ‘canberra’, ‘chebyshev’, ‘correlation’, ‘dice’, ‘hamming’, ‘jaccard’, ‘kulsinski’, ‘mahalanobis’, ‘minkowski’, ‘rogerstanimoto’, ‘russellrao’, ‘seuclidean’, ‘sokalmichener’, ‘sokalsneath’, ‘sqeuclidean’, ‘yule’]

Sparse matrices are only supported by scikit-learn metrics. See scipy.spatial.distance for details on these metrics.

'kulsinski' is deprecated from SciPy 1.9 and will be removed in SciPy 1.11.

Parameter for the Minkowski metric from pairwise_distances. When p = 1, this is equivalent to using manhattan_distance (l1), and euclidean_distance (l2) for p = 2. For arbitrary p, minkowski_distance (l_p) is used.

Additional keyword arguments for the metric function.

The extraction method used to extract clusters using the calculated reachability and ordering.

The maximum distance between two samples for one to be considered as in the neighborhood of the other. By default it assumes the same value as max_eps. Used only when cluster_method='dbscan'.

Determines the minimum steepness on the reachability plot that constitutes a cluster boundary. For example, an upwards point in the reachability plot is defined by the ratio from one point to its successor being at most 1-xi. Used only when cluster_method='xi'.

Correct clusters according to the predecessors calculated by OPTICS [2]. This parameter has minimal effect on most datasets. Used only when cluster_method='xi'.

Minimum number of samples in an OPTICS cluster, expressed as an absolute number or a fraction of the number of samples (rounded to be at least 2). If None, the value of min_samples is used instead. Used only when cluster_method='xi'.

Algorithm used to compute the nearest neighbors:

‘ball_tree’ will use BallTree.

‘kd_tree’ will use KDTree.

‘brute’ will use a brute-force search.

‘auto’ (default) will attempt to decide the most appropriate algorithm based on the values passed to fit method.

Note: fitting on sparse input will override the setting of this parameter, using brute force.

Leaf size passed to BallTree or KDTree. This can affect the speed of the construction and query, as well as the memory required to store the tree. The optimal value depends on the nature of the problem.

Used to cache the output of the computation of the tree. By default, no caching is done. If a string is given, it is the path to the caching directory.

The number of parallel jobs to run for neighbors search. None means 1 unless in a joblib.parallel_backend context. -1 means using all processors. See Glossary for more details.

Cluster labels for each point in the dataset given to fit(). Noisy samples and points which are not included in a leaf cluster of cluster_hierarchy_ are labeled as -1.

Reachability distances per sample, indexed by object order. Use clust.reachability_[clust.ordering_] to access in cluster order.

The cluster ordered list of sample indices.

Distance at which each sample becomes a core point, indexed by object order. Points which will never be core have a distance of inf. Use clust.core_distances_[clust.ordering_] to access in cluster order.

Point that a sample was reached from, indexed by object order. Seed points have a predecessor of -1.

The list of clusters in the form of [start, end] in each row, with all indices inclusive. The clusters are ordered according to (end, -start) (ascending) so that larger clusters encompassing smaller clusters come after those smaller ones. Since labels_ does not reflect the hierarchy, usually len(cluster_hierarchy_) > np.unique(optics.labels_). Please also note that these indices are of the ordering_, i.e. X[ordering_][start:end + 1] form a cluster. Only available when cluster_method='xi'.

Number of features seen during fit.

Added in version 0.24.

Names of features seen during fit. Defined only when X has feature names that are all strings.

Added in version 1.0.

A similar clustering for a specified neighborhood radius (eps). Our implementation is optimized for runtime.

Ankerst, Mihael, Markus M. Breunig, Hans-Peter Kriegel, and Jörg Sander. “OPTICS: ordering points to identify the clustering structure.” ACM SIGMOD Record 28, no. 2 (1999): 49-60.

Schubert, Erich, Michael Gertz. “Improving the Cluster Structure Extracted from OPTICS Plots.” Proc. of the Conference “Lernen, Wissen, Daten, Analysen” (LWDA) (2018): 318-329.

For a more detailed example see Demo of OPTICS clustering algorithm.

For a comparison of OPTICS with other clustering algorithms, see Comparing different clustering algorithms on toy datasets

Perform OPTICS clustering.

Extracts an ordered list of points and reachability distances, and performs initial clustering using max_eps distance specified at OPTICS object instantiation.

A feature array, or array of distances between samples if metric=’precomputed’. If a sparse matrix is provided, it will be converted into CSR format.

Not used, present for API consistency by convention.

Returns a fitted instance of self.

Perform clustering on X and returns cluster labels.

Not used, present for API consistency by convention.

Arguments to be passed to fit.

Added in version 1.4.

Get metadata routing of this object.

Please check User Guide on how the routing mechanism works.

A MetadataRequest encapsulating routing information.

Get parameters for this estimator.

If True, will return the parameters for this estimator and contained subobjects that are estimators.

Parameter names mapped to their values.

Set the parameters of this estimator.

The method works on simple estimators as well as on nested objects (such as Pipeline). The latter have parameters of the form <component>__<parameter> so that it’s possible to update each component of a nested object.

Estimator parameters.

Comparing different clustering algorithms on toy datasets

Demo of OPTICS clustering algorithm

**Examples:**

Example 1 (sql):
```sql
>>> from sklearn.cluster import OPTICS
>>> import numpy as np
>>> X = np.array([[1, 2], [2, 5], [3, 6],
...               [8, 7], [8, 8], [7, 3]])
>>> clustering = OPTICS(min_samples=2).fit(X)
>>> clustering.labels_
array([0, 0, 0, 1, 1, 1])
```

---

## SGDOneClassSVM#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDOneClassSVM.html

**Contents:**
- SGDOneClassSVM#
- Gallery examples#

Solves linear One-Class SVM using Stochastic Gradient Descent.

This implementation is meant to be used with a kernel approximation technique (e.g. sklearn.kernel_approximation.Nystroem) to obtain results similar to sklearn.svm.OneClassSVM which uses a Gaussian kernel by default.

Read more in the User Guide.

Added in version 1.0.

The nu parameter of the One Class SVM: an upper bound on the fraction of training errors and a lower bound of the fraction of support vectors. Should be in the interval (0, 1]. By default 0.5 will be taken.

Whether the intercept should be estimated or not. Defaults to True.

The maximum number of passes over the training data (aka epochs). It only impacts the behavior in the fit method, and not the partial_fit. Defaults to 1000. Values must be in the range [1, inf).

The stopping criterion. If it is not None, the iterations will stop when (loss > previous_loss - tol). Defaults to 1e-3. Values must be in the range [0.0, inf).

Whether or not the training data should be shuffled after each epoch. Defaults to True.

The seed of the pseudo random number generator to use when shuffling the data. If int, random_state is the seed used by the random number generator; If RandomState instance, random_state is the random number generator; If None, the random number generator is the RandomState instance used by np.random.

The learning rate schedule to use with fit. (If using partial_fit, learning rate must be controlled directly).

‘constant’: eta = eta0

‘optimal’: eta = 1.0 / (alpha * (t + t0)) where t0 is chosen by a heuristic proposed by Leon Bottou.

‘invscaling’: eta = eta0 / pow(t, power_t)

‘adaptive’: eta = eta0, as long as the training keeps decreasing. Each time n_iter_no_change consecutive epochs fail to decrease the training loss by tol or fail to increase validation score by tol if early_stopping is True, the current learning rate is divided by 5.

The initial learning rate for the ‘constant’, ‘invscaling’ or ‘adaptive’ schedules. The default value is 0.0, but note that eta0 is not used by the default learning rate ‘optimal’. Values must be in the range (0.0, inf).

The exponent for inverse scaling learning rate. Values must be in the range [0.0, inf).

Deprecated since version 1.8: Negative values for power_t are deprecated in version 1.8 and will raise an error in 1.10. Use values in the range [0.0, inf) instead.

When set to True, reuse the solution of the previous call to fit as initialization, otherwise, just erase the previous solution. See the Glossary.

Repeatedly calling fit or partial_fit when warm_start is True can result in a different solution than when calling fit a single time because of the way the data is shuffled. If a dynamic learning rate is used, the learning rate is adapted depending on the number of samples already seen. Calling fit resets this counter, while partial_fit will result in increasing the existing counter.

When set to True, computes the averaged SGD weights and stores the result in the coef_ attribute. If set to an int greater than 1, averaging will begin once the total number of samples seen reaches average. So average=10 will begin averaging after seeing 10 samples.

Weights assigned to the features.

Offset used to define the decision function from the raw scores. We have the relation: decision_function = score_samples - offset.

The actual number of iterations to reach the stopping criterion.

Number of weight updates performed during training. Same as (n_iter_ * n_samples + 1).

Number of features seen during fit.

Added in version 0.24.

Names of features seen during fit. Defined only when X has feature names that are all strings.

Added in version 1.0.

Unsupervised Outlier Detection.

This estimator has a linear complexity in the number of training samples and is thus better suited than the sklearn.svm.OneClassSVM implementation for datasets with a large number of training samples (say > 10,000).

Signed distance to the separating hyperplane.

Signed distance is positive for an inlier and negative for an outlier.

Decision function values of the samples.

Convert coefficient matrix to dense array format.

Converts the coef_ member (back) to a numpy.ndarray. This is the default format of coef_ and is required for fitting, so calling this method is only required on models that have previously been sparsified; otherwise, it is a no-op.

Fit linear One-Class SVM with Stochastic Gradient Descent.

This solves an equivalent optimization problem of the One-Class SVM primal optimization problem and returns a weight vector w and an offset rho such that the decision function is given by <w, x> - rho.

Not used, present for API consistency by convention.

The initial coefficients to warm-start the optimization.

The initial offset to warm-start the optimization.

Weights applied to individual samples. If not provided, uniform weights are assumed. These weights will be multiplied with class_weight (passed through the constructor) if class_weight is specified.

Returns a fitted instance of self.

Perform fit on X and returns labels for X.

Returns -1 for outliers and 1 for inliers.

Not used, present for API consistency by convention.

Arguments to be passed to fit.

Added in version 1.4.

1 for inliers, -1 for outliers.

Get metadata routing of this object.

Please check User Guide on how the routing mechanism works.

A MetadataRequest encapsulating routing information.

Get parameters for this estimator.

If True, will return the parameters for this estimator and contained subobjects that are estimators.

Parameter names mapped to their values.

Fit linear One-Class SVM with Stochastic Gradient Descent.

Subset of the training data.

Not used, present for API consistency by convention.

Weights applied to individual samples. If not provided, uniform weights are assumed.

Returns a fitted instance of self.

Return labels (1 inlier, -1 outlier) of the samples.

Labels of the samples.

Raw scoring function of the samples.

Unshiffted scoring function values of the samples.

Configure whether metadata should be requested to be passed to the fit method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to fit if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to fit.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Added in version 1.3.

Metadata routing for coef_init parameter in fit.

Metadata routing for offset_init parameter in fit.

Metadata routing for sample_weight parameter in fit.

Set the parameters of this estimator.

The method works on simple estimators as well as on nested objects (such as Pipeline). The latter have parameters of the form <component>__<parameter> so that it’s possible to update each component of a nested object.

Estimator parameters.

Configure whether metadata should be requested to be passed to the partial_fit method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to partial_fit if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to partial_fit.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Added in version 1.3.

Metadata routing for sample_weight parameter in partial_fit.

Convert coefficient matrix to sparse format.

Converts the coef_ member to a scipy.sparse matrix, which for L1-regularized models can be much more memory- and storage-efficient than the usual numpy.ndarray representation.

The intercept_ member is not converted.

For non-sparse models, i.e. when there are not many zeros in coef_, this may actually increase memory usage, so use this method with care. A rule of thumb is that the number of zero elements, which can be computed with (coef_ == 0).sum(), must be more than 50% for this to provide significant benefits.

After calling this method, further fitting with the partial_fit method (if any) will not work until you call densify.

One-Class SVM versus One-Class SVM using Stochastic Gradient Descent

Comparing anomaly detection algorithms for outlier detection on toy datasets

**Examples:**

Example 1 (python):
```python
>>> import numpy as np
>>> from sklearn import linear_model
>>> X = np.array([[-1, -1], [-2, -1], [1, 1], [2, 1]])
>>> clf = linear_model.SGDOneClassSVM(random_state=42, tol=None)
>>> clf.fit(X)
SGDOneClassSVM(random_state=42, tol=None)
```

Example 2 (json):
```json
>>> print(clf.predict([[4, 4]]))
[1]
```

---

## AdaBoostClassifier#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html

**Contents:**
- AdaBoostClassifier#
- Gallery examples#

An AdaBoost classifier.

An AdaBoost [1] classifier is a meta-estimator that begins by fitting a classifier on the original dataset and then fits additional copies of the classifier on the same dataset but where the weights of incorrectly classified instances are adjusted such that subsequent classifiers focus more on difficult cases.

This class implements the algorithm based on [2].

Read more in the User Guide.

Added in version 0.14.

The base estimator from which the boosted ensemble is built. Support for sample weighting is required, as well as proper classes_ and n_classes_ attributes. If None, then the base estimator is DecisionTreeClassifier initialized with max_depth=1.

Added in version 1.2: base_estimator was renamed to estimator.

The maximum number of estimators at which boosting is terminated. In case of perfect fit, the learning procedure is stopped early. Values must be in the range [1, inf).

Weight applied to each classifier at each boosting iteration. A higher learning rate increases the contribution of each classifier. There is a trade-off between the learning_rate and n_estimators parameters. Values must be in the range (0.0, inf).

Controls the random seed given at each estimator at each boosting iteration. Thus, it is only used when estimator exposes a random_state. Pass an int for reproducible output across multiple function calls. See Glossary.

The base estimator from which the ensemble is grown.

Added in version 1.2: base_estimator_ was renamed to estimator_.

The collection of fitted sub-estimators.

The number of classes.

Weights for each estimator in the boosted ensemble.

Classification error for each estimator in the boosted ensemble.

The impurity-based feature importances.

Number of features seen during fit.

Added in version 0.24.

Names of features seen during fit. Defined only when X has feature names that are all strings.

Added in version 1.0.

An AdaBoost regressor that begins by fitting a regressor on the original dataset and then fits additional copies of the regressor on the same dataset but where the weights of instances are adjusted according to the error of the current prediction.

GB builds an additive model in a forward stage-wise fashion. Regression trees are fit on the negative gradient of the binomial or multinomial deviance loss function. Binary classification is a special case where only a single regression tree is induced.

A non-parametric supervised learning method used for classification. Creates a model that predicts the value of a target variable by learning simple decision rules inferred from the data features.

Y. Freund, R. Schapire, “A Decision-Theoretic Generalization of on-Line Learning and an Application to Boosting”, 1995.

J. Zhu, H. Zou, S. Rosset, T. Hastie, “Multi-class adaboost.” Statistics and its Interface 2.3 (2009): 349-360.

For a detailed example of using AdaBoost to fit a sequence of DecisionTrees as weaklearners, please refer to Multi-class AdaBoosted Decision Trees.

For a detailed example of using AdaBoost to fit a non-linearly separable classification dataset composed of two Gaussian quantiles clusters, please refer to Two-class AdaBoost.

Compute the decision function of X.

The training input samples. Sparse matrix can be CSC, CSR, COO, DOK, or LIL. COO, DOK, and LIL are converted to CSR.

The decision function of the input samples. The order of outputs is the same as that of the classes_ attribute. Binary classification is a special cases with k == 1, otherwise k==n_classes. For binary classification, values closer to -1 or 1 mean more like the first or second class in classes_, respectively.

Build a boosted classifier/regressor from the training set (X, y).

The training input samples. Sparse matrix can be CSC, CSR, COO, DOK, or LIL. COO, DOK, and LIL are converted to CSR.

Sample weights. If None, the sample weights are initialized to 1 / n_samples.

Raise NotImplementedError.

This estimator does not support metadata routing yet.

Get parameters for this estimator.

If True, will return the parameters for this estimator and contained subobjects that are estimators.

Parameter names mapped to their values.

Predict classes for X.

The predicted class of an input sample is computed as the weighted mean prediction of the classifiers in the ensemble.

The training input samples. Sparse matrix can be CSC, CSR, COO, DOK, or LIL. COO, DOK, and LIL are converted to CSR.

The predicted classes.

Predict class log-probabilities for X.

The predicted class log-probabilities of an input sample is computed as the weighted mean predicted class log-probabilities of the classifiers in the ensemble.

The training input samples. Sparse matrix can be CSC, CSR, COO, DOK, or LIL. COO, DOK, and LIL are converted to CSR.

The class probabilities of the input samples. The order of outputs is the same of that of the classes_ attribute.

Predict class probabilities for X.

The predicted class probabilities of an input sample is computed as the weighted mean predicted class probabilities of the classifiers in the ensemble.

The training input samples. Sparse matrix can be CSC, CSR, COO, DOK, or LIL. COO, DOK, and LIL are converted to CSR.

The class probabilities of the input samples. The order of outputs is the same of that of the classes_ attribute.

Return accuracy on provided data and labels.

In multi-label classification, this is the subset accuracy which is a harsh metric since you require for each sample that each label set be correctly predicted.

Mean accuracy of self.predict(X) w.r.t. y.

Configure whether metadata should be requested to be passed to the fit method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to fit if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to fit.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Added in version 1.3.

Metadata routing for sample_weight parameter in fit.

Set the parameters of this estimator.

The method works on simple estimators as well as on nested objects (such as Pipeline). The latter have parameters of the form <component>__<parameter> so that it’s possible to update each component of a nested object.

Estimator parameters.

Configure whether metadata should be requested to be passed to the score method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to score if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to score.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Added in version 1.3.

Metadata routing for sample_weight parameter in score.

Compute decision function of X for each boosting iteration.

This method allows monitoring (i.e. determine error on testing set) after each boosting iteration.

The training input samples. Sparse matrix can be CSC, CSR, COO, DOK, or LIL. COO, DOK, and LIL are converted to CSR.

The decision function of the input samples. The order of outputs is the same of that of the classes_ attribute. Binary classification is a special cases with k == 1, otherwise k==n_classes. For binary classification, values closer to -1 or 1 mean more like the first or second class in classes_, respectively.

Return staged predictions for X.

The predicted class of an input sample is computed as the weighted mean prediction of the classifiers in the ensemble.

This generator method yields the ensemble prediction after each iteration of boosting and therefore allows monitoring, such as to determine the prediction on a test set after each boost.

The input samples. Sparse matrix can be CSC, CSR, COO, DOK, or LIL. COO, DOK, and LIL are converted to CSR.

The predicted classes.

Predict class probabilities for X.

The predicted class probabilities of an input sample is computed as the weighted mean predicted class probabilities of the classifiers in the ensemble.

This generator method yields the ensemble predicted class probabilities after each iteration of boosting and therefore allows monitoring, such as to determine the predicted class probabilities on a test set after each boost.

The training input samples. Sparse matrix can be CSC, CSR, COO, DOK, or LIL. COO, DOK, and LIL are converted to CSR.

The class probabilities of the input samples. The order of outputs is the same of that of the classes_ attribute.

Return staged scores for X, y.

This generator method yields the ensemble score after each iteration of boosting and therefore allows monitoring, such as to determine the score on a test set after each boost.

The training input samples. Sparse matrix can be CSC, CSR, COO, DOK, or LIL. COO, DOK, and LIL are converted to CSR.

Classifier comparison

Multi-class AdaBoosted Decision Trees

Plot the decision surfaces of ensembles of trees on the iris dataset

**Examples:**

Example 1 (sql):
```sql
>>> from sklearn.ensemble import AdaBoostClassifier
>>> from sklearn.datasets import make_classification
>>> X, y = make_classification(n_samples=1000, n_features=4,
...                            n_informative=2, n_redundant=0,
...                            random_state=0, shuffle=False)
>>> clf = AdaBoostClassifier(n_estimators=100, random_state=0)
>>> clf.fit(X, y)
AdaBoostClassifier(n_estimators=100, random_state=0)
>>> clf.predict([[0, 0, 0, 0]])
array([1])
>>> clf.score(X, y)
0.96
```

---

## kmeans_plusplus#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.cluster.kmeans_plusplus.html

**Contents:**
- kmeans_plusplus#
- Gallery examples#

Init n_clusters seeds according to k-means++.

Added in version 0.24.

The data to pick seeds from.

The number of centroids to initialize.

The weights for each observation in X. If None, all observations are assigned equal weight. sample_weight is ignored if init is a callable or a user provided array.

Added in version 1.3.

Squared Euclidean norm of each data point.

Determines random number generation for centroid initialization. Pass an int for reproducible output across multiple function calls. See Glossary.

The number of seeding trials for each center (except the first), of which the one reducing inertia the most is greedily chosen. Set to None to make the number of trials depend logarithmically on the number of seeds (2+log(k)) which is the recommended setting. Setting to 1 disables the greedy cluster selection and recovers the vanilla k-means++ algorithm which was empirically shown to work less well than its greedy variant.

The initial centers for k-means.

The index location of the chosen centers in the data array X. For a given index and center, X[index] = center.

Selects initial cluster centers for k-mean clustering in a smart way to speed up convergence. see: Arthur, D. and Vassilvitskii, S. “k-means++: the advantages of careful seeding”. ACM-SIAM symposium on Discrete algorithms. 2007

An example of K-Means++ initialization

**Examples:**

Example 1 (sql):
```sql
>>> from sklearn.cluster import kmeans_plusplus
>>> import numpy as np
>>> X = np.array([[1, 2], [1, 4], [1, 0],
...               [10, 2], [10, 4], [10, 0]])
>>> centers, indices = kmeans_plusplus(X, n_clusters=2, random_state=0)
>>> centers
array([[10,  2],
       [ 1,  0]])
>>> indices
array([3, 2])
```

---

## GaussianProcessRegressor#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.gaussian_process.GaussianProcessRegressor.html

**Contents:**
- GaussianProcessRegressor#
- Gallery examples#

Gaussian process regression (GPR).

The implementation is based on Algorithm 2.1 of [RW2006].

In addition to standard scikit-learn estimator API, GaussianProcessRegressor:

allows prediction without prior fitting (based on the GP prior)

provides an additional method sample_y(X), which evaluates samples drawn from the GPR (prior or posterior) at given inputs

exposes a method log_marginal_likelihood(theta), which can be used externally for other ways of selecting hyperparameters, e.g., via Markov chain Monte Carlo.

To learn the difference between a point-estimate approach vs. a more Bayesian modelling approach, refer to the example entitled Comparison of kernel ridge and Gaussian process regression.

Read more in the User Guide.

Added in version 0.18.

The kernel specifying the covariance function of the GP. If None is passed, the kernel ConstantKernel(1.0, constant_value_bounds="fixed") * RBF(1.0, length_scale_bounds="fixed") is used as default. Note that the kernel hyperparameters are optimized during fitting unless the bounds are marked as “fixed”.

Value added to the diagonal of the kernel matrix during fitting. This can prevent a potential numerical issue during fitting, by ensuring that the calculated values form a positive definite matrix. It can also be interpreted as the variance of additional Gaussian measurement noise on the training observations. Note that this is different from using a WhiteKernel. If an array is passed, it must have the same number of entries as the data used for fitting and is used as datapoint-dependent noise level. Allowing to specify the noise level directly as a parameter is mainly for convenience and for consistency with Ridge. For an example illustrating how the alpha parameter controls the noise variance in Gaussian Process Regression, see Gaussian Processes regression: basic introductory example.

Can either be one of the internally supported optimizers for optimizing the kernel’s parameters, specified by a string, or an externally defined optimizer passed as a callable. If a callable is passed, it must have the signature:

Per default, the L-BFGS-B algorithm from scipy.optimize.minimize is used. If None is passed, the kernel’s parameters are kept fixed. Available internal optimizers are: {'fmin_l_bfgs_b'}.

The number of restarts of the optimizer for finding the kernel’s parameters which maximize the log-marginal likelihood. The first run of the optimizer is performed from the kernel’s initial parameters, the remaining ones (if any) from thetas sampled log-uniform randomly from the space of allowed theta-values. If greater than 0, all bounds must be finite. Note that n_restarts_optimizer == 0 implies that one run is performed.

Whether or not to normalize the target values y by removing the mean and scaling to unit-variance. This is recommended for cases where zero-mean, unit-variance priors are used. Note that, in this implementation, the normalisation is reversed before the GP predictions are reported.

Changed in version 0.23.

If True, a persistent copy of the training data is stored in the object. Otherwise, just a reference to the training data is stored, which might cause predictions to change if the data is modified externally.

The number of dimensions of the target values. Used to decide the number of outputs when sampling from the prior distributions (i.e. calling sample_y before fit). This parameter is ignored once fit has been called.

Added in version 1.3.

Determines random number generation used to initialize the centers. Pass an int for reproducible results across multiple function calls. See Glossary.

Feature vectors or other representations of training data (also required for prediction).

Target values in training data (also required for prediction).

The kernel used for prediction. The structure of the kernel is the same as the one passed as parameter but with optimized hyperparameters.

Lower-triangular Cholesky decomposition of the kernel in X_train_.

Dual coefficients of training data points in kernel space.

The log-marginal-likelihood of self.kernel_.theta.

Number of features seen during fit.

Added in version 0.24.

Names of features seen during fit. Defined only when X has feature names that are all strings.

Added in version 1.0.

Gaussian process classification (GPC) based on Laplace approximation.

Carl E. Rasmussen and Christopher K.I. Williams, “Gaussian Processes for Machine Learning”, MIT Press 2006

Fit Gaussian process regression model.

Feature vectors or other representations of training data.

GaussianProcessRegressor class instance.

Get metadata routing of this object.

Please check User Guide on how the routing mechanism works.

A MetadataRequest encapsulating routing information.

Get parameters for this estimator.

If True, will return the parameters for this estimator and contained subobjects that are estimators.

Parameter names mapped to their values.

Return log-marginal likelihood of theta for training data.

Kernel hyperparameters for which the log-marginal likelihood is evaluated. If None, the precomputed log_marginal_likelihood of self.kernel_.theta is returned.

If True, the gradient of the log-marginal likelihood with respect to the kernel hyperparameters at position theta is returned additionally. If True, theta must not be None.

If True, the kernel attribute is copied. If False, the kernel attribute is modified, but may result in a performance improvement.

Log-marginal likelihood of theta for training data.

Gradient of the log-marginal likelihood with respect to the kernel hyperparameters at position theta. Only returned when eval_gradient is True.

Predict using the Gaussian process regression model.

We can also predict based on an unfitted model by using the GP prior. In addition to the mean of the predictive distribution, optionally also returns its standard deviation (return_std=True) or covariance (return_cov=True). Note that at most one of the two can be requested.

Query points where the GP is evaluated.

If True, the standard-deviation of the predictive distribution at the query points is returned along with the mean.

If True, the covariance of the joint predictive distribution at the query points is returned along with the mean.

Mean of predictive distribution at query points.

Standard deviation of predictive distribution at query points. Only returned when return_std is True.

Covariance of joint predictive distribution at query points. Only returned when return_cov is True.

Draw samples from Gaussian process and evaluate at X.

Query points where the GP is evaluated.

Number of samples drawn from the Gaussian process per query point.

Determines random number generation to randomly draw samples. Pass an int for reproducible results across multiple function calls. See Glossary.

Values of n_samples samples drawn from Gaussian process and evaluated at query points.

Return coefficient of determination on test data.

The coefficient of determination, \(R^2\), is defined as \((1 - \frac{u}{v})\), where \(u\) is the residual sum of squares ((y_true - y_pred)** 2).sum() and \(v\) is the total sum of squares ((y_true - y_true.mean()) ** 2).sum(). The best possible score is 1.0 and it can be negative (because the model can be arbitrarily worse). A constant model that always predicts the expected value of y, disregarding the input features, would get a \(R^2\) score of 0.0.

Test samples. For some estimators this may be a precomputed kernel matrix or a list of generic objects instead with shape (n_samples, n_samples_fitted), where n_samples_fitted is the number of samples used in the fitting for the estimator.

\(R^2\) of self.predict(X) w.r.t. y.

The \(R^2\) score used when calling score on a regressor uses multioutput='uniform_average' from version 0.23 to keep consistent with default value of r2_score. This influences the score method of all the multioutput regressors (except for MultiOutputRegressor).

Set the parameters of this estimator.

The method works on simple estimators as well as on nested objects (such as Pipeline). The latter have parameters of the form <component>__<parameter> so that it’s possible to update each component of a nested object.

Estimator parameters.

Configure whether metadata should be requested to be passed to the predict method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to predict if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to predict.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Added in version 1.3.

Metadata routing for return_cov parameter in predict.

Metadata routing for return_std parameter in predict.

Configure whether metadata should be requested to be passed to the score method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to score if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to score.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Added in version 1.3.

Metadata routing for sample_weight parameter in score.

Comparison of kernel ridge and Gaussian process regression

Forecasting of CO2 level on Mona Loa dataset using Gaussian process regression (GPR)

Ability of Gaussian process regression (GPR) to estimate data noise-level

Gaussian Processes regression: basic introductory example

Gaussian processes on discrete data structures

Illustration of prior and posterior Gaussian process for different kernels

**Examples:**

Example 1 (python):
```python
def optimizer(obj_func, initial_theta, bounds):
    # * 'obj_func': the objective function to be minimized, which
    #   takes the hyperparameters theta as a parameter and an
    #   optional flag eval_gradient, which determines if the
    #   gradient is returned additionally to the function value
    # * 'initial_theta': the initial value for theta, which can be
    #   used by local optimizers
    # * 'bounds': the bounds on the values of theta
    ....
    # Returned are the best found hyperparameters theta and
    # the corresponding value of the target function.
    return theta_opt, func_min
```

Example 2 (sql):
```sql
>>> from sklearn.datasets import make_friedman2
>>> from sklearn.gaussian_process import GaussianProcessRegressor
>>> from sklearn.gaussian_process.kernels import DotProduct, WhiteKernel
>>> X, y = make_friedman2(n_samples=500, noise=0, random_state=0)
>>> kernel = DotProduct() + WhiteKernel()
>>> gpr = GaussianProcessRegressor(kernel=kernel,
...         random_state=0).fit(X, y)
>>> gpr.score(X, y)
0.3680...
>>> gpr.predict(X[:2,:], return_std=True)
(array([653.0, 592.1]), array([316.6, 316.6]))
```

---

## PLSCanonical#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.cross_decomposition.PLSCanonical.html

**Contents:**
- PLSCanonical#
- Gallery examples#

Partial Least Squares transformer and regressor.

For a comparison between other cross decomposition algorithms, see Compare cross decomposition methods.

Read more in the User Guide.

Added in version 0.8.

Number of components to keep. Should be in [1, min(n_samples, n_features, n_targets)].

Whether to scale X and y.

The algorithm used to estimate the first singular vectors of the cross-covariance matrix. ‘nipals’ uses the power method while ‘svd’ will compute the whole SVD.

The maximum number of iterations of the power method when algorithm='nipals'. Ignored otherwise.

The tolerance used as convergence criteria in the power method: the algorithm stops whenever the squared norm of u_i - u_{i-1} is less than tol, where u corresponds to the left singular vector.

Whether to copy X and y in fit before applying centering, and potentially scaling. If False, these operations will be done inplace, modifying both arrays.

The left singular vectors of the cross-covariance matrices of each iteration.

The right singular vectors of the cross-covariance matrices of each iteration.

The projection matrix used to transform X.

The projection matrix used to transform y.

The coefficients of the linear model such that y is approximated as y = X @ coef_.T + intercept_.

The intercepts of the linear model such that y is approximated as y = X @ coef_.T + intercept_.

Added in version 1.1.

Number of iterations of the power method, for each component. Empty if algorithm='svd'.

Number of features seen during fit.

Names of features seen during fit. Defined only when X has feature names that are all strings.

Added in version 1.0.

Canonical Correlation Analysis.

Partial Least Square SVD.

Training vectors, where n_samples is the number of samples and n_features is the number of predictors.

Target vectors, where n_samples is the number of samples and n_targets is the number of response variables.

Learn and apply the dimension reduction on the train data.

Training vectors, where n_samples is the number of samples and n_features is the number of predictors.

Target vectors, where n_samples is the number of samples and n_targets is the number of response variables.

Return x_scores if y is not given, (x_scores, y_scores) otherwise.

Get output feature names for transformation.

The feature names out will prefixed by the lowercased class name. For example, if the transformer outputs 3 features, then the feature names out are: ["class_name0", "class_name1", "class_name2"].

Only used to validate feature names with the names seen in fit.

Transformed feature names.

Get metadata routing of this object.

Please check User Guide on how the routing mechanism works.

A MetadataRequest encapsulating routing information.

Get parameters for this estimator.

If True, will return the parameters for this estimator and contained subobjects that are estimators.

Parameter names mapped to their values.

Transform data back to its original space.

New data, where n_samples is the number of samples and n_components is the number of pls components.

New target, where n_samples is the number of samples and n_components is the number of pls components.

Return the reconstructed X data.

Return the reconstructed X target. Only returned when y is given.

This transformation will only be exact if n_components=n_features.

Predict targets of given samples.

Whether to copy X or perform in-place normalization.

Returns predicted values.

This call requires the estimation of a matrix of shape (n_features, n_targets), which may be an issue in high dimensional space.

Return coefficient of determination on test data.

The coefficient of determination, \(R^2\), is defined as \((1 - \frac{u}{v})\), where \(u\) is the residual sum of squares ((y_true - y_pred)** 2).sum() and \(v\) is the total sum of squares ((y_true - y_true.mean()) ** 2).sum(). The best possible score is 1.0 and it can be negative (because the model can be arbitrarily worse). A constant model that always predicts the expected value of y, disregarding the input features, would get a \(R^2\) score of 0.0.

Test samples. For some estimators this may be a precomputed kernel matrix or a list of generic objects instead with shape (n_samples, n_samples_fitted), where n_samples_fitted is the number of samples used in the fitting for the estimator.

\(R^2\) of self.predict(X) w.r.t. y.

The \(R^2\) score used when calling score on a regressor uses multioutput='uniform_average' from version 0.23 to keep consistent with default value of r2_score. This influences the score method of all the multioutput regressors (except for MultiOutputRegressor).

Set output container.

See Introducing the set_output API for an example on how to use the API.

Configure output of transform and fit_transform.

"default": Default output format of a transformer

"pandas": DataFrame output

"polars": Polars output

None: Transform configuration is unchanged

Added in version 1.4: "polars" option was added.

Set the parameters of this estimator.

The method works on simple estimators as well as on nested objects (such as Pipeline). The latter have parameters of the form <component>__<parameter> so that it’s possible to update each component of a nested object.

Estimator parameters.

Configure whether metadata should be requested to be passed to the predict method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to predict if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to predict.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Added in version 1.3.

Metadata routing for copy parameter in predict.

Configure whether metadata should be requested to be passed to the score method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to score if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to score.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Added in version 1.3.

Metadata routing for sample_weight parameter in score.

Configure whether metadata should be requested to be passed to the transform method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to transform if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to transform.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Added in version 1.3.

Metadata routing for copy parameter in transform.

Apply the dimension reduction.

Samples to transform.

Whether to copy X and y, or perform in-place normalization.

Return x_scores if y is not given, (x_scores, y_scores) otherwise.

Compare cross decomposition methods

**Examples:**

Example 1 (csharp):
```csharp
>>> from sklearn.cross_decomposition import PLSCanonical
>>> X = [[0., 0., 1.], [1.,0.,0.], [2.,2.,2.], [2.,5.,4.]]
>>> y = [[0.1, -0.2], [0.9, 1.1], [6.2, 5.9], [11.9, 12.3]]
>>> plsca = PLSCanonical(n_components=2)
>>> plsca.fit(X, y)
PLSCanonical()
>>> X_c, y_c = plsca.transform(X, y)
```

---

## 

**URL:** https://scikit-learn.org/stable/_sources/modules/isotonic.rst.txt

---

## GaussianNB#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html

**Contents:**
- GaussianNB#
- Gallery examples#

Gaussian Naive Bayes (GaussianNB).

Can perform online updates to model parameters via partial_fit. For details on algorithm used to update feature means and variance online, see Stanford CS tech report STAN-CS-79-773 by Chan, Golub, and LeVeque.

Read more in the User Guide.

Prior probabilities of the classes. If specified, the priors are not adjusted according to the data.

Portion of the largest variance of all features that is added to variances for calculation stability.

Added in version 0.20.

number of training samples observed in each class.

probability of each class.

class labels known to the classifier.

absolute additive value to variances.

Number of features seen during fit.

Added in version 0.24.

Names of features seen during fit. Defined only when X has feature names that are all strings.

Added in version 1.0.

Variance of each feature per class.

Added in version 1.0.

mean of each feature per class.

Naive Bayes classifier for multivariate Bernoulli models.

Naive Bayes classifier for categorical features.

Complement Naive Bayes classifier.

Naive Bayes classifier for multinomial models.

Fit Gaussian Naive Bayes according to X, y.

Training vectors, where n_samples is the number of samples and n_features is the number of features.

Weights applied to individual samples (1. for unweighted).

Added in version 0.17: Gaussian Naive Bayes supports fitting with sample_weight.

Returns the instance itself.

Get metadata routing of this object.

Please check User Guide on how the routing mechanism works.

A MetadataRequest encapsulating routing information.

Get parameters for this estimator.

If True, will return the parameters for this estimator and contained subobjects that are estimators.

Parameter names mapped to their values.

Incremental fit on a batch of samples.

This method is expected to be called several times consecutively on different chunks of a dataset so as to implement out-of-core or online learning.

This is especially useful when the whole dataset is too big to fit in memory at once.

This method has some performance and numerical stability overhead, hence it is better to call partial_fit on chunks of data that are as large as possible (as long as fitting in the memory budget) to hide the overhead.

Training vectors, where n_samples is the number of samples and n_features is the number of features.

List of all the classes that can possibly appear in the y vector.

Must be provided at the first call to partial_fit, can be omitted in subsequent calls.

Weights applied to individual samples (1. for unweighted).

Added in version 0.17.

Returns the instance itself.

Perform classification on an array of test vectors X.

Predicted target values for X.

Return joint log probability estimates for the test vector X.

For each row x of X and class y, the joint log probability is given by log P(x, y) = log P(y) + log P(x|y), where log P(y) is the class prior probability and log P(x|y) is the class-conditional probability.

Returns the joint log-probability of the samples for each class in the model. The columns correspond to the classes in sorted order, as they appear in the attribute classes_.

Return log-probability estimates for the test vector X.

Returns the log-probability of the samples for each class in the model. The columns correspond to the classes in sorted order, as they appear in the attribute classes_.

Return probability estimates for the test vector X.

Returns the probability of the samples for each class in the model. The columns correspond to the classes in sorted order, as they appear in the attribute classes_.

Return accuracy on provided data and labels.

In multi-label classification, this is the subset accuracy which is a harsh metric since you require for each sample that each label set be correctly predicted.

Mean accuracy of self.predict(X) w.r.t. y.

Configure whether metadata should be requested to be passed to the fit method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to fit if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to fit.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Added in version 1.3.

Metadata routing for sample_weight parameter in fit.

Set the parameters of this estimator.

The method works on simple estimators as well as on nested objects (such as Pipeline). The latter have parameters of the form <component>__<parameter> so that it’s possible to update each component of a nested object.

Estimator parameters.

Configure whether metadata should be requested to be passed to the partial_fit method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to partial_fit if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to partial_fit.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Added in version 1.3.

Metadata routing for classes parameter in partial_fit.

Metadata routing for sample_weight parameter in partial_fit.

Configure whether metadata should be requested to be passed to the score method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to score if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to score.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Added in version 1.3.

Metadata routing for sample_weight parameter in score.

Probability calibration of classifiers

Probability Calibration curves

Comparison of Calibration of Classifiers

Classifier comparison

Plotting Learning Curves and Checking Models’ Scalability

Release Highlights for scikit-learn 1.8

**Examples:**

Example 1 (python):
```python
>>> import numpy as np
>>> X = np.array([[-1, -1], [-2, -1], [-3, -2], [1, 1], [2, 1], [3, 2]])
>>> Y = np.array([1, 1, 1, 2, 2, 2])
>>> from sklearn.naive_bayes import GaussianNB
>>> clf = GaussianNB()
>>> clf.fit(X, Y)
GaussianNB()
>>> print(clf.predict([[-0.8, -1]]))
[1]
>>> clf_pf = GaussianNB()
>>> clf_pf.partial_fit(X, Y, np.unique(Y))
GaussianNB()
>>> print(clf_pf.predict([[-0.8, -1]]))
[1]
```

---

## SelectFwe#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectFwe.html

**Contents:**
- SelectFwe#

Filter: Select the p-values corresponding to Family-wise error rate.

Read more in the User Guide.

Function taking two arrays X and y, and returning a pair of arrays (scores, pvalues). Default is f_classif (see below “See Also”). The default function only works with classification tasks.

The highest uncorrected p-value for features to keep.

p-values of feature scores.

Number of features seen during fit.

Added in version 0.24.

Names of features seen during fit. Defined only when X has feature names that are all strings.

Added in version 1.0.

ANOVA F-value between label/feature for classification tasks.

Chi-squared stats of non-negative features for classification tasks.

F-value between label/feature for regression tasks.

Select features based on percentile of the highest scores.

Select features based on the k highest scores.

Select features based on a false positive rate test.

Select features based on an estimated false discovery rate.

Univariate feature selector with configurable mode.

Run score function on (X, y) and get the appropriate features.

The training input samples.

The target values (class labels in classification, real numbers in regression). If the selector is unsupervised then y can be set to None.

Returns the instance itself.

Fit to data, then transform it.

Fits transformer to X and y with optional parameters fit_params and returns a transformed version of X.

Target values (None for unsupervised transformations).

Additional fit parameters. Pass only if the estimator accepts additional params in its fit method.

Mask feature names according to selected features.

If input_features is None, then feature_names_in_ is used as feature names in. If feature_names_in_ is not defined, then the following input feature names are generated: ["x0", "x1", ..., "x(n_features_in_ - 1)"].

If input_features is an array-like, then input_features must match feature_names_in_ if feature_names_in_ is defined.

Transformed feature names.

Get metadata routing of this object.

Please check User Guide on how the routing mechanism works.

A MetadataRequest encapsulating routing information.

Get parameters for this estimator.

If True, will return the parameters for this estimator and contained subobjects that are estimators.

Parameter names mapped to their values.

Get a mask, or integer index, of the features selected.

If True, the return value will be an array of integers, rather than a boolean mask.

An index that selects the retained features from a feature vector. If indices is False, this is a boolean array of shape [# input features], in which an element is True iff its corresponding feature is selected for retention. If indices is True, this is an integer array of shape [# output features] whose values are indices into the input feature vector.

Reverse the transformation operation.

X with columns of zeros inserted where features would have been removed by transform.

Set output container.

See Introducing the set_output API for an example on how to use the API.

Configure output of transform and fit_transform.

"default": Default output format of a transformer

"pandas": DataFrame output

"polars": Polars output

None: Transform configuration is unchanged

Added in version 1.4: "polars" option was added.

Set the parameters of this estimator.

The method works on simple estimators as well as on nested objects (such as Pipeline). The latter have parameters of the form <component>__<parameter> so that it’s possible to update each component of a nested object.

Estimator parameters.

Reduce X to the selected features.

The input samples with only the selected features.

**Examples:**

Example 1 (sql):
```sql
>>> from sklearn.datasets import load_breast_cancer
>>> from sklearn.feature_selection import SelectFwe, chi2
>>> X, y = load_breast_cancer(return_X_y=True)
>>> X.shape
(569, 30)
>>> X_new = SelectFwe(chi2, alpha=0.01).fit_transform(X, y)
>>> X_new.shape
(569, 15)
```

---

## Product#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.gaussian_process.kernels.Product.html

**Contents:**
- Product#

The Product kernel takes two kernels \(k_1\) and \(k_2\) and combines them via

Note that the __mul__ magic method is overridden, so Product(RBF(), RBF()) is equivalent to using the * operator with RBF() * RBF().

Read more in the User Guide.

Added in version 0.18.

The first base-kernel of the product-kernel

The second base-kernel of the product-kernel

Return the kernel k(X, Y) and optionally its gradient.

Left argument of the returned kernel k(X, Y)

Right argument of the returned kernel k(X, Y). If None, k(X, X) is evaluated instead.

Determines whether the gradient with respect to the log of the kernel hyperparameter is computed.

The gradient of the kernel k(X, X) with respect to the log of the hyperparameter of the kernel. Only returned when eval_gradient is True.

Returns the log-transformed bounds on the theta.

The log-transformed bounds on the kernel’s hyperparameters theta

Returns a clone of self with given hyperparameters theta.

Returns the diagonal of the kernel k(X, X).

The result of this method is identical to np.diag(self(X)); however, it can be evaluated more efficiently since only the diagonal is evaluated.

Argument to the kernel.

Diagonal of kernel k(X, X)

Get parameters of this kernel.

If True, will return the parameters for this estimator and contained subobjects that are estimators.

Parameter names mapped to their values.

Returns a list of all hyperparameter.

Returns whether the kernel is stationary.

Returns the number of non-fixed hyperparameters of the kernel.

Returns whether the kernel is stationary.

Set the parameters of this kernel.

The method works on simple kernels as well as on nested kernels. The latter have parameters of the form <component>__<parameter> so that it’s possible to update each component of a nested object.

Returns the (flattened, log-transformed) non-fixed hyperparameters.

Note that theta are typically the log-transformed values of the kernel’s hyperparameters as this representation of the search space is more amenable for hyperparameter search, as hyperparameters like length-scales naturally live on a log-scale.

The non-fixed, log-transformed hyperparameters of the kernel

**Examples:**

Example 1 (sql):
```sql
>>> from sklearn.datasets import make_friedman2
>>> from sklearn.gaussian_process import GaussianProcessRegressor
>>> from sklearn.gaussian_process.kernels import (RBF, Product,
...            ConstantKernel)
>>> X, y = make_friedman2(n_samples=500, noise=0, random_state=0)
>>> kernel = Product(ConstantKernel(2), RBF())
>>> gpr = GaussianProcessRegressor(kernel=kernel,
...         random_state=0).fit(X, y)
>>> gpr.score(X, y)
1.0
>>> kernel
1.41**2 * RBF(length_scale=1)
```

---

## SparsePCA#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.SparsePCA.html

**Contents:**
- SparsePCA#
- Gallery examples#

Sparse Principal Components Analysis (SparsePCA).

Finds the set of sparse components that can optimally reconstruct the data. The amount of sparseness is controllable by the coefficient of the L1 penalty, given by the parameter alpha.

Read more in the User Guide.

Number of sparse atoms to extract. If None, then n_components is set to n_features.

Sparsity controlling parameter. Higher values lead to sparser components.

Amount of ridge shrinkage to apply in order to improve conditioning when calling the transform method.

Maximum number of iterations to perform.

Tolerance for the stopping condition.

Method to be used for optimization. lars: uses the least angle regression method to solve the lasso problem (linear_model.lars_path) cd: uses the coordinate descent method to compute the Lasso solution (linear_model.Lasso). Lars will be faster if the estimated components are sparse.

Number of parallel jobs to run. None means 1 unless in a joblib.parallel_backend context. -1 means using all processors. See Glossary for more details.

Initial values for the loadings for warm restart scenarios. Only used if U_init and V_init are not None.

Initial values for the components for warm restart scenarios. Only used if U_init and V_init are not None.

Controls the verbosity; the higher, the more messages. Defaults to 0.

Used during dictionary learning. Pass an int for reproducible results across multiple function calls. See Glossary.

Sparse components extracted from the data.

Vector of errors at each iteration.

Estimated number of components.

Added in version 0.23.

Number of iterations run.

Per-feature empirical mean, estimated from the training set. Equal to X.mean(axis=0).

Number of features seen during fit.

Added in version 0.24.

Names of features seen during fit. Defined only when X has feature names that are all strings.

Added in version 1.0.

Principal Component Analysis implementation.

Mini batch variant of SparsePCA that is faster but less accurate.

Generic dictionary learning problem using a sparse code.

Fit the model from data in X.

Training vector, where n_samples is the number of samples and n_features is the number of features.

Not used, present here for API consistency by convention.

Returns the instance itself.

Fit to data, then transform it.

Fits transformer to X and y with optional parameters fit_params and returns a transformed version of X.

Target values (None for unsupervised transformations).

Additional fit parameters. Pass only if the estimator accepts additional params in its fit method.

Get output feature names for transformation.

The feature names out will prefixed by the lowercased class name. For example, if the transformer outputs 3 features, then the feature names out are: ["class_name0", "class_name1", "class_name2"].

Only used to validate feature names with the names seen in fit.

Transformed feature names.

Get metadata routing of this object.

Please check User Guide on how the routing mechanism works.

A MetadataRequest encapsulating routing information.

Get parameters for this estimator.

If True, will return the parameters for this estimator and contained subobjects that are estimators.

Parameter names mapped to their values.

Transform data from the latent space to the original space.

This inversion is an approximation due to the loss of information induced by the forward decomposition.

Added in version 1.2.

Data in the latent space.

Reconstructed data in the original space.

Set output container.

See Introducing the set_output API for an example on how to use the API.

Configure output of transform and fit_transform.

"default": Default output format of a transformer

"pandas": DataFrame output

"polars": Polars output

None: Transform configuration is unchanged

Added in version 1.4: "polars" option was added.

Set the parameters of this estimator.

The method works on simple estimators as well as on nested objects (such as Pipeline). The latter have parameters of the form <component>__<parameter> so that it’s possible to update each component of a nested object.

Estimator parameters.

Least Squares projection of the data onto the sparse components.

To avoid instability issues in case the system is under-determined, regularization can be applied (Ridge regression) via the ridge_alpha parameter.

Note that Sparse PCA components orthogonality is not enforced as in PCA hence one cannot use a simple linear projection.

Test data to be transformed, must have the same number of features as the data used to train the model.

Faces dataset decompositions

**Examples:**

Example 1 (csharp):
```csharp
>>> import numpy as np
>>> from sklearn.datasets import make_friedman1
>>> from sklearn.decomposition import SparsePCA
>>> X, _ = make_friedman1(n_samples=200, n_features=30, random_state=0)
>>> transformer = SparsePCA(n_components=5, random_state=0)
>>> transformer.fit(X)
SparsePCA(...)
>>> X_transformed = transformer.transform(X)
>>> X_transformed.shape
(200, 5)
>>> # most values in the components_ are zero (sparsity)
>>> np.mean(transformer.components_ == 0)
np.float64(0.9666)
```

---

## ledoit_wolf#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.covariance.ledoit_wolf.html

**Contents:**
- ledoit_wolf#
- Gallery examples#

Estimate the shrunk Ledoit-Wolf covariance matrix.

Read more in the User Guide.

Data from which to compute the covariance estimate.

If True, data will not be centered before computation. Useful to work with data whose mean is significantly equal to zero but is not exactly zero. If False, data will be centered before computation.

Size of blocks into which the covariance matrix will be split. This is purely a memory optimization and does not affect results.

Coefficient in the convex combination used for the computation of the shrunk estimate.

The regularized (shrunk) covariance is:

(1 - shrinkage) * cov + shrinkage * mu * np.identity(n_features)

where mu = trace(cov) / n_features

Sparse inverse covariance estimation

**Examples:**

Example 1 (sql):
```sql
>>> import numpy as np
>>> from sklearn.covariance import empirical_covariance, ledoit_wolf
>>> real_cov = np.array([[.4, .2], [.2, .8]])
>>> rng = np.random.RandomState(0)
>>> X = rng.multivariate_normal(mean=[0, 0], cov=real_cov, size=50)
>>> covariance, shrinkage = ledoit_wolf(X)
>>> covariance
array([[0.44, 0.16],
       [0.16, 0.80]])
>>> shrinkage
np.float64(0.23)
```

---

## 3.4. Metrics and scoring: quantifying the quality of predictions#

**URL:** https://scikit-learn.org/stable/modules/model_evaluation.html

**Contents:**
- 3.4. Metrics and scoring: quantifying the quality of predictions#
- 3.4.1. Which scoring function should I use?#
- 3.4.2. Scoring API overview#
- 3.4.3. The scoring parameter: defining model evaluation rules#
  - 3.4.3.1. String name scorers#
  - 3.4.3.2. Callable scorers#
    - 3.4.3.2.1. Adapting predefined metrics via make_scorer#
    - 3.4.3.2.2. Creating a custom scorer object#
  - 3.4.3.3. Using multiple metric evaluation#
- 3.4.4. Classification metrics#

Before we take a closer look into the details of the many scores and evaluation metrics, we want to give some guidance, inspired by statistical decision theory, on the choice of scoring functions for supervised learning, see [Gneiting2009]:

Which scoring function should I use?

Which scoring function is a good one for my task?

In a nutshell, if the scoring function is given, e.g. in a kaggle competition or in a business context, use that one. If you are free to choose, it starts by considering the ultimate goal and application of the prediction. It is useful to distinguish two steps:

Predicting: Usually, the response variable \(Y\) is a random variable, in the sense that there is no deterministic function \(Y = g(X)\) of the features \(X\). Instead, there is a probability distribution \(F\) of \(Y\). One can aim to predict the whole distribution, known as probabilistic prediction, or—more the focus of scikit-learn—issue a point prediction (or point forecast) by choosing a property or functional of that distribution \(F\). Typical examples are the mean (expected value), the median or a quantile of the response variable \(Y\) (conditionally on \(X\)).

Once that is settled, use a strictly consistent scoring function for that (target) functional, see [Gneiting2009]. This means using a scoring function that is aligned with measuring the distance between predictions y_pred and the true target functional using observations of \(Y\), i.e. y_true. For classification strictly proper scoring rules, see Wikipedia entry for Scoring rule and [Gneiting2007], coincide with strictly consistent scoring functions. The table further below provides examples. One could say that consistent scoring functions act as truth serum in that they guarantee “that truth telling […] is an optimal strategy in expectation” [Gneiting2014].

Once a strictly consistent scoring function is chosen, it is best used for both: as loss function for model training and as metric/score in model evaluation and model comparison.

Note that for regressors, the prediction is done with predict while for classifiers it is usually predict_proba.

Decision Making: The most common decisions are done on binary classification tasks, where the result of predict_proba is turned into a single outcome, e.g., from the predicted probability of rain a decision is made on how to act (whether to take mitigating measures like an umbrella or not). For classifiers, this is what predict returns. See also Tuning the decision threshold for class prediction. There are many scoring functions which measure different aspects of such a decision, most of them are covered with or derived from the metrics.confusion_matrix.

List of strictly consistent scoring functions: Here, we list some of the most relevant statistical functionals and corresponding strictly consistent scoring functions for tasks in practice. Note that the list is not complete and that there are more of them. For further criteria on how to select a specific one, see [Fissler2022].

scoring or loss function

predict, strictly positive

predict, strictly positive

predict, depends on power

no consistent one exists

1 The Brier score is just a different name for the squared error in case of classification with one-hot encoded targets.

2 The zero-one loss is only consistent but not strictly consistent for the mode. The zero-one loss is equivalent to one minus the accuracy score, meaning it gives different score values but the same ranking.

3 R² gives the same ranking as squared error.

Fictitious Example: Let’s make the above arguments more tangible. Consider a setting in network reliability engineering, such as maintaining stable internet or Wi-Fi connections. As provider of the network, you have access to the dataset of log entries of network connections containing network load over time and many interesting features. Your goal is to improve the reliability of the connections. In fact, you promise your customers that on at least 99% of all days there are no connection discontinuities larger than 1 minute. Therefore, you are interested in a prediction of the 99% quantile (of longest connection interruption duration per day) in order to know in advance when to add more bandwidth and thereby satisfy your customers. So the target functional is the 99% quantile. From the table above, you choose the pinball loss as scoring function (fair enough, not much choice given), for model training (e.g. HistGradientBoostingRegressor(loss="quantile", quantile=0.99)) as well as model evaluation (mean_pinball_loss(..., alpha=0.99) - we apologize for the different argument names, quantile and alpha) be it in grid search for finding hyperparameters or in comparing to other models like QuantileRegressor(quantile=0.99).

T. Gneiting and A. E. Raftery. Strictly Proper Scoring Rules, Prediction, and Estimation In: Journal of the American Statistical Association 102 (2007), pp. 359– 378. link to pdf

T. Gneiting. Making and Evaluating Point Forecasts Journal of the American Statistical Association 106 (2009): 746 - 762.

T. Gneiting and M. Katzfuss. Probabilistic Forecasting. In: Annual Review of Statistics and Its Application 1.1 (2014), pp. 125–151.

T. Fissler, C. Lorentzen and M. Mayer. Model Comparison and Calibration Assessment: User Guide for Consistent Scoring Functions in Machine Learning and Actuarial Practice.

There are 3 different APIs for evaluating the quality of a model’s predictions:

Estimator score method: Estimators have a score method providing a default evaluation criterion for the problem they are designed to solve. Most commonly this is accuracy for classifiers and the coefficient of determination (\(R^2\)) for regressors. Details for each estimator can be found in its documentation.

Scoring parameter: Model-evaluation tools that use cross-validation (such as model_selection.GridSearchCV, model_selection.validation_curve and linear_model.LogisticRegressionCV) rely on an internal scoring strategy. This can be specified using the scoring parameter of that tool and is discussed in the section The scoring parameter: defining model evaluation rules.

Metric functions: The sklearn.metrics module implements functions assessing prediction error for specific purposes. These metrics are detailed in sections on Classification metrics, Multilabel ranking metrics, Regression metrics and Clustering metrics.

Finally, Dummy estimators are useful to get a baseline value of those metrics for random predictions.

For “pairwise” metrics, between samples and not estimators or predictions, see the Pairwise metrics, Affinities and Kernels section.

Model selection and evaluation tools that internally use cross-validation (such as model_selection.GridSearchCV, model_selection.validation_curve and linear_model.LogisticRegressionCV) take a scoring parameter that controls what metric they apply to the estimators evaluated.

They can be specified in several ways:

None: the estimator’s default evaluation criterion (i.e., the metric used in the estimator’s score method) is used.

String name: common metrics can be passed via a string name.

Callable: more complex metrics can be passed via a custom metric callable (e.g., function).

Some tools do also accept multiple metric evaluation. See Using multiple metric evaluation for details.

For the most common use cases, you can designate a scorer object with the scoring parameter via a string name; the table below shows all possible values. All scorer objects follow the convention that higher return values are better than lower return values. Thus metrics which measure the distance between the model and the data, like metrics.mean_squared_error, are available as ‘neg_mean_squared_error’ which return the negated value of the metric.

metrics.accuracy_score

metrics.balanced_accuracy_score

metrics.top_k_accuracy_score

metrics.average_precision_score

metrics.brier_score_loss

requires predict_proba support

requires predict_proba support

metrics.precision_score

suffixes apply as with ‘f1’

suffixes apply as with ‘f1’

metrics.jaccard_score

suffixes apply as with ‘f1’

metrics.roc_auc_score

metrics.roc_auc_score

metrics.roc_auc_score

‘roc_auc_ovr_weighted’

metrics.roc_auc_score

‘roc_auc_ovo_weighted’

metrics.roc_auc_score

metrics.d2_log_loss_score

requires predict_proba support

metrics.d2_brier_score

requires predict_proba support

‘adjusted_mutual_info_score’

metrics.adjusted_mutual_info_score

‘adjusted_rand_score’

metrics.adjusted_rand_score

metrics.completeness_score

‘fowlkes_mallows_score’

metrics.fowlkes_mallows_score

metrics.homogeneity_score

metrics.mutual_info_score

‘normalized_mutual_info_score’

metrics.normalized_mutual_info_score

metrics.v_measure_score

metrics.explained_variance_score

‘neg_mean_absolute_error’

metrics.mean_absolute_error

‘neg_mean_squared_error’

metrics.mean_squared_error

‘neg_root_mean_squared_error’

metrics.root_mean_squared_error

‘neg_mean_squared_log_error’

metrics.mean_squared_log_error

‘neg_root_mean_squared_log_error’

metrics.root_mean_squared_log_error

‘neg_median_absolute_error’

metrics.median_absolute_error

‘neg_mean_poisson_deviance’

metrics.mean_poisson_deviance

‘neg_mean_gamma_deviance’

metrics.mean_gamma_deviance

‘neg_mean_absolute_percentage_error’

metrics.mean_absolute_percentage_error

‘d2_absolute_error_score’

metrics.d2_absolute_error_score

If a wrong scoring name is passed, an InvalidParameterError is raised. You can retrieve the names of all available scorers by calling get_scorer_names.

For more complex use cases and more flexibility, you can pass a callable to the scoring parameter. This can be done by:

Adapting predefined metrics via make_scorer

Creating a custom scorer object (most flexible)

The following metric functions are not implemented as named scorers, sometimes because they require additional parameters, such as fbeta_score. They cannot be passed to the scoring parameters; instead their callable needs to be passed to make_scorer together with the value of the user-settable parameters.

make_scorer(fbeta_score, beta=2)

metrics.mean_tweedie_deviance

make_scorer(mean_tweedie_deviance, power=1.5)

metrics.mean_pinball_loss

make_scorer(mean_pinball_loss, alpha=0.95)

metrics.d2_tweedie_score

make_scorer(d2_tweedie_score, power=1.5)

metrics.d2_pinball_score

make_scorer(d2_pinball_score, alpha=0.95)

One typical use case is to wrap an existing metric function from the library with non-default values for its parameters, such as the beta parameter for the fbeta_score function:

The module sklearn.metrics also exposes a set of simple functions measuring a prediction error given ground truth and prediction:

functions ending with _score return a value to maximize, the higher the better.

functions ending with _error, _loss, or _deviance return a value to minimize, the lower the better. When converting into a scorer object using make_scorer, set the greater_is_better parameter to False (True by default; see the parameter description below).

You can create your own custom scorer object using make_scorer.

You can build a completely custom scorer object from a simple python function using make_scorer, which can take several parameters:

the python function you want to use (my_custom_loss_func in the example below)

whether the python function returns a score (greater_is_better=True, the default) or a loss (greater_is_better=False). If a loss, the output of the python function is negated by the scorer object, conforming to the cross validation convention that scorers return higher values for better models.

for classification metrics only: whether the python function you provided requires continuous decision certainties. If the scoring function only accepts probability estimates (e.g. metrics.log_loss), then one needs to set the parameter response_method="predict_proba". Some scoring functions do not necessarily require probability estimates but rather non-thresholded decision values (e.g. metrics.roc_auc_score). In this case, one can provide a list (e.g., response_method=["decision_function", "predict_proba"]), and scorer will use the first available method, in the order given in the list, to compute the scores.

any additional parameters of the scoring function, such as beta or labels.

Here is an example of building custom scorers, and of using the greater_is_better parameter:

While defining the custom scoring function alongside the calling function should work out of the box with the default joblib backend (loky), importing it from another module will be a more robust approach and work independently of the joblib backend.

For example, to use n_jobs greater than 1 in the example below, custom_scoring_function function is saved in a user-created module (custom_scorer_module.py) and imported:

Scikit-learn also permits evaluation of multiple metrics in GridSearchCV, RandomizedSearchCV and cross_validate.

There are three ways to specify multiple scoring metrics for the scoring parameter:

As an iterable of string metrics:

As a dict mapping the scorer name to the scoring function:

Note that the dict values can either be scorer functions or one of the predefined metric strings.

As a callable that returns a dictionary of scores:

The sklearn.metrics module implements several loss, score, and utility functions to measure classification performance. Some metrics might require probability estimates of the positive class, confidence values, or binary decisions values. Most implementations allow each sample to provide a weighted contribution to the overall score, through the sample_weight parameter.

Some of these are restricted to the binary classification case:

precision_recall_curve(y_true, y_score, *[, ...])

Compute precision-recall pairs for different probability thresholds.

roc_curve(y_true, y_score, *[, pos_label, ...])

Compute Receiver operating characteristic (ROC).

class_likelihood_ratios(y_true, y_pred, *[, ...])

Compute binary classification positive and negative likelihood ratios.

det_curve(y_true, y_score[, pos_label, ...])

Compute Detection Error Tradeoff (DET) for different probability thresholds.

confusion_matrix_at_thresholds(y_true, y_score)

Calculate binary confusion matrix terms per classification threshold.

Others also work in the multiclass case:

balanced_accuracy_score(y_true, y_pred, *[, ...])

Compute the balanced accuracy.

cohen_kappa_score(y1, y2, *[, labels, ...])

Compute Cohen's kappa: a statistic that measures inter-annotator agreement.

confusion_matrix(y_true, y_pred, *[, ...])

Compute confusion matrix to evaluate the accuracy of a classification.

hinge_loss(y_true, pred_decision, *[, ...])

Average hinge loss (non-regularized).

matthews_corrcoef(y_true, y_pred, *[, ...])

Compute the Matthews correlation coefficient (MCC).

roc_auc_score(y_true, y_score, *[, average, ...])

Compute Area Under the Receiver Operating Characteristic Curve (ROC AUC) from prediction scores.

top_k_accuracy_score(y_true, y_score, *[, ...])

Top-k Accuracy classification score.

Some also work in the multilabel case:

accuracy_score(y_true, y_pred, *[, ...])

Accuracy classification score.

classification_report(y_true, y_pred, *[, ...])

Build a text report showing the main classification metrics.

f1_score(y_true, y_pred, *[, labels, ...])

Compute the F1 score, also known as balanced F-score or F-measure.

fbeta_score(y_true, y_pred, *, beta[, ...])

Compute the F-beta score.

hamming_loss(y_true, y_pred, *[, sample_weight])

Compute the average Hamming loss.

jaccard_score(y_true, y_pred, *[, labels, ...])

Jaccard similarity coefficient score.

log_loss(y_true, y_pred, *[, normalize, ...])

Log loss, aka logistic loss or cross-entropy loss.

multilabel_confusion_matrix(y_true, y_pred, *)

Compute a confusion matrix for each class or sample.

precision_recall_fscore_support(y_true, ...)

Compute precision, recall, F-measure and support for each class.

precision_score(y_true, y_pred, *[, labels, ...])

Compute the precision.

recall_score(y_true, y_pred, *[, labels, ...])

roc_auc_score(y_true, y_score, *[, average, ...])

Compute Area Under the Receiver Operating Characteristic Curve (ROC AUC) from prediction scores.

zero_one_loss(y_true, y_pred, *[, ...])

Zero-one classification loss.

d2_log_loss_score(y_true, y_pred, *[, ...])

\(D^2\) score function, fraction of log loss explained.

And some work with binary and multilabel (but not multiclass) problems:

average_precision_score(y_true, y_score, *)

Compute average precision (AP) from prediction scores.

In the following sub-sections, we will describe each of those functions, preceded by some notes on common API and metric definition.

Some metrics are essentially defined for binary classification tasks (e.g. f1_score, roc_auc_score). In these cases, by default only the positive label is evaluated, assuming by default that the positive class is labelled 1 (though this may be configurable through the pos_label parameter).

In extending a binary metric to multiclass or multilabel problems, the data is treated as a collection of binary problems, one for each class. There are then a number of ways to average binary metric calculations across the set of classes, each of which may be useful in some scenario. Where available, you should select among these using the average parameter.

"macro" simply calculates the mean of the binary metrics, giving equal weight to each class. In problems where infrequent classes are nonetheless important, macro-averaging may be a means of highlighting their performance. On the other hand, the assumption that all classes are equally important is often untrue, such that macro-averaging will over-emphasize the typically low performance on an infrequent class.

"weighted" accounts for class imbalance by computing the average of binary metrics in which each class’s score is weighted by its presence in the true data sample.

"micro" gives each sample-class pair an equal contribution to the overall metric (except as a result of sample-weight). Rather than summing the metric per class, this sums the dividends and divisors that make up the per-class metrics to calculate an overall quotient. Micro-averaging may be preferred in multilabel settings, including multiclass classification where a majority class is to be ignored.

"samples" applies only to multilabel problems. It does not calculate a per-class measure, instead calculating the metric over the true and predicted classes for each sample in the evaluation data, and returning their (sample_weight-weighted) average.

Selecting average=None will return an array with the score for each class.

While multiclass data is provided to the metric, like binary targets, as an array of class labels, multilabel data is specified as an indicator matrix, in which cell [i, j] has value 1 if sample i has label j and value 0 otherwise.

The accuracy_score function computes the accuracy, either the fraction (default) or the count (normalize=False) of correct predictions.

In multilabel classification, the function returns the subset accuracy. If the entire set of predicted labels for a sample strictly match with the true set of labels, then the subset accuracy is 1.0; otherwise it is 0.0.

If \(\hat{y}_i\) is the predicted value of the \(i\)-th sample and \(y_i\) is the corresponding true value, then the fraction of correct predictions over \(n_\text{samples}\) is defined as

where \(1(x)\) is the indicator function.

In the multilabel case with binary label indicators:

See Test with permutations the significance of a classification score for an example of accuracy score usage using permutations of the dataset.

The top_k_accuracy_score function is a generalization of accuracy_score. The difference is that a prediction is considered correct as long as the true label is associated with one of the k highest predicted scores. accuracy_score is the special case of k = 1.

The function covers the binary and multiclass classification cases but not the multilabel case.

If \(\hat{f}_{i,j}\) is the predicted class for the \(i\)-th sample corresponding to the \(j\)-th largest predicted score and \(y_i\) is the corresponding true value, then the fraction of correct predictions over \(n_\text{samples}\) is defined as

where \(k\) is the number of guesses allowed and \(1(x)\) is the indicator function.

The balanced_accuracy_score function computes the balanced accuracy, which avoids inflated performance estimates on imbalanced datasets. It is the macro-average of recall scores per class or, equivalently, raw accuracy where each sample is weighted according to the inverse prevalence of its true class. Thus for balanced datasets, the score is equal to accuracy.

In the binary case, balanced accuracy is equal to the arithmetic mean of sensitivity (true positive rate) and specificity (true negative rate), or the area under the ROC curve with binary predictions rather than scores:

If the classifier performs equally well on either class, this term reduces to the conventional accuracy (i.e., the number of correct predictions divided by the total number of predictions).

In contrast, if the conventional accuracy is above chance only because the classifier takes advantage of an imbalanced test set, then the balanced accuracy, as appropriate, will drop to \(\frac{1}{n\_classes}\).

The score ranges from 0 to 1, or when adjusted=True is used, it is rescaled to the range \(\frac{1}{1 - n\_classes}\) to 1, inclusive, with performance at random scoring 0.

If \(y_i\) is the true value of the \(i\)-th sample, and \(w_i\) is the corresponding sample weight, then we adjust the sample weight to:

where \(1(x)\) is the indicator function. Given predicted \(\hat{y}_i\) for sample \(i\), balanced accuracy is defined as:

With adjusted=True, balanced accuracy reports the relative increase from \(\texttt{balanced-accuracy}(y, \mathbf{0}, w) = \frac{1}{n\_classes}\). In the binary case, this is also known as Youden’s J statistic, or informedness.

The multiclass definition here seems the most reasonable extension of the metric used in binary classification, though there is no certain consensus in the literature:

Our definition: [Mosley2013], [Kelleher2015] and [Guyon2015], where [Guyon2015] adopt the adjusted version to ensure that random predictions have a score of \(0\) and perfect predictions have a score of \(1\).

Class balanced accuracy as described in [Mosley2013]: the minimum between the precision and the recall for each class is computed. Those values are then averaged over the total number of classes to get the balanced accuracy.

Balanced Accuracy as described in [Urbanowicz2015]: the average of sensitivity and specificity is computed for each class and then averaged over total number of classes.

I. Guyon, K. Bennett, G. Cawley, H.J. Escalante, S. Escalera, T.K. Ho, N. Macià, B. Ray, M. Saeed, A.R. Statnikov, E. Viegas, Design of the 2015 ChaLearn AutoML Challenge, IJCNN 2015.

L. Mosley, A balanced approach to the multi-class imbalance problem, IJCV 2010.

John. D. Kelleher, Brian Mac Namee, Aoife D’Arcy, Fundamentals of Machine Learning for Predictive Data Analytics: Algorithms, Worked Examples, and Case Studies, 2015.

Urbanowicz R.J., Moore, J.H. ExSTraCS 2.0: description and evaluation of a scalable learning classifier system, Evol. Intel. (2015) 8: 89.

The function cohen_kappa_score computes Cohen’s kappa statistic. This measure is intended to compare labelings by different human annotators, not a classifier versus a ground truth.

The kappa score is a number between -1 and 1. Scores above .8 are generally considered good agreement; zero or lower means no agreement (practically random labels).

Kappa scores can be computed for binary or multiclass problems, but not for multilabel problems (except by manually computing a per-label score) and not for more than two annotators.

The confusion_matrix function evaluates classification accuracy by computing the confusion matrix with each row corresponding to the true class (Wikipedia and other references may use different convention for axes).

By definition, entry \(i, j\) in a confusion matrix is the number of observations actually in group \(i\), but predicted to be in group \(j\). Here is an example:

ConfusionMatrixDisplay can be used to visually represent a confusion matrix as shown in the Evaluate the performance of a classifier with Confusion Matrix example, which creates the following figure:

The parameter normalize allows to report ratios instead of counts. The confusion matrix can be normalized in 3 different ways: 'pred', 'true', and 'all' which will divide the counts by the sum of each columns, rows, or the entire matrix, respectively.

For binary problems, we can get counts of true negatives, false positives, false negatives and true positives as follows:

With confusion_matrix_at_thresholds we can get true negatives, false positives, false negatives and true positives for different thresholds:

Note that the thresholds consist of distinct y_score values, in decreasing order.

See Evaluate the performance of a classifier with Confusion Matrix for an example of using a confusion matrix to evaluate classifier output quality.

See Recognizing hand-written digits for an example of using a confusion matrix to classify hand-written digits.

See Classification of text documents using sparse features for an example of using a confusion matrix to classify text documents.

The classification_report function builds a text report showing the main classification metrics. Here is a small example with custom target_names and inferred labels:

See Recognizing hand-written digits for an example of classification report usage for hand-written digits.

See Custom refit strategy of a grid search with cross-validation for an example of classification report usage for grid search with nested cross-validation.

The hamming_loss computes the average Hamming loss or Hamming distance between two sets of samples.

If \(\hat{y}_{i,j}\) is the predicted value for the \(j\)-th label of a given sample \(i\), \(y_{i,j}\) is the corresponding true value, \(n_\text{samples}\) is the number of samples and \(n_\text{labels}\) is the number of labels, then the Hamming loss \(L_{Hamming}\) is defined as:

where \(1(x)\) is the indicator function.

The equation above does not hold true in the case of multiclass classification. Please refer to the note below for more information.

In the multilabel case with binary label indicators:

In multiclass classification, the Hamming loss corresponds to the Hamming distance between y_true and y_pred which is similar to the Zero one loss function. However, while zero-one loss penalizes prediction sets that do not strictly match true sets, the Hamming loss penalizes individual labels. Thus the Hamming loss, upper bounded by the zero-one loss, is always between zero and one, inclusive; and predicting a proper subset or superset of the true labels will give a Hamming loss between zero and one, exclusive.

Intuitively, precision is the ability of the classifier not to label as positive a sample that is negative, and recall is the ability of the classifier to find all the positive samples.

The F-measure (\(F_\beta\) and \(F_1\) measures) can be interpreted as a weighted harmonic mean of the precision and recall. A \(F_\beta\) measure reaches its best value at 1 and its worst score at 0. With \(\beta = 1\), \(F_\beta\) and \(F_1\) are equivalent, and the recall and the precision are equally important.

The precision_recall_curve computes a precision-recall curve from the ground truth label and a score given by the classifier by varying a decision threshold.

The average_precision_score function computes the average precision (AP) from prediction scores. The value is between 0 and 1 and higher is better. AP is defined as

where \(P_n\) and \(R_n\) are the precision and recall at the nth threshold. With random predictions, the AP is the fraction of positive samples.

References [Manning2008] and [Everingham2010] present alternative variants of AP that interpolate the precision-recall curve. Currently, average_precision_score does not implement any interpolated variant. References [Davis2006] and [Flach2015] describe why a linear interpolation of points on the precision-recall curve provides an overly-optimistic measure of classifier performance. This linear interpolation is used when computing area under the curve with the trapezoidal rule in auc. [Chen2024] benchmarks different interpolation strategies to demonstrate the effects.

Several functions allow you to analyze the precision, recall and F-measures score:

average_precision_score(y_true, y_score, *)

Compute average precision (AP) from prediction scores.

f1_score(y_true, y_pred, *[, labels, ...])

Compute the F1 score, also known as balanced F-score or F-measure.

fbeta_score(y_true, y_pred, *, beta[, ...])

Compute the F-beta score.

precision_recall_curve(y_true, y_score, *[, ...])

Compute precision-recall pairs for different probability thresholds.

precision_recall_fscore_support(y_true, ...)

Compute precision, recall, F-measure and support for each class.

precision_score(y_true, y_pred, *[, labels, ...])

Compute the precision.

recall_score(y_true, y_pred, *[, labels, ...])

Note that the precision_recall_curve function is restricted to the binary case. The average_precision_score function supports multiclass and multilabel formats by computing each class score in a One-vs-the-rest (OvR) fashion and averaging them or not depending of its average argument value.

The PrecisionRecallDisplay.from_estimator and PrecisionRecallDisplay.from_predictions functions will plot the precision-recall curve as follows.

See Custom refit strategy of a grid search with cross-validation for an example of precision_score and recall_score usage to estimate parameters using grid search with nested cross-validation.

See Precision-Recall for an example of precision_recall_curve usage to evaluate classifier output quality.

C.D. Manning, P. Raghavan, H. Schütze, Introduction to Information Retrieval, 2008.

M. Everingham, L. Van Gool, C.K.I. Williams, J. Winn, A. Zisserman, The Pascal Visual Object Classes (VOC) Challenge, IJCV 2010.

J. Davis, M. Goadrich, The Relationship Between Precision-Recall and ROC Curves, ICML 2006.

P.A. Flach, M. Kull, Precision-Recall-Gain Curves: PR Analysis Done Right, NIPS 2015.

W. Chen, C. Miao, Z. Zhang, C.S. Fung, R. Wang, Y. Chen, Y. Qian, L. Cheng, K.Y. Yip, S.K Tsui, Q. Cao, Commonly used software tools produce conflicting and overly-optimistic AUPRC values, Genome Biology 2024.

In a binary classification task, the terms ‘’positive’’ and ‘’negative’’ refer to the classifier’s prediction, and the terms ‘’true’’ and ‘’false’’ refer to whether that prediction corresponds to the external judgment (sometimes known as the ‘’observation’’). Given these definitions, we can formulate the following table:

Actual class (observation)

Predicted class (expectation)

tp (true positive) Correct result

fp (false positive) Unexpected result

fn (false negative) Missing result

tn (true negative) Correct absence of result

In this context, we can define the notions of precision and recall:

(Sometimes recall is also called ‘’sensitivity’’)

F-measure is the weighted harmonic mean of precision and recall, with precision’s contribution to the mean weighted by some parameter \(\beta\):

To avoid division by zero when precision and recall are zero, Scikit-Learn calculates F-measure with this otherwise-equivalent formula:

Note that this formula is still undefined when there are no true positives, false positives, or false negatives. By default, F-1 for a set of exclusively true negatives is calculated as 0, however this behavior can be changed using the zero_division parameter. Here are some small examples in binary classification:

In a multiclass and multilabel classification task, the notions of precision, recall, and F-measures can be applied to each label independently. There are a few ways to combine results across labels, specified by the average argument to the average_precision_score, f1_score, fbeta_score, precision_recall_fscore_support, precision_score and recall_score functions, as described above.

Note the following behaviors when averaging:

If all labels are included, “micro”-averaging in a multiclass setting will produce precision, recall and \(F\) that are all identical to accuracy.

“weighted” averaging may produce a F-score that is not between precision and recall.

“macro” averaging for F-measures is calculated as the arithmetic mean over per-label/class F-measures, not the harmonic mean over the arithmetic precision and recall means. Both calculations can be seen in the literature but are not equivalent, see [OB2019] for details.

To make this more explicit, consider the following notation:

\(y\) the set of true \((sample, label)\) pairs

\(\hat{y}\) the set of predicted \((sample, label)\) pairs

\(L\) the set of labels

\(S\) the set of samples

\(y_s\) the subset of \(y\) with sample \(s\), i.e. \(y_s := \left\{(s', l) \in y | s' = s\right\}\)

\(y_l\) the subset of \(y\) with label \(l\)

similarly, \(\hat{y}_s\) and \(\hat{y}_l\) are subsets of \(\hat{y}\)

\(P(A, B) := \frac{\left| A \cap B \right|}{\left|B\right|}\) for some sets \(A\) and \(B\)

\(R(A, B) := \frac{\left| A \cap B \right|}{\left|A\right|}\) (Conventions vary on handling \(A = \emptyset\); this implementation uses \(R(A, B):=0\), and similar for \(P\).)

\(F_\beta(A, B) := \left(1 + \beta^2\right) \frac{P(A, B) \times R(A, B)}{\beta^2 P(A, B) + R(A, B)}\)

Then the metrics are defined as:

\(F_\beta(y, \hat{y})\)

\(\frac{1}{\left|S\right|} \sum_{s \in S} P(y_s, \hat{y}_s)\)

\(\frac{1}{\left|S\right|} \sum_{s \in S} R(y_s, \hat{y}_s)\)

\(\frac{1}{\left|S\right|} \sum_{s \in S} F_\beta(y_s, \hat{y}_s)\)

\(\frac{1}{\left|L\right|} \sum_{l \in L} P(y_l, \hat{y}_l)\)

\(\frac{1}{\left|L\right|} \sum_{l \in L} R(y_l, \hat{y}_l)\)

\(\frac{1}{\left|L\right|} \sum_{l \in L} F_\beta(y_l, \hat{y}_l)\)

\(\frac{1}{\sum_{l \in L} \left|y_l\right|} \sum_{l \in L} \left|y_l\right| P(y_l, \hat{y}_l)\)

\(\frac{1}{\sum_{l \in L} \left|y_l\right|} \sum_{l \in L} \left|y_l\right| R(y_l, \hat{y}_l)\)

\(\frac{1}{\sum_{l \in L} \left|y_l\right|} \sum_{l \in L} \left|y_l\right| F_\beta(y_l, \hat{y}_l)\)

\(\langle P(y_l, \hat{y}_l) | l \in L \rangle\)

\(\langle R(y_l, \hat{y}_l) | l \in L \rangle\)

\(\langle F_\beta(y_l, \hat{y}_l) | l \in L \rangle\)

For multiclass classification with a “negative class”, it is possible to exclude some labels:

Similarly, labels not present in the data sample may be accounted for in macro-averaging.

Opitz, J., & Burst, S. (2019). “Macro f1 and macro f1.”

The jaccard_score function computes the average of Jaccard similarity coefficients, also called the Jaccard index, between pairs of label sets.

The Jaccard similarity coefficient with a ground truth label set \(y\) and predicted label set \(\hat{y}\), is defined as

The jaccard_score (like precision_recall_fscore_support) applies natively to binary targets. By computing it set-wise it can be extended to apply to multilabel and multiclass through the use of average (see above).

In the 2D comparison case (e.g. image similarity):

In the multilabel case with binary label indicators:

Multiclass problems are binarized and treated like the corresponding multilabel problem:

The hinge_loss function computes the average distance between the model and the data using hinge loss, a one-sided metric that considers only prediction errors. (Hinge loss is used in maximal margin classifiers such as support vector machines.)

If the true label \(y_i\) of a binary classification task is encoded as \(y_i=\left\{-1, +1\right\}\) for every sample \(i\); and \(w_i\) is the corresponding predicted decision (an array of shape (n_samples,) as output by the decision_function method), then the hinge loss is defined as:

If there are more than two labels, hinge_loss uses a multiclass variant due to Crammer & Singer. Here is the paper describing it.

In this case the predicted decision is an array of shape (n_samples, n_labels). If \(w_{i, y_i}\) is the predicted decision for the true label \(y_i\) of the \(i\)-th sample; and \(\hat{w}_{i, y_i} = \max\left\{w_{i, y_j}~|~y_j \ne y_i \right\}\) is the maximum of the predicted decisions for all the other labels, then the multi-class hinge loss is defined by:

Here is a small example demonstrating the use of the hinge_loss function with an svm classifier in a binary class problem:

Here is an example demonstrating the use of the hinge_loss function with an svm classifier in a multiclass problem:

Log loss, also called logistic regression loss or cross-entropy loss, is defined on probability estimates. It is commonly used in (multinomial) logistic regression and neural networks, as well as in some variants of expectation-maximization, and can be used to evaluate the probability outputs (predict_proba) of a classifier instead of its discrete predictions.

For binary classification with a true label \(y \in \{0,1\}\) and a probability estimate \(\hat{p} \approx \operatorname{Pr}(y = 1)\), the log loss per sample is the negative log-likelihood of the classifier given the true label:

This extends to the multiclass case as follows. Let the true labels for a set of samples be encoded as a 1-of-K binary indicator matrix \(Y\), i.e., \(y_{i,k} = 1\) if sample \(i\) has label \(k\) taken from a set of \(K\) labels. Let \(\hat{P}\) be a matrix of probability estimates, with elements \(\hat{p}_{i,k} \approx \operatorname{Pr}(y_{i,k} = 1)\). Then the log loss of the whole set is

To see how this generalizes the binary log loss given above, note that in the binary case, \(\hat{p}_{i,0} = 1 - \hat{p}_{i,1}\) and \(y_{i,0} = 1 - y_{i,1}\), so expanding the inner sum over \(y_{i,k} \in \{0,1\}\) gives the binary log loss.

The log_loss function computes log loss given a list of ground-truth labels and a probability matrix, as returned by an estimator’s predict_proba method.

The first [.9, .1] in y_pred denotes 90% probability that the first sample has label 0. The log loss is non-negative.

The matthews_corrcoef function computes the Matthew’s correlation coefficient (MCC) for binary classes. Quoting Wikipedia:

“The Matthews correlation coefficient is used in machine learning as a measure of the quality of binary (two-class) classifications. It takes into account true and false positives and negatives and is generally regarded as a balanced measure which can be used even if the classes are of very different sizes. The MCC is in essence a correlation coefficient value between -1 and +1. A coefficient of +1 represents a perfect prediction, 0 an average random prediction and -1 an inverse prediction. The statistic is also known as the phi coefficient.”

In the binary (two-class) case, \(tp\), \(tn\), \(fp\) and \(fn\) are respectively the number of true positives, true negatives, false positives and false negatives, the MCC is defined as

In the multiclass case, the Matthews correlation coefficient can be defined in terms of a confusion_matrix \(C\) for \(K\) classes. To simplify the definition consider the following intermediate variables:

\(t_k=\sum_{i}^{K} C_{ik}\) the number of times class \(k\) truly occurred,

\(p_k=\sum_{i}^{K} C_{ki}\) the number of times class \(k\) was predicted,

\(c=\sum_{k}^{K} C_{kk}\) the total number of samples correctly predicted,

\(s=\sum_{i}^{K} \sum_{j}^{K} C_{ij}\) the total number of samples.

Then the multiclass MCC is defined as:

When there are more than two labels, the value of the MCC will no longer range between -1 and +1. Instead the minimum value will be somewhere between -1 and 0 depending on the number and distribution of ground truth labels. The maximum value is always +1. For additional information, see [WikipediaMCC2021].

Here is a small example illustrating the usage of the matthews_corrcoef function:

Wikipedia contributors. Phi coefficient. Wikipedia, The Free Encyclopedia. April 21, 2021, 12:21 CEST. Available at: https://en.wikipedia.org/wiki/Phi_coefficient Accessed April 21, 2021.

The multilabel_confusion_matrix function computes class-wise (default) or sample-wise (samplewise=True) multilabel confusion matrix to evaluate the accuracy of a classification. multilabel_confusion_matrix also treats multiclass data as if it were multilabel, as this is a transformation commonly applied to evaluate multiclass problems with binary classification metrics (such as precision, recall, etc.).

When calculating class-wise multilabel confusion matrix \(C\), the count of true negatives for class \(i\) is \(C_{i,0,0}\), false negatives is \(C_{i,1,0}\), true positives is \(C_{i,1,1}\) and false positives is \(C_{i,0,1}\).

Here is an example demonstrating the use of the multilabel_confusion_matrix function with multilabel indicator matrix input:

Or a confusion matrix can be constructed for each sample’s labels:

Here is an example demonstrating the use of the multilabel_confusion_matrix function with multiclass input:

Here are some examples demonstrating the use of the multilabel_confusion_matrix function to calculate recall (or sensitivity), specificity, fall out and miss rate for each class in a problem with multilabel indicator matrix input.

Calculating recall (also called the true positive rate or the sensitivity) for each class:

Calculating specificity (also called the true negative rate) for each class:

Calculating fall out (also called the false positive rate) for each class:

Calculating miss rate (also called the false negative rate) for each class:

The function roc_curve computes the receiver operating characteristic curve, or ROC curve. Quoting Wikipedia :

“A receiver operating characteristic (ROC), or simply ROC curve, is a graphical plot which illustrates the performance of a binary classifier system as its discrimination threshold is varied. It is created by plotting the fraction of true positives out of the positives (TPR = true positive rate) vs. the fraction of false positives out of the negatives (FPR = false positive rate), at various threshold settings. TPR is also known as sensitivity, and FPR is one minus the specificity or true negative rate.”

This function requires the true binary value and the target scores, which can either be probability estimates of the positive class, confidence values, or binary decisions. Here is a small example of how to use the roc_curve function:

Compared to metrics such as the subset accuracy, the Hamming loss, or the F1 score, ROC doesn’t require optimizing a threshold for each label.

The roc_auc_score function, denoted by ROC-AUC or AUROC, computes the area under the ROC curve. By doing so, the curve information is summarized in one number.

The following figure shows the ROC curve and ROC-AUC score for a classifier aimed to distinguish the virginica flower from the rest of the species in the Iris plants dataset:

For more information see the Wikipedia article on AUC.

In the binary case, you can either provide the probability estimates, using the classifier.predict_proba() method, or the non-thresholded decision values given by the classifier.decision_function() method. In the case of providing the probability estimates, the probability of the class with the “greater label” should be provided. The “greater label” corresponds to classifier.classes_[1] and thus classifier.predict_proba(X)[:, 1]. Therefore, the y_score parameter is of size (n_samples,).

We can use the probability estimates corresponding to clf.classes_[1].

Otherwise, we can use the non-thresholded decision values

The roc_auc_score function can also be used in multi-class classification. Two averaging strategies are currently supported: the one-vs-one algorithm computes the average of the pairwise ROC AUC scores, and the one-vs-rest algorithm computes the average of the ROC AUC scores for each class against all other classes. In both cases, the predicted labels are provided in an array with values from 0 to n_classes, and the scores correspond to the probability estimates that a sample belongs to a particular class. The OvO and OvR algorithms support weighting uniformly (average='macro') and by prevalence (average='weighted').

Computes the average AUC of all possible pairwise combinations of classes. [HT2001] defines a multiclass AUC metric weighted uniformly:

where \(c\) is the number of classes and \(\text{AUC}(j | k)\) is the AUC with class \(j\) as the positive class and class \(k\) as the negative class. In general, \(\text{AUC}(j | k) \neq \text{AUC}(k | j)\) in the multiclass case. This algorithm is used by setting the keyword argument multiclass to 'ovo' and average to 'macro'.

The [HT2001] multiclass AUC metric can be extended to be weighted by the prevalence:

where \(c\) is the number of classes. This algorithm is used by setting the keyword argument multiclass to 'ovo' and average to 'weighted'. The 'weighted' option returns a prevalence-weighted average as described in [FC2009].

Computes the AUC of each class against the rest [PD2000]. The algorithm is functionally the same as the multilabel case. To enable this algorithm set the keyword argument multiclass to 'ovr'. Additionally to 'macro' [F2006] and 'weighted' [F2001] averaging, OvR supports 'micro' averaging.

In applications where a high false positive rate is not tolerable the parameter max_fpr of roc_auc_score can be used to summarize the ROC curve up to the given limit.

The following figure shows the micro-averaged ROC curve and its corresponding ROC-AUC score for a classifier aimed to distinguish the different species in the Iris plants dataset:

In multi-label classification, the roc_auc_score function is extended by averaging over the labels as above. In this case, you should provide a y_score of shape (n_samples, n_classes). Thus, when using the probability estimates, one needs to select the probability of the class with the greater label for each output.

And the decision values do not require such processing.

See Multiclass Receiver Operating Characteristic (ROC) for an example of using ROC to evaluate the quality of the output of a classifier.

See Receiver Operating Characteristic (ROC) with cross validation for an example of using ROC to evaluate classifier output quality, using cross-validation.

See Species distribution modeling for an example of using ROC to model species distribution.

Hand, D.J. and Till, R.J., (2001). A simple generalisation of the area under the ROC curve for multiple class classification problems. Machine learning, 45(2), pp. 171-186.

Ferri, Cèsar & Hernandez-Orallo, Jose & Modroiu, R. (2009). An Experimental Comparison of Performance Measures for Classification. Pattern Recognition Letters. 30. 27-38.

Provost, F., Domingos, P. (2000). Well-trained PETs: Improving probability estimation trees (Section 6.2), CeDER Working Paper #IS-00-04, Stern School of Business, New York University.

Fawcett, T., 2006. An introduction to ROC analysis. Pattern Recognition Letters, 27(8), pp. 861-874.

Fawcett, T., 2001. Using rule sets to maximize ROC performance In Data Mining, 2001. Proceedings IEEE International Conference, pp. 131-138.

The function det_curve computes the detection error tradeoff curve (DET) curve [WikipediaDET2017]. Quoting Wikipedia:

“A detection error tradeoff (DET) graph is a graphical plot of error rates for binary classification systems, plotting false reject rate vs. false accept rate. The x- and y-axes are scaled non-linearly by their standard normal deviates (or just by logarithmic transformation), yielding tradeoff curves that are more linear than ROC curves, and use most of the image area to highlight the differences of importance in the critical operating region.”

DET curves are a variation of receiver operating characteristic (ROC) curves where False Negative Rate is plotted on the y-axis instead of True Positive Rate. DET curves are commonly plotted in normal deviate scale by transformation with \(\phi^{-1}\) (with \(\phi\) being the cumulative distribution function). The resulting performance curves explicitly visualize the tradeoff of error types for given classification algorithms. See [Martin1997] for examples and further motivation.

This figure compares the ROC and DET curves of two example classifiers on the same classification task:

DET curves form a linear curve in normal deviate scale if the detection scores are normally (or close-to normally) distributed. It was shown by [Navratil2007] that the reverse is not necessarily true and even more general distributions are able to produce linear DET curves.

The normal deviate scale transformation spreads out the points such that a comparatively larger space of plot is occupied. Therefore curves with similar classification performance might be easier to distinguish on a DET plot.

With False Negative Rate being “inverse” to True Positive Rate the point of perfection for DET curves is the origin (in contrast to the top left corner for ROC curves).

DET curves are intuitive to read and hence allow quick visual assessment of a classifier’s performance. Additionally DET curves can be consulted for threshold analysis and operating point selection. This is particularly helpful if a comparison of error types is required.

On the other hand DET curves do not provide their metric as a single number. Therefore for either automated evaluation or comparison to other classification tasks metrics like the derived area under ROC curve might be better suited.

See Detection error tradeoff (DET) curve for an example comparison between receiver operating characteristic (ROC) curves and Detection error tradeoff (DET) curves.

Wikipedia contributors. Detection error tradeoff. Wikipedia, The Free Encyclopedia. September 4, 2017, 23:33 UTC. Available at: https://en.wikipedia.org/w/index.php?title=Detection_error_tradeoff&oldid=798982054. Accessed February 19, 2018.

A. Martin, G. Doddington, T. Kamm, M. Ordowski, and M. Przybocki, The DET Curve in Assessment of Detection Task Performance, NIST 1997.

J. Navratil and D. Klusacek, “On Linear DETs”, 2007 IEEE International Conference on Acoustics, Speech and Signal Processing - ICASSP ‘07, Honolulu, HI, 2007, pp. IV-229-IV-232.

The zero_one_loss function computes the sum or the average of the 0-1 classification loss (\(L_{0-1}\)) over \(n_{\text{samples}}\). By default, the function normalizes over the sample. To get the sum of the \(L_{0-1}\), set normalize to False.

In multilabel classification, the zero_one_loss scores a subset as one if its labels strictly match the predictions, and as a zero if there are any errors. By default, the function returns the percentage of imperfectly predicted subsets. To get the count of such subsets instead, set normalize to False.

If \(\hat{y}_i\) is the predicted value of the \(i\)-th sample and \(y_i\) is the corresponding true value, then the 0-1 loss \(L_{0-1}\) is defined as:

where \(1(x)\) is the indicator function. The zero-one loss can also be computed as \(\text{zero-one loss} = 1 - \text{accuracy}\).

In the multilabel case with binary label indicators, where the first label set [0,1] has an error:

See Recursive feature elimination with cross-validation for an example of zero one loss usage to perform recursive feature elimination with cross-validation.

The brier_score_loss function computes the Brier score for binary and multiclass probabilistic predictions and is equivalent to the mean squared error. Quoting Wikipedia:

“The Brier score is a strictly proper scoring rule that measures the accuracy of probabilistic predictions. […] [It] is applicable to tasks in which predictions must assign probabilities to a set of mutually exclusive discrete outcomes or classes.”

Let the true labels for a set of \(N\) data points be encoded as a 1-of-K binary indicator matrix \(Y\), i.e., \(y_{i,k} = 1\) if sample \(i\) has label \(k\) taken from a set of \(K\) labels. Let \(\hat{P}\) be a matrix of probability estimates with elements \(\hat{p}_{i,k} \approx \operatorname{Pr}(y_{i,k} = 1)\). Following the original definition by [Brier1950], the Brier score is given by:

The Brier score lies in the interval \([0, 2]\) and the lower the value the better the probability estimates are (the mean squared difference is smaller). Actually, the Brier score is a strictly proper scoring rule, meaning that it achieves the best score only when the estimated probabilities equal the true ones.

Note that in the binary case, the Brier score is usually divided by two and ranges between \([0,1]\). For binary targets \(y_i \in \{0, 1\}\) and probability estimates \(\hat{p}_i \approx \operatorname{Pr}(y_i = 1)\) for the positive class, the Brier score is then equal to:

The brier_score_loss function computes the Brier score given the ground-truth labels and predicted probabilities, as returned by an estimator’s predict_proba method. The scale_by_half parameter controls which of the two above definitions to follow.

The Brier score can be used to assess how well a classifier is calibrated. However, a lower Brier score loss does not always mean a better calibration. This is because, by analogy with the bias-variance decomposition of the mean squared error, the Brier score loss can be decomposed as the sum of calibration loss and refinement loss [Bella2012]. Calibration loss is defined as the mean squared deviation from empirical probabilities derived from the slope of ROC segments. Refinement loss can be defined as the expected optimal loss as measured by the area under the optimal cost curve. Refinement loss can change independently from calibration loss, thus a lower Brier score loss does not necessarily mean a better calibrated model. “Only when refinement loss remains the same does a lower Brier score loss always mean better calibration” [Bella2012], [Flach2008].

See Probability calibration of classifiers for an example of Brier score loss usage to perform probability calibration of classifiers.

G. Brier, Verification of forecasts expressed in terms of probability, Monthly weather review 78.1 (1950)

Bella, Ferri, Hernández-Orallo, and Ramírez-Quintana “Calibration of Machine Learning Models” in Khosrow-Pour, M. “Machine learning: concepts, methodologies, tools and applications.” Hershey, PA: Information Science Reference (2012).

Flach, Peter, and Edson Matsubara. “On classification, ranking, and probability estimation.” Dagstuhl Seminar Proceedings. Schloss Dagstuhl-Leibniz-Zentrum für Informatik (2008).

The class_likelihood_ratios function computes the positive and negative likelihood ratios \(LR_\pm\) for binary classes, which can be interpreted as the ratio of post-test to pre-test odds as explained below. As a consequence, this metric is invariant w.r.t. the class prevalence (the number of samples in the positive class divided by the total number of samples) and can be extrapolated between populations regardless of any possible class imbalance.

The \(LR_\pm\) metrics are therefore very useful in settings where the data available to learn and evaluate a classifier is a study population with nearly balanced classes, such as a case-control study, while the target application, i.e. the general population, has very low prevalence.

The positive likelihood ratio \(LR_+\) is the probability of a classifier to correctly predict that a sample belongs to the positive class divided by the probability of predicting the positive class for a sample belonging to the negative class:

The notation here refers to predicted (\(P\)) or true (\(T\)) label and the sign \(+\) and \(-\) refer to the positive and negative class, respectively, e.g. \(P+\) stands for “predicted positive”.

Analogously, the negative likelihood ratio \(LR_-\) is the probability of a sample of the positive class being classified as belonging to the negative class divided by the probability of a sample of the negative class being correctly classified:

For classifiers above chance \(LR_+\) above 1 higher is better, while \(LR_-\) ranges from 0 to 1 and lower is better. Values of \(LR_\pm\approx 1\) correspond to chance level.

Notice that probabilities differ from counts, for instance \(\operatorname{PR}(P+|T+)\) is not equal to the number of true positive counts tp (see the wikipedia page for the actual formulas).

Class Likelihood Ratios to measure classification performance

Both class likelihood ratios are interpretable in terms of an odds ratio (pre-test and post-tests):

Odds are in general related to probabilities via

On a given population, the pre-test probability is given by the prevalence. By converting odds to probabilities, the likelihood ratios can be translated into a probability of truly belonging to either class before and after a classifier prediction:

The positive likelihood ratio (LR+) is undefined when \(fp=0\), meaning the classifier does not misclassify any negative labels as positives. This condition can either indicate a perfect identification of all the negative cases or, if there are also no true positive predictions (\(tp=0\)), that the classifier does not predict the positive class at all. In the first case, LR+ can be interpreted as np.inf, in the second case (for instance, with highly imbalanced data) it can be interpreted as np.nan.

The negative likelihood ratio (LR-) is undefined when \(tn=0\). Such divergence is invalid, as \(LR_- > 1.0\) would indicate an increase in the odds of a sample belonging to the positive class after being classified as negative, as if the act of classifying caused the positive condition. This includes the case of a DummyClassifier that always predicts the positive class (i.e. when \(tn=fn=0\)).

Both class likelihood ratios (LR+ and LR-) are undefined when \(tp=fn=0\), which means that no samples of the positive class were present in the test set. This can happen when cross-validating on highly imbalanced data and also leads to a division by zero.

If a division by zero occurs and raise_warning is set to True (default), class_likelihood_ratios raises an UndefinedMetricWarning and returns np.nan by default to avoid pollution when averaging over cross-validation folds. Users can set return values in case of a division by zero with the replace_undefined_by param.

For a worked-out demonstration of the class_likelihood_ratios function, see the example below.

Wikipedia entry for Likelihood ratios in diagnostic testing

Brenner, H., & Gefeller, O. (1997). Variation of sensitivity, specificity, likelihood ratios and predictive values with disease prevalence. Statistics in medicine, 16(9), 981-991.

The D² score computes the fraction of deviance explained. It is a generalization of R², where the squared error is generalized and replaced by a classification deviance of choice \(\text{dev}(y, \hat{y})\) (e.g., Log loss, Brier score,). D² is a form of a skill score. It is calculated as

Where \(y_{\text{null}}\) is the optimal prediction of an intercept-only model (e.g., the per-class proportion of y_true in the case of the Log loss and Brier score).

Like R², the best possible score is 1.0 and it can be negative (because the model can be arbitrarily worse). A constant model that always predicts \(y_{\text{null}}\), disregarding the input features, would get a D² score of 0.0.

The d2_log_loss_score function implements the special case of D² with the log loss, see Log loss, i.e.:

Here are some usage examples of the d2_log_loss_score function:

The d2_brier_score function implements the special case of D² with the Brier score, see Brier score loss, i.e.:

This is also referred to as the Brier Skill Score (BSS).

Here are some usage examples of the d2_brier_score function:

In multilabel learning, each sample can have any number of ground truth labels associated with it. The goal is to give high scores and better rank to the ground truth labels.

The coverage_error function computes the average number of labels that have to be included in the final prediction such that all true labels are predicted. This is useful if you want to know how many top-scored-labels you have to predict in average without missing any true one. The best value of this metric is thus the average number of true labels.

Our implementation’s score is 1 greater than the one given in Tsoumakas et al., 2010. This extends it to handle the degenerate case in which an instance has 0 true labels.

Formally, given a binary indicator matrix of the ground truth labels \(y \in \left\{0, 1\right\}^{n_\text{samples} \times n_\text{labels}}\) and the score associated with each label \(\hat{f} \in \mathbb{R}^{n_\text{samples} \times n_\text{labels}}\), the coverage is defined as

with \(\text{rank}_{ij} = \left|\left\{k: \hat{f}_{ik} \geq \hat{f}_{ij} \right\}\right|\). Given the rank definition, ties in y_scores are broken by giving the maximal rank that would have been assigned to all tied values.

Here is a small example of usage of this function:

The label_ranking_average_precision_score function implements label ranking average precision (LRAP). This metric is linked to the average_precision_score function, but is based on the notion of label ranking instead of precision and recall.

Label ranking average precision (LRAP) averages over the samples the answer to the following question: for each ground truth label, what fraction of higher-ranked labels were true labels? This performance measure will be higher if you are able to give better rank to the labels associated with each sample. The obtained score is always strictly greater than 0, and the best value is 1. If there is exactly one relevant label per sample, label ranking average precision is equivalent to the mean reciprocal rank.

Formally, given a binary indicator matrix of the ground truth labels \(y \in \left\{0, 1\right\}^{n_\text{samples} \times n_\text{labels}}\) and the score associated with each label \(\hat{f} \in \mathbb{R}^{n_\text{samples} \times n_\text{labels}}\), the average precision is defined as

where \(\mathcal{L}_{ij} = \left\{k: y_{ik} = 1, \hat{f}_{ik} \geq \hat{f}_{ij} \right\}\), \(\text{rank}_{ij} = \left|\left\{k: \hat{f}_{ik} \geq \hat{f}_{ij} \right\}\right|\), \(|\cdot|\) computes the cardinality of the set (i.e., the number of elements in the set), and \(||\cdot||_0\) is the \(\ell_0\) “norm” (which computes the number of nonzero elements in a vector).

Here is a small example of usage of this function:

The label_ranking_loss function computes the ranking loss which averages over the samples the number of label pairs that are incorrectly ordered, i.e. true labels have a lower score than false labels, weighted by the inverse of the number of ordered pairs of false and true labels. The lowest achievable ranking loss is zero.

Formally, given a binary indicator matrix of the ground truth labels \(y \in \left\{0, 1\right\}^{n_\text{samples} \times n_\text{labels}}\) and the score associated with each label \(\hat{f} \in \mathbb{R}^{n_\text{samples} \times n_\text{labels}}\), the ranking loss is defined as

where \(|\cdot|\) computes the cardinality of the set (i.e., the number of elements in the set) and \(||\cdot||_0\) is the \(\ell_0\) “norm” (which computes the number of nonzero elements in a vector).

Here is a small example of usage of this function:

Tsoumakas, G., Katakis, I., & Vlahavas, I. (2010). Mining multi-label data. In Data mining and knowledge discovery handbook (pp. 667-685). Springer US.

Discounted Cumulative Gain (DCG) and Normalized Discounted Cumulative Gain (NDCG) are ranking metrics implemented in dcg_score and ndcg_score ; they compare a predicted order to ground-truth scores, such as the relevance of answers to a query.

From the Wikipedia page for Discounted Cumulative Gain:

“Discounted cumulative gain (DCG) is a measure of ranking quality. In information retrieval, it is often used to measure effectiveness of web search engine algorithms or related applications. Using a graded relevance scale of documents in a search-engine result set, DCG measures the usefulness, or gain, of a document based on its position in the result list. The gain is accumulated from the top of the result list to the bottom, with the gain of each result discounted at lower ranks.”

DCG orders the true targets (e.g. relevance of query answers) in the predicted order, then multiplies them by a logarithmic decay and sums the result. The sum can be truncated after the first \(K\) results, in which case we call it DCG@K. NDCG, or NDCG@K is DCG divided by the DCG obtained by a perfect prediction, so that it is always between 0 and 1. Usually, NDCG is preferred to DCG.

Compared with the ranking loss, NDCG can take into account relevance scores, rather than a ground-truth ranking. So if the ground-truth consists only of an ordering, the ranking loss should be preferred; if the ground-truth consists of actual usefulness scores (e.g. 0 for irrelevant, 1 for relevant, 2 for very relevant), NDCG can be used.

For one sample, given the vector of continuous ground-truth values for each target \(y \in \mathbb{R}^{M}\), where \(M\) is the number of outputs, and the prediction \(\hat{y}\), which induces the ranking function \(f\), the DCG score is

and the NDCG score is the DCG score divided by the DCG score obtained for \(y\).

Wikipedia entry for Discounted Cumulative Gain

Jarvelin, K., & Kekalainen, J. (2002). Cumulated gain-based evaluation of IR techniques. ACM Transactions on Information Systems (TOIS), 20(4), 422-446.

Wang, Y., Wang, L., Li, Y., He, D., Chen, W., & Liu, T. Y. (2013, May). A theoretical analysis of NDCG ranking measures. In Proceedings of the 26th Annual Conference on Learning Theory (COLT 2013)

McSherry, F., & Najork, M. (2008, March). Computing information retrieval performance measures efficiently in the presence of tied scores. In European conference on information retrieval (pp. 414-421). Springer, Berlin, Heidelberg.

The sklearn.metrics module implements several loss, score, and utility functions to measure regression performance. Some of those have been enhanced to handle the multioutput case: mean_squared_error, mean_absolute_error, r2_score, explained_variance_score, mean_pinball_loss, d2_pinball_score and d2_absolute_error_score.

These functions have a multioutput keyword argument which specifies the way the scores or losses for each individual target should be averaged. The default is 'uniform_average', which specifies a uniformly weighted mean over outputs. If an ndarray of shape (n_outputs,) is passed, then its entries are interpreted as weights and an according weighted average is returned. If multioutput is 'raw_values', then all unaltered individual scores or losses will be returned in an array of shape (n_outputs,).

The r2_score and explained_variance_score accept an additional value 'variance_weighted' for the multioutput parameter. This option leads to a weighting of each individual score by the variance of the corresponding target variable. This setting quantifies the globally captured unscaled variance. If the target variables are of different scale, then this score puts more importance on explaining the higher variance variables.

The r2_score function computes the coefficient of determination, usually denoted as \(R^2\).

It represents the proportion of variance (of y) that has been explained by the independent variables in the model. It provides an indication of goodness of fit and therefore a measure of how well unseen samples are likely to be predicted by the model, through the proportion of explained variance.

As such variance is dataset dependent, \(R^2\) may not be meaningfully comparable across different datasets. Best possible score is 1.0 and it can be negative (because the model can be arbitrarily worse). A constant model that always predicts the expected (average) value of y, disregarding the input features, would get an \(R^2\) score of 0.0.

Note: when the prediction residuals have zero mean, the \(R^2\) score and the Explained variance score are identical.

If \(\hat{y}_i\) is the predicted value of the \(i\)-th sample and \(y_i\) is the corresponding true value for total \(n\) samples, the estimated \(R^2\) is defined as:

where \(\bar{y} = \frac{1}{n} \sum_{i=1}^{n} y_i\) and \(\sum_{i=1}^{n} (y_i - \hat{y}_i)^2 = \sum_{i=1}^{n} \epsilon_i^2\).

Note that r2_score calculates unadjusted \(R^2\) without correcting for bias in sample variance of y.

In the particular case where the true target is constant, the \(R^2\) score is not finite: it is either NaN (perfect predictions) or -Inf (imperfect predictions). Such non-finite scores may prevent correct model optimization such as grid-search cross-validation to be performed correctly. For this reason the default behaviour of r2_score is to replace them with 1.0 (perfect predictions) or 0.0 (imperfect predictions). If force_finite is set to False, this score falls back on the original \(R^2\) definition.

Here is a small example of usage of the r2_score function:

See L1-based models for Sparse Signals for an example of R² score usage to evaluate Lasso and Elastic Net on sparse signals.

The mean_absolute_error function computes mean absolute error, a risk metric corresponding to the expected value of the absolute error loss or \(l1\)-norm loss.

If \(\hat{y}_i\) is the predicted value of the \(i\)-th sample, and \(y_i\) is the corresponding true value, then the mean absolute error (MAE) estimated over \(n_{\text{samples}}\) is defined as

Here is a small example of usage of the mean_absolute_error function:

The mean_squared_error function computes mean squared error, a risk metric corresponding to the expected value of the squared (quadratic) error or loss.

If \(\hat{y}_i\) is the predicted value of the \(i\)-th sample, and \(y_i\) is the corresponding true value, then the mean squared error (MSE) estimated over \(n_{\text{samples}}\) is defined as

Here is a small example of usage of the mean_squared_error function:

See Gradient Boosting regression for an example of mean squared error usage to evaluate gradient boosting regression.

Taking the square root of the MSE, called the root mean squared error (RMSE), is another common metric that provides a measure in the same units as the target variable. RMSE is available through the root_mean_squared_error function.

The mean_squared_log_error function computes a risk metric corresponding to the expected value of the squared logarithmic (quadratic) error or loss.

If \(\hat{y}_i\) is the predicted value of the \(i\)-th sample, and \(y_i\) is the corresponding true value, then the mean squared logarithmic error (MSLE) estimated over \(n_{\text{samples}}\) is defined as

Where \(\log_e (x)\) means the natural logarithm of \(x\). This metric is best to use when targets having exponential growth, such as population counts, average sales of a commodity over a span of years etc. Note that this metric penalizes an under-predicted estimate greater than an over-predicted estimate.

Here is a small example of usage of the mean_squared_log_error function:

The root mean squared logarithmic error (RMSLE) is available through the root_mean_squared_log_error function.

The mean_absolute_percentage_error (MAPE), also known as mean absolute percentage deviation (MAPD), is an evaluation metric for regression problems. The idea of this metric is to be sensitive to relative errors. It is for example not changed by a global scaling of the target variable.

If \(\hat{y}_i\) is the predicted value of the \(i\)-th sample and \(y_i\) is the corresponding true value, then the mean absolute percentage error (MAPE) estimated over \(n_{\text{samples}}\) is defined as

where \(\epsilon\) is an arbitrary small yet strictly positive number to avoid undefined results when y is zero.

The mean_absolute_percentage_error function supports multioutput.

Here is a small example of usage of the mean_absolute_percentage_error function:

In above example, if we had used mean_absolute_error, it would have ignored the small magnitude values and only reflected the error in prediction of highest magnitude value. But that problem is resolved in case of MAPE because it calculates relative percentage error with respect to actual output.

The MAPE formula here does not represent the common “percentage” definition: the percentage in the range [0, 100] is converted to a relative value in the range [0, 1] by dividing by 100. Thus, an error of 200% corresponds to a relative error of 2. The motivation here is to have a range of values that is more consistent with other error metrics in scikit-learn, such as accuracy_score.

To obtain the mean absolute percentage error as per the Wikipedia formula, multiply the mean_absolute_percentage_error computed here by 100.

Wikipedia entry for Mean Absolute Percentage Error

The median_absolute_error is particularly interesting because it is robust to outliers. The loss is calculated by taking the median of all absolute differences between the target and the prediction.

If \(\hat{y}_i\) is the predicted value of the \(i\)-th sample and \(y_i\) is the corresponding true value, then the median absolute error (MedAE) estimated over \(n_{\text{samples}}\) is defined as

The median_absolute_error does not support multioutput.

Here is a small example of usage of the median_absolute_error function:

The max_error function computes the maximum residual error , a metric that captures the worst case error between the predicted value and the true value. In a perfectly fitted single output regression model, max_error would be 0 on the training set and though this would be highly unlikely in the real world, this metric shows the extent of error that the model had when it was fitted.

If \(\hat{y}_i\) is the predicted value of the \(i\)-th sample, and \(y_i\) is the corresponding true value, then the max error is defined as

Here is a small example of usage of the max_error function:

The max_error does not support multioutput.

The explained_variance_score computes the explained variance regression score.

If \(\hat{y}\) is the estimated target output, \(y\) the corresponding (correct) target output, and \(Var\) is Variance, the square of the standard deviation, then the explained variance is estimated as follow:

The best possible score is 1.0, lower values are worse.

Link to R² score, the coefficient of determination

The difference between the explained variance score and the R² score, the coefficient of determination is that the explained variance score does not account for systematic offset in the prediction. For this reason, the R² score, the coefficient of determination should be preferred in general.

In the particular case where the true target is constant, the Explained Variance score is not finite: it is either NaN (perfect predictions) or -Inf (imperfect predictions). Such non-finite scores may prevent correct model optimization such as grid-search cross-validation to be performed correctly. For this reason the default behaviour of explained_variance_score is to replace them with 1.0 (perfect predictions) or 0.0 (imperfect predictions). You can set the force_finite parameter to False to prevent this fix from happening and fallback on the original Explained Variance score.

Here is a small example of usage of the explained_variance_score function:

The mean_tweedie_deviance function computes the mean Tweedie deviance error with a power parameter (\(p\)). This is a metric that elicits predicted expectation values of regression targets.

Following special cases exist,

when power=0 it is equivalent to mean_squared_error.

when power=1 it is equivalent to mean_poisson_deviance.

when power=2 it is equivalent to mean_gamma_deviance.

If \(\hat{y}_i\) is the predicted value of the \(i\)-th sample, and \(y_i\) is the corresponding true value, then the mean Tweedie deviance error (D) for power \(p\), estimated over \(n_{\text{samples}}\) is defined as

Tweedie deviance is a homogeneous function of degree 2-power. Thus, Gamma distribution with power=2 means that simultaneously scaling y_true and y_pred has no effect on the deviance. For Poisson distribution power=1 the deviance scales linearly, and for Normal distribution (power=0), quadratically. In general, the higher power the less weight is given to extreme deviations between true and predicted targets.

For instance, let’s compare the two predictions 1.5 and 150 that are both 50% larger than their corresponding true value.

The mean squared error (power=0) is very sensitive to the prediction difference of the second point,:

If we increase power to 1,:

the difference in errors decreases. Finally, by setting, power=2:

we would get identical errors. The deviance when power=2 is thus only sensitive to relative errors.

The mean_pinball_loss function is used to evaluate the predictive performance of quantile regression models.

The value of pinball loss is equivalent to half of mean_absolute_error when the quantile parameter alpha is set to 0.5.

Here is a small example of usage of the mean_pinball_loss function:

It is possible to build a scorer object with a specific choice of alpha:

Such a scorer can be used to evaluate the generalization performance of a quantile regressor via cross-validation:

It is also possible to build scorer objects for hyper-parameter tuning. The sign of the loss must be switched to ensure that greater means better as explained in the example linked below.

See Prediction Intervals for Gradient Boosting Regression for an example of using the pinball loss to evaluate and tune the hyper-parameters of quantile regression models on data with non-symmetric noise and outliers.

The D² score computes the fraction of deviance explained. It is a generalization of R², where the squared error is generalized and replaced by a deviance of choice \(\text{dev}(y, \hat{y})\) (e.g., Tweedie, pinball or mean absolute error). D² is a form of a skill score. It is calculated as

Where \(y_{\text{null}}\) is the optimal prediction of an intercept-only model (e.g., the mean of y_true for the Tweedie case, the median for absolute error and the alpha-quantile for pinball loss).

Like R², the best possible score is 1.0 and it can be negative (because the model can be arbitrarily worse). A constant model that always predicts \(y_{\text{null}}\), disregarding the input features, would get a D² score of 0.0.

The d2_tweedie_score function implements the special case of D² where \(\text{dev}(y, \hat{y})\) is the Tweedie deviance, see Mean Poisson, Gamma, and Tweedie deviances. It is also known as D² Tweedie and is related to McFadden’s likelihood ratio index.

The argument power defines the Tweedie power as for mean_tweedie_deviance. Note that for power=0, d2_tweedie_score equals r2_score (for single targets).

A scorer object with a specific choice of power can be built by:

The d2_pinball_score function implements the special case of D² with the pinball loss, see Pinball loss, i.e.:

The argument alpha defines the slope of the pinball loss as for mean_pinball_loss (Pinball loss). It determines the quantile level alpha for which the pinball loss and also D² are optimal. Note that for alpha=0.5 (the default) d2_pinball_score equals d2_absolute_error_score.

A scorer object with a specific choice of alpha can be built by:

The d2_absolute_error_score function implements the special case of the Mean absolute error:

Here are some usage examples of the d2_absolute_error_score function:

Among methods to assess the quality of regression models, scikit-learn provides the PredictionErrorDisplay class. It allows to visually inspect the prediction errors of a model in two different manners.

The plot on the left shows the actual values vs predicted values. For a noise-free regression task aiming to predict the (conditional) expectation of y, a perfect regression model would display data points on the diagonal defined by predicted equal to actual values. The further away from this optimal line, the larger the error of the model. In a more realistic setting with irreducible noise, that is, when not all the variations of y can be explained by features in X, then the best model would lead to a cloud of points densely arranged around the diagonal.

Note that the above only holds when the predicted values is the expected value of y given X. This is typically the case for regression models that minimize the mean squared error objective function or more generally the mean Tweedie deviance for any value of its “power” parameter.

When plotting the predictions of an estimator that predicts a quantile of y given X, e.g. QuantileRegressor or any other model minimizing the pinball loss, a fraction of the points are either expected to lie above or below the diagonal depending on the estimated quantile level.

All in all, while intuitive to read, this plot does not really inform us on what to do to obtain a better model.

The right-hand side plot shows the residuals (i.e. the difference between the actual and the predicted values) vs. the predicted values.

This plot makes it easier to visualize if the residuals follow and homoscedastic or heteroschedastic distribution.

In particular, if the true distribution of y|X is Poisson or Gamma distributed, it is expected that the variance of the residuals of the optimal model would grow with the predicted value of E[y|X] (either linearly for Poisson or quadratically for Gamma).

When fitting a linear least squares regression model (see LinearRegression and Ridge), we can use this plot to check if some of the model assumptions are met, in particular that the residuals should be uncorrelated, their expected value should be null and that their variance should be constant (homoschedasticity).

If this is not the case, and in particular if the residuals plot show some banana-shaped structure, this is a hint that the model is likely mis-specified and that non-linear feature engineering or switching to a non-linear regression model might be useful.

Refer to the example below to see a model evaluation that makes use of this display.

See Effect of transforming the targets in regression model for an example on how to use PredictionErrorDisplay to visualize the prediction quality improvement of a regression model obtained by transforming the target before learning.

The sklearn.metrics module implements several loss, score, and utility functions to measure clustering performance. For more information see the Clustering performance evaluation section for instance clustering, and Biclustering evaluation for biclustering.

When doing supervised learning, a simple sanity check consists of comparing one’s estimator against simple rules of thumb. DummyClassifier implements several such simple strategies for classification:

stratified generates random predictions by respecting the training set class distribution.

most_frequent always predicts the most frequent label in the training set.

prior always predicts the class that maximizes the class prior (like most_frequent) and predict_proba returns the class prior.

uniform generates predictions uniformly at random.

A major motivation of this method is F1-scoring, when the positive class is in the minority.

Note that with all these strategies, the predict method completely ignores the input data!

To illustrate DummyClassifier, first let’s create an imbalanced dataset:

Next, let’s compare the accuracy of SVC and most_frequent:

We see that SVC doesn’t do much better than a dummy classifier. Now, let’s change the kernel:

We see that the accuracy was boosted to almost 100%. A cross validation strategy is recommended for a better estimate of the accuracy, if it is not too CPU costly. For more information see the Cross-validation: evaluating estimator performance section. Moreover if you want to optimize over the parameter space, it is highly recommended to use an appropriate methodology; see the Tuning the hyper-parameters of an estimator section for details.

More generally, when the accuracy of a classifier is too close to random, it probably means that something went wrong: features are not helpful, a hyperparameter is not correctly tuned, the classifier is suffering from class imbalance, etc…

DummyRegressor also implements four simple rules of thumb for regression:

mean always predicts the mean of the training targets.

median always predicts the median of the training targets.

quantile always predicts a user provided quantile of the training targets.

constant always predicts a constant value that is provided by the user.

In all these strategies, the predict method completely ignores the input data.

**Examples:**

Example 1 (python):
```python
>>> from sklearn import svm, datasets
>>> from sklearn.model_selection import cross_val_score
>>> X, y = datasets.load_iris(return_X_y=True)
>>> clf = svm.SVC(random_state=0)
>>> cross_val_score(clf, X, y, cv=5, scoring='recall_macro')
array([0.96, 0.96, 0.96, 0.93, 1.        ])
```

Example 2 (sql):
```sql
>>> from sklearn.metrics import fbeta_score, make_scorer
>>> ftwo_scorer = make_scorer(fbeta_score, beta=2)
>>> from sklearn.model_selection import GridSearchCV
>>> from sklearn.svm import LinearSVC
>>> grid = GridSearchCV(LinearSVC(), param_grid={'C': [1, 10]},
...                     scoring=ftwo_scorer, cv=5)
```

Example 3 (python):
```python
>>> import numpy as np
>>> def my_custom_loss_func(y_true, y_pred):
...     diff = np.abs(y_true - y_pred).max()
...     return float(np.log1p(diff))
...
>>> # score will negate the return value of my_custom_loss_func,
>>> # which will be np.log(2), 0.693, given the values for X
>>> # and y defined below.
>>> score = make_scorer(my_custom_loss_func, greater_is_better=False)
>>> X = [[1], [1]]
>>> y = [0, 1]
>>> from sklearn.dummy import DummyClassifier
>>> clf = DummyClassifier(strategy='most_frequent', random_state=0)
>>> clf = clf.fit(X, y)
>>> my_custom_loss_func(y, clf.predict(X))
0.69
>>> score(clf, X, y)
-0.69
```

Example 4 (python):
```python
>>> from custom_scorer_module import custom_scoring_function
>>> cross_val_score(model,
...  X_train,
...  y_train,
...  scoring=make_scorer(custom_scoring_function, greater_is_better=False),
...  cv=5,
...  n_jobs=-1)
```

---

## MiniBatchDictionaryLearning#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.MiniBatchDictionaryLearning.html

**Contents:**
- MiniBatchDictionaryLearning#
- Gallery examples#

Mini-batch dictionary learning.

Finds a dictionary (a set of atoms) that performs well at sparsely encoding the fitted data.

Solves the optimization problem:

||.||_Fro stands for the Frobenius norm and ||.||_1,1 stands for the entry-wise matrix norm which is the sum of the absolute values of all the entries in the matrix.

Read more in the User Guide.

Number of dictionary elements to extract.

Sparsity controlling parameter.

Maximum number of iterations over the complete dataset before stopping independently of any early stopping criterion heuristics.

Added in version 1.1.

'lars': uses the least angle regression method to solve the lasso problem (linear_model.lars_path)

'cd': uses the coordinate descent method to compute the Lasso solution (linear_model.Lasso). Lars will be faster if the estimated components are sparse.

Number of parallel jobs to run. None means 1 unless in a joblib.parallel_backend context. -1 means using all processors. See Glossary for more details.

Number of samples in each mini-batch.

Changed in version 1.3: The default value of batch_size changed from 3 to 256 in version 1.3.

Whether to shuffle the samples before forming batches.

Initial value of the dictionary for warm restart scenarios.

Algorithm used to transform the data:

'lars': uses the least angle regression method (linear_model.lars_path);

'lasso_lars': uses Lars to compute the Lasso solution.

'lasso_cd': uses the coordinate descent method to compute the Lasso solution (linear_model.Lasso). 'lasso_lars' will be faster if the estimated components are sparse.

'omp': uses orthogonal matching pursuit to estimate the sparse solution.

'threshold': squashes to zero all coefficients less than alpha from the projection dictionary * X'.

Number of nonzero coefficients to target in each column of the solution. This is only used by algorithm='lars' and algorithm='omp'. If None, then transform_n_nonzero_coefs=int(n_features / 10).

If algorithm='lasso_lars' or algorithm='lasso_cd', alpha is the penalty applied to the L1 norm. If algorithm='threshold', alpha is the absolute value of the threshold below which coefficients will be squashed to zero. If None, defaults to alpha.

Changed in version 1.2: When None, default value changed from 1.0 to alpha.

To control the verbosity of the procedure.

Whether to split the sparse feature vector into the concatenation of its negative part and its positive part. This can improve the performance of downstream classifiers.

Used for initializing the dictionary when dict_init is not specified, randomly shuffling the data when shuffle is set to True, and updating the dictionary. Pass an int for reproducible results across multiple function calls. See Glossary.

Whether to enforce positivity when finding the code.

Added in version 0.20.

Whether to enforce positivity when finding the dictionary.

Added in version 0.20.

Maximum number of iterations to perform if algorithm='lasso_cd' or 'lasso_lars'.

Added in version 0.22.

A callable that gets invoked at the end of each iteration.

Added in version 1.1.

Control early stopping based on the norm of the differences in the dictionary between 2 steps.

To disable early stopping based on changes in the dictionary, set tol to 0.0.

Added in version 1.1.

Control early stopping based on the consecutive number of mini batches that does not yield an improvement on the smoothed cost function.

To disable convergence detection based on cost function, set max_no_improvement to None.

Added in version 1.1.

Components extracted from the data.

Number of features seen during fit.

Added in version 0.24.

Names of features seen during fit. Defined only when X has feature names that are all strings.

Added in version 1.0.

Number of iterations over the full dataset.

Number of mini-batches processed.

Added in version 1.1.

Find a dictionary that sparsely encodes data.

Mini-batch Sparse Principal Components Analysis.

Find a sparse representation of data from a fixed, precomputed dictionary.

Sparse Principal Components Analysis.

J. Mairal, F. Bach, J. Ponce, G. Sapiro, 2009: Online dictionary learning for sparse coding (https://www.di.ens.fr/~fbach/mairal_icml09.pdf)

We can check the level of sparsity of X_transformed:

We can compare the average squared euclidean norm of the reconstruction error of the sparse coded signal relative to the squared euclidean norm of the original signal:

For a more detailed example, see Image denoising using dictionary learning

Fit the model from data in X.

Training vector, where n_samples is the number of samples and n_features is the number of features.

Not used, present for API consistency by convention.

Returns the instance itself.

Fit to data, then transform it.

Fits transformer to X and y with optional parameters fit_params and returns a transformed version of X.

Target values (None for unsupervised transformations).

Additional fit parameters. Pass only if the estimator accepts additional params in its fit method.

Get output feature names for transformation.

The feature names out will prefixed by the lowercased class name. For example, if the transformer outputs 3 features, then the feature names out are: ["class_name0", "class_name1", "class_name2"].

Only used to validate feature names with the names seen in fit.

Transformed feature names.

Get metadata routing of this object.

Please check User Guide on how the routing mechanism works.

A MetadataRequest encapsulating routing information.

Get parameters for this estimator.

If True, will return the parameters for this estimator and contained subobjects that are estimators.

Parameter names mapped to their values.

Transform data back to its original space.

Data to be transformed back. Must have the same number of components as the data used to train the model.

Update the model using the data in X as a mini-batch.

Training vector, where n_samples is the number of samples and n_features is the number of features.

Not used, present for API consistency by convention.

Return the instance itself.

Set output container.

See Introducing the set_output API for an example on how to use the API.

Configure output of transform and fit_transform.

"default": Default output format of a transformer

"pandas": DataFrame output

"polars": Polars output

None: Transform configuration is unchanged

Added in version 1.4: "polars" option was added.

Set the parameters of this estimator.

The method works on simple estimators as well as on nested objects (such as Pipeline). The latter have parameters of the form <component>__<parameter> so that it’s possible to update each component of a nested object.

Estimator parameters.

Encode the data as a sparse combination of the dictionary atoms.

Coding method is determined by the object parameter transform_algorithm.

Test data to be transformed, must have the same number of features as the data used to train the model.

Faces dataset decompositions

Image denoising using dictionary learning

**Examples:**

Example 1 (unknown):
```unknown
(U^*,V^*) = argmin 0.5 || X - U V ||_Fro^2 + alpha * || U ||_1,1
             (U,V)
             with || V_k ||_2 <= 1 for all  0 <= k < n_components
```

Example 2 (sql):
```sql
>>> import numpy as np
>>> from sklearn.datasets import make_sparse_coded_signal
>>> from sklearn.decomposition import MiniBatchDictionaryLearning
>>> X, dictionary, code = make_sparse_coded_signal(
...     n_samples=30, n_components=15, n_features=20, n_nonzero_coefs=10,
...     random_state=42)
>>> dict_learner = MiniBatchDictionaryLearning(
...     n_components=15, batch_size=3, transform_algorithm='lasso_lars',
...     transform_alpha=0.1, max_iter=20, random_state=42)
>>> X_transformed = dict_learner.fit_transform(X)
```

Example 3 (unknown):
```unknown
>>> np.mean(X_transformed == 0) > 0.5
np.True_
```

Example 4 (unknown):
```unknown
>>> X_hat = X_transformed @ dict_learner.components_
>>> np.mean(np.sum((X_hat - X) ** 2, axis=1) / np.sum(X ** 2, axis=1))
np.float64(0.052)
```

---

## load_diabetes#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_diabetes.html

**Contents:**
- load_diabetes#
- Gallery examples#

Load and return the diabetes dataset (regression).

The meaning of each feature (i.e. feature_names) might be unclear (especially for ltg) as the documentation of the original dataset is not explicit. We provide information that seems correct in regard with the scientific literature in this field of research.

Read more in the User Guide.

If True, returns (data, target) instead of a Bunch object. See below for more information about the data and target object.

Added in version 0.18.

If True, the data is a pandas DataFrame including columns with appropriate dtypes (numeric). The target is a pandas DataFrame or Series depending on the number of target columns. If return_X_y is True, then (data, target) will be pandas DataFrames or Series as described below.

Added in version 0.23.

If True, the feature variables are mean centered and scaled by the standard deviation times the square root of n_samples. If False, raw data is returned for the feature variables.

Added in version 1.1.

Dictionary-like object, with the following attributes.

The data matrix. If as_frame=True, data will be a pandas DataFrame.

The regression target. If as_frame=True, target will be a pandas Series.

The names of the dataset columns.

Only present when as_frame=True. DataFrame with data and target.

Added in version 0.23.

The full description of the dataset.

The path to the location of the data.

The path to the location of the target.

Returns a tuple of two ndarray of shape (n_samples, n_features) A 2D array with each row representing one sample and each column representing the features and/or target of a given sample.

Added in version 0.18.

Model Complexity Influence

Gradient Boosting regression

Plot individual and voting regression predictions

Model-based and sequential feature selection

Imputing missing values before building an estimator

Lasso model selection via information criteria

Lasso, Lasso-LARS, and Elastic Net paths

Lasso model selection: AIC-BIC / cross-validation

Ordinary Least Squares and Ridge Regression

Advanced Plotting With Partial Dependence

Plotting Cross-Validated Predictions

Release Highlights for scikit-learn 1.2

**Examples:**

Example 1 (sql):
```sql
>>> from sklearn.datasets import load_diabetes
>>> diabetes = load_diabetes()
>>> diabetes.target[:3]
array([151.,  75., 141.])
>>> diabetes.data.shape
(442, 10)
```

---

## ExpSineSquared#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.gaussian_process.kernels.ExpSineSquared.html

**Contents:**
- ExpSineSquared#
- Gallery examples#

Exp-Sine-Squared kernel (aka periodic kernel).

The ExpSineSquared kernel allows one to model functions which repeat themselves exactly. It is parameterized by a length scale parameter \(l>0\) and a periodicity parameter \(p>0\). Only the isotropic variant where \(l\) is a scalar is supported at the moment. The kernel is given by:

where \(l\) is the length scale of the kernel, \(p\) the periodicity of the kernel and \(d(\cdot,\cdot)\) is the Euclidean distance.

Read more in the User Guide.

Added in version 0.18.

The length scale of the kernel.

The periodicity of the kernel.

The lower and upper bound on ‘length_scale’. If set to “fixed”, ‘length_scale’ cannot be changed during hyperparameter tuning.

The lower and upper bound on ‘periodicity’. If set to “fixed”, ‘periodicity’ cannot be changed during hyperparameter tuning.

Return the kernel k(X, Y) and optionally its gradient.

Left argument of the returned kernel k(X, Y)

Right argument of the returned kernel k(X, Y). If None, k(X, X) if evaluated instead.

Determines whether the gradient with respect to the log of the kernel hyperparameter is computed. Only supported when Y is None.

The gradient of the kernel k(X, X) with respect to the log of the hyperparameter of the kernel. Only returned when eval_gradient is True.

Returns the log-transformed bounds on the theta.

The log-transformed bounds on the kernel’s hyperparameters theta

Returns a clone of self with given hyperparameters theta.

Returns the diagonal of the kernel k(X, X).

The result of this method is identical to np.diag(self(X)); however, it can be evaluated more efficiently since only the diagonal is evaluated.

Left argument of the returned kernel k(X, Y)

Diagonal of kernel k(X, X)

Get parameters of this kernel.

If True, will return the parameters for this estimator and contained subobjects that are estimators.

Parameter names mapped to their values.

Returns the length scale

Returns a list of all hyperparameter specifications.

Returns whether the kernel is stationary.

Returns the number of non-fixed hyperparameters of the kernel.

Returns whether the kernel is defined on fixed-length feature vectors or generic objects. Defaults to True for backward compatibility.

Set the parameters of this kernel.

The method works on simple kernels as well as on nested kernels. The latter have parameters of the form <component>__<parameter> so that it’s possible to update each component of a nested object.

Returns the (flattened, log-transformed) non-fixed hyperparameters.

Note that theta are typically the log-transformed values of the kernel’s hyperparameters as this representation of the search space is more amenable for hyperparameter search, as hyperparameters like length-scales naturally live on a log-scale.

The non-fixed, log-transformed hyperparameters of the kernel

Comparison of kernel ridge and Gaussian process regression

Forecasting of CO2 level on Mona Loa dataset using Gaussian process regression (GPR)

Illustration of prior and posterior Gaussian process for different kernels

**Examples:**

Example 1 (sql):
```sql
>>> from sklearn.datasets import make_friedman2
>>> from sklearn.gaussian_process import GaussianProcessRegressor
>>> from sklearn.gaussian_process.kernels import ExpSineSquared
>>> X, y = make_friedman2(n_samples=50, noise=0, random_state=0)
>>> kernel = ExpSineSquared(length_scale=1, periodicity=1)
>>> gpr = GaussianProcessRegressor(kernel=kernel, alpha=5,
...         random_state=0).fit(X, y)
>>> gpr.score(X, y)
0.0144
>>> gpr.predict(X[:2,:], return_std=True)
(array([425.6, 457.5]), array([0.3894, 0.3467]))
```

---

## DotProduct#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.gaussian_process.kernels.DotProduct.html

**Contents:**
- DotProduct#
- Gallery examples#

The DotProduct kernel is non-stationary and can be obtained from linear regression by putting \(N(0, 1)\) priors on the coefficients of \(x_d (d = 1, . . . , D)\) and a prior of \(N(0, \sigma_0^2)\) on the bias. The DotProduct kernel is invariant to a rotation of the coordinates about the origin, but not translations. It is parameterized by a parameter sigma_0 \(\sigma\) which controls the inhomogenity of the kernel. For \(\sigma_0^2 =0\), the kernel is called the homogeneous linear kernel, otherwise it is inhomogeneous. The kernel is given by

The DotProduct kernel is commonly combined with exponentiation.

See [1], Chapter 4, Section 4.2, for further details regarding the DotProduct kernel.

Read more in the User Guide.

Added in version 0.18.

Parameter controlling the inhomogenity of the kernel. If sigma_0=0, the kernel is homogeneous.

The lower and upper bound on ‘sigma_0’. If set to “fixed”, ‘sigma_0’ cannot be changed during hyperparameter tuning.

Carl Edward Rasmussen, Christopher K. I. Williams (2006). “Gaussian Processes for Machine Learning”. The MIT Press.

Return the kernel k(X, Y) and optionally its gradient.

Left argument of the returned kernel k(X, Y)

Right argument of the returned kernel k(X, Y). If None, k(X, X) if evaluated instead.

Determines whether the gradient with respect to the log of the kernel hyperparameter is computed. Only supported when Y is None.

The gradient of the kernel k(X, X) with respect to the log of the hyperparameter of the kernel. Only returned when eval_gradient is True.

Returns the log-transformed bounds on the theta.

The log-transformed bounds on the kernel’s hyperparameters theta

Returns a clone of self with given hyperparameters theta.

Returns the diagonal of the kernel k(X, X).

The result of this method is identical to np.diag(self(X)); however, it can be evaluated more efficiently since only the diagonal is evaluated.

Left argument of the returned kernel k(X, Y).

Diagonal of kernel k(X, X).

Get parameters of this kernel.

If True, will return the parameters for this estimator and contained subobjects that are estimators.

Parameter names mapped to their values.

Returns a list of all hyperparameter specifications.

Returns whether the kernel is stationary.

Returns the number of non-fixed hyperparameters of the kernel.

Returns whether the kernel is defined on fixed-length feature vectors or generic objects. Defaults to True for backward compatibility.

Set the parameters of this kernel.

The method works on simple kernels as well as on nested kernels. The latter have parameters of the form <component>__<parameter> so that it’s possible to update each component of a nested object.

Returns the (flattened, log-transformed) non-fixed hyperparameters.

Note that theta are typically the log-transformed values of the kernel’s hyperparameters as this representation of the search space is more amenable for hyperparameter search, as hyperparameters like length-scales naturally live on a log-scale.

The non-fixed, log-transformed hyperparameters of the kernel

Iso-probability lines for Gaussian Processes classification (GPC)

Illustration of Gaussian process classification (GPC) on the XOR dataset

Illustration of prior and posterior Gaussian process for different kernels

**Examples:**

Example 1 (sql):
```sql
>>> from sklearn.datasets import make_friedman2
>>> from sklearn.gaussian_process import GaussianProcessRegressor
>>> from sklearn.gaussian_process.kernels import DotProduct, WhiteKernel
>>> X, y = make_friedman2(n_samples=500, noise=0, random_state=0)
>>> kernel = DotProduct() + WhiteKernel()
>>> gpr = GaussianProcessRegressor(kernel=kernel,
...         random_state=0).fit(X, y)
>>> gpr.score(X, y)
0.3680
>>> gpr.predict(X[:2,:], return_std=True)
(array([653.0, 592.1]), array([316.6, 316.6]))
```

---

## 

**URL:** https://scikit-learn.org/stable/_sources/modules/linear_model.rst.txt

---

## mean_pinball_loss#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_pinball_loss.html

**Contents:**
- mean_pinball_loss#
- Gallery examples#

Pinball loss for quantile regression.

Read more in the User Guide.

Ground truth (correct) target values.

Estimated target values.

This loss is equivalent to Mean absolute error when alpha=0.5, alpha=0.95 is minimized by estimators of the 95th percentile.

Defines aggregating of multiple output values. Array-like value defines weights used to average errors.

Returns a full set of errors in case of multioutput input.

Errors of all outputs are averaged with uniform weight.

If multioutput is ‘raw_values’, then mean absolute error is returned for each output separately. If multioutput is ‘uniform_average’ or an ndarray of weights, then the weighted average of all output errors is returned.

The pinball loss output is a non-negative floating point. The best value is 0.0.

Lagged features for time series forecasting

Prediction Intervals for Gradient Boosting Regression

Features in Histogram Gradient Boosting Trees

Release Highlights for scikit-learn 1.0

**Examples:**

Example 1 (sql):
```sql
>>> from sklearn.metrics import mean_pinball_loss
>>> y_true = [1, 2, 3]
>>> mean_pinball_loss(y_true, [0, 2, 3], alpha=0.1)
0.03...
>>> mean_pinball_loss(y_true, [1, 2, 4], alpha=0.1)
0.3...
>>> mean_pinball_loss(y_true, [0, 2, 3], alpha=0.9)
0.3...
>>> mean_pinball_loss(y_true, [1, 2, 4], alpha=0.9)
0.03...
>>> mean_pinball_loss(y_true, y_true, alpha=0.1)
0.0
>>> mean_pinball_loss(y_true, y_true, alpha=0.9)
0.0
```

---

## ExtraTreesRegressor#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.ExtraTreesRegressor.html

**Contents:**
- ExtraTreesRegressor#
- Gallery examples#

An extra-trees regressor.

This class implements a meta estimator that fits a number of randomized decision trees (a.k.a. extra-trees) on various sub-samples of the dataset and uses averaging to improve the predictive accuracy and control over-fitting.

This estimator has native support for missing values (NaNs) for random splits. During training, a random threshold will be chosen to split the non-missing values on. Then the non-missing values will be sent to the left and right child based on the randomly selected threshold, while the missing values will also be randomly sent to the left or right child. This is repeated for every feature considered at each split. The best split among these is chosen.

Read more in the User Guide.

The number of trees in the forest.

Changed in version 0.22: The default value of n_estimators changed from 10 to 100 in 0.22.

The function to measure the quality of a split. Supported criteria are “squared_error” for the mean squared error, which is equal to variance reduction as feature selection criterion and minimizes the L2 loss using the mean of each terminal node, “friedman_mse”, which uses mean squared error with Friedman’s improvement score for potential splits, “absolute_error” for the mean absolute error, which minimizes the L1 loss using the median of each terminal node, and “poisson” which uses reduction in Poisson deviance to find splits. Training using “absolute_error” is significantly slower than when using “squared_error”.

Added in version 0.18: Mean Absolute Error (MAE) criterion.

The maximum depth of the tree. If None, then nodes are expanded until all leaves are pure or until all leaves contain less than min_samples_split samples.

The minimum number of samples required to split an internal node:

If int, then consider min_samples_split as the minimum number.

If float, then min_samples_split is a fraction and ceil(min_samples_split * n_samples) are the minimum number of samples for each split.

Changed in version 0.18: Added float values for fractions.

The minimum number of samples required to be at a leaf node. A split point at any depth will only be considered if it leaves at least min_samples_leaf training samples in each of the left and right branches. This may have the effect of smoothing the model, especially in regression.

If int, then consider min_samples_leaf as the minimum number.

If float, then min_samples_leaf is a fraction and ceil(min_samples_leaf * n_samples) are the minimum number of samples for each node.

Changed in version 0.18: Added float values for fractions.

The minimum weighted fraction of the sum total of weights (of all the input samples) required to be at a leaf node. Samples have equal weight when sample_weight is not provided.

The number of features to consider when looking for the best split:

If int, then consider max_features features at each split.

If float, then max_features is a fraction and max(1, int(max_features * n_features_in_)) features are considered at each split.

If “sqrt”, then max_features=sqrt(n_features).

If “log2”, then max_features=log2(n_features).

If None or 1.0, then max_features=n_features.

The default of 1.0 is equivalent to bagged trees and more randomness can be achieved by setting smaller values, e.g. 0.3.

Changed in version 1.1: The default of max_features changed from "auto" to 1.0.

Note: the search for a split does not stop until at least one valid partition of the node samples is found, even if it requires to effectively inspect more than max_features features.

Grow trees with max_leaf_nodes in best-first fashion. Best nodes are defined as relative reduction in impurity. If None then unlimited number of leaf nodes.

A node will be split if this split induces a decrease of the impurity greater than or equal to this value.

The weighted impurity decrease equation is the following:

where N is the total number of samples, N_t is the number of samples at the current node, N_t_L is the number of samples in the left child, and N_t_R is the number of samples in the right child.

N, N_t, N_t_R and N_t_L all refer to the weighted sum, if sample_weight is passed.

Added in version 0.19.

Whether bootstrap samples are used when building trees. If False, the whole dataset is used to build each tree.

Whether to use out-of-bag samples to estimate the generalization score. By default, r2_score is used. Provide a callable with signature metric(y_true, y_pred) to use a custom metric. Only available if bootstrap=True.

For an illustration of out-of-bag (OOB) error estimation, see the example OOB Errors for Random Forests.

The number of jobs to run in parallel. fit, predict, decision_path and apply are all parallelized over the trees. None means 1 unless in a joblib.parallel_backend context. -1 means using all processors. See Glossary for more details.

Controls 3 sources of randomness:

the bootstrapping of the samples used when building trees (if bootstrap=True)

the sampling of the features to consider when looking for the best split at each node (if max_features < n_features)

the draw of the splits for each of the max_features

See Glossary for details.

Controls the verbosity when fitting and predicting.

When set to True, reuse the solution of the previous call to fit and add more estimators to the ensemble, otherwise, just fit a whole new forest. See Glossary and Fitting additional trees for details.

Complexity parameter used for Minimal Cost-Complexity Pruning. The subtree with the largest cost complexity that is smaller than ccp_alpha will be chosen. By default, no pruning is performed. See Minimal Cost-Complexity Pruning for details. See Post pruning decision trees with cost complexity pruning for an example of such pruning.

Added in version 0.22.

If bootstrap is True, the number of samples to draw from X to train each base estimator.

If None (default), then draw X.shape[0] samples.

If int, then draw max_samples samples.

If float, then draw max_samples * X.shape[0] samples. Thus, max_samples should be in the interval (0.0, 1.0].

Added in version 0.22.

1: monotonically increasing

-1: monotonically decreasing

If monotonic_cst is None, no constraints are applied.

multioutput regressions (i.e. when n_outputs_ > 1),

regressions trained on data with missing values.

Read more in the User Guide.

Added in version 1.4.

The child estimator template used to create the collection of fitted sub-estimators.

Added in version 1.2: base_estimator_ was renamed to estimator_.

The collection of fitted sub-estimators.

The impurity-based feature importances.

Number of features seen during fit.

Added in version 0.24.

Names of features seen during fit. Defined only when X has feature names that are all strings.

Added in version 1.0.

The number of outputs.

Score of the training dataset obtained using an out-of-bag estimate. This attribute exists only when oob_score is True.

Prediction computed with out-of-bag estimate on the training set. This attribute exists only when oob_score is True.

The subset of drawn samples for each base estimator.

An extra-trees classifier with random splits.

A random forest classifier with optimal splits.

Ensemble regressor using trees with optimal splits.

The default values for the parameters controlling the size of the trees (e.g. max_depth, min_samples_leaf, etc.) lead to fully grown and unpruned trees which can potentially be very large on some data sets. To reduce memory consumption, the complexity and size of the trees should be controlled by setting those parameter values.

P. Geurts, D. Ernst., and L. Wehenkel, “Extremely randomized trees”, Machine Learning, 63(1), 3-42, 2006.

Apply trees in the forest to X, return leaf indices.

The input samples. Internally, its dtype will be converted to dtype=np.float32. If a sparse matrix is provided, it will be converted into a sparse csr_matrix.

For each datapoint x in X and for each tree in the forest, return the index of the leaf x ends up in.

Return the decision path in the forest.

Added in version 0.18.

The input samples. Internally, its dtype will be converted to dtype=np.float32. If a sparse matrix is provided, it will be converted into a sparse csr_matrix.

Return a node indicator matrix where non zero elements indicates that the samples goes through the nodes. The matrix is of CSR format.

The columns from indicator[n_nodes_ptr[i]:n_nodes_ptr[i+1]] gives the indicator value for the i-th estimator.

Build a forest of trees from the training set (X, y).

The training input samples. Internally, its dtype will be converted to dtype=np.float32. If a sparse matrix is provided, it will be converted into a sparse csc_matrix.

The target values (class labels in classification, real numbers in regression).

Sample weights. If None, then samples are equally weighted. Splits that would create child nodes with net zero or negative weight are ignored while searching for a split in each node. In the case of classification, splits are also ignored if they would result in any single class carrying a negative weight in either child node.

Get metadata routing of this object.

Please check User Guide on how the routing mechanism works.

A MetadataRequest encapsulating routing information.

Get parameters for this estimator.

If True, will return the parameters for this estimator and contained subobjects that are estimators.

Parameter names mapped to their values.

Predict regression target for X.

The predicted regression target of an input sample is computed as the mean predicted regression targets of the trees in the forest.

The input samples. Internally, its dtype will be converted to dtype=np.float32. If a sparse matrix is provided, it will be converted into a sparse csr_matrix.

The predicted values.

Return coefficient of determination on test data.

The coefficient of determination, \(R^2\), is defined as \((1 - \frac{u}{v})\), where \(u\) is the residual sum of squares ((y_true - y_pred)** 2).sum() and \(v\) is the total sum of squares ((y_true - y_true.mean()) ** 2).sum(). The best possible score is 1.0 and it can be negative (because the model can be arbitrarily worse). A constant model that always predicts the expected value of y, disregarding the input features, would get a \(R^2\) score of 0.0.

Test samples. For some estimators this may be a precomputed kernel matrix or a list of generic objects instead with shape (n_samples, n_samples_fitted), where n_samples_fitted is the number of samples used in the fitting for the estimator.

\(R^2\) of self.predict(X) w.r.t. y.

The \(R^2\) score used when calling score on a regressor uses multioutput='uniform_average' from version 0.23 to keep consistent with default value of r2_score. This influences the score method of all the multioutput regressors (except for MultiOutputRegressor).

Configure whether metadata should be requested to be passed to the fit method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to fit if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to fit.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Added in version 1.3.

Metadata routing for sample_weight parameter in fit.

Set the parameters of this estimator.

The method works on simple estimators as well as on nested objects (such as Pipeline). The latter have parameters of the form <component>__<parameter> so that it’s possible to update each component of a nested object.

Estimator parameters.

Configure whether metadata should be requested to be passed to the score method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to score if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to score.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Added in version 1.3.

Metadata routing for sample_weight parameter in score.

Face completion with a multi-output estimators

**Examples:**

Example 1 (yaml):
```yaml
N_t / N * (impurity - N_t_R / N_t * right_impurity
                    - N_t_L / N_t * left_impurity)
```

Example 2 (sql):
```sql
>>> from sklearn.datasets import load_diabetes
>>> from sklearn.model_selection import train_test_split
>>> from sklearn.ensemble import ExtraTreesRegressor
>>> X, y = load_diabetes(return_X_y=True)
>>> X_train, X_test, y_train, y_test = train_test_split(
...     X, y, random_state=0)
>>> reg = ExtraTreesRegressor(n_estimators=100, random_state=0).fit(
...    X_train, y_train)
>>> reg.score(X_test, y_test)
0.2727...
```

---

## DistanceMetric#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.metrics.DistanceMetric.html

**Contents:**
- DistanceMetric#

Uniform interface for fast distance metric functions.

The DistanceMetric class provides a convenient way to compute pairwise distances between samples. It supports various distance metrics, such as Euclidean distance, Manhattan distance, and more.

The pairwise method can be used to compute pairwise distances between samples in the input arrays. It returns a distance matrix representing the distances between all pairs of samples.

The get_metric method allows you to retrieve a specific metric using its string identifier.

The following lists the string metric identifiers and the associated distance metric classes:

Metrics intended for real-valued vector spaces:

sum(w * |x - y|^p)^(1/p)

sqrt(sum((x - y)^2 / V))

sqrt((x - y)' V^-1 (x - y))

Metrics intended for two-dimensional vector spaces: Note that the haversine distance metric requires data in the form of [latitude, longitude] and both inputs and outputs are in units of radians.

2 arcsin(sqrt(sin^2(0.5*dx) + cos(x1)cos(x2)sin^2(0.5*dy)))

Metrics intended for integer-valued vector spaces: Though intended for integer-valued vectors, these are also valid metrics in the case of real-valued vectors.

N_unequal(x, y) / N_tot

sum(|x - y| / (|x| + |y|))

sum(|x - y|) / (sum(|x|) + sum(|y|))

Metrics intended for boolean-valued vector spaces: Any nonzero entry is evaluated to “True”. In the listings below, the following abbreviations are used:

N: number of dimensions

NTT: number of dims in which both values are True

NTF: number of dims in which the first value is True, second is False

NFT: number of dims in which the first value is False, second is True

NFF: number of dims in which both values are False

NNEQ: number of non-equal dimensions, NNEQ = NTF + NFT

NNZ: number of nonzero dimensions, NNZ = NTF + NFT + NTT

(NNEQ + N - NTT) / (NNEQ + N)

RogersTanimotoDistance

2 * NNEQ / (N + NNEQ)

SokalMichenerDistance

2 * NNEQ / (N + NNEQ)

NNEQ / (NNEQ + 0.5 * NTT)

User-defined distance:

Here func is a function which takes two one-dimensional numpy arrays, and returns a distance. Note that in order to be used within the BallTree, the distance must be a true metric: i.e. it must satisfy the following properties

Non-negativity: d(x, y) >= 0

Identity: d(x, y) = 0 if and only if x == y

Symmetry: d(x, y) = d(y, x)

Triangle Inequality: d(x, y) + d(y, z) >= d(x, z)

Because of the Python object overhead involved in calling the python function, this will be fairly slow, but it will have the same scaling as other distances.

Get the given distance metric from the string identifier.

See the docstring of DistanceMetric for a list of available metrics.

The string identifier or class name of the desired distance metric. See the documentation of the DistanceMetric class for a list of available metrics.

The data type of the input on which the metric will be applied. This affects the precision of the computed distances. By default, it is set to np.float64.

Additional keyword arguments that will be passed to the requested metric. These arguments can be used to customize the behavior of the specific metric.

An instance of the requested distance metric class.

**Examples:**

Example 1 (sql):
```sql
>>> from sklearn.metrics import DistanceMetric
>>> dist = DistanceMetric.get_metric('euclidean')
>>> X = [[1, 2], [3, 4], [5, 6]]
>>> Y = [[7, 8], [9, 10]]
>>> dist.pairwise(X,Y)
array([[7.81..., 10.63...]
       [5.65...,  8.48...]
       [1.41...,  4.24...]])
```

---

## rand_score#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.metrics.rand_score.html

**Contents:**
- rand_score#
- Gallery examples#

The Rand Index computes a similarity measure between two clusterings by considering all pairs of samples and counting pairs that are assigned in the same or different clusters in the predicted and true clusterings [1] [2].

The raw RI score [3] is:

Read more in the User Guide.

Ground truth class labels to be used as a reference.

Cluster labels to evaluate.

Similarity score between 0.0 and 1.0, inclusive, 1.0 stands for perfect match.

Adjusted Mutual Information.

Hubert, L., Arabie, P. “Comparing partitions.” Journal of Classification 2, 193–218 (1985)..

Wikipedia: Simple Matching Coefficient

Wikipedia: Rand Index

Perfectly matching labelings have a score of 1 even

Labelings that assign all classes members to the same clusters are complete but may not always be pure, hence penalized:

Adjustment for chance in clustering performance evaluation

**Examples:**

Example 1 (unknown):
```unknown
RI = (number of agreeing pairs) / (number of pairs)
```

Example 2 (sql):
```sql
>>> from sklearn.metrics.cluster import rand_score
>>> rand_score([0, 0, 1, 1], [1, 1, 0, 0])
1.0
```

Example 3 (unknown):
```unknown
>>> rand_score([0, 0, 1, 2], [0, 0, 1, 1])
0.83
```

---

## NearestNeighbors#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.NearestNeighbors.html

**Contents:**
- NearestNeighbors#
- Gallery examples#

Unsupervised learner for implementing neighbor searches.

Read more in the User Guide.

Added in version 0.9.

Number of neighbors to use by default for kneighbors queries.

Range of parameter space to use by default for radius_neighbors queries.

Algorithm used to compute the nearest neighbors:

‘ball_tree’ will use BallTree

‘kd_tree’ will use KDTree

‘brute’ will use a brute-force search.

‘auto’ will attempt to decide the most appropriate algorithm based on the values passed to fit method.

Note: fitting on sparse input will override the setting of this parameter, using brute force.

Leaf size passed to BallTree or KDTree. This can affect the speed of the construction and query, as well as the memory required to store the tree. The optimal value depends on the nature of the problem.

Metric to use for distance computation. Default is “minkowski”, which results in the standard Euclidean distance when p = 2. See the documentation of scipy.spatial.distance and the metrics listed in distance_metrics for valid metric values.

If metric is “precomputed”, X is assumed to be a distance matrix and must be square during fit. X may be a sparse graph, in which case only “nonzero” elements may be considered neighbors.

If metric is a callable function, it takes two arrays representing 1D vectors as inputs and must return one value indicating the distance between those vectors. This works for Scipy’s metrics, but is less efficient than passing the metric name as a string.

Parameter for the Minkowski metric from sklearn.metrics.pairwise.pairwise_distances. When p = 1, this is equivalent to using manhattan_distance (l1), and euclidean_distance (l2) for p = 2. For arbitrary p, minkowski_distance (l_p) is used.

Additional keyword arguments for the metric function.

The number of parallel jobs to run for neighbors search. None means 1 unless in a joblib.parallel_backend context. -1 means using all processors. See Glossary for more details.

Metric used to compute distances to neighbors.

Parameters for the metric used to compute distances to neighbors.

Number of features seen during fit.

Added in version 0.24.

Names of features seen during fit. Defined only when X has feature names that are all strings.

Added in version 1.0.

Number of samples in the fitted data.

Classifier implementing the k-nearest neighbors vote.

Classifier implementing a vote among neighbors within a given radius.

Regression based on k-nearest neighbors.

Regression based on neighbors within a fixed radius.

Space partitioning data structure for organizing points in a multi-dimensional space, used for nearest neighbor search.

See Nearest Neighbors in the online documentation for a discussion of the choice of algorithm and leaf_size.

https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm

Fit the nearest neighbors estimator from the training dataset.

Not used, present for API consistency by convention.

The fitted nearest neighbors estimator.

Get metadata routing of this object.

Please check User Guide on how the routing mechanism works.

A MetadataRequest encapsulating routing information.

Get parameters for this estimator.

If True, will return the parameters for this estimator and contained subobjects that are estimators.

Parameter names mapped to their values.

Find the K-neighbors of a point.

Returns indices of and distances to the neighbors of each point.

The query point or points. If not provided, neighbors of each indexed point are returned. In this case, the query point is not considered its own neighbor.

Number of neighbors required for each sample. The default is the value passed to the constructor.

Whether or not to return the distances.

Array representing the lengths to points, only present if return_distance=True.

Indices of the nearest points in the population matrix.

In the following example, we construct a NearestNeighbors class from an array representing our data set and ask who’s the closest point to [1,1,1]

As you can see, it returns [[0.5]], and [[2]], which means that the element is at distance 0.5 and is the third element of samples (indexes start at 0). You can also query for multiple points:

Compute the (weighted) graph of k-Neighbors for points in X.

The query point or points. If not provided, neighbors of each indexed point are returned. In this case, the query point is not considered its own neighbor. For metric='precomputed' the shape should be (n_queries, n_indexed). Otherwise the shape should be (n_queries, n_features).

Number of neighbors for each sample. The default is the value passed to the constructor.

Type of returned matrix: ‘connectivity’ will return the connectivity matrix with ones and zeros, in ‘distance’ the edges are distances between points, type of distance depends on the selected metric parameter in NearestNeighbors class.

n_samples_fit is the number of samples in the fitted data. A[i, j] gives the weight of the edge connecting i to j. The matrix is of CSR format.

Compute the (weighted) graph of Neighbors for points in X.

Find the neighbors within a given radius of a point or points.

Return the indices and distances of each point from the dataset lying in a ball with size radius around the points of the query array. Points lying on the boundary are included in the results.

The result points are not necessarily sorted by distance to their query point.

The query point or points. If not provided, neighbors of each indexed point are returned. In this case, the query point is not considered its own neighbor.

Limiting distance of neighbors to return. The default is the value passed to the constructor.

Whether or not to return the distances.

If True, the distances and indices will be sorted by increasing distances before being returned. If False, the results may not be sorted. If return_distance=False, setting sort_results=True will result in an error.

Added in version 0.22.

Array representing the distances to each point, only present if return_distance=True. The distance values are computed according to the metric constructor parameter.

An array of arrays of indices of the approximate nearest points from the population matrix that lie within a ball of size radius around the query points.

Because the number of neighbors of each point is not necessarily equal, the results for multiple query points cannot be fit in a standard data array. For efficiency, radius_neighbors returns arrays of objects, where each object is a 1D array of indices or distances.

In the following example, we construct a NeighborsClassifier class from an array representing our data set and ask who’s the closest point to [1, 1, 1]:

The first array returned contains the distances to all points which are closer than 1.6, while the second array returned contains their indices. In general, multiple points can be queried at the same time.

Compute the (weighted) graph of Neighbors for points in X.

Neighborhoods are restricted the points at a distance lower than radius.

The query point or points. If not provided, neighbors of each indexed point are returned. In this case, the query point is not considered its own neighbor.

Radius of neighborhoods. The default is the value passed to the constructor.

Type of returned matrix: ‘connectivity’ will return the connectivity matrix with ones and zeros, in ‘distance’ the edges are distances between points, type of distance depends on the selected metric parameter in NearestNeighbors class.

If True, in each row of the result, the non-zero entries will be sorted by increasing distances. If False, the non-zero entries may not be sorted. Only used with mode=’distance’.

Added in version 0.22.

n_samples_fit is the number of samples in the fitted data. A[i, j] gives the weight of the edge connecting i to j. The matrix is of CSR format.

Compute the (weighted) graph of k-Neighbors for points in X.

Set the parameters of this estimator.

The method works on simple estimators as well as on nested objects (such as Pipeline). The latter have parameters of the form <component>__<parameter> so that it’s possible to update each component of a nested object.

Estimator parameters.

Approximate nearest neighbors in TSNE

**Examples:**

Example 1 (sql):
```sql
>>> import numpy as np
>>> from sklearn.neighbors import NearestNeighbors
>>> samples = [[0, 0, 2], [1, 0, 0], [0, 0, 1]]
>>> neigh = NearestNeighbors(n_neighbors=2, radius=0.4)
>>> neigh.fit(samples)
NearestNeighbors(...)
>>> neigh.kneighbors([[0, 0, 1.3]], 2, return_distance=False)
array([[2, 0]]...)
>>> nbrs = neigh.radius_neighbors(
...    [[0, 0, 1.3]], 0.4, return_distance=False
... )
>>> np.asarray(nbrs[0][0])
array(2)
```

Example 2 (python):
```python
>>> samples = [[0., 0., 0.], [0., .5, 0.], [1., 1., .5]]
>>> from sklearn.neighbors import NearestNeighbors
>>> neigh = NearestNeighbors(n_neighbors=1)
>>> neigh.fit(samples)
NearestNeighbors(n_neighbors=1)
>>> print(neigh.kneighbors([[1., 1., 1.]]))
(array([[0.5]]), array([[2]]))
```

Example 3 (json):
```json
>>> X = [[0., 1., 0.], [1., 0., 1.]]
>>> neigh.kneighbors(X, return_distance=False)
array([[1],
       [2]]...)
```

Example 4 (sql):
```sql
>>> X = [[0], [3], [1]]
>>> from sklearn.neighbors import NearestNeighbors
>>> neigh = NearestNeighbors(n_neighbors=2)
>>> neigh.fit(X)
NearestNeighbors(n_neighbors=2)
>>> A = neigh.kneighbors_graph(X)
>>> A.toarray()
array([[1., 0., 1.],
       [0., 1., 1.],
       [1., 0., 1.]])
```

---

## 12.1. Array API support (experimental)#

**URL:** https://scikit-learn.org/stable/modules/array_api.html

**Contents:**
- 12.1. Array API support (experimental)#
- 12.1.1. Enabling array API support#
- 12.1.2. Example usage#
  - 12.1.2.1. PyTorch Support#
- 12.1.3. Support for Array API-compatible inputs#
  - 12.1.3.1. Estimators#
  - 12.1.3.2. Meta-estimators#
  - 12.1.3.3. Metrics#
  - 12.1.3.4. Tools#
- 12.1.4. Input and output array type handling#

The Array API specification defines a standard API for all array manipulation libraries with a NumPy-like API. Scikit-learn vendors pinned copies of array-api-compat and array-api-extra.

Scikit-learn’s support for the array API standard requires the environment variable SCIPY_ARRAY_API to be set to 1 before importing scipy and scikit-learn:

Please note that this environment variable is intended for temporary use. For more details, refer to SciPy’s Array API documentation.

Some scikit-learn estimators that primarily rely on NumPy (as opposed to using Cython) to implement the algorithmic logic of their fit, predict or transform methods can be configured to accept any Array API compatible input data structures and automatically dispatch operations to the underlying namespace instead of relying on NumPy.

At this stage, this support is considered experimental and must be enabled explicitly by the array_api_dispatch configuration. See below for details.

Currently, only array-api-strict, cupy, and PyTorch are known to work with scikit-learn’s estimators.

The following video provides an overview of the standard’s design principles and how it facilitates interoperability between array libraries:

Scikit-learn on GPUs with Array API by Thomas Fan at PyData NYC 2023.

The configuration array_api_dispatch=True needs to be set to True to enable array API support. We recommend setting this configuration globally to ensure consistent behaviour and prevent accidental mixing of array namespaces. Note that in the examples below, we use a context manager (config_context) to avoid having to reset it to False at the end of every code snippet, so as to not affect the rest of the documentation.

Scikit-learn accepts array-like inputs for all metrics and some estimators. When array_api_dispatch=False, these inputs are converted into NumPy arrays using numpy.asarray (or numpy.array). While this will successfully convert some array API inputs (e.g., JAX array), we generally recommend setting array_api_dispatch=True when using array API inputs. This is because NumPy conversion can often fail, e.g., torch tensor allocated on GPU.

The example code snippet below demonstrates how to use CuPy to run LinearDiscriminantAnalysis on a GPU:

After the model is trained, fitted attributes that are arrays will also be from the same Array API namespace as the training data. For example, if CuPy’s Array API namespace was used for training, then fitted attributes will be on the GPU. We provide an experimental _estimator_with_converted_arrays utility that transfers an estimator attributes from Array API to an ndarray:

PyTorch Tensors can also be passed directly:

Estimators and other tools in scikit-learn that support Array API compatible inputs.

decomposition.PCA (with svd_solver="full", svd_solver="covariance_eigh", or svd_solver="randomized" (svd_solver="randomized" only if power_iteration_normalizer="QR"))

linear_model.Ridge (with solver="svd")

linear_model.RidgeCV (with solver="svd", see Note on device support for float64)

linear_model.RidgeClassifier (with solver="svd")

linear_model.RidgeClassifierCV (with solver="svd", see Note on device support for float64)

discriminant_analysis.LinearDiscriminantAnalysis (with solver="svd")

naive_bayes.GaussianNB

preprocessing.Binarizer

preprocessing.KernelCenterer

preprocessing.LabelBinarizer (with sparse_output=False)

preprocessing.LabelEncoder

preprocessing.MaxAbsScaler

preprocessing.MinMaxScaler

preprocessing.Normalizer

preprocessing.PolynomialFeatures

preprocessing.StandardScaler (see Note on device support for float64)

mixture.GaussianMixture (with init_params="random" or init_params="random_from_data" and warm_start=False)

Meta-estimators that accept Array API inputs conditioned on the fact that the base estimator also does:

calibration.CalibratedClassifierCV (with method="temperature")

model_selection.GridSearchCV

model_selection.RandomizedSearchCV

model_selection.HalvingGridSearchCV

model_selection.HalvingRandomSearchCV

sklearn.metrics.accuracy_score

sklearn.metrics.balanced_accuracy_score

sklearn.metrics.brier_score_loss

sklearn.metrics.cluster.calinski_harabasz_score

sklearn.metrics.cohen_kappa_score

sklearn.metrics.confusion_matrix

sklearn.metrics.d2_brier_score

sklearn.metrics.d2_log_loss_score

sklearn.metrics.d2_tweedie_score

sklearn.metrics.det_curve

sklearn.metrics.explained_variance_score

sklearn.metrics.f1_score

sklearn.metrics.fbeta_score

sklearn.metrics.hamming_loss

sklearn.metrics.jaccard_score

sklearn.metrics.log_loss

sklearn.metrics.max_error

sklearn.metrics.mean_absolute_error

sklearn.metrics.mean_absolute_percentage_error

sklearn.metrics.mean_gamma_deviance

sklearn.metrics.mean_pinball_loss

sklearn.metrics.mean_poisson_deviance (requires enabling array API support for SciPy)

sklearn.metrics.mean_squared_error

sklearn.metrics.mean_squared_log_error

sklearn.metrics.mean_tweedie_deviance

sklearn.metrics.median_absolute_error

sklearn.metrics.multilabel_confusion_matrix

sklearn.metrics.pairwise.additive_chi2_kernel

sklearn.metrics.pairwise.chi2_kernel

sklearn.metrics.pairwise.cosine_similarity

sklearn.metrics.pairwise.cosine_distances

sklearn.metrics.pairwise.pairwise_distances (only supports “cosine”, “euclidean”, “manhattan” and “l2” metrics)

sklearn.metrics.pairwise.euclidean_distances (see Note on device support for float64)

sklearn.metrics.pairwise.laplacian_kernel

sklearn.metrics.pairwise.linear_kernel

sklearn.metrics.pairwise.manhattan_distances

sklearn.metrics.pairwise.paired_cosine_distances

sklearn.metrics.pairwise.paired_euclidean_distances

sklearn.metrics.pairwise.pairwise_kernels

sklearn.metrics.pairwise.polynomial_kernel

sklearn.metrics.pairwise.rbf_kernel (see Note on device support for float64)

sklearn.metrics.pairwise.sigmoid_kernel

sklearn.metrics.precision_score

sklearn.metrics.precision_recall_curve

sklearn.metrics.precision_recall_fscore_support

sklearn.metrics.r2_score

sklearn.metrics.recall_score

sklearn.metrics.roc_curve

sklearn.metrics.root_mean_squared_error

sklearn.metrics.root_mean_squared_log_error

sklearn.metrics.zero_one_loss

preprocessing.label_binarize (with sparse_output=False)

model_selection.cross_val_predict

model_selection.train_test_split

utils.check_consistent_length

Coverage is expected to grow over time. Please follow the dedicated meta-issue on GitHub to track progress.

Estimators and scoring functions are able to accept input arrays from different array libraries and/or devices. When a mixed set of input arrays is passed, scikit-learn converts arrays as needed to make them all consistent.

For estimators, the rule is “everything follows X “ - mixed array inputs are converted so that they all match the array library and device of X. For scoring functions the rule is “everything follows y_pred “ - mixed array inputs are converted so that they all match the array library and device of y_pred.

When a function or method has been called with array API compatible inputs, the convention is to return arrays from the same array library and on the same device as the input data.

When an estimator is fitted with an array API compatible X, all other array inputs, including constructor arguments, (e.g., y, sample_weight) will be converted to match the array library and device of X, if they do not already. This behaviour enables switching from processing on the CPU to processing on the GPU at any point within a pipeline.

This allows estimators to accept mixed input types, enabling X to be moved to a different device within a pipeline, without explicitly moving y. Note that scikit-learn pipelines do not allow transformation of y (to avoid leakage).

Take for example a pipeline where X and y both start on CPU, and go through the following three steps:

TargetEncoder, which will transform categorial X but also requires y, meaning both X and y need to be on CPU.

FunctionTransformer(func=partial(torch.asarray, device="cuda")), which moves X to GPU, to improve performance in the next step.

Ridge, whose performance can be improved when passed arrays on a GPU, as they can handle large matrix operations very efficiently.

X initially contains categorical string data (thus needs to be on CPU), which is target encoded to numerical values in TargetEncoder. X is then explicitly moved to GPU to improve the performance of Ridge. y cannot be transformed by the pipeline (recall scikit-learn pipelines do not allow transformation of y) but as Ridge is able to accept mixed input types, this is not a problem and the pipeline is able to be run.

The fitted attributes of an estimator fitted with an array API compatible X, will be arrays from the same library as the input and stored on the same device. The predict and transform method subsequently expect inputs from the same array library and device as the data passed to the fit method.

When an array API compatible y_pred is passed to a scoring function, all other array inputs (e.g., y_true, sample_weight) will be converted to match the array library and device of y_pred, if they do not already. This allows scoring functions to accept mixed input types, enabling them to be used within a meta-estimator (or function that accepts estimators), with a pipeline that moves input arrays between devices (e.g., CPU to GPU).

For example, to be able to use the pipeline described above within e.g., cross_validate or GridSearchCV, the scoring function internally called needs to be able to accept mixed input types.

The output type of scoring functions depends on the number of output values. When a scoring function returns a scalar value, it will return a Python scalar (typically a float instance) instead of an array scalar value. For scoring functions that support multiclass or multioutput, an array from the same array library and device as y_pred will be returned when multiple values need to be output.

Add the array_api_support tag to an estimator’s set of tags to indicate that it supports the array API. This will enable dedicated checks as part of the common tests to verify that the estimators’ results are the same when using vanilla NumPy and array API inputs.

To run these checks you need to install array-api-strict in your test environment. This allows you to run checks without having a GPU. To run the full set of checks you also need to install PyTorch, CuPy and have a GPU. Checks that can not be executed or have missing dependencies will be automatically skipped. Therefore it’s important to run the tests with the -v flag to see which checks are skipped:

Running the scikit-learn tests against array-api-strict should help reveal most code problems related to handling multiple device inputs via the use of simulated non-CPU devices. This allows for fast iterative development and debugging of array API related code.

However, to ensure full handling of PyTorch or CuPy inputs allocated on actual GPU devices, it is necessary to run the tests against those libraries and hardware. This can either be achieved by using Google Colab or leveraging our CI infrastructure on pull requests (manually triggered by maintainers for cost reasons).

On macOS, PyTorch can use the Metal Performance Shaders (MPS) to access hardware accelerators (e.g. the internal GPU component of the M1 or M2 chips). However, the MPS device support for PyTorch is incomplete at the time of writing. See the following github issue for more details:

pytorch/pytorch#77764

To enable the MPS support in PyTorch, set the environment variable PYTORCH_ENABLE_MPS_FALLBACK=1 before running the tests:

At the time of writing all scikit-learn tests should pass, however, the computational speed is not necessarily better than with the CPU device.

Certain operations within scikit-learn will automatically perform operations on floating-point values with float64 precision to prevent overflows and ensure correctness (e.g., metrics.pairwise.euclidean_distances, preprocessing.StandardScaler). However, certain combinations of array namespaces and devices, such as PyTorch on MPS (see Note on MPS device support) do not support the float64 data type. In these cases, scikit-learn will revert to using the float32 data type instead. This can result in different behavior (typically numerically unstable results) compared to not using array API dispatching or using a device with float64 support.

**Examples:**

Example 1 (unknown):
```unknown
export SCIPY_ARRAY_API=1
```

Example 2 (python):
```python
>>> from sklearn.datasets import make_classification
>>> from sklearn import config_context
>>> from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
>>> import cupy

>>> X_np, y_np = make_classification(random_state=0)
>>> X_cu = cupy.asarray(X_np)
>>> y_cu = cupy.asarray(y_np)
>>> X_cu.device
<CUDA Device 0>

>>> with config_context(array_api_dispatch=True):
...     lda = LinearDiscriminantAnalysis()
...     X_trans = lda.fit_transform(X_cu, y_cu)
>>> X_trans.device
<CUDA Device 0>
```

Example 3 (csharp):
```csharp
>>> from sklearn.utils._array_api import _estimator_with_converted_arrays
>>> cupy_to_ndarray = lambda array : array.get()
>>> lda_np = _estimator_with_converted_arrays(lda, cupy_to_ndarray)
>>> X_trans = lda_np.transform(X_np)
>>> type(X_trans)
<class 'numpy.ndarray'>
```

Example 4 (jsx):
```jsx
>>> import torch
>>> X_torch = torch.asarray(X_np, device="cuda", dtype=torch.float32)
>>> y_torch = torch.asarray(y_np, device="cuda", dtype=torch.float32)

>>> with config_context(array_api_dispatch=True):
...     lda = LinearDiscriminantAnalysis()
...     X_trans = lda.fit_transform(X_torch, y_torch)
>>> type(X_trans)
<class 'torch.Tensor'>
>>> X_trans.device.type
'cuda'
```

---

## MultiLabelBinarizer#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MultiLabelBinarizer.html

**Contents:**
- MultiLabelBinarizer#

Transform between iterable of iterables and a multilabel format.

Although a list of sets or tuples is a very intuitive format for multilabel data, it is unwieldy to process. This transformer converts between this intuitive format and the supported multilabel format: a (samples x classes) binary matrix indicating the presence of a class label.

Indicates an ordering for the class labels. All entries should be unique (cannot contain duplicate classes).

Set to True if output binary array is desired in CSR sparse format.

A copy of the classes parameter when provided. Otherwise it corresponds to the sorted set of classes found when fitting.

Encode categorical features using a one-hot aka one-of-K scheme.

A common mistake is to pass in a list, which leads to the following issue:

To correct this, the list of labels should be passed in as:

Fit the label sets binarizer, storing classes_.

A set of labels (any orderable and hashable object) for each sample. If the classes parameter is set, y will not be iterated.

Fit the label sets binarizer and transform the given label sets.

A set of labels (any orderable and hashable object) for each sample. If the classes parameter is set, y will not be iterated.

A matrix such that y_indicator[i, j] = 1 iff classes_[j] is in y[i], and 0 otherwise. Sparse matrix will be of CSR format.

Get metadata routing of this object.

Please check User Guide on how the routing mechanism works.

A MetadataRequest encapsulating routing information.

Get parameters for this estimator.

If True, will return the parameters for this estimator and contained subobjects that are estimators.

Parameter names mapped to their values.

Transform the given indicator matrix into label sets.

A matrix containing only 1s ands 0s.

The set of labels for each sample such that y[i] consists of classes_[j] for each yt[i, j] == 1.

Set output container.

See Introducing the set_output API for an example on how to use the API.

Configure output of transform and fit_transform.

"default": Default output format of a transformer

"pandas": DataFrame output

"polars": Polars output

None: Transform configuration is unchanged

Added in version 1.4: "polars" option was added.

Set the parameters of this estimator.

The method works on simple estimators as well as on nested objects (such as Pipeline). The latter have parameters of the form <component>__<parameter> so that it’s possible to update each component of a nested object.

Estimator parameters.

Transform the given label sets.

A set of labels (any orderable and hashable object) for each sample. If the classes parameter is set, y will not be iterated.

A matrix such that y_indicator[i, j] = 1 iff classes_[j] is in y[i], and 0 otherwise.

**Examples:**

Example 1 (sql):
```sql
>>> from sklearn.preprocessing import MultiLabelBinarizer
>>> mlb = MultiLabelBinarizer()
>>> mlb.fit_transform([(1, 2), (3,)])
array([[1, 1, 0],
       [0, 0, 1]])
>>> mlb.classes_
array([1, 2, 3])
```

Example 2 (json):
```json
>>> mlb.fit_transform([{'sci-fi', 'thriller'}, {'comedy'}])
array([[0, 1, 1],
       [1, 0, 0]])
>>> list(mlb.classes_)
['comedy', 'sci-fi', 'thriller']
```

Example 3 (unknown):
```unknown
>>> mlb = MultiLabelBinarizer()
>>> mlb.fit(['sci-fi', 'thriller', 'comedy'])
MultiLabelBinarizer()
>>> mlb.classes_
array(['-', 'c', 'd', 'e', 'f', 'h', 'i', 'l', 'm', 'o', 'r', 's', 't',
    'y'], dtype=object)
```

Example 4 (unknown):
```unknown
>>> mlb = MultiLabelBinarizer()
>>> mlb.fit([['sci-fi', 'thriller', 'comedy']])
MultiLabelBinarizer()
>>> mlb.classes_
array(['comedy', 'sci-fi', 'thriller'], dtype=object)
```

---

## MultiOutputRegressor#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.multioutput.MultiOutputRegressor.html

**Contents:**
- MultiOutputRegressor#
- Gallery examples#

Multi target regression.

This strategy consists of fitting one regressor per target. This is a simple strategy for extending regressors that do not natively support multi-target regression.

Added in version 0.18.

An estimator object implementing fit and predict.

The number of jobs to run in parallel. fit, predict and partial_fit (if supported by the passed estimator) will be parallelized for each target.

When individual estimators are fast to train or predict, using n_jobs > 1 can result in slower performance due to the parallelism overhead.

None means 1 unless in a joblib.parallel_backend context. -1 means using all available processes / threads. See Glossary for more details.

Changed in version 0.20: n_jobs default changed from 1 to None.

Estimators used for predictions.

Number of features seen during fit. Only defined if the underlying estimator exposes such an attribute when fit.

Added in version 0.24.

Names of features seen during fit. Only defined if the underlying estimators expose such an attribute when fit.

Added in version 1.0.

A multi-label model that arranges regressions into a chain.

Classifies each output independently rather than chaining.

Fit the model to data, separately for each output variable.

Multi-output targets. An indicator matrix turns on multilabel estimation.

Sample weights. If None, then samples are equally weighted. Only supported if the underlying regressor supports sample weights.

Parameters passed to the estimator.fit method of each step.

Added in version 0.23.

Returns a fitted instance.

Get metadata routing of this object.

Please check User Guide on how the routing mechanism works.

Added in version 1.3.

A MetadataRouter encapsulating routing information.

Get parameters for this estimator.

If True, will return the parameters for this estimator and contained subobjects that are estimators.

Parameter names mapped to their values.

Incrementally fit the model to data, for each output variable.

Multi-output targets.

Sample weights. If None, then samples are equally weighted. Only supported if the underlying regressor supports sample weights.

Parameters passed to the estimator.partial_fit method of each sub-estimator.

Only available if enable_metadata_routing=True. See the User Guide.

Added in version 1.3.

Returns a fitted instance.

Predict multi-output variable using model for each target variable.

Multi-output targets predicted across multiple predictors. Note: Separate models are generated for each predictor.

Return coefficient of determination on test data.

The coefficient of determination, \(R^2\), is defined as \((1 - \frac{u}{v})\), where \(u\) is the residual sum of squares ((y_true - y_pred)** 2).sum() and \(v\) is the total sum of squares ((y_true - y_true.mean()) ** 2).sum(). The best possible score is 1.0 and it can be negative (because the model can be arbitrarily worse). A constant model that always predicts the expected value of y, disregarding the input features, would get a \(R^2\) score of 0.0.

Test samples. For some estimators this may be a precomputed kernel matrix or a list of generic objects instead with shape (n_samples, n_samples_fitted), where n_samples_fitted is the number of samples used in the fitting for the estimator.

\(R^2\) of self.predict(X) w.r.t. y.

The \(R^2\) score used when calling score on a regressor uses multioutput='uniform_average' from version 0.23 to keep consistent with default value of r2_score. This influences the score method of all the multioutput regressors (except for MultiOutputRegressor).

Configure whether metadata should be requested to be passed to the fit method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to fit if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to fit.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Added in version 1.3.

Metadata routing for sample_weight parameter in fit.

Set the parameters of this estimator.

The method works on simple estimators as well as on nested objects (such as Pipeline). The latter have parameters of the form <component>__<parameter> so that it’s possible to update each component of a nested object.

Estimator parameters.

Configure whether metadata should be requested to be passed to the partial_fit method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to partial_fit if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to partial_fit.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Added in version 1.3.

Metadata routing for sample_weight parameter in partial_fit.

Configure whether metadata should be requested to be passed to the score method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to score if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to score.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Added in version 1.3.

Metadata routing for sample_weight parameter in score.

Comparing random forests and the multi-output meta estimator

**Examples:**

Example 1 (sql):
```sql
>>> import numpy as np
>>> from sklearn.datasets import load_linnerud
>>> from sklearn.multioutput import MultiOutputRegressor
>>> from sklearn.linear_model import Ridge
>>> X, y = load_linnerud(return_X_y=True)
>>> regr = MultiOutputRegressor(Ridge(random_state=123)).fit(X, y)
>>> regr.predict(X[[0]])
array([[176, 35.1, 57.1]])
```

---

## 

**URL:** https://scikit-learn.org/stable/_sources/modules/clustering.rst.txt

---

## Isomap#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.manifold.Isomap.html

**Contents:**
- Isomap#
- Gallery examples#

Non-linear dimensionality reduction through Isometric Mapping

Read more in the User Guide.

Number of neighbors to consider for each point. If n_neighbors is an int, then radius must be None.

Limiting distance of neighbors to return. If radius is a float, then n_neighbors must be set to None.

Added in version 1.1.

Number of coordinates for the manifold.

‘auto’ : Attempt to choose the most efficient solver for the given problem.

‘arpack’ : Use Arnoldi decomposition to find the eigenvalues and eigenvectors.

‘dense’ : Use a direct solver (i.e. LAPACK) for the eigenvalue decomposition.

Convergence tolerance passed to arpack or lobpcg. not used if eigen_solver == ‘dense’.

Maximum number of iterations for the arpack solver. not used if eigen_solver == ‘dense’.

Method to use in finding shortest path.

‘auto’ : attempt to choose the best algorithm automatically.

‘FW’ : Floyd-Warshall algorithm.

‘D’ : Dijkstra’s algorithm.

Algorithm to use for nearest neighbors search, passed to neighbors.NearestNeighbors instance.

The number of parallel jobs to run. None means 1 unless in a joblib.parallel_backend context. -1 means using all processors. See Glossary for more details.

The metric to use when calculating distance between instances in a feature array. If metric is a string or callable, it must be one of the options allowed by sklearn.metrics.pairwise_distances for its metric parameter. If metric is “precomputed”, X is assumed to be a distance matrix and must be square. X may be a Glossary.

Added in version 0.22.

Parameter for the Minkowski metric from sklearn.metrics.pairwise.pairwise_distances. When p = 1, this is equivalent to using manhattan_distance (l1), and euclidean_distance (l2) for p = 2. For arbitrary p, minkowski_distance (l_p) is used.

Added in version 0.22.

Additional keyword arguments for the metric function.

Added in version 0.22.

Stores the embedding vectors.

KernelPCA object used to implement the embedding.

Stores nearest neighbors instance, including BallTree or KDtree if applicable.

Stores the geodesic distance matrix of training data.

Number of features seen during fit.

Added in version 0.24.

Names of features seen during fit. Defined only when X has feature names that are all strings.

Added in version 1.0.

Principal component analysis that is a linear dimensionality reduction method.

Non-linear dimensionality reduction using kernels and PCA.

Manifold learning using multidimensional scaling.

T-distributed Stochastic Neighbor Embedding.

Manifold learning using Locally Linear Embedding.

Spectral embedding for non-linear dimensionality.

Tenenbaum, J.B.; De Silva, V.; & Langford, J.C. A global geometric framework for nonlinear dimensionality reduction. Science 290 (5500)

Compute the embedding vectors for data X.

Sample data, shape = (n_samples, n_features), in the form of a numpy array, sparse matrix, precomputed tree, or NearestNeighbors object.

Not used, present for API consistency by convention.

Returns a fitted instance of self.

Fit the model from data in X and transform X.

Training vector, where n_samples is the number of samples and n_features is the number of features.

Not used, present for API consistency by convention.

X transformed in the new space.

Get output feature names for transformation.

The feature names out will prefixed by the lowercased class name. For example, if the transformer outputs 3 features, then the feature names out are: ["class_name0", "class_name1", "class_name2"].

Only used to validate feature names with the names seen in fit.

Transformed feature names.

Get metadata routing of this object.

Please check User Guide on how the routing mechanism works.

A MetadataRequest encapsulating routing information.

Get parameters for this estimator.

If True, will return the parameters for this estimator and contained subobjects that are estimators.

Parameter names mapped to their values.

Compute the reconstruction error for the embedding.

Reconstruction error.

The cost function of an isomap embedding is

E = frobenius_norm[K(D) - K(D_fit)] / n_samples

Where D is the matrix of distances for the input data X, D_fit is the matrix of distances for the output embedding X_fit, and K is the isomap kernel:

K(D) = -0.5 * (I - 1/n_samples) * D^2 * (I - 1/n_samples)

Set output container.

See Introducing the set_output API for an example on how to use the API.

Configure output of transform and fit_transform.

"default": Default output format of a transformer

"pandas": DataFrame output

"polars": Polars output

None: Transform configuration is unchanged

Added in version 1.4: "polars" option was added.

Set the parameters of this estimator.

The method works on simple estimators as well as on nested objects (such as Pipeline). The latter have parameters of the form <component>__<parameter> so that it’s possible to update each component of a nested object.

Estimator parameters.

This is implemented by linking the points X into the graph of geodesic distances of the training data. First the n_neighbors nearest neighbors of X are found in the training data, and from these the shortest geodesic distances from each point in X to each point in the training data are computed in order to construct the kernel. The embedding of X is the projection of this kernel onto the embedding vectors of the training set.

If neighbors_algorithm=’precomputed’, X is assumed to be a distance matrix or a sparse graph of shape (n_queries, n_samples_fit).

X transformed in the new space.

Comparison of Manifold Learning methods

Manifold learning on handwritten digits: Locally Linear Embedding, Isomap…

Manifold Learning methods on a severed sphere

Release Highlights for scikit-learn 0.22

**Examples:**

Example 1 (sql):
```sql
>>> from sklearn.datasets import load_digits
>>> from sklearn.manifold import Isomap
>>> X, _ = load_digits(return_X_y=True)
>>> X.shape
(1797, 64)
>>> embedding = Isomap(n_components=2)
>>> X_transformed = embedding.fit_transform(X[:100])
>>> X_transformed.shape
(100, 2)
```

---

## v_measure_score#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.metrics.v_measure_score.html

**Contents:**
- v_measure_score#
- Gallery examples#

V-measure cluster labeling given a ground truth.

This score is identical to normalized_mutual_info_score with the 'arithmetic' option for averaging.

The V-measure is the harmonic mean between homogeneity and completeness:

This metric is independent of the absolute values of the labels: a permutation of the class or cluster label values won’t change the score value in any way.

This metric is furthermore symmetric: switching label_true with label_pred will return the same score value. This can be useful to measure the agreement of two independent label assignments strategies on the same dataset when the real ground truth is not known.

Read more in the User Guide.

Ground truth class labels to be used as a reference.

Cluster labels to evaluate.

Ratio of weight attributed to homogeneity vs completeness. If beta is greater than 1, completeness is weighted more strongly in the calculation. If beta is less than 1, homogeneity is weighted more strongly.

Score between 0.0 and 1.0. 1.0 stands for perfectly complete labeling.

Homogeneity metric of cluster labeling.

Completeness metric of cluster labeling.

Normalized Mutual Information.

Andrew Rosenberg and Julia Hirschberg, 2007. V-Measure: A conditional entropy-based external cluster evaluation measure

Perfect labelings are both homogeneous and complete, hence have score 1.0:

Labelings that assign all classes members to the same clusters are complete but not homogeneous, hence penalized:

Labelings that have pure clusters with members coming from the same classes are homogeneous but un-necessary splits harm completeness and thus penalize V-measure as well:

If classes members are completely split across different clusters, the assignment is totally incomplete, hence the V-Measure is null:

Clusters that include samples from totally different classes totally destroy the homogeneity of the labeling, hence:

Biclustering documents with the Spectral Co-clustering algorithm

Adjustment for chance in clustering performance evaluation

Demo of affinity propagation clustering algorithm

Demo of DBSCAN clustering algorithm

A demo of K-Means clustering on the handwritten digits data

Release Highlights for scikit-learn 1.3

Clustering text documents using k-means

**Examples:**

Example 1 (unknown):
```unknown
v = (1 + beta) * homogeneity * completeness
     / (beta * homogeneity + completeness)
```

Example 2 (sql):
```sql
>>> from sklearn.metrics.cluster import v_measure_score
>>> v_measure_score([0, 0, 1, 1], [0, 0, 1, 1])
1.0
>>> v_measure_score([0, 0, 1, 1], [1, 1, 0, 0])
1.0
```

Example 3 (unknown):
```unknown
>>> print("%.6f" % v_measure_score([0, 0, 1, 2], [0, 0, 1, 1]))
0.8
>>> print("%.6f" % v_measure_score([0, 1, 2, 3], [0, 0, 1, 1]))
0.67
```

Example 4 (unknown):
```unknown
>>> print("%.6f" % v_measure_score([0, 0, 1, 1], [0, 0, 1, 2]))
0.8
>>> print("%.6f" % v_measure_score([0, 0, 1, 1], [0, 1, 2, 3]))
0.67
```

---

## LinearSVC#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.svm.LinearSVC.html

**Contents:**
- LinearSVC#
- Gallery examples#

Linear Support Vector Classification.

Similar to SVC with parameter kernel=’linear’, but implemented in terms of liblinear rather than libsvm, so it has more flexibility in the choice of penalties and loss functions and should scale better to large numbers of samples.

The main differences between LinearSVC and SVC lie in the loss function used by default, and in the handling of intercept regularization between those two implementations.

This class supports both dense and sparse input and the multiclass support is handled according to a one-vs-the-rest scheme.

Read more in the User Guide.

Specifies the norm used in the penalization. The ‘l2’ penalty is the standard used in SVC. The ‘l1’ leads to coef_ vectors that are sparse.

Specifies the loss function. ‘hinge’ is the standard SVM loss (used e.g. by the SVC class) while ‘squared_hinge’ is the square of the hinge loss. The combination of penalty='l1' and loss='hinge' is not supported.

Select the algorithm to either solve the dual or primal optimization problem. Prefer dual=False when n_samples > n_features. dual="auto" will choose the value of the parameter automatically, based on the values of n_samples, n_features, loss, multi_class and penalty. If n_samples < n_features and optimizer supports chosen loss, multi_class and penalty, then dual will be set to True, otherwise it will be set to False.

Changed in version 1.3: The "auto" option is added in version 1.3 and will be the default in version 1.5.

Tolerance for stopping criteria.

Regularization parameter. The strength of the regularization is inversely proportional to C. Must be strictly positive. For an intuitive visualization of the effects of scaling the regularization parameter C, see Scaling the regularization parameter for SVCs.

Determines the multi-class strategy if y contains more than two classes. "ovr" trains n_classes one-vs-rest classifiers, while "crammer_singer" optimizes a joint objective over all classes. While crammer_singer is interesting from a theoretical perspective as it is consistent, it is seldom used in practice as it rarely leads to better accuracy and is more expensive to compute. If "crammer_singer" is chosen, the options loss, penalty and dual will be ignored.

Whether or not to fit an intercept. If set to True, the feature vector is extended to include an intercept term: [x_1, ..., x_n, 1], where 1 corresponds to the intercept. If set to False, no intercept will be used in calculations (i.e. data is expected to be already centered).

When fit_intercept is True, the instance vector x becomes [x_1, ..., x_n, intercept_scaling], i.e. a “synthetic” feature with a constant value equal to intercept_scaling is appended to the instance vector. The intercept becomes intercept_scaling * synthetic feature weight. Note that liblinear internally penalizes the intercept, treating it like any other term in the feature vector. To reduce the impact of the regularization on the intercept, the intercept_scaling parameter can be set to a value greater than 1; the higher the value of intercept_scaling, the lower the impact of regularization on it. Then, the weights become [w_x_1, ..., w_x_n, w_intercept*intercept_scaling], where w_x_1, ..., w_x_n represent the feature weights and the intercept weight is scaled by intercept_scaling. This scaling allows the intercept term to have a different regularization behavior compared to the other features.

Set the parameter C of class i to class_weight[i]*C for SVC. If not given, all classes are supposed to have weight one. The “balanced” mode uses the values of y to automatically adjust weights inversely proportional to class frequencies in the input data as n_samples / (n_classes * np.bincount(y)).

Enable verbose output. Note that this setting takes advantage of a per-process runtime setting in liblinear that, if enabled, may not work properly in a multithreaded context.

Controls the pseudo random number generation for shuffling the data for the dual coordinate descent (if dual=True). When dual=False the underlying implementation of LinearSVC is not random and random_state has no effect on the results. Pass an int for reproducible output across multiple function calls. See Glossary.

The maximum number of iterations to be run.

Weights assigned to the features (coefficients in the primal problem).

coef_ is a readonly property derived from raw_coef_ that follows the internal memory layout of liblinear.

Constants in decision function.

The unique classes labels.

Number of features seen during fit.

Added in version 0.24.

Names of features seen during fit. Defined only when X has feature names that are all strings.

Added in version 1.0.

Maximum number of iterations run across all classes.

Implementation of Support Vector Machine classifier using libsvm: the kernel can be non-linear but its SMO algorithm does not scale to large number of samples as LinearSVC does. Furthermore SVC multi-class mode is implemented using one vs one scheme while LinearSVC uses one vs the rest. It is possible to implement one vs the rest with SVC by using the OneVsRestClassifier wrapper. Finally SVC can fit dense data without memory copy if the input is C-contiguous. Sparse data will still incur memory copy though.

SGDClassifier can optimize the same cost function as LinearSVC by adjusting the penalty and loss parameters. In addition it requires less memory, allows incremental (online) learning, and implements various loss functions and regularization regimes.

The underlying C implementation uses a random number generator to select features when fitting the model. It is thus not uncommon to have slightly different results for the same input data. If that happens, try with a smaller tol parameter.

The underlying implementation, liblinear, uses a sparse internal representation for the data that will incur a memory copy.

Predict output may not match that of standalone liblinear in certain cases. See differences from liblinear in the narrative documentation.

LIBLINEAR: A Library for Large Linear Classification

Predict confidence scores for samples.

The confidence score for a sample is proportional to the signed distance of that sample to the hyperplane.

The data matrix for which we want to get the confidence scores.

Confidence scores per (n_samples, n_classes) combination. In the binary case, confidence score for self.classes_[1] where >0 means this class would be predicted.

Convert coefficient matrix to dense array format.

Converts the coef_ member (back) to a numpy.ndarray. This is the default format of coef_ and is required for fitting, so calling this method is only required on models that have previously been sparsified; otherwise, it is a no-op.

Fit the model according to the given training data.

Training vector, where n_samples is the number of samples and n_features is the number of features.

Target vector relative to X.

Array of weights that are assigned to individual samples. If not provided, then each sample is given unit weight.

Added in version 0.18.

An instance of the estimator.

Get metadata routing of this object.

Please check User Guide on how the routing mechanism works.

A MetadataRequest encapsulating routing information.

Get parameters for this estimator.

If True, will return the parameters for this estimator and contained subobjects that are estimators.

Parameter names mapped to their values.

Predict class labels for samples in X.

The data matrix for which we want to get the predictions.

Vector containing the class labels for each sample.

Return accuracy on provided data and labels.

In multi-label classification, this is the subset accuracy which is a harsh metric since you require for each sample that each label set be correctly predicted.

Mean accuracy of self.predict(X) w.r.t. y.

Configure whether metadata should be requested to be passed to the fit method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to fit if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to fit.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Added in version 1.3.

Metadata routing for sample_weight parameter in fit.

Set the parameters of this estimator.

The method works on simple estimators as well as on nested objects (such as Pipeline). The latter have parameters of the form <component>__<parameter> so that it’s possible to update each component of a nested object.

Estimator parameters.

Configure whether metadata should be requested to be passed to the score method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to score if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to score.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Added in version 1.3.

Metadata routing for sample_weight parameter in score.

Convert coefficient matrix to sparse format.

Converts the coef_ member to a scipy.sparse matrix, which for L1-regularized models can be much more memory- and storage-efficient than the usual numpy.ndarray representation.

The intercept_ member is not converted.

For non-sparse models, i.e. when there are not many zeros in coef_, this may actually increase memory usage, so use this method with care. A rule of thumb is that the number of zero elements, which can be computed with (coef_ == 0).sum(), must be more than 50% for this to provide significant benefits.

After calling this method, further fitting with the partial_fit method (if any) will not work until you call densify.

Probability Calibration curves

Comparison of Calibration of Classifiers

Column Transformer with Heterogeneous Data Sources

Selecting dimensionality reduction with Pipeline and GridSearchCV

Univariate Feature Selection

Scalable learning with polynomial kernel approximation

Explicit feature map approximation for RBF kernels

Detection error tradeoff (DET) curve

Feature discretization

Release Highlights for scikit-learn 0.22

Plot different SVM classifiers in the iris dataset

Plot the support vectors in LinearSVC

Scaling the regularization parameter for SVCs

Classification of text documents using sparse features

**Examples:**

Example 1 (sql):
```sql
>>> from sklearn.svm import LinearSVC
>>> from sklearn.pipeline import make_pipeline
>>> from sklearn.preprocessing import StandardScaler
>>> from sklearn.datasets import make_classification
>>> X, y = make_classification(n_features=4, random_state=0)
>>> clf = make_pipeline(StandardScaler(),
...                     LinearSVC(random_state=0, tol=1e-5))
>>> clf.fit(X, y)
Pipeline(steps=[('standardscaler', StandardScaler()),
                ('linearsvc', LinearSVC(random_state=0, tol=1e-05))])
```

Example 2 (json):
```json
>>> print(clf.named_steps['linearsvc'].coef_)
[[0.141   0.526 0.679 0.493]]
```

Example 3 (json):
```json
>>> print(clf.named_steps['linearsvc'].intercept_)
[0.1693]
>>> print(clf.predict([[0, 0, 0, 0]]))
[1]
```

---

## StandardScaler#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html

**Contents:**
- StandardScaler#
- Gallery examples#

Standardize features by removing the mean and scaling to unit variance.

The standard score of a sample x is calculated as:

where u is the mean of the training samples or zero if with_mean=False, and s is the standard deviation of the training samples or one if with_std=False.

Centering and scaling happen independently on each feature by computing the relevant statistics on the samples in the training set. Mean and standard deviation are then stored to be used on later data using transform.

Standardization of a dataset is a common requirement for many machine learning estimators: they might behave badly if the individual features do not more or less look like standard normally distributed data (e.g. Gaussian with 0 mean and unit variance).

For instance many elements used in the objective function of a learning algorithm (such as the RBF kernel of Support Vector Machines or the L1 and L2 regularizers of linear models) assume that all features are centered around 0 and have variance in the same order. If a feature has a variance that is orders of magnitude larger than others, it might dominate the objective function and make the estimator unable to learn from other features correctly as expected.

StandardScaler is sensitive to outliers, and the features may scale differently from each other in the presence of outliers. For an example visualization, refer to Compare StandardScaler with other scalers.

This scaler can also be applied to sparse CSR or CSC matrices by passing with_mean=False to avoid breaking the sparsity structure of the data.

Read more in the User Guide.

If False, try to avoid a copy and do inplace scaling instead. This is not guaranteed to always work inplace; e.g. if the data is not a NumPy array or scipy.sparse CSR matrix, a copy may still be returned.

If True, center the data before scaling. This does not work (and will raise an exception) when attempted on sparse matrices, because centering them entails building a dense matrix which in common use cases is likely to be too large to fit in memory.

If True, scale the data to unit variance (or equivalently, unit standard deviation).

Per feature relative scaling of the data to achieve zero mean and unit variance. Generally this is calculated using np.sqrt(var_). If a variance is zero, we can’t achieve unit variance, and the data is left as-is, giving a scaling factor of 1. scale_ is equal to None when with_std=False.

Added in version 0.17: scale_

The mean value for each feature in the training set. Equal to None when with_mean=False and with_std=False.

The variance for each feature in the training set. Used to compute scale_. Equal to None when with_mean=False and with_std=False.

Number of features seen during fit.

Added in version 0.24.

Names of features seen during fit. Defined only when X has feature names that are all strings.

Added in version 1.0.

The number of samples processed by the estimator for each feature. If there are no missing samples, the n_samples_seen will be an integer, otherwise it will be an array of dtype int. If sample_weights are used it will be a float (if no missing data) or an array of dtype float that sums the weights seen so far. Will be reset on new calls to fit, but increments across partial_fit calls.

Equivalent function without the estimator API.

Further removes the linear correlation across features with ‘whiten=True’.

NaNs are treated as missing values: disregarded in fit, and maintained in transform.

We use a biased estimator for the standard deviation, equivalent to numpy.std(x, ddof=0). Note that the choice of ddof is unlikely to affect model performance.

Compute the mean and std to be used for later scaling.

The data used to compute the mean and standard deviation used for later scaling along the features axis.

Individual weights for each sample.

Added in version 0.24: parameter sample_weight support to StandardScaler.

Fit to data, then transform it.

Fits transformer to X and y with optional parameters fit_params and returns a transformed version of X.

Target values (None for unsupervised transformations).

Additional fit parameters. Pass only if the estimator accepts additional params in its fit method.

Get output feature names for transformation.

If input_features is None, then feature_names_in_ is used as feature names in. If feature_names_in_ is not defined, then the following input feature names are generated: ["x0", "x1", ..., "x(n_features_in_ - 1)"].

If input_features is an array-like, then input_features must match feature_names_in_ if feature_names_in_ is defined.

Same as input features.

Get metadata routing of this object.

Please check User Guide on how the routing mechanism works.

A MetadataRequest encapsulating routing information.

Get parameters for this estimator.

If True, will return the parameters for this estimator and contained subobjects that are estimators.

Parameter names mapped to their values.

Scale back the data to the original representation.

The data used to scale along the features axis.

Copy the input X or not.

Online computation of mean and std on X for later scaling.

All of X is processed as a single batch. This is intended for cases when fit is not feasible due to very large number of n_samples or because X is read from a continuous stream.

The algorithm for incremental mean and std is given in Equation 1.5a,b in Chan, Tony F., Gene H. Golub, and Randall J. LeVeque. “Algorithms for computing the sample variance: Analysis and recommendations.” The American Statistician 37.3 (1983): 242-247:

The data used to compute the mean and standard deviation used for later scaling along the features axis.

Individual weights for each sample.

Added in version 0.24: parameter sample_weight support to StandardScaler.

Configure whether metadata should be requested to be passed to the fit method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to fit if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to fit.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Added in version 1.3.

Metadata routing for sample_weight parameter in fit.

Configure whether metadata should be requested to be passed to the inverse_transform method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to inverse_transform if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to inverse_transform.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Added in version 1.3.

Metadata routing for copy parameter in inverse_transform.

Set output container.

See Introducing the set_output API for an example on how to use the API.

Configure output of transform and fit_transform.

"default": Default output format of a transformer

"pandas": DataFrame output

"polars": Polars output

None: Transform configuration is unchanged

Added in version 1.4: "polars" option was added.

Set the parameters of this estimator.

The method works on simple estimators as well as on nested objects (such as Pipeline). The latter have parameters of the form <component>__<parameter> so that it’s possible to update each component of a nested object.

Estimator parameters.

Configure whether metadata should be requested to be passed to the partial_fit method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to partial_fit if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to partial_fit.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Added in version 1.3.

Metadata routing for sample_weight parameter in partial_fit.

Configure whether metadata should be requested to be passed to the transform method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to transform if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to transform.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Added in version 1.3.

Metadata routing for copy parameter in transform.

Perform standardization by centering and scaling.

The data used to scale along the features axis.

Copy the input X or not.

Faces recognition example using eigenfaces and SVMs

Classifier comparison

Comparing different clustering algorithms on toy datasets

Demo of DBSCAN clustering algorithm

Demo of HDBSCAN clustering algorithm

A demo of K-Means clustering on the handwritten digits data

Comparing different hierarchical linkage methods on toy datasets

Column Transformer with Mixed Types

Pipelining: chaining a PCA and a logistic regression

Principal Component Regression vs Partial Least Squares Regression

Factor Analysis (with rotation) to visualize patterns

Combine predictors using stacking

Visualizing the probabilistic predictions of a VotingClassifier

Model-based and sequential feature selection

Common pitfalls in the interpretation of coefficients of linear models

Comparing Linear Bayesian Regressors

Lasso model selection via information criteria

Lasso model selection: AIC-BIC / cross-validation

L1 Penalty and Sparsity in Logistic Regression

Regularization path of L1- Logistic Regression

Poisson regression and non-normal loss

MNIST classification using multinomial logistic + L1

Tweedie regression on insurance claims

Visualizations with Display Objects

Displaying estimators and complex pipelines

Evaluation of outlier detection estimators

Advanced Plotting With Partial Dependence

Introducing the set_output API

Post-tuning the decision threshold for cost-sensitive learning

Detection error tradeoff (DET) curve

Post-hoc tuning the cut-off point of decision function

Nearest Neighbors Classification

Comparing Nearest Neighbors with and without Neighborhood Components Analysis

Dimensionality Reduction with Neighborhood Components Analysis

Varying regularization in Multi-layer Perceptron

Compare the effect of different scalers on data with outliers

Feature discretization

Importance of Feature Scaling

Release Highlights for scikit-learn 0.22

Release Highlights for scikit-learn 0.23

Release Highlights for scikit-learn 1.0

Release Highlights for scikit-learn 1.1

Release Highlights for scikit-learn 1.2

Release Highlights for scikit-learn 1.4

Release Highlights for scikit-learn 1.5

Release Highlights for scikit-learn 1.7

Release Highlights for scikit-learn 1.8

SVM-Anova: SVM with univariate feature selection

**Examples:**

Example 1 (unknown):
```unknown
z = (x - u) / s
```

Example 2 (csharp):
```csharp
>>> from sklearn.preprocessing import StandardScaler
>>> data = [[0, 0], [0, 0], [1, 1], [1, 1]]
>>> scaler = StandardScaler()
>>> print(scaler.fit(data))
StandardScaler()
>>> print(scaler.mean_)
[0.5 0.5]
>>> print(scaler.transform(data))
[[-1. -1.]
 [-1. -1.]
 [ 1.  1.]
 [ 1.  1.]]
>>> print(scaler.transform([[2, 2]]))
[[3. 3.]]
```

---

## AgglomerativeClustering#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.cluster.AgglomerativeClustering.html

**Contents:**
- AgglomerativeClustering#
- Gallery examples#

Agglomerative Clustering.

Recursively merges pair of clusters of sample data; uses linkage distance.

Read more in the User Guide.

The number of clusters to find. It must be None if distance_threshold is not None.

Metric used to compute the linkage. Can be “euclidean”, “l1”, “l2”, “manhattan”, “cosine”, or “precomputed”. If linkage is “ward”, only “euclidean” is accepted. If “precomputed”, a distance matrix is needed as input for the fit method. If connectivity is None, linkage is “single” and affinity is not “precomputed” any valid pairwise distance metric can be assigned.

For an example of agglomerative clustering with different metrics, see Agglomerative clustering with different metrics.

Added in version 1.2.

Used to cache the output of the computation of the tree. By default, no caching is done. If a string is given, it is the path to the caching directory.

Connectivity matrix. Defines for each sample the neighboring samples following a given structure of the data. This can be a connectivity matrix itself or a callable that transforms the data into a connectivity matrix, such as derived from kneighbors_graph. Default is None, i.e, the hierarchical clustering algorithm is unstructured.

For an example of connectivity matrix using kneighbors_graph, see Hierarchical clustering with and without structure.

Stop early the construction of the tree at n_clusters. This is useful to decrease computation time if the number of clusters is not small compared to the number of samples. This option is useful only when specifying a connectivity matrix. Note also that when varying the number of clusters and using caching, it may be advantageous to compute the full tree. It must be True if distance_threshold is not None. By default compute_full_tree is “auto”, which is equivalent to True when distance_threshold is not None or that n_clusters is inferior to the maximum between 100 or 0.02 * n_samples. Otherwise, “auto” is equivalent to False.

Which linkage criterion to use. The linkage criterion determines which distance to use between sets of observation. The algorithm will merge the pairs of cluster that minimize this criterion.

‘ward’ minimizes the variance of the clusters being merged.

‘average’ uses the average of the distances of each observation of the two sets.

‘complete’ or ‘maximum’ linkage uses the maximum distances between all observations of the two sets.

‘single’ uses the minimum of the distances between all observations of the two sets.

Added in version 0.20: Added the ‘single’ option

For examples comparing different linkage criteria, see Comparing different hierarchical linkage methods on toy datasets.

The linkage distance threshold at or above which clusters will not be merged. If not None, n_clusters must be None and compute_full_tree must be True.

Added in version 0.21.

Computes distances between clusters even if distance_threshold is not used. This can be used to make dendrogram visualization, but introduces a computational and memory overhead.

Added in version 0.24.

For an example of dendrogram visualization, see Plot Hierarchical Clustering Dendrogram.

The number of clusters found by the algorithm. If distance_threshold=None, it will be equal to the given n_clusters.

Cluster labels for each point.

Number of leaves in the hierarchical tree.

The estimated number of connected components in the graph.

Added in version 0.21: n_connected_components_ was added to replace n_components_.

Number of features seen during fit.

Added in version 0.24.

Names of features seen during fit. Defined only when X has feature names that are all strings.

Added in version 1.0.

The children of each non-leaf node. Values less than n_samples correspond to leaves of the tree which are the original samples. A node i greater than or equal to n_samples is a non-leaf node and has children children_[i - n_samples]. Alternatively at the i-th iteration, children[i][0] and children[i][1] are merged to form node n_samples + i.

Distances between nodes in the corresponding place in children_. Only computed if distance_threshold is used or compute_distances is set to True.

Agglomerative clustering but for features instead of samples.

Hierarchical clustering with ward linkage.

For a comparison of Agglomerative clustering with other clustering algorithms, see Comparing different clustering algorithms on toy datasets

Fit the hierarchical clustering from features, or distance matrix.

Training instances to cluster, or distances between instances if metric='precomputed'.

Not used, present here for API consistency by convention.

Returns the fitted instance.

Fit and return the result of each sample’s clustering assignment.

In addition to fitting, this method also return the result of the clustering assignment for each sample in the training set.

Training instances to cluster, or distances between instances if affinity='precomputed'.

Not used, present here for API consistency by convention.

Get metadata routing of this object.

Please check User Guide on how the routing mechanism works.

A MetadataRequest encapsulating routing information.

Get parameters for this estimator.

If True, will return the parameters for this estimator and contained subobjects that are estimators.

Parameter names mapped to their values.

Set the parameters of this estimator.

The method works on simple estimators as well as on nested objects (such as Pipeline). The latter have parameters of the form <component>__<parameter> so that it’s possible to update each component of a nested object.

Estimator parameters.

Agglomerative clustering with different metrics

Plot Hierarchical Clustering Dendrogram

Comparing different clustering algorithms on toy datasets

A demo of structured Ward hierarchical clustering on an image of coins

Various Agglomerative Clustering on a 2D embedding of digits

Comparing different hierarchical linkage methods on toy datasets

Hierarchical clustering with and without structure

**Examples:**

Example 1 (sql):
```sql
>>> from sklearn.cluster import AgglomerativeClustering
>>> import numpy as np
>>> X = np.array([[1, 2], [1, 4], [1, 0],
...               [4, 2], [4, 4], [4, 0]])
>>> clustering = AgglomerativeClustering().fit(X)
>>> clustering
AgglomerativeClustering()
>>> clustering.labels_
array([1, 1, 1, 0, 0, 0])
```

---

## 

**URL:** https://scikit-learn.org/stable/_sources/modules/tree.rst.txt

---

## PLSRegression#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.cross_decomposition.PLSRegression.html

**Contents:**
- PLSRegression#
- Gallery examples#

PLSRegression is also known as PLS2 or PLS1, depending on the number of targets.

For a comparison between other cross decomposition algorithms, see Compare cross decomposition methods.

Read more in the User Guide.

Added in version 0.8.

Number of components to keep. Should be in [1, n_features].

Whether to scale X and y.

The maximum number of iterations of the power method when algorithm='nipals'. Ignored otherwise.

The tolerance used as convergence criteria in the power method: the algorithm stops whenever the squared norm of u_i - u_{i-1} is less than tol, where u corresponds to the left singular vector.

Whether to copy X and y in fit before applying centering, and potentially scaling. If False, these operations will be done inplace, modifying both arrays.

The left singular vectors of the cross-covariance matrices of each iteration.

The right singular vectors of the cross-covariance matrices of each iteration.

The transformed training samples.

The transformed training targets.

The projection matrix used to transform X.

The projection matrix used to transform y.

The coefficients of the linear model such that y is approximated as y = X @ coef_.T + intercept_.

The intercepts of the linear model such that y is approximated as y = X @ coef_.T + intercept_.

Added in version 1.1.

Number of iterations of the power method, for each component.

Number of features seen during fit.

Names of features seen during fit. Defined only when X has feature names that are all strings.

Added in version 1.0.

Partial Least Squares transformer and regressor.

For a comparison between PLS Regression and PCA, see Principal Component Regression vs Partial Least Squares Regression.

Training vectors, where n_samples is the number of samples and n_features is the number of predictors.

Target vectors, where n_samples is the number of samples and n_targets is the number of response variables.

Learn and apply the dimension reduction on the train data.

Training vectors, where n_samples is the number of samples and n_features is the number of predictors.

Target vectors, where n_samples is the number of samples and n_targets is the number of response variables.

Return x_scores if y is not given, (x_scores, y_scores) otherwise.

Get output feature names for transformation.

The feature names out will prefixed by the lowercased class name. For example, if the transformer outputs 3 features, then the feature names out are: ["class_name0", "class_name1", "class_name2"].

Only used to validate feature names with the names seen in fit.

Transformed feature names.

Get metadata routing of this object.

Please check User Guide on how the routing mechanism works.

A MetadataRequest encapsulating routing information.

Get parameters for this estimator.

If True, will return the parameters for this estimator and contained subobjects that are estimators.

Parameter names mapped to their values.

Transform data back to its original space.

New data, where n_samples is the number of samples and n_components is the number of pls components.

New target, where n_samples is the number of samples and n_components is the number of pls components.

Return the reconstructed X data.

Return the reconstructed X target. Only returned when y is given.

This transformation will only be exact if n_components=n_features.

Predict targets of given samples.

Whether to copy X or perform in-place normalization.

Returns predicted values.

This call requires the estimation of a matrix of shape (n_features, n_targets), which may be an issue in high dimensional space.

Return coefficient of determination on test data.

The coefficient of determination, \(R^2\), is defined as \((1 - \frac{u}{v})\), where \(u\) is the residual sum of squares ((y_true - y_pred)** 2).sum() and \(v\) is the total sum of squares ((y_true - y_true.mean()) ** 2).sum(). The best possible score is 1.0 and it can be negative (because the model can be arbitrarily worse). A constant model that always predicts the expected value of y, disregarding the input features, would get a \(R^2\) score of 0.0.

Test samples. For some estimators this may be a precomputed kernel matrix or a list of generic objects instead with shape (n_samples, n_samples_fitted), where n_samples_fitted is the number of samples used in the fitting for the estimator.

\(R^2\) of self.predict(X) w.r.t. y.

The \(R^2\) score used when calling score on a regressor uses multioutput='uniform_average' from version 0.23 to keep consistent with default value of r2_score. This influences the score method of all the multioutput regressors (except for MultiOutputRegressor).

Set output container.

See Introducing the set_output API for an example on how to use the API.

Configure output of transform and fit_transform.

"default": Default output format of a transformer

"pandas": DataFrame output

"polars": Polars output

None: Transform configuration is unchanged

Added in version 1.4: "polars" option was added.

Set the parameters of this estimator.

The method works on simple estimators as well as on nested objects (such as Pipeline). The latter have parameters of the form <component>__<parameter> so that it’s possible to update each component of a nested object.

Estimator parameters.

Configure whether metadata should be requested to be passed to the predict method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to predict if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to predict.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Added in version 1.3.

Metadata routing for copy parameter in predict.

Configure whether metadata should be requested to be passed to the score method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to score if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to score.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Added in version 1.3.

Metadata routing for sample_weight parameter in score.

Configure whether metadata should be requested to be passed to the transform method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to transform if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to transform.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Added in version 1.3.

Metadata routing for copy parameter in transform.

Apply the dimension reduction.

Samples to transform.

Whether to copy X and y, or perform in-place normalization.

Return x_scores if y is not given, (x_scores, y_scores) otherwise.

Compare cross decomposition methods

Principal Component Regression vs Partial Least Squares Regression

**Examples:**

Example 1 (sql):
```sql
>>> from sklearn.cross_decomposition import PLSRegression
>>> X = [[0., 0., 1.], [1.,0.,0.], [2.,2.,2.], [2.,5.,4.]]
>>> y = [[0.1, -0.2], [0.9, 1.1], [6.2, 5.9], [11.9, 12.3]]
>>> pls2 = PLSRegression(n_components=2)
>>> pls2.fit(X, y)
PLSRegression()
>>> y_pred = pls2.predict(X)
```

---

## LabelSpreading#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.semi_supervised.LabelSpreading.html

**Contents:**
- LabelSpreading#
- Gallery examples#

LabelSpreading model for semi-supervised learning.

This model is similar to the basic Label Propagation algorithm, but uses affinity matrix based on the normalized graph Laplacian and soft clamping across the labels.

Read more in the User Guide.

String identifier for kernel function to use or the kernel function itself. Only ‘rbf’ and ‘knn’ strings are valid inputs. The function passed should take two inputs, each of shape (n_samples, n_features), and return a (n_samples, n_samples) shaped weight matrix.

Parameter for rbf kernel.

Parameter for knn kernel which is a strictly positive integer.

Clamping factor. A value in (0, 1) that specifies the relative amount that an instance should adopt the information from its neighbors as opposed to its initial label. alpha=0 means keeping the initial label information; alpha=1 means replacing all initial information.

Maximum number of iterations allowed.

Convergence tolerance: threshold to consider the system at steady state.

The number of parallel jobs to run. None means 1 unless in a joblib.parallel_backend context. -1 means using all processors. See Glossary for more details.

The distinct labels used in classifying instances.

Categorical distribution for each item.

Label assigned to each item during fit.

Number of features seen during fit.

Added in version 0.24.

Names of features seen during fit. Defined only when X has feature names that are all strings.

Added in version 1.0.

Number of iterations run.

Unregularized graph based semi-supervised learning.

Dengyong Zhou, Olivier Bousquet, Thomas Navin Lal, Jason Weston, Bernhard Schoelkopf. Learning with local and global consistency (2004)

Fit a semi-supervised label propagation model to X.

The input samples (labeled and unlabeled) are provided by matrix X, and target labels are provided by matrix y. We conventionally apply the label -1 to unlabeled samples in matrix y in a semi-supervised classification.

Training data, where n_samples is the number of samples and n_features is the number of features.

Target class values with unlabeled points marked as -1. All unlabeled samples will be transductively assigned labels internally, which are stored in transduction_.

Returns the instance itself.

Get metadata routing of this object.

Please check User Guide on how the routing mechanism works.

A MetadataRequest encapsulating routing information.

Get parameters for this estimator.

If True, will return the parameters for this estimator and contained subobjects that are estimators.

Parameter names mapped to their values.

Perform inductive inference across the model.

Predictions for input data.

Predict probability for each possible outcome.

Compute the probability estimates for each single sample in X and each possible outcome seen during training (categorical distribution).

Normalized probability distributions across class labels.

Return accuracy on provided data and labels.

In multi-label classification, this is the subset accuracy which is a harsh metric since you require for each sample that each label set be correctly predicted.

Mean accuracy of self.predict(X) w.r.t. y.

Set the parameters of this estimator.

The method works on simple estimators as well as on nested objects (such as Pipeline). The latter have parameters of the form <component>__<parameter> so that it’s possible to update each component of a nested object.

Estimator parameters.

Configure whether metadata should be requested to be passed to the score method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to score if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to score.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Added in version 1.3.

Metadata routing for sample_weight parameter in score.

Label Propagation digits: Demonstrating performance

Label Propagation digits: Active learning

Label Propagation circles: Learning a complex structure

Semi-supervised Classification on a Text Dataset

Decision boundary of semi-supervised classifiers versus SVM on the Iris dataset

**Examples:**

Example 1 (python):
```python
>>> import numpy as np
>>> from sklearn import datasets
>>> from sklearn.semi_supervised import LabelSpreading
>>> label_prop_model = LabelSpreading()
>>> iris = datasets.load_iris()
>>> rng = np.random.RandomState(42)
>>> random_unlabeled_points = rng.rand(len(iris.target)) < 0.3
>>> labels = np.copy(iris.target)
>>> labels[random_unlabeled_points] = -1
>>> label_prop_model.fit(iris.data, labels)
LabelSpreading(...)
```

---

## MultiTaskLassoCV#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.MultiTaskLassoCV.html

**Contents:**
- MultiTaskLassoCV#

Multi-task Lasso model trained with L1/L2 mixed-norm as regularizer.

See glossary entry for cross-validation estimator.

The optimization objective for MultiTaskLasso is:

i.e. the sum of norm of each row.

Read more in the User Guide.

Added in version 0.15.

Length of the path. eps=1e-3 means that alpha_min / alpha_max = 1e-3.

Number of alphas along the regularization path.

Deprecated since version 1.7: n_alphas was deprecated in 1.7 and will be removed in 1.9. Use alphas instead.

Values of alphas to test along the regularization path. If int, alphas values are generated automatically. If array-like, list of alpha values to use.

Changed in version 1.7: alphas accepts an integer value which removes the need to pass n_alphas.

Deprecated since version 1.7: alphas=None was deprecated in 1.7 and will be removed in 1.9, at which point the default value will be set to 100.

Whether to calculate the intercept for this model. If set to false, no intercept will be used in calculations (i.e. data is expected to be centered).

The maximum number of iterations.

The tolerance for the optimization: if the updates are smaller or equal to tol, the optimization code checks the dual gap for optimality and continues until it is smaller or equal to tol.

If True, X will be copied; else, it may be overwritten.

Determines the cross-validation splitting strategy. Possible inputs for cv are:

None, to use the default 5-fold cross-validation,

int, to specify the number of folds.

An iterable yielding (train, test) splits as arrays of indices.

For int/None inputs, KFold is used.

Refer User Guide for the various cross-validation strategies that can be used here.

Changed in version 0.22: cv default value if None changed from 3-fold to 5-fold.

Number of CPUs to use during the cross validation. Note that this is used only if multiple values for l1_ratio are given. None means 1 unless in a joblib.parallel_backend context. -1 means using all processors. See Glossary for more details.

The seed of the pseudo random number generator that selects a random feature to update. Used when selection == ‘random’. Pass an int for reproducible output across multiple function calls. See Glossary.

If set to ‘random’, a random coefficient is updated every iteration rather than looping over features sequentially by default. This (setting to ‘random’) often leads to significantly faster convergence especially when tol is higher than 1e-4.

Independent term in decision function.

Parameter vector (W in the cost function formula). Note that coef_ stores the transpose of W, W.T.

The amount of penalization chosen by cross validation.

Mean square error for the test set on each fold, varying alpha.

The grid of alphas used for fitting.

Number of iterations run by the coordinate descent solver to reach the specified tolerance for the optimal alpha.

The dual gap at the end of the optimization for the optimal alpha.

Number of features seen during fit.

Added in version 0.24.

Names of features seen during fit. Defined only when X has feature names that are all strings.

Added in version 1.0.

Multi-task ElasticNet model trained with L1/L2 mixed-norm as regularizer.

Elastic net model with best model selection by cross-validation.

Multi-task L1/L2 ElasticNet with built-in cross-validation.

The algorithm used to fit the model is coordinate descent.

In fit, once the best parameter alpha is found through cross-validation, the model is fit again using the entire training set.

To avoid unnecessary memory duplication the X and y arguments of the fit method should be directly passed as Fortran-contiguous numpy arrays.

Fit MultiTaskLasso model with coordinate descent.

Fit is on grid of alphas and best alpha estimated by cross-validation.

Target. Will be cast to X’s dtype if necessary.

Parameters to be passed to the CV splitter.

Added in version 1.4: Only available if enable_metadata_routing=True, which can be set by using sklearn.set_config(enable_metadata_routing=True). See Metadata Routing User Guide for more details.

Returns an instance of fitted model.

Get metadata routing of this object.

Please check User Guide on how the routing mechanism works.

Added in version 1.4.

A MetadataRouter encapsulating routing information.

Get parameters for this estimator.

If True, will return the parameters for this estimator and contained subobjects that are estimators.

Parameter names mapped to their values.

Compute Lasso path with coordinate descent.

The Lasso optimization function varies for mono and multi-outputs.

For mono-output tasks it is:

For multi-output tasks it is:

i.e. the sum of norm of each row.

Read more in the User Guide.

Training data. Pass directly as Fortran-contiguous data to avoid unnecessary memory duplication. If y is mono-output then X can be sparse.

Length of the path. eps=1e-3 means that alpha_min / alpha_max = 1e-3.

Number of alphas along the regularization path.

List of alphas where to compute the models. If None alphas are set automatically.

Whether to use a precomputed Gram matrix to speed up calculations. If set to 'auto' let us decide. The Gram matrix can also be passed as argument.

Xy = np.dot(X.T, y) that can be precomputed. It is useful only when the Gram matrix is precomputed.

If True, X will be copied; else, it may be overwritten.

The initial values of the coefficients.

Whether to return the number of iterations or not.

If set to True, forces coefficients to be positive. (Only allowed when y.ndim == 1).

Keyword arguments passed to the coordinate descent solver.

The alphas along the path where models are computed.

Coefficients along the path.

The dual gaps at the end of the optimization for each alpha.

The number of iterations taken by the coordinate descent optimizer to reach the specified tolerance for each alpha.

Compute Least Angle Regression or Lasso path using LARS algorithm.

The Lasso is a linear model that estimates sparse coefficients.

Lasso model fit with Least Angle Regression a.k.a. Lars.

Lasso linear model with iterative fitting along a regularization path.

Cross-validated Lasso using the LARS algorithm.

Estimator that can be used to transform signals into sparse linear combination of atoms from a fixed.

For an example, see examples/linear_model/plot_lasso_lasso_lars_elasticnet_path.py.

To avoid unnecessary memory duplication the X argument of the fit method should be directly passed as a Fortran-contiguous numpy array.

Note that in certain cases, the Lars solver may be significantly faster to implement this functionality. In particular, linear interpolation can be used to retrieve model coefficients between the values output by lars_path.

The underlying coordinate descent solver uses gap safe screening rules to speedup fitting time, see User Guide on coordinate descent.

Comparing lasso_path and lars_path with interpolation:

Predict using the linear model.

Returns predicted values.

Return coefficient of determination on test data.

The coefficient of determination, \(R^2\), is defined as \((1 - \frac{u}{v})\), where \(u\) is the residual sum of squares ((y_true - y_pred)** 2).sum() and \(v\) is the total sum of squares ((y_true - y_true.mean()) ** 2).sum(). The best possible score is 1.0 and it can be negative (because the model can be arbitrarily worse). A constant model that always predicts the expected value of y, disregarding the input features, would get a \(R^2\) score of 0.0.

Test samples. For some estimators this may be a precomputed kernel matrix or a list of generic objects instead with shape (n_samples, n_samples_fitted), where n_samples_fitted is the number of samples used in the fitting for the estimator.

\(R^2\) of self.predict(X) w.r.t. y.

The \(R^2\) score used when calling score on a regressor uses multioutput='uniform_average' from version 0.23 to keep consistent with default value of r2_score. This influences the score method of all the multioutput regressors (except for MultiOutputRegressor).

Configure whether metadata should be requested to be passed to the fit method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to fit if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to fit.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Added in version 1.3.

Metadata routing for sample_weight parameter in fit.

Set the parameters of this estimator.

The method works on simple estimators as well as on nested objects (such as Pipeline). The latter have parameters of the form <component>__<parameter> so that it’s possible to update each component of a nested object.

Estimator parameters.

Configure whether metadata should be requested to be passed to the score method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to score if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to score.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Added in version 1.3.

Metadata routing for sample_weight parameter in score.

**Examples:**

Example 1 (unknown):
```unknown
(1 / (2 * n_samples)) * ||Y - XW||^Fro_2 + alpha * ||W||_21
```

Example 2 (unknown):
```unknown
||W||_21 = \sum_i \sqrt{\sum_j w_{ij}^2}
```

Example 3 (sql):
```sql
>>> from sklearn.linear_model import MultiTaskLassoCV
>>> from sklearn.datasets import make_regression
>>> from sklearn.metrics import r2_score
>>> X, y = make_regression(n_targets=2, noise=4, random_state=0)
>>> reg = MultiTaskLassoCV(cv=5, random_state=0).fit(X, y)
>>> r2_score(y, reg.predict(X))
0.9994
>>> reg.alpha_
np.float64(0.4321...)
>>> reg.predict(X[:1,])
array([[153.7971,  94.9015]])
```

Example 4 (unknown):
```unknown
(1 / (2 * n_samples)) * ||y - Xw||^2_2 + alpha * ||w||_1
```

---

## LedoitWolf#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.covariance.LedoitWolf.html

**Contents:**
- LedoitWolf#
- Gallery examples#

LedoitWolf Estimator.

Ledoit-Wolf is a particular form of shrinkage, where the shrinkage coefficient is computed using O. Ledoit and M. Wolf’s formula as described in “A Well-Conditioned Estimator for Large-Dimensional Covariance Matrices”, Ledoit and Wolf, Journal of Multivariate Analysis, Volume 88, Issue 2, February 2004, pages 365-411.

Read more in the User Guide.

Specify if the estimated precision is stored.

If True, data will not be centered before computation. Useful when working with data whose mean is almost, but not exactly zero. If False (default), data will be centered before computation.

Size of blocks into which the covariance matrix will be split during its Ledoit-Wolf estimation. This is purely a memory optimization and does not affect results.

Estimated covariance matrix.

Estimated location, i.e. the estimated mean.

Estimated pseudo inverse matrix. (stored only if store_precision is True)

Coefficient in the convex combination used for the computation of the shrunk estimate. Range is [0, 1].

Number of features seen during fit.

Added in version 0.24.

Names of features seen during fit. Defined only when X has feature names that are all strings.

Added in version 1.0.

An object for detecting outliers in a Gaussian distributed dataset.

Maximum likelihood covariance estimator.

Sparse inverse covariance estimation with an l1-penalized estimator.

Sparse inverse covariance with cross-validated choice of the l1 penalty.

Minimum Covariance Determinant (robust estimator of covariance).

Oracle Approximating Shrinkage Estimator.

Covariance estimator with shrinkage.

The regularised covariance is:

(1 - shrinkage) * cov + shrinkage * mu * np.identity(n_features)

where mu = trace(cov) / n_features and shrinkage is given by the Ledoit and Wolf formula (see References)

“A Well-Conditioned Estimator for Large-Dimensional Covariance Matrices”, Ledoit and Wolf, Journal of Multivariate Analysis, Volume 88, Issue 2, February 2004, pages 365-411.

See also Shrinkage covariance estimation: LedoitWolf vs OAS and max-likelihood and Ledoit-Wolf vs OAS estimation for more detailed examples.

Compute the Mean Squared Error between two covariance estimators.

The covariance to compare with.

The type of norm used to compute the error. Available error types: - ‘frobenius’ (default): sqrt(tr(A^t.A)) - ‘spectral’: sqrt(max(eigenvalues(A^t.A)) where A is the error (comp_cov - self.covariance_).

If True (default), the squared error norm is divided by n_features. If False, the squared error norm is not rescaled.

Whether to compute the squared error norm or the error norm. If True (default), the squared error norm is returned. If False, the error norm is returned.

The Mean Squared Error (in the sense of the Frobenius norm) between self and comp_cov covariance estimators.

Fit the Ledoit-Wolf shrunk covariance model to X.

Training data, where n_samples is the number of samples and n_features is the number of features.

Not used, present for API consistency by convention.

Returns the instance itself.

Get metadata routing of this object.

Please check User Guide on how the routing mechanism works.

A MetadataRequest encapsulating routing information.

Get parameters for this estimator.

If True, will return the parameters for this estimator and contained subobjects that are estimators.

Parameter names mapped to their values.

Getter for the precision matrix.

The precision matrix associated to the current covariance object.

Compute the squared Mahalanobis distances of given observations.

For a detailed example of how outliers affects the Mahalanobis distance, see Robust covariance estimation and Mahalanobis distances relevance.

The observations, the Mahalanobis distances of the which we compute. Observations are assumed to be drawn from the same distribution than the data used in fit.

Squared Mahalanobis distances of the observations.

Compute the log-likelihood of X_test under the estimated Gaussian model.

The Gaussian model is defined by its mean and covariance matrix which are represented respectively by self.location_ and self.covariance_.

Test data of which we compute the likelihood, where n_samples is the number of samples and n_features is the number of features. X_test is assumed to be drawn from the same distribution than the data used in fit (including centering).

Not used, present for API consistency by convention.

The log-likelihood of X_test with self.location_ and self.covariance_ as estimators of the Gaussian model mean and covariance matrix respectively.

Set the parameters of this estimator.

The method works on simple estimators as well as on nested objects (such as Pipeline). The latter have parameters of the form <component>__<parameter> so that it’s possible to update each component of a nested object.

Estimator parameters.

Shrinkage covariance estimation: LedoitWolf vs OAS and max-likelihood

Ledoit-Wolf vs OAS estimation

Model selection with Probabilistic PCA and Factor Analysis (FA)

**Examples:**

Example 1 (sql):
```sql
>>> import numpy as np
>>> from sklearn.covariance import LedoitWolf
>>> real_cov = np.array([[.4, .2],
...                      [.2, .8]])
>>> np.random.seed(0)
>>> X = np.random.multivariate_normal(mean=[0, 0],
...                                   cov=real_cov,
...                                   size=50)
>>> cov = LedoitWolf().fit(X)
>>> cov.covariance_
array([[0.4406, 0.1616],
       [0.1616, 0.8022]])
>>> cov.location_
array([ 0.0595 , -0.0075])
```

---

## 1.14. Semi-supervised learning#

**URL:** https://scikit-learn.org/stable/modules/semi_supervised.html

**Contents:**
- 1.14. Semi-supervised learning#
- 1.14.1. Self Training#
- 1.14.2. Label Propagation#

Semi-supervised learning is a situation in which in your training data some of the samples are not labeled. The semi-supervised estimators in sklearn.semi_supervised are able to make use of this additional unlabeled data to better capture the shape of the underlying data distribution and generalize better to new samples. These algorithms can perform well when we have a very small amount of labeled points and a large amount of unlabeled points.

Unlabeled entries in y

It is important to assign an identifier to unlabeled points along with the labeled data when training the model with the fit method. The identifier that this implementation uses is the integer value \(-1\). Note that for string labels, the dtype of y should be object so that it can contain both strings and integers.

Semi-supervised algorithms need to make assumptions about the distribution of the dataset in order to achieve performance gains. See here for more details.

Semi-supervised Classification on a Text Dataset

This self-training implementation is based on Yarowsky’s [1] algorithm. Using this algorithm, a given supervised classifier can function as a semi-supervised classifier, allowing it to learn from unlabeled data.

SelfTrainingClassifier can be called with any classifier that implements predict_proba, passed as the parameter estimator. In each iteration, the estimator predicts labels for the unlabeled samples and adds a subset of these labels to the labeled dataset.

The choice of this subset is determined by the selection criterion. This selection can be done using a threshold on the prediction probabilities, or by choosing the k_best samples according to the prediction probabilities.

The labels used for the final fit as well as the iteration in which each sample was labeled are available as attributes. The optional max_iter parameter specifies how many times the loop is executed at most.

The max_iter parameter may be set to None, causing the algorithm to iterate until all samples have labels or no new samples are selected in that iteration.

When using the self-training classifier, the calibration of the classifier is important.

Effect of varying threshold for self-training

Decision boundary of semi-supervised classifiers versus SVM on the Iris dataset

“Unsupervised word sense disambiguation rivaling supervised methods” David Yarowsky, Proceedings of the 33rd annual meeting on Association for Computational Linguistics (ACL ‘95). Association for Computational Linguistics, Stroudsburg, PA, USA, 189-196.

Label propagation denotes a few variations of semi-supervised graph inference algorithms.

Used for classification tasks

Kernel methods to project data into alternate dimensional spaces

scikit-learn provides two label propagation models: LabelPropagation and LabelSpreading. Both work by constructing a similarity graph over all items in the input dataset.

An illustration of label-propagation: the structure of unlabeled observations is consistent with the class structure, and thus the class label can be propagated to the unlabeled observations of the training set.#

LabelPropagation and LabelSpreading differ in modifications to the similarity matrix that graph and the clamping effect on the label distributions. Clamping allows the algorithm to change the weight of the true ground labeled data to some degree. The LabelPropagation algorithm performs hard clamping of input labels, which means \(\alpha=0\). This clamping factor can be relaxed, to say \(\alpha=0.2\), which means that we will always retain 80 percent of our original label distribution, but the algorithm gets to change its confidence of the distribution within 20 percent.

LabelPropagation uses the raw similarity matrix constructed from the data with no modifications. In contrast, LabelSpreading minimizes a loss function that has regularization properties, as such it is often more robust to noise. The algorithm iterates on a modified version of the original graph and normalizes the edge weights by computing the normalized graph Laplacian matrix. This procedure is also used in Spectral clustering.

Label propagation models have two built-in kernel methods. Choice of kernel affects both scalability and performance of the algorithms. The following are available:

rbf (\(\exp(-\gamma |x-y|^2), \gamma > 0\)). \(\gamma\) is specified by keyword gamma.

knn (\(1[x' \in kNN(x)]\)). \(k\) is specified by keyword n_neighbors.

The RBF kernel will produce a fully connected graph which is represented in memory by a dense matrix. This matrix may be very large and combined with the cost of performing a full matrix multiplication calculation for each iteration of the algorithm can lead to prohibitively long running times. On the other hand, the KNN kernel will produce a much more memory-friendly sparse matrix which can drastically reduce running times.

Decision boundary of semi-supervised classifiers versus SVM on the Iris dataset

Label Propagation circles: Learning a complex structure

Label Propagation digits: Demonstrating performance

Label Propagation digits: Active learning

[2] Yoshua Bengio, Olivier Delalleau, Nicolas Le Roux. In Semi-Supervised Learning (2006), pp. 193-216

[3] Olivier Delalleau, Yoshua Bengio, Nicolas Le Roux. Efficient Non-Parametric Function Induction in Semi-Supervised Learning. AISTAT 2005 https://www.gatsby.ucl.ac.uk/aistats/fullpapers/204.pdf

---

## 

**URL:** https://scikit-learn.org/stable/_sources/modules/mixture.rst.txt

---

## 2.5. Decomposing signals in components (matrix factorization problems)#

**URL:** https://scikit-learn.org/stable/modules/decomposition.html

**Contents:**
- 2.5. Decomposing signals in components (matrix factorization problems)#
- 2.5.1. Principal component analysis (PCA)#
  - 2.5.1.1. Exact PCA and probabilistic interpretation#
  - 2.5.1.2. Incremental PCA#
  - 2.5.1.3. PCA using randomized SVD#
  - 2.5.1.4. Sparse principal components analysis (SparsePCA and MiniBatchSparsePCA)#
- 2.5.2. Kernel Principal Component Analysis (kPCA)#
  - 2.5.2.1. Exact Kernel PCA#
  - 2.5.2.2. Choice of solver for Kernel PCA#
- 2.5.3. Truncated singular value decomposition and latent semantic analysis#

PCA is used to decompose a multivariate dataset in a set of successive orthogonal components that explain a maximum amount of the variance. In scikit-learn, PCA is implemented as a transformer object that learns \(n\) components in its fit method, and can be used on new data to project it on these components.

PCA centers but does not scale the input data for each feature before applying the SVD. The optional parameter whiten=True makes it possible to project the data onto the singular space while scaling each component to unit variance. This is often useful if the models down-stream make strong assumptions on the isotropy of the signal: this is for example the case for Support Vector Machines with the RBF kernel and the K-Means clustering algorithm.

Below is an example of the iris dataset, which is comprised of 4 features, projected on the 2 dimensions that explain most variance:

The PCA object also provides a probabilistic interpretation of the PCA that can give a likelihood of data based on the amount of variance it explains. As such it implements a score method that can be used in cross-validation:

Principal Component Analysis (PCA) on Iris Dataset

Comparison of LDA and PCA 2D projection of Iris dataset

Model selection with Probabilistic PCA and Factor Analysis (FA)

The PCA object is very useful, but has certain limitations for large datasets. The biggest limitation is that PCA only supports batch processing, which means all of the data to be processed must fit in main memory. The IncrementalPCA object uses a different form of processing and allows for partial computations which almost exactly match the results of PCA while processing the data in a minibatch fashion. IncrementalPCA makes it possible to implement out-of-core Principal Component Analysis either by:

Using its partial_fit method on chunks of data fetched sequentially from the local hard drive or a network database.

Calling its fit method on a memory mapped file using numpy.memmap.

IncrementalPCA only stores estimates of component and noise variances, in order to update explained_variance_ratio_ incrementally. This is why memory usage depends on the number of samples per batch, rather than the number of samples to be processed in the dataset.

As in PCA, IncrementalPCA centers but does not scale the input data for each feature before applying the SVD.

It is often interesting to project data to a lower-dimensional space that preserves most of the variance, by dropping the singular vector of components associated with lower singular values.

For instance, if we work with 64x64 pixel gray-level pictures for face recognition, the dimensionality of the data is 4096 and it is slow to train an RBF support vector machine on such wide data. Furthermore we know that the intrinsic dimensionality of the data is much lower than 4096 since all pictures of human faces look somewhat alike. The samples lie on a manifold of much lower dimension (say around 200 for instance). The PCA algorithm can be used to linearly transform the data while both reducing the dimensionality and preserving most of the explained variance at the same time.

The class PCA used with the optional parameter svd_solver='randomized' is very useful in that case: since we are going to drop most of the singular vectors it is much more efficient to limit the computation to an approximated estimate of the singular vectors we will keep to actually perform the transform.

For instance, the following shows 16 sample portraits (centered around 0.0) from the Olivetti dataset. On the right hand side are the first 16 singular vectors reshaped as portraits. Since we only require the top 16 singular vectors of a dataset with size \(n_{samples} = 400\) and \(n_{features} = 64 \times 64 = 4096\), the computation time is less than 1s:

If we note \(n_{\max} = \max(n_{\mathrm{samples}}, n_{\mathrm{features}})\) and \(n_{\min} = \min(n_{\mathrm{samples}}, n_{\mathrm{features}})\), the time complexity of the randomized PCA is \(O(n_{\max}^2 \cdot n_{\mathrm{components}})\) instead of \(O(n_{\max}^2 \cdot n_{\min})\) for the exact method implemented in PCA.

The memory footprint of randomized PCA is also proportional to \(2 \cdot n_{\max} \cdot n_{\mathrm{components}}\) instead of \(n_{\max} \cdot n_{\min}\) for the exact method.

Note: the implementation of inverse_transform in PCA with svd_solver='randomized' is not the exact inverse transform of transform even when whiten=False (default).

Faces recognition example using eigenfaces and SVMs

Faces dataset decompositions

Algorithm 4.3 in “Finding structure with randomness: Stochastic algorithms for constructing approximate matrix decompositions” Halko, et al., 2009

“An implementation of a randomized algorithm for principal component analysis” A. Szlam et al. 2014

SparsePCA is a variant of PCA, with the goal of extracting the set of sparse components that best reconstruct the data.

Mini-batch sparse PCA (MiniBatchSparsePCA) is a variant of SparsePCA that is faster but less accurate. The increased speed is reached by iterating over small chunks of the set of features, for a given number of iterations.

Principal component analysis (PCA) has the disadvantage that the components extracted by this method have exclusively dense expressions, i.e. they have non-zero coefficients when expressed as linear combinations of the original variables. This can make interpretation difficult. In many cases, the real underlying components can be more naturally imagined as sparse vectors; for example in face recognition, components might naturally map to parts of faces.

Sparse principal components yield a more parsimonious, interpretable representation, clearly emphasizing which of the original features contribute to the differences between samples.

The following example illustrates 16 components extracted using sparse PCA from the Olivetti faces dataset. It can be seen how the regularization term induces many zeros. Furthermore, the natural structure of the data causes the non-zero coefficients to be vertically adjacent. The model does not enforce this mathematically: each component is a vector \(h \in \mathbf{R}^{4096}\), and there is no notion of vertical adjacency except during the human-friendly visualization as 64x64 pixel images. The fact that the components shown below appear local is the effect of the inherent structure of the data, which makes such local patterns minimize reconstruction error. There exist sparsity-inducing norms that take into account adjacency and different kinds of structure; see [Jen09] for a review of such methods. For more details on how to use Sparse PCA, see the Examples section, below.

Note that there are many different formulations for the Sparse PCA problem. The one implemented here is based on [Mrl09] . The optimization problem solved is a PCA problem (dictionary learning) with an \(\ell_1\) penalty on the components:

\(||.||_{\text{Fro}}\) stands for the Frobenius norm and \(||.||_{1,1}\) stands for the entry-wise matrix norm which is the sum of the absolute values of all the entries in the matrix. The sparsity-inducing \(||.||_{1,1}\) matrix norm also prevents learning components from noise when few training samples are available. The degree of penalization (and thus sparsity) can be adjusted through the hyperparameter alpha. Small values lead to a gently regularized factorization, while larger values shrink many coefficients to zero.

While in the spirit of an online algorithm, the class MiniBatchSparsePCA does not implement partial_fit because the algorithm is online along the features direction, not the samples direction.

Faces dataset decompositions

“Online Dictionary Learning for Sparse Coding” J. Mairal, F. Bach, J. Ponce, G. Sapiro, 2009

“Structured Sparse Principal Component Analysis” R. Jenatton, G. Obozinski, F. Bach, 2009

KernelPCA is an extension of PCA which achieves non-linear dimensionality reduction through the use of kernels (see Pairwise metrics, Affinities and Kernels) [Scholkopf1997]. It has many applications including denoising, compression and structured prediction (kernel dependency estimation). KernelPCA supports both transform and inverse_transform.

KernelPCA.inverse_transform relies on a kernel ridge to learn the function mapping samples from the PCA basis into the original feature space [Bakir2003]. Thus, the reconstruction obtained with KernelPCA.inverse_transform is an approximation. See the example linked below for more details.

Image denoising using kernel PCA

Schölkopf, Bernhard, Alexander Smola, and Klaus-Robert Müller. “Kernel principal component analysis.” International conference on artificial neural networks. Springer, Berlin, Heidelberg, 1997.

Bakır, Gökhan H., Jason Weston, and Bernhard Schölkopf. “Learning to find pre-images.” Advances in neural information processing systems 16 (2003): 449-456.

While in PCA the number of components is bounded by the number of features, in KernelPCA the number of components is bounded by the number of samples. Many real-world datasets have large number of samples! In these cases finding all the components with a full kPCA is a waste of computation time, as data is mostly described by the first few components (e.g. n_components<=100). In other words, the centered Gram matrix that is eigendecomposed in the Kernel PCA fitting process has an effective rank that is much smaller than its size. This is a situation where approximate eigensolvers can provide speedup with very low precision loss.

The optional parameter eigen_solver='randomized' can be used to significantly reduce the computation time when the number of requested n_components is small compared with the number of samples. It relies on randomized decomposition methods to find an approximate solution in a shorter time.

The time complexity of the randomized KernelPCA is \(O(n_{\mathrm{samples}}^2 \cdot n_{\mathrm{components}})\) instead of \(O(n_{\mathrm{samples}}^3)\) for the exact method implemented with eigen_solver='dense'.

The memory footprint of randomized KernelPCA is also proportional to \(2 \cdot n_{\mathrm{samples}} \cdot n_{\mathrm{components}}\) instead of \(n_{\mathrm{samples}}^2\) for the exact method.

Note: this technique is the same as in PCA using randomized SVD.

In addition to the above two solvers, eigen_solver='arpack' can be used as an alternate way to get an approximate decomposition. In practice, this method only provides reasonable execution times when the number of components to find is extremely small. It is enabled by default when the desired number of components is less than 10 (strict) and the number of samples is more than 200 (strict). See KernelPCA for details.

dense solver: scipy.linalg.eigh documentation

Algorithm 4.3 in “Finding structure with randomness: Stochastic algorithms for constructing approximate matrix decompositions” Halko, et al. (2009)

“An implementation of a randomized algorithm for principal component analysis” A. Szlam et al. (2014)

arpack solver: scipy.sparse.linalg.eigsh documentation R. B. Lehoucq, D. C. Sorensen, and C. Yang, (1998)

TruncatedSVD implements a variant of singular value decomposition (SVD) that only computes the \(k\) largest singular values, where \(k\) is a user-specified parameter.

TruncatedSVD is very similar to PCA, but differs in that the matrix \(X\) does not need to be centered. When the columnwise (per-feature) means of \(X\) are subtracted from the feature values, truncated SVD on the resulting matrix is equivalent to PCA.

When truncated SVD is applied to term-document matrices (as returned by CountVectorizer or TfidfVectorizer), this transformation is known as latent semantic analysis (LSA), because it transforms such matrices to a “semantic” space of low dimensionality. In particular, LSA is known to combat the effects of synonymy and polysemy (both of which roughly mean there are multiple meanings per word), which cause term-document matrices to be overly sparse and exhibit poor similarity under measures such as cosine similarity.

LSA is also known as latent semantic indexing, LSI, though strictly that refers to its use in persistent indexes for information retrieval purposes.

Mathematically, truncated SVD applied to training samples \(X\) produces a low-rank approximation \(X\):

After this operation, \(U_k \Sigma_k\) is the transformed training set with \(k\) features (called n_components in the API).

To also transform a test set \(X\), we multiply it with \(V_k\):

Most treatments of LSA in the natural language processing (NLP) and information retrieval (IR) literature swap the axes of the matrix \(X\) so that it has shape (n_features, n_samples). We present LSA in a different way that matches the scikit-learn API better, but the singular values found are the same.

While the TruncatedSVD transformer works with any feature matrix, using it on tf-idf matrices is recommended over raw frequency counts in an LSA/document processing setting. In particular, sublinear scaling and inverse document frequency should be turned on (sublinear_tf=True, use_idf=True) to bring the feature values closer to a Gaussian distribution, compensating for LSA’s erroneous assumptions about textual data.

Clustering text documents using k-means

Christopher D. Manning, Prabhakar Raghavan and Hinrich Schütze (2008), Introduction to Information Retrieval, Cambridge University Press, chapter 18: Matrix decompositions & latent semantic indexing

The SparseCoder object is an estimator that can be used to transform signals into sparse linear combination of atoms from a fixed, precomputed dictionary such as a discrete wavelet basis. This object therefore does not implement a fit method. The transformation amounts to a sparse coding problem: finding a representation of the data as a linear combination of as few dictionary atoms as possible. All variations of dictionary learning implement the following transform methods, controllable via the transform_method initialization parameter:

Orthogonal matching pursuit (Orthogonal Matching Pursuit (OMP))

Least-angle regression (Least Angle Regression)

Lasso computed by least-angle regression

Lasso using coordinate descent (Lasso)

Thresholding is very fast but it does not yield accurate reconstructions. They have been shown useful in literature for classification tasks. For image reconstruction tasks, orthogonal matching pursuit yields the most accurate, unbiased reconstruction.

The dictionary learning objects offer, via the split_code parameter, the possibility to separate the positive and negative values in the results of sparse coding. This is useful when dictionary learning is used for extracting features that will be used for supervised learning, because it allows the learning algorithm to assign different weights to negative loadings of a particular atom, from to the corresponding positive loading.

The split code for a single sample has length 2 * n_components and is constructed using the following rule: First, the regular code of length n_components is computed. Then, the first n_components entries of the split_code are filled with the positive part of the regular code vector. The second half of the split code is filled with the negative part of the code vector, only with a positive sign. Therefore, the split_code is non-negative.

Sparse coding with a precomputed dictionary

Dictionary learning (DictionaryLearning) is a matrix factorization problem that amounts to finding a (usually overcomplete) dictionary that will perform well at sparsely encoding the fitted data.

Representing data as sparse combinations of atoms from an overcomplete dictionary is suggested to be the way the mammalian primary visual cortex works. Consequently, dictionary learning applied on image patches has been shown to give good results in image processing tasks such as image completion, inpainting and denoising, as well as for supervised recognition tasks.

Dictionary learning is an optimization problem solved by alternatively updating the sparse code, as a solution to multiple Lasso problems, considering the dictionary fixed, and then updating the dictionary to best fit the sparse code.

\(||.||_{\text{Fro}}\) stands for the Frobenius norm and \(||.||_{1,1}\) stands for the entry-wise matrix norm which is the sum of the absolute values of all the entries in the matrix. After using such a procedure to fit the dictionary, the transform is simply a sparse coding step that shares the same implementation with all dictionary learning objects (see Sparse coding with a precomputed dictionary).

It is also possible to constrain the dictionary and/or code to be positive to match constraints that may be present in the data. Below are the faces with different positivity constraints applied. Red indicates negative values, blue indicates positive values, and white represents zeros.

“Online dictionary learning for sparse coding” J. Mairal, F. Bach, J. Ponce, G. Sapiro, 2009

MiniBatchDictionaryLearning implements a faster, but less accurate version of the dictionary learning algorithm that is better suited for large datasets.

By default, MiniBatchDictionaryLearning divides the data into mini-batches and optimizes in an online manner by cycling over the mini-batches for the specified number of iterations. However, at the moment it does not implement a stopping condition.

The estimator also implements partial_fit, which updates the dictionary by iterating only once over a mini-batch. This can be used for online learning when the data is not readily available from the start, or for when the data does not fit into memory.

Clustering for dictionary learning

Note that when using dictionary learning to extract a representation (e.g. for sparse coding) clustering can be a good proxy to learn the dictionary. For instance the MiniBatchKMeans estimator is computationally efficient and implements on-line learning with a partial_fit method.

Example: Online learning of a dictionary of parts of faces

The following image shows how a dictionary, learned from 4x4 pixel image patches extracted from part of the image of a raccoon face, looks like.

Image denoising using dictionary learning

In unsupervised learning we only have a dataset \(X = \{x_1, x_2, \dots, x_n \}\). How can this dataset be described mathematically? A very simple continuous latent variable model for \(X\) is

The vector \(h_i\) is called “latent” because it is unobserved. \(\epsilon\) is considered a noise term distributed according to a Gaussian with mean 0 and covariance \(\Psi\) (i.e. \(\epsilon \sim \mathcal{N}(0, \Psi)\)), \(\mu\) is some arbitrary offset vector. Such a model is called “generative” as it describes how \(x_i\) is generated from \(h_i\). If we use all the \(x_i\)’s as columns to form a matrix \(\mathbf{X}\) and all the \(h_i\)’s as columns of a matrix \(\mathbf{H}\) then we can write (with suitably defined \(\mathbf{M}\) and \(\mathbf{E}\)):

In other words, we decomposed matrix \(\mathbf{X}\).

If \(h_i\) is given, the above equation automatically implies the following probabilistic interpretation:

For a complete probabilistic model we also need a prior distribution for the latent variable \(h\). The most straightforward assumption (based on the nice properties of the Gaussian distribution) is \(h \sim \mathcal{N}(0, \mathbf{I})\). This yields a Gaussian as the marginal distribution of \(x\):

Now, without any further assumptions the idea of having a latent variable \(h\) would be superfluous – \(x\) can be completely modelled with a mean and a covariance. We need to impose some more specific structure on one of these two parameters. A simple additional assumption regards the structure of the error covariance \(\Psi\):

\(\Psi = \sigma^2 \mathbf{I}\): This assumption leads to the probabilistic model of PCA.

\(\Psi = \mathrm{diag}(\psi_1, \psi_2, \dots, \psi_n)\): This model is called FactorAnalysis, a classical statistical model. The matrix W is sometimes called the “factor loading matrix”.

Both models essentially estimate a Gaussian with a low-rank covariance matrix. Because both models are probabilistic they can be integrated in more complex models, e.g. Mixture of Factor Analysers. One gets very different models (e.g. FastICA) if non-Gaussian priors on the latent variables are assumed.

Factor analysis can produce similar components (the columns of its loading matrix) to PCA. However, one can not make any general statements about these components (e.g. whether they are orthogonal):

The main advantage for Factor Analysis over PCA is that it can model the variance in every direction of the input space independently (heteroscedastic noise):

This allows better model selection than probabilistic PCA in the presence of heteroscedastic noise:

Factor Analysis is often followed by a rotation of the factors (with the parameter rotation), usually to improve interpretability. For example, Varimax rotation maximizes the sum of the variances of the squared loadings, i.e., it tends to produce sparser factors, which are influenced by only a few features each (the “simple structure”). See e.g., the first example below.

Factor Analysis (with rotation) to visualize patterns

Model selection with Probabilistic PCA and Factor Analysis (FA)

Independent component analysis separates a multivariate signal into additive subcomponents that are maximally independent. It is implemented in scikit-learn using the Fast ICA algorithm. Typically, ICA is not used for reducing dimensionality but for separating superimposed signals. Since the ICA model does not include a noise term, for the model to be correct, whitening must be applied. This can be done internally using the whiten argument or manually using one of the PCA variants.

It is classically used to separate mixed signals (a problem known as blind source separation), as in the example below:

ICA can also be used as yet another non linear decomposition that finds components with some sparsity:

Blind source separation using FastICA

FastICA on 2D point clouds

Faces dataset decompositions

NMF [1] is an alternative approach to decomposition that assumes that the data and the components are non-negative. NMF can be plugged in instead of PCA or its variants, in the cases where the data matrix does not contain negative values. It finds a decomposition of samples \(X\) into two matrices \(W\) and \(H\) of non-negative elements, by optimizing the distance \(d\) between \(X\) and the matrix product \(WH\). The most widely used distance function is the squared Frobenius norm, which is an obvious extension of the Euclidean norm to matrices:

Unlike PCA, the representation of a vector is obtained in an additive fashion, by superimposing the components, without subtracting. Such additive models are efficient for representing images and text.

It has been observed in [Hoyer, 2004] [2] that, when carefully constrained, NMF can produce a parts-based representation of the dataset, resulting in interpretable models. The following example displays 16 sparse components found by NMF from the images in the Olivetti faces dataset, in comparison with the PCA eigenfaces.

The init attribute determines the initialization method applied, which has a great impact on the performance of the method. NMF implements the method Nonnegative Double Singular Value Decomposition. NNDSVD [4] is based on two SVD processes, one approximating the data matrix, the other approximating positive sections of the resulting partial SVD factors utilizing an algebraic property of unit rank matrices. The basic NNDSVD algorithm is better fit for sparse factorization. Its variants NNDSVDa (in which all zeros are set equal to the mean of all elements of the data), and NNDSVDar (in which the zeros are set to random perturbations less than the mean of the data divided by 100) are recommended in the dense case.

Note that the Multiplicative Update (‘mu’) solver cannot update zeros present in the initialization, so it leads to poorer results when used jointly with the basic NNDSVD algorithm which introduces a lot of zeros; in this case, NNDSVDa or NNDSVDar should be preferred.

NMF can also be initialized with correctly scaled random non-negative matrices by setting init="random". An integer seed or a RandomState can also be passed to random_state to control reproducibility.

In NMF, L1 and L2 priors can be added to the loss function in order to regularize the model. The L2 prior uses the Frobenius norm, while the L1 prior uses an elementwise L1 norm. As in ElasticNet, we control the combination of L1 and L2 with the l1_ratio (\(\rho\)) parameter, and the intensity of the regularization with the alpha_W and alpha_H (\(\alpha_W\) and \(\alpha_H\)) parameters. The priors are scaled by the number of samples (\(n\_samples\)) for H and the number of features (\(n\_features\)) for W to keep their impact balanced with respect to one another and to the data fit term as independent as possible of the size of the training set. Then the priors terms are:

and the regularized objective function is:

As described previously, the most widely used distance function is the squared Frobenius norm, which is an obvious extension of the Euclidean norm to matrices:

Other distance functions can be used in NMF as, for example, the (generalized) Kullback-Leibler (KL) divergence, also referred as I-divergence:

Or, the Itakura-Saito (IS) divergence:

These three distances are special cases of the beta-divergence family, with \(\beta = 2, 1, 0\) respectively [6]. The beta-divergence is defined by :

Note that this definition is not valid if \(\beta \in (0; 1)\), yet it can be continuously extended to the definitions of \(d_{KL}\) and \(d_{IS}\) respectively.

NMF implements two solvers, using Coordinate Descent (‘cd’) [5], and Multiplicative Update (‘mu’) [6]. The ‘mu’ solver can optimize every beta-divergence, including of course the Frobenius norm (\(\beta=2\)), the (generalized) Kullback-Leibler divergence (\(\beta=1\)) and the Itakura-Saito divergence (\(\beta=0\)). Note that for \(\beta \in (1; 2)\), the ‘mu’ solver is significantly faster than for other values of \(\beta\). Note also that with a negative (or 0, i.e. ‘itakura-saito’) \(\beta\), the input matrix cannot contain zero values.

The ‘cd’ solver can only optimize the Frobenius norm. Due to the underlying non-convexity of NMF, the different solvers may converge to different minima, even when optimizing the same distance function.

NMF is best used with the fit_transform method, which returns the matrix W. The matrix H is stored into the fitted model in the components_ attribute; the method transform will decompose a new matrix X_new based on these stored components:

Faces dataset decompositions

Topic extraction with Non-negative Matrix Factorization and Latent Dirichlet Allocation

MiniBatchNMF [7] implements a faster, but less accurate version of the non negative matrix factorization (i.e. NMF), better suited for large datasets.

By default, MiniBatchNMF divides the data into mini-batches and optimizes the NMF model in an online manner by cycling over the mini-batches for the specified number of iterations. The batch_size parameter controls the size of the batches.

In order to speed up the mini-batch algorithm it is also possible to scale past batches, giving them less importance than newer batches. This is done by introducing a so-called forgetting factor controlled by the forget_factor parameter.

The estimator also implements partial_fit, which updates H by iterating only once over a mini-batch. This can be used for online learning when the data is not readily available from the start, or when the data does not fit into memory.

“Learning the parts of objects by non-negative matrix factorization” D. Lee, S. Seung, 1999

“Non-negative Matrix Factorization with Sparseness Constraints” P. Hoyer, 2004

“SVD based initialization: A head start for nonnegative matrix factorization” C. Boutsidis, E. Gallopoulos, 2008

“Fast local algorithms for large scale nonnegative matrix and tensor factorizations.” A. Cichocki, A. Phan, 2009

“Algorithms for nonnegative matrix factorization with the beta-divergence” C. Fevotte, J. Idier, 2011

“Online algorithms for nonnegative matrix factorization with the Itakura-Saito divergence” A. Lefevre, F. Bach, C. Fevotte, 2011

Latent Dirichlet Allocation is a generative probabilistic model for collections of discrete datasets such as text corpora. It is also a topic model that is used for discovering abstract topics from a collection of documents.

The graphical model of LDA is a three-level generative model:

Note on notations presented in the graphical model above, which can be found in Hoffman et al. (2013):

The corpus is a collection of \(D\) documents.

A document \(d \in D\) is a sequence of \(N_d\) words.

There are \(K\) topics in the corpus.

The boxes represent repeated sampling.

In the graphical model, each node is a random variable and has a role in the generative process. A shaded node indicates an observed variable and an unshaded node indicates a hidden (latent) variable. In this case, words in the corpus are the only data that we observe. The latent variables determine the random mixture of topics in the corpus and the distribution of words in the documents. The goal of LDA is to use the observed words to infer the hidden topic structure.

When modeling text corpora, the model assumes the following generative process for a corpus with \(D\) documents and \(K\) topics, with \(K\) corresponding to n_components in the API:

For each topic \(k \in K\), draw \(\beta_k \sim \mathrm{Dirichlet}(\eta)\). This provides a distribution over the words, i.e. the probability of a word appearing in topic \(k\). \(\eta\) corresponds to topic_word_prior.

For each document \(d \in D\), draw the topic proportions \(\theta_d \sim \mathrm{Dirichlet}(\alpha)\). \(\alpha\) corresponds to doc_topic_prior.

For each word \(n=1,\cdots,N_d\) in document \(d\):

Draw the topic assignment \(z_{dn} \sim \mathrm{Multinomial} (\theta_d)\)

Draw the observed word \(w_{dn} \sim \mathrm{Multinomial} (\beta_{z_{dn}})\)

For parameter estimation, the posterior distribution is:

Since the posterior is intractable, variational Bayesian method uses a simpler distribution \(q(z,\theta,\beta | \lambda, \phi, \gamma)\) to approximate it, and those variational parameters \(\lambda\), \(\phi\), \(\gamma\) are optimized to maximize the Evidence Lower Bound (ELBO):

Maximizing ELBO is equivalent to minimizing the Kullback-Leibler(KL) divergence between \(q(z,\theta,\beta)\) and the true posterior \(p(z, \theta, \beta |w, \alpha, \eta)\).

LatentDirichletAllocation implements the online variational Bayes algorithm and supports both online and batch update methods. While the batch method updates variational variables after each full pass through the data, the online method updates variational variables from mini-batch data points.

Although the online method is guaranteed to converge to a local optimum point, the quality of the optimum point and the speed of convergence may depend on mini-batch size and attributes related to learning rate setting.

When LatentDirichletAllocation is applied on a “document-term” matrix, the matrix will be decomposed into a “topic-term” matrix and a “document-topic” matrix. While “topic-term” matrix is stored as components_ in the model, “document-topic” matrix can be calculated from transform method.

LatentDirichletAllocation also implements partial_fit method. This is used when data can be fetched sequentially.

Topic extraction with Non-negative Matrix Factorization and Latent Dirichlet Allocation

“Latent Dirichlet Allocation” D. Blei, A. Ng, M. Jordan, 2003

“Online Learning for Latent Dirichlet Allocation” M. Hoffman, D. Blei, F. Bach, 2010

“Stochastic Variational Inference” M. Hoffman, D. Blei, C. Wang, J. Paisley, 2013

“The varimax criterion for analytic rotation in factor analysis” H. F. Kaiser, 1958

See also Dimensionality reduction for dimensionality reduction with Neighborhood Components Analysis.

**Examples:**

Example 1 (csharp):
```csharp
>>> import numpy as np
>>> X = np.array([[1, 1], [2, 1], [3, 1.2], [4, 1], [5, 0.8], [6, 1]])
>>> from sklearn.decomposition import NMF
>>> model = NMF(n_components=2, init='random', random_state=0)
>>> W = model.fit_transform(X)
>>> H = model.components_
>>> X_new = np.array([[1, 0], [1, 6.1], [1, 0], [1, 4], [3.2, 1], [0, 4]])
>>> W_new = model.transform(X_new)
```

---

## 7.6. Random Projection#

**URL:** https://scikit-learn.org/stable/modules/random_projection.html

**Contents:**
- 7.6. Random Projection#
- 7.6.1. The Johnson-Lindenstrauss lemma#
- 7.6.2. Gaussian random projection#
- 7.6.3. Sparse random projection#
- 7.6.4. Inverse Transform#

The sklearn.random_projection module implements a simple and computationally efficient way to reduce the dimensionality of the data by trading a controlled amount of accuracy (as additional variance) for faster processing times and smaller model sizes. This module implements two types of unstructured random matrix: Gaussian random matrix and sparse random matrix.

The dimensions and distribution of random projections matrices are controlled so as to preserve the pairwise distances between any two samples of the dataset. Thus random projection is a suitable approximation technique for distance based method.

Sanjoy Dasgupta. 2000. Experiments with random projection. In Proceedings of the Sixteenth conference on Uncertainty in artificial intelligence (UAI’00), Craig Boutilier and Moisés Goldszmidt (Eds.). Morgan Kaufmann Publishers Inc., San Francisco, CA, USA, 143-151.

Ella Bingham and Heikki Mannila. 2001. Random projection in dimensionality reduction: applications to image and text data. In Proceedings of the seventh ACM SIGKDD international conference on Knowledge discovery and data mining (KDD ‘01). ACM, New York, NY, USA, 245-250.

The main theoretical result behind the efficiency of random projection is the Johnson-Lindenstrauss lemma (quoting Wikipedia):

In mathematics, the Johnson-Lindenstrauss lemma is a result concerning low-distortion embeddings of points from high-dimensional into low-dimensional Euclidean space. The lemma states that a small set of points in a high-dimensional space can be embedded into a space of much lower dimension in such a way that distances between the points are nearly preserved. The map used for the embedding is at least Lipschitz, and can even be taken to be an orthogonal projection.

Knowing only the number of samples, the johnson_lindenstrauss_min_dim estimates conservatively the minimal size of the random subspace to guarantee a bounded distortion introduced by the random projection:

See The Johnson-Lindenstrauss bound for embedding with random projections for a theoretical explication on the Johnson-Lindenstrauss lemma and an empirical validation using sparse random matrices.

Sanjoy Dasgupta and Anupam Gupta, 1999. An elementary proof of the Johnson-Lindenstrauss Lemma.

The GaussianRandomProjection reduces the dimensionality by projecting the original input space on a randomly generated matrix where components are drawn from the following distribution \(N(0, \frac{1}{n_{components}})\).

Here is a small excerpt which illustrates how to use the Gaussian random projection transformer:

The SparseRandomProjection reduces the dimensionality by projecting the original input space using a sparse random matrix.

Sparse random matrices are an alternative to dense Gaussian random projection matrix that guarantees similar embedding quality while being much more memory efficient and allowing faster computation of the projected data.

If we define s = 1 / density, the elements of the random matrix are drawn from

where \(n_{\text{components}}\) is the size of the projected subspace. By default the density of non zero elements is set to the minimum density as recommended by Ping Li et al.: \(1 / \sqrt{n_{\text{features}}}\).

Here is a small excerpt which illustrates how to use the sparse random projection transformer:

D. Achlioptas. 2003. Database-friendly random projections: Johnson-Lindenstrauss with binary coins. Journal of Computer and System Sciences 66 (2003) 671-687.

Ping Li, Trevor J. Hastie, and Kenneth W. Church. 2006. Very sparse random projections. In Proceedings of the 12th ACM SIGKDD international conference on Knowledge discovery and data mining (KDD ‘06). ACM, New York, NY, USA, 287-296.

The random projection transformers have compute_inverse_components parameter. When set to True, after creating the random components_ matrix during fitting, the transformer computes the pseudo-inverse of this matrix and stores it as inverse_components_. The inverse_components_ matrix has shape \(n_{features} \times n_{components}\), and it is always a dense matrix, regardless of whether the components matrix is sparse or dense. So depending on the number of features and components, it may use a lot of memory.

When the inverse_transform method is called, it computes the product of the input X and the transpose of the inverse components. If the inverse components have been computed during fit, they are reused at each call to inverse_transform. Otherwise they are recomputed each time, which can be costly. The result is always dense, even if X is sparse.

Here is a small code example which illustrates how to use the inverse transform feature:

**Examples:**

Example 1 (sql):
```sql
>>> from sklearn.random_projection import johnson_lindenstrauss_min_dim
>>> johnson_lindenstrauss_min_dim(n_samples=1e6, eps=0.5)
np.int64(663)
>>> johnson_lindenstrauss_min_dim(n_samples=1e6, eps=[0.5, 0.1, 0.01])
array([    663,   11841, 1112658])
>>> johnson_lindenstrauss_min_dim(n_samples=[1e4, 1e5, 1e6], eps=0.1)
array([ 7894,  9868, 11841])
```

Example 2 (python):
```python
>>> import numpy as np
>>> from sklearn import random_projection
>>> X = np.random.rand(100, 10000)
>>> transformer = random_projection.GaussianRandomProjection()
>>> X_new = transformer.fit_transform(X)
>>> X_new.shape
(100, 3947)
```

Example 3 (python):
```python
>>> import numpy as np
>>> from sklearn import random_projection
>>> X = np.random.rand(100, 10000)
>>> transformer = random_projection.SparseRandomProjection()
>>> X_new = transformer.fit_transform(X)
>>> X_new.shape
(100, 3947)
```

Example 4 (csharp):
```csharp
>>> import numpy as np
>>> from sklearn.random_projection import SparseRandomProjection
>>> X = np.random.rand(100, 10000)
>>> transformer = SparseRandomProjection(
...   compute_inverse_components=True
... )
...
>>> X_new = transformer.fit_transform(X)
>>> X_new.shape
(100, 3947)
>>> X_new_inversed = transformer.inverse_transform(X_new)
>>> X_new_inversed.shape
(100, 10000)
>>> X_new_again = transformer.transform(X_new_inversed)
>>> np.allclose(X_new, X_new_again)
True
```

---

## adjusted_rand_score#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.metrics.adjusted_rand_score.html

**Contents:**
- adjusted_rand_score#
- Gallery examples#

Rand index adjusted for chance.

The Rand Index computes a similarity measure between two clusterings by considering all pairs of samples and counting pairs that are assigned in the same or different clusters in the predicted and true clusterings.

The raw RI score is then “adjusted for chance” into the ARI score using the following scheme:

The adjusted Rand index is thus ensured to have a value close to 0.0 for random labeling independently of the number of clusters and samples and exactly 1.0 when the clusterings are identical (up to a permutation). The adjusted Rand index is bounded below by -0.5 for especially discordant clusterings.

ARI is a symmetric measure:

Read more in the User Guide.

Ground truth class labels to be used as a reference.

Cluster labels to evaluate.

Similarity score between -0.5 and 1.0. Random labelings have an ARI close to 0.0. 1.0 stands for perfect match.

Adjusted Mutual Information.

L. Hubert and P. Arabie, Comparing Partitions, Journal of Classification 1985 https://link.springer.com/article/10.1007%2FBF01908075

D. Steinley, Properties of the Hubert-Arabie adjusted Rand index, Psychological Methods 2004

https://en.wikipedia.org/wiki/Rand_index#Adjusted_Rand_index

Minimum adjusted Rand index for two clusterings of a given size, 2022, J. E. Chacón and A. I. Rastrojo

Perfectly matching labelings have a score of 1 even

Labelings that assign all classes members to the same clusters are complete but may not always be pure, hence penalized:

ARI is symmetric, so labelings that have pure clusters with members coming from the same classes but unnecessary splits are penalized:

If classes members are completely split across different clusters, the assignment is totally incomplete, hence the ARI is very low:

ARI may take a negative value for especially discordant labelings that are a worse choice than the expected value of random labels:

See Adjustment for chance in clustering performance evaluation for a more detailed example.

Adjustment for chance in clustering performance evaluation

Demo of affinity propagation clustering algorithm

Demo of DBSCAN clustering algorithm

A demo of K-Means clustering on the handwritten digits data

Clustering text documents using k-means

**Examples:**

Example 1 (unknown):
```unknown
ARI = (RI - Expected_RI) / (max(RI) - Expected_RI)
```

Example 2 (unknown):
```unknown
adjusted_rand_score(a, b) == adjusted_rand_score(b, a)
```

Example 3 (sql):
```sql
>>> from sklearn.metrics.cluster import adjusted_rand_score
>>> adjusted_rand_score([0, 0, 1, 1], [0, 0, 1, 1])
1.0
>>> adjusted_rand_score([0, 0, 1, 1], [1, 1, 0, 0])
1.0
```

Example 4 (unknown):
```unknown
>>> adjusted_rand_score([0, 0, 1, 2], [0, 0, 1, 1])
0.57
```

---

## ComplementNB#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.ComplementNB.html

**Contents:**
- ComplementNB#
- Gallery examples#

The Complement Naive Bayes classifier described in Rennie et al. (2003).

The Complement Naive Bayes classifier was designed to correct the “severe assumptions” made by the standard Multinomial Naive Bayes classifier. It is particularly suited for imbalanced data sets.

Read more in the User Guide.

Added in version 0.20.

Additive (Laplace/Lidstone) smoothing parameter (set alpha=0 and force_alpha=True, for no smoothing).

If False and alpha is less than 1e-10, it will set alpha to 1e-10. If True, alpha will remain unchanged. This may cause numerical errors if alpha is too close to 0.

Added in version 1.2.

Changed in version 1.4: The default value of force_alpha changed to True.

Only used in edge case with a single class in the training set.

Prior probabilities of the classes. Not used.

Whether or not a second normalization of the weights is performed. The default behavior mirrors the implementations found in Mahout and Weka, which do not follow the full algorithm described in Table 9 of the paper.

Number of samples encountered for each class during fitting. This value is weighted by the sample weight when provided.

Smoothed empirical log probability for each class. Only used in edge case with a single class in the training set.

Class labels known to the classifier

Number of samples encountered for each feature during fitting. This value is weighted by the sample weight when provided.

Number of samples encountered for each (class, feature) during fitting. This value is weighted by the sample weight when provided.

Empirical weights for class complements.

Number of features seen during fit.

Added in version 0.24.

Names of features seen during fit. Defined only when X has feature names that are all strings.

Added in version 1.0.

Naive Bayes classifier for multivariate Bernoulli models.

Naive Bayes classifier for categorical features.

Gaussian Naive Bayes.

Naive Bayes classifier for multinomial models.

Rennie, J. D., Shih, L., Teevan, J., & Karger, D. R. (2003). Tackling the poor assumptions of naive bayes text classifiers. In ICML (Vol. 3, pp. 616-623). https://people.csail.mit.edu/jrennie/papers/icml03-nb.pdf

Fit Naive Bayes classifier according to X, y.

Training vectors, where n_samples is the number of samples and n_features is the number of features.

Weights applied to individual samples (1. for unweighted).

Returns the instance itself.

Get metadata routing of this object.

Please check User Guide on how the routing mechanism works.

A MetadataRequest encapsulating routing information.

Get parameters for this estimator.

If True, will return the parameters for this estimator and contained subobjects that are estimators.

Parameter names mapped to their values.

Incremental fit on a batch of samples.

This method is expected to be called several times consecutively on different chunks of a dataset so as to implement out-of-core or online learning.

This is especially useful when the whole dataset is too big to fit in memory at once.

This method has some performance overhead hence it is better to call partial_fit on chunks of data that are as large as possible (as long as fitting in the memory budget) to hide the overhead.

Training vectors, where n_samples is the number of samples and n_features is the number of features.

List of all the classes that can possibly appear in the y vector.

Must be provided at the first call to partial_fit, can be omitted in subsequent calls.

Weights applied to individual samples (1. for unweighted).

Returns the instance itself.

Perform classification on an array of test vectors X.

Predicted target values for X.

Return joint log probability estimates for the test vector X.

For each row x of X and class y, the joint log probability is given by log P(x, y) = log P(y) + log P(x|y), where log P(y) is the class prior probability and log P(x|y) is the class-conditional probability.

Returns the joint log-probability of the samples for each class in the model. The columns correspond to the classes in sorted order, as they appear in the attribute classes_.

Return log-probability estimates for the test vector X.

Returns the log-probability of the samples for each class in the model. The columns correspond to the classes in sorted order, as they appear in the attribute classes_.

Return probability estimates for the test vector X.

Returns the probability of the samples for each class in the model. The columns correspond to the classes in sorted order, as they appear in the attribute classes_.

Return accuracy on provided data and labels.

In multi-label classification, this is the subset accuracy which is a harsh metric since you require for each sample that each label set be correctly predicted.

Mean accuracy of self.predict(X) w.r.t. y.

Configure whether metadata should be requested to be passed to the fit method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to fit if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to fit.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Added in version 1.3.

Metadata routing for sample_weight parameter in fit.

Set the parameters of this estimator.

The method works on simple estimators as well as on nested objects (such as Pipeline). The latter have parameters of the form <component>__<parameter> so that it’s possible to update each component of a nested object.

Estimator parameters.

Configure whether metadata should be requested to be passed to the partial_fit method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to partial_fit if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to partial_fit.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Added in version 1.3.

Metadata routing for classes parameter in partial_fit.

Metadata routing for sample_weight parameter in partial_fit.

Configure whether metadata should be requested to be passed to the score method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to score if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to score.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Added in version 1.3.

Metadata routing for sample_weight parameter in score.

Sample pipeline for text feature extraction and evaluation

Classification of text documents using sparse features

**Examples:**

Example 1 (json):
```json
>>> import numpy as np
>>> rng = np.random.RandomState(1)
>>> X = rng.randint(5, size=(6, 100))
>>> y = np.array([1, 2, 3, 4, 5, 6])
>>> from sklearn.naive_bayes import ComplementNB
>>> clf = ComplementNB()
>>> clf.fit(X, y)
ComplementNB()
>>> print(clf.predict(X[2:3]))
[3]
```

---

## 2.4. Biclustering#

**URL:** https://scikit-learn.org/stable/modules/biclustering.html

**Contents:**
- 2.4. Biclustering#
- 2.4.1. Spectral Co-Clustering#
  - 2.4.1.1. Mathematical formulation#
- 2.4.2. Spectral Biclustering#
  - 2.4.2.1. Mathematical formulation#
- 2.4.3. Biclustering evaluation#

Biclustering algorithms simultaneously cluster rows and columns of a data matrix. These clusters of rows and columns are known as biclusters. Each determines a submatrix of the original data matrix with some desired properties.

For instance, given a matrix of shape (10, 10), one possible bicluster with three rows and two columns induces a submatrix of shape (3, 2):

For visualization purposes, given a bicluster, the rows and columns of the data matrix may be rearranged to make the bicluster contiguous.

Algorithms differ in how they define biclusters. Some of the common types include:

constant values, constant rows, or constant columns

unusually high or low values

submatrices with low variance

correlated rows or columns

Algorithms also differ in how rows and columns may be assigned to biclusters, which leads to different bicluster structures. Block diagonal or checkerboard structures occur when rows and columns are divided into partitions.

If each row and each column belongs to exactly one bicluster, then rearranging the rows and columns of the data matrix reveals the biclusters on the diagonal. Here is an example of this structure where biclusters have higher average values than the other rows and columns:

An example of biclusters formed by partitioning rows and columns.#

In the checkerboard case, each row belongs to all column clusters, and each column belongs to all row clusters. Here is an example of this structure where the variance of the values within each bicluster is small:

An example of checkerboard biclusters.#

After fitting a model, row and column cluster membership can be found in the rows_ and columns_ attributes. rows_[i] is a binary vector with nonzero entries corresponding to rows that belong to bicluster i. Similarly, columns_[i] indicates which columns belong to bicluster i.

Some models also have row_labels_ and column_labels_ attributes. These models partition the rows and columns, such as in the block diagonal and checkerboard bicluster structures.

Biclustering has many other names in different fields including co-clustering, two-mode clustering, two-way clustering, block clustering, coupled two-way clustering, etc. The names of some algorithms, such as the Spectral Co-Clustering algorithm, reflect these alternate names.

The SpectralCoclustering algorithm finds biclusters with values higher than those in the corresponding other rows and columns. Each row and each column belongs to exactly one bicluster, so rearranging the rows and columns to make partitions contiguous reveals these high values along the diagonal:

The algorithm treats the input data matrix as a bipartite graph: the rows and columns of the matrix correspond to the two sets of vertices, and each entry corresponds to an edge between a row and a column. The algorithm approximates the normalized cut of this graph to find heavy subgraphs.

An approximate solution to the optimal normalized cut may be found via the generalized eigenvalue decomposition of the Laplacian of the graph. Usually this would mean working directly with the Laplacian matrix. If the original data matrix \(A\) has shape \(m \times n\), the Laplacian matrix for the corresponding bipartite graph has shape \((m + n) \times (m + n)\). However, in this case it is possible to work directly with \(A\), which is smaller and more efficient.

The input matrix \(A\) is preprocessed as follows:

Where \(R\) is the diagonal matrix with entry \(i\) equal to \(\sum_{j} A_{ij}\) and \(C\) is the diagonal matrix with entry \(j\) equal to \(\sum_{i} A_{ij}\).

The singular value decomposition, \(A_n = U \Sigma V^\top\), provides the partitions of the rows and columns of \(A\). A subset of the left singular vectors gives the row partitions, and a subset of the right singular vectors gives the column partitions.

The \(\ell = \lceil \log_2 k \rceil\) singular vectors, starting from the second, provide the desired partitioning information. They are used to form the matrix \(Z\):

where the columns of \(U\) are \(u_2, \dots, u_{\ell + 1}\), and similarly for \(V\).

Then the rows of \(Z\) are clustered using k-means. The first n_rows labels provide the row partitioning, and the remaining n_columns labels provide the column partitioning.

A demo of the Spectral Co-Clustering algorithm: A simple example showing how to generate a data matrix with biclusters and apply this method to it.

Biclustering documents with the Spectral Co-clustering algorithm: An example of finding biclusters in the twenty newsgroup dataset.

Dhillon, Inderjit S, 2001. Co-clustering documents and words using bipartite spectral graph partitioning

The SpectralBiclustering algorithm assumes that the input data matrix has a hidden checkerboard structure. The rows and columns of a matrix with this structure may be partitioned so that the entries of any bicluster in the Cartesian product of row clusters and column clusters are approximately constant. For instance, if there are two row partitions and three column partitions, each row will belong to three biclusters, and each column will belong to two biclusters.

The algorithm partitions the rows and columns of a matrix so that a corresponding blockwise-constant checkerboard matrix provides a good approximation to the original matrix.

The input matrix \(A\) is first normalized to make the checkerboard pattern more obvious. There are three possible methods:

Independent row and column normalization, as in Spectral Co-Clustering. This method makes the rows sum to a constant and the columns sum to a different constant.

Bistochastization: repeated row and column normalization until convergence. This method makes both rows and columns sum to the same constant.

Log normalization: the log of the data matrix is computed: \(L = \log A\). Then the column mean \(\overline{L_{i \cdot}}\), row mean \(\overline{L_{\cdot j}}\), and overall mean \(\overline{L_{\cdot \cdot}}\) of \(L\) are computed. The final matrix is computed according to the formula

After normalizing, the first few singular vectors are computed, just as in the Spectral Co-Clustering algorithm.

If log normalization was used, all the singular vectors are meaningful. However, if independent normalization or bistochastization were used, the first singular vectors, \(u_1\) and \(v_1\). are discarded. From now on, the “first” singular vectors refers to \(u_2 \dots u_{p+1}\) and \(v_2 \dots v_{p+1}\) except in the case of log normalization.

Given these singular vectors, they are ranked according to which can be best approximated by a piecewise-constant vector. The approximations for each vector are found using one-dimensional k-means and scored using the Euclidean distance. Some subset of the best left and right singular vectors are selected. Next, the data is projected to this best subset of singular vectors and clustered.

For instance, if \(p\) singular vectors were calculated, the \(q\) best are found as described, where \(q<p\). Let \(U\) be the matrix with columns the \(q\) best left singular vectors, and similarly \(V\) for the right. To partition the rows, the rows of \(A\) are projected to a \(q\) dimensional space: \(A * V\). Treating the \(m\) rows of this \(m \times q\) matrix as samples and clustering using k-means yields the row labels. Similarly, projecting the columns to \(A^{\top} * U\) and clustering this \(n \times q\) matrix yields the column labels.

A demo of the Spectral Biclustering algorithm: a simple example showing how to generate a checkerboard matrix and bicluster it.

Kluger, Yuval, et. al., 2003. Spectral biclustering of microarray data: coclustering genes and conditions

There are two ways of evaluating a biclustering result: internal and external. Internal measures, such as cluster stability, rely only on the data and the result themselves. Currently there are no internal bicluster measures in scikit-learn. External measures refer to an external source of information, such as the true solution. When working with real data the true solution is usually unknown, but biclustering artificial data may be useful for evaluating algorithms precisely because the true solution is known.

To compare a set of found biclusters to the set of true biclusters, two similarity measures are needed: a similarity measure for individual biclusters, and a way to combine these individual similarities into an overall score.

To compare individual biclusters, several measures have been used. For now, only the Jaccard index is implemented:

where \(A\) and \(B\) are biclusters, \(|A \cap B|\) is the number of elements in their intersection. The Jaccard index achieves its minimum of 0 when the biclusters do not overlap at all and its maximum of 1 when they are identical.

Several methods have been developed to compare two sets of biclusters. For now, only consensus_score (Hochreiter et. al., 2010) is available:

Compute bicluster similarities for pairs of biclusters, one in each set, using the Jaccard index or a similar measure.

Assign biclusters from one set to another in a one-to-one fashion to maximize the sum of their similarities. This step is performed using scipy.optimize.linear_sum_assignment, which uses a modified Jonker-Volgenant algorithm.

The final sum of similarities is divided by the size of the larger set.

The minimum consensus score, 0, occurs when all pairs of biclusters are totally dissimilar. The maximum score, 1, occurs when both sets are identical.

Hochreiter, Bodenhofer, et. al., 2010. FABIA: factor analysis for bicluster acquisition.

**Examples:**

Example 1 (json):
```json
>>> import numpy as np
>>> data = np.arange(100).reshape(10, 10)
>>> rows = np.array([0, 2, 3])[:, np.newaxis]
>>> columns = np.array([1, 2])
>>> data[rows, columns]
array([[ 1,  2],
       [21, 22],
       [31, 32]])
```

---

## MultiTaskElasticNetCV#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.MultiTaskElasticNetCV.html

**Contents:**
- MultiTaskElasticNetCV#

Multi-task L1/L2 ElasticNet with built-in cross-validation.

See glossary entry for cross-validation estimator.

The optimization objective for MultiTaskElasticNet is:

i.e. the sum of norm of each row.

Read more in the User Guide.

Added in version 0.15.

The ElasticNet mixing parameter, with 0 < l1_ratio <= 1. For l1_ratio = 1 the penalty is an L1/L2 penalty. For l1_ratio = 0 it is an L2 penalty. For 0 < l1_ratio < 1, the penalty is a combination of L1/L2 and L2. This parameter can be a list, in which case the different values are tested by cross-validation and the one giving the best prediction score is used. Note that a good choice of list of values for l1_ratio is often to put more values close to 1 (i.e. Lasso) and less close to 0 (i.e. Ridge), as in [.1, .5, .7, .9, .95, .99, 1].

Length of the path. eps=1e-3 means that alpha_min / alpha_max = 1e-3.

Number of alphas along the regularization path.

Deprecated since version 1.7: n_alphas was deprecated in 1.7 and will be removed in 1.9. Use alphas instead.

Values of alphas to test along the regularization path, used for each l1_ratio. If int, alphas values are generated automatically. If array-like, list of alpha values to use.

Changed in version 1.7: alphas accepts an integer value which removes the need to pass n_alphas.

Deprecated since version 1.7: alphas=None was deprecated in 1.7 and will be removed in 1.9, at which point the default value will be set to 100.

Whether to calculate the intercept for this model. If set to false, no intercept will be used in calculations (i.e. data is expected to be centered).

The maximum number of iterations.

The tolerance for the optimization: if the updates are smaller or equal to tol, the optimization code checks the dual gap for optimality and continues until it is smaller or equal to tol.

Determines the cross-validation splitting strategy. Possible inputs for cv are:

None, to use the default 5-fold cross-validation,

int, to specify the number of folds.

An iterable yielding (train, test) splits as arrays of indices.

For int/None inputs, KFold is used.

Refer User Guide for the various cross-validation strategies that can be used here.

Changed in version 0.22: cv default value if None changed from 3-fold to 5-fold.

If True, X will be copied; else, it may be overwritten.

Number of CPUs to use during the cross validation. Note that this is used only if multiple values for l1_ratio are given. None means 1 unless in a joblib.parallel_backend context. -1 means using all processors. See Glossary for more details.

The seed of the pseudo random number generator that selects a random feature to update. Used when selection == ‘random’. Pass an int for reproducible output across multiple function calls. See Glossary.

If set to ‘random’, a random coefficient is updated every iteration rather than looping over features sequentially by default. This (setting to ‘random’) often leads to significantly faster convergence especially when tol is higher than 1e-4.

Independent term in decision function.

Parameter vector (W in the cost function formula). Note that coef_ stores the transpose of W, W.T.

The amount of penalization chosen by cross validation.

Mean square error for the test set on each fold, varying alpha.

The grid of alphas used for fitting, for each l1_ratio.

Best l1_ratio obtained by cross-validation.

Number of iterations run by the coordinate descent solver to reach the specified tolerance for the optimal alpha.

The dual gap at the end of the optimization for the optimal alpha.

Number of features seen during fit.

Added in version 0.24.

Names of features seen during fit. Defined only when X has feature names that are all strings.

Added in version 1.0.

Multi-task L1/L2 ElasticNet with built-in cross-validation.

Elastic net model with best model selection by cross-validation.

Multi-task Lasso model trained with L1 norm as regularizer and built-in cross-validation.

The algorithm used to fit the model is coordinate descent.

In fit, once the best parameters l1_ratio and alpha are found through cross-validation, the model is fit again using the entire training set.

To avoid unnecessary memory duplication the X and y arguments of the fit method should be directly passed as Fortran-contiguous numpy arrays.

Fit MultiTaskElasticNet model with coordinate descent.

Fit is on grid of alphas and best alpha estimated by cross-validation.

Training target variable. Will be cast to X’s dtype if necessary.

Parameters to be passed to the CV splitter.

Added in version 1.4: Only available if enable_metadata_routing=True, which can be set by using sklearn.set_config(enable_metadata_routing=True). See Metadata Routing User Guide for more details.

Returns MultiTaskElasticNet instance.

Get metadata routing of this object.

Please check User Guide on how the routing mechanism works.

Added in version 1.4.

A MetadataRouter encapsulating routing information.

Get parameters for this estimator.

If True, will return the parameters for this estimator and contained subobjects that are estimators.

Parameter names mapped to their values.

Compute elastic net path with coordinate descent.

The elastic net optimization function varies for mono and multi-outputs.

For mono-output tasks it is:

For multi-output tasks it is:

i.e. the sum of norm of each row.

Read more in the User Guide.

Training data. Pass directly as Fortran-contiguous data to avoid unnecessary memory duplication. If y is mono-output then X can be sparse.

Number between 0 and 1 passed to elastic net (scaling between l1 and l2 penalties). l1_ratio=1 corresponds to the Lasso.

Length of the path. eps=1e-3 means that alpha_min / alpha_max = 1e-3.

Number of alphas along the regularization path.

List of alphas where to compute the models. If None alphas are set automatically.

Whether to use a precomputed Gram matrix to speed up calculations. If set to 'auto' let us decide. The Gram matrix can also be passed as argument.

Xy = np.dot(X.T, y) that can be precomputed. It is useful only when the Gram matrix is precomputed.

If True, X will be copied; else, it may be overwritten.

The initial values of the coefficients.

Whether to return the number of iterations or not.

If set to True, forces coefficients to be positive. (Only allowed when y.ndim == 1).

If set to False, the input validation checks are skipped (including the Gram matrix when provided). It is assumed that they are handled by the caller.

Keyword arguments passed to the coordinate descent solver.

The alphas along the path where models are computed.

Coefficients along the path.

The dual gaps at the end of the optimization for each alpha.

The number of iterations taken by the coordinate descent optimizer to reach the specified tolerance for each alpha. (Is returned when return_n_iter is set to True).

Multi-task ElasticNet model trained with L1/L2 mixed-norm as regularizer.

Multi-task L1/L2 ElasticNet with built-in cross-validation.

Linear regression with combined L1 and L2 priors as regularizer.

Elastic Net model with iterative fitting along a regularization path.

For an example, see examples/linear_model/plot_lasso_lasso_lars_elasticnet_path.py.

The underlying coordinate descent solver uses gap safe screening rules to speedup fitting time, see User Guide on coordinate descent.

Predict using the linear model.

Returns predicted values.

Return coefficient of determination on test data.

The coefficient of determination, \(R^2\), is defined as \((1 - \frac{u}{v})\), where \(u\) is the residual sum of squares ((y_true - y_pred)** 2).sum() and \(v\) is the total sum of squares ((y_true - y_true.mean()) ** 2).sum(). The best possible score is 1.0 and it can be negative (because the model can be arbitrarily worse). A constant model that always predicts the expected value of y, disregarding the input features, would get a \(R^2\) score of 0.0.

Test samples. For some estimators this may be a precomputed kernel matrix or a list of generic objects instead with shape (n_samples, n_samples_fitted), where n_samples_fitted is the number of samples used in the fitting for the estimator.

\(R^2\) of self.predict(X) w.r.t. y.

The \(R^2\) score used when calling score on a regressor uses multioutput='uniform_average' from version 0.23 to keep consistent with default value of r2_score. This influences the score method of all the multioutput regressors (except for MultiOutputRegressor).

Configure whether metadata should be requested to be passed to the fit method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to fit if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to fit.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Added in version 1.3.

Metadata routing for sample_weight parameter in fit.

Set the parameters of this estimator.

The method works on simple estimators as well as on nested objects (such as Pipeline). The latter have parameters of the form <component>__<parameter> so that it’s possible to update each component of a nested object.

Estimator parameters.

Configure whether metadata should be requested to be passed to the score method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to score if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to score.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Added in version 1.3.

Metadata routing for sample_weight parameter in score.

**Examples:**

Example 1 (unknown):
```unknown
(1 / (2 * n_samples)) * ||Y - XW||^Fro_2
+ alpha * l1_ratio * ||W||_21
+ 0.5 * alpha * (1 - l1_ratio) * ||W||_Fro^2
```

Example 2 (unknown):
```unknown
||W||_21 = \sum_i \sqrt{\sum_j w_{ij}^2}
```

Example 3 (python):
```python
>>> from sklearn import linear_model
>>> clf = linear_model.MultiTaskElasticNetCV(cv=3)
>>> clf.fit([[0,0], [1, 1], [2, 2]],
...         [[0, 0], [1, 1], [2, 2]])
MultiTaskElasticNetCV(cv=3)
>>> print(clf.coef_)
[[0.51841231 0.479658]
 [0.51841231 0.479658]]
>>> print(clf.intercept_)
[0.001929... 0.001929...]
```

Example 4 (unknown):
```unknown
1 / (2 * n_samples) * ||y - Xw||^2_2
+ alpha * l1_ratio * ||w||_1
+ 0.5 * alpha * (1 - l1_ratio) * ||w||^2_2
```

---

## 7.5. Unsupervised dimensionality reduction#

**URL:** https://scikit-learn.org/stable/modules/unsupervised_reduction.html

**Contents:**
- 7.5. Unsupervised dimensionality reduction#
- 7.5.1. PCA: principal component analysis#
- 7.5.2. Random projections#
- 7.5.3. Feature agglomeration#

If your number of features is high, it may be useful to reduce it with an unsupervised step prior to supervised steps. Many of the Unsupervised learning methods implement a transform method that can be used to reduce the dimensionality. Below we discuss two specific examples of this pattern that are heavily used.

The unsupervised data reduction and the supervised estimator can be chained in one step. See Pipeline: chaining estimators.

decomposition.PCA looks for a combination of features that capture well the variance of the original features. See Decomposing signals in components (matrix factorization problems).

Faces recognition example using eigenfaces and SVMs

The module: random_projection provides several tools for data reduction by random projections. See the relevant section of the documentation: Random Projection.

The Johnson-Lindenstrauss bound for embedding with random projections

cluster.FeatureAgglomeration applies Hierarchical clustering to group together features that behave similarly.

Feature agglomeration vs. univariate selection

Feature agglomeration

Note that if features have very different scaling or statistical properties, cluster.FeatureAgglomeration may not be able to capture the links between related features. Using a preprocessing.StandardScaler can be useful in these settings.

---

## Lasso#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html

**Contents:**
- Lasso#
- Gallery examples#

Linear Model trained with L1 prior as regularizer (aka the Lasso).

The optimization objective for Lasso is:

Technically the Lasso model is optimizing the same objective function as the Elastic Net with l1_ratio=1.0 (no L2 penalty).

Read more in the User Guide.

Constant that multiplies the L1 term, controlling regularization strength. alpha must be a non-negative float i.e. in [0, inf).

When alpha = 0, the objective is equivalent to ordinary least squares, solved by the LinearRegression object. For numerical reasons, using alpha = 0 with the Lasso object is not advised. Instead, you should use the LinearRegression object.

Whether to calculate the intercept for this model. If set to False, no intercept will be used in calculations (i.e. data is expected to be centered).

Whether to use a precomputed Gram matrix to speed up calculations. The Gram matrix can also be passed as argument. For sparse input this option is always False to preserve sparsity.

If True, X will be copied; else, it may be overwritten.

The maximum number of iterations.

The tolerance for the optimization: if the updates are smaller or equal to tol, the optimization code checks the dual gap for optimality and continues until it is smaller or equal to tol, see Notes below.

When set to True, reuse the solution of the previous call to fit as initialization, otherwise, just erase the previous solution. See the Glossary.

When set to True, forces the coefficients to be positive.

The seed of the pseudo random number generator that selects a random feature to update. Used when selection == ‘random’. Pass an int for reproducible output across multiple function calls. See Glossary.

If set to ‘random’, a random coefficient is updated every iteration rather than looping over features sequentially by default. This (setting to ‘random’) often leads to significantly faster convergence especially when tol is higher than 1e-4.

Parameter vector (w in the cost function formula).

Given param alpha, the dual gaps at the end of the optimization, same shape as each observation of y.

Sparse representation of the fitted coef_.

Independent term in decision function.

Number of iterations run by the coordinate descent solver to reach the specified tolerance.

Number of features seen during fit.

Added in version 0.24.

Names of features seen during fit. Defined only when X has feature names that are all strings.

Added in version 1.0.

Regularization path using LARS.

Regularization path using Lasso.

Lasso Path along the regularization parameter using LARS algorithm.

Lasso alpha parameter by cross-validation.

Lasso least angle parameter algorithm by cross-validation.

Sparse coding array estimator.

The algorithm used to fit the model is coordinate descent.

To avoid unnecessary memory duplication the X argument of the fit method should be directly passed as a Fortran-contiguous numpy array.

Regularization improves the conditioning of the problem and reduces the variance of the estimates. Larger values specify stronger regularization. Alpha corresponds to 1 / (2C) in other linear models such as LogisticRegression or LinearSVC.

The precise stopping criteria based on tol are the following: First, check that that maximum coordinate update, i.e. \(\max_j |w_j^{new} - w_j^{old}|\) is smaller or equal to tol times the maximum absolute coefficient, \(\max_j |w_j|\). If so, then additionally check whether the dual gap is smaller or equal to tol times \(||y||_2^2 / n_{\text{samples}}\).

The target can be a 2-dimensional array, resulting in the optimization of the following objective:

where \(||W||_{1,1}\) is the sum of the magnitude of the matrix coefficients. It should not be confused with MultiTaskLasso which instead penalizes the \(L_{2,1}\) norm of the coefficients, yielding row-wise sparsity in the coefficients.

The underlying coordinate descent solver uses gap safe screening rules to speedup fitting time, see User Guide on coordinate descent.

L1-based models for Sparse Signals compares Lasso with other L1-based regression models (ElasticNet and ARD Regression) for sparse signal recovery in the presence of noise and feature correlation.

Fit model with coordinate descent.

Note that large sparse matrices and arrays requiring int64 indices are not accepted.

Target. Will be cast to X’s dtype if necessary.

Sample weights. Internally, the sample_weight vector will be rescaled to sum to n_samples.

Added in version 0.23.

Allow to bypass several input checking. Don’t use this parameter unless you know what you do.

Coordinate descent is an algorithm that considers each column of data at a time hence it will automatically convert the X input as a Fortran-contiguous numpy array if necessary.

To avoid memory re-allocation it is advised to allocate the initial data in memory directly using that format.

Get metadata routing of this object.

Please check User Guide on how the routing mechanism works.

A MetadataRequest encapsulating routing information.

Get parameters for this estimator.

If True, will return the parameters for this estimator and contained subobjects that are estimators.

Parameter names mapped to their values.

Compute elastic net path with coordinate descent.

The elastic net optimization function varies for mono and multi-outputs.

For mono-output tasks it is:

For multi-output tasks it is:

i.e. the sum of norm of each row.

Read more in the User Guide.

Training data. Pass directly as Fortran-contiguous data to avoid unnecessary memory duplication. If y is mono-output then X can be sparse.

Number between 0 and 1 passed to elastic net (scaling between l1 and l2 penalties). l1_ratio=1 corresponds to the Lasso.

Length of the path. eps=1e-3 means that alpha_min / alpha_max = 1e-3.

Number of alphas along the regularization path.

List of alphas where to compute the models. If None alphas are set automatically.

Whether to use a precomputed Gram matrix to speed up calculations. If set to 'auto' let us decide. The Gram matrix can also be passed as argument.

Xy = np.dot(X.T, y) that can be precomputed. It is useful only when the Gram matrix is precomputed.

If True, X will be copied; else, it may be overwritten.

The initial values of the coefficients.

Whether to return the number of iterations or not.

If set to True, forces coefficients to be positive. (Only allowed when y.ndim == 1).

If set to False, the input validation checks are skipped (including the Gram matrix when provided). It is assumed that they are handled by the caller.

Keyword arguments passed to the coordinate descent solver.

The alphas along the path where models are computed.

Coefficients along the path.

The dual gaps at the end of the optimization for each alpha.

The number of iterations taken by the coordinate descent optimizer to reach the specified tolerance for each alpha. (Is returned when return_n_iter is set to True).

Multi-task ElasticNet model trained with L1/L2 mixed-norm as regularizer.

Multi-task L1/L2 ElasticNet with built-in cross-validation.

Linear regression with combined L1 and L2 priors as regularizer.

Elastic Net model with iterative fitting along a regularization path.

For an example, see examples/linear_model/plot_lasso_lasso_lars_elasticnet_path.py.

The underlying coordinate descent solver uses gap safe screening rules to speedup fitting time, see User Guide on coordinate descent.

Predict using the linear model.

Returns predicted values.

Return coefficient of determination on test data.

The coefficient of determination, \(R^2\), is defined as \((1 - \frac{u}{v})\), where \(u\) is the residual sum of squares ((y_true - y_pred)** 2).sum() and \(v\) is the total sum of squares ((y_true - y_true.mean()) ** 2).sum(). The best possible score is 1.0 and it can be negative (because the model can be arbitrarily worse). A constant model that always predicts the expected value of y, disregarding the input features, would get a \(R^2\) score of 0.0.

Test samples. For some estimators this may be a precomputed kernel matrix or a list of generic objects instead with shape (n_samples, n_samples_fitted), where n_samples_fitted is the number of samples used in the fitting for the estimator.

\(R^2\) of self.predict(X) w.r.t. y.

The \(R^2\) score used when calling score on a regressor uses multioutput='uniform_average' from version 0.23 to keep consistent with default value of r2_score. This influences the score method of all the multioutput regressors (except for MultiOutputRegressor).

Configure whether metadata should be requested to be passed to the fit method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to fit if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to fit.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Added in version 1.3.

Metadata routing for sample_weight parameter in fit.

Set the parameters of this estimator.

The method works on simple estimators as well as on nested objects (such as Pipeline). The latter have parameters of the form <component>__<parameter> so that it’s possible to update each component of a nested object.

Estimator parameters.

Configure whether metadata should be requested to be passed to the score method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to score if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to score.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Added in version 1.3.

Metadata routing for sample_weight parameter in score.

Compressive sensing: tomography reconstruction with L1 prior (Lasso)

L1-based models for Sparse Signals

Lasso on dense and sparse data

Joint feature selection with multi-task Lasso

Ordinary Least Squares and Ridge Regression

Release Highlights for scikit-learn 0.23

Release Highlights for scikit-learn 1.4

**Examples:**

Example 1 (unknown):
```unknown
(1 / (2 * n_samples)) * ||y - Xw||^2_2 + alpha * ||w||_1
```

Example 2 (unknown):
```unknown
(1 / (2 * n_samples)) * ||Y - XW||^2_F + alpha * ||W||_11
```

Example 3 (python):
```python
>>> from sklearn import linear_model
>>> clf = linear_model.Lasso(alpha=0.1)
>>> clf.fit([[0,0], [1, 1], [2, 2]], [0, 1, 2])
Lasso(alpha=0.1)
>>> print(clf.coef_)
[0.85 0.  ]
>>> print(clf.intercept_)
0.15
```

Example 4 (unknown):
```unknown
1 / (2 * n_samples) * ||y - Xw||^2_2
+ alpha * l1_ratio * ||w||_1
+ 0.5 * alpha * (1 - l1_ratio) * ||w||^2_2
```

---

## RadiusNeighborsTransformer#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.RadiusNeighborsTransformer.html

**Contents:**
- RadiusNeighborsTransformer#

Transform X into a (weighted) graph of neighbors nearer than a radius.

The transformed data is a sparse graph as returned by radius_neighbors_graph.

Read more in the User Guide.

Added in version 0.22.

Type of returned matrix: ‘connectivity’ will return the connectivity matrix with ones and zeros, and ‘distance’ will return the distances between neighbors according to the given metric.

Radius of neighborhood in the transformed sparse graph.

Algorithm used to compute the nearest neighbors:

‘ball_tree’ will use BallTree

‘kd_tree’ will use KDTree

‘brute’ will use a brute-force search.

‘auto’ will attempt to decide the most appropriate algorithm based on the values passed to fit method.

Note: fitting on sparse input will override the setting of this parameter, using brute force.

Leaf size passed to BallTree or KDTree. This can affect the speed of the construction and query, as well as the memory required to store the tree. The optimal value depends on the nature of the problem.

Metric to use for distance computation. Default is “minkowski”, which results in the standard Euclidean distance when p = 2. See the documentation of scipy.spatial.distance and the metrics listed in distance_metrics for valid metric values.

If metric is a callable function, it takes two arrays representing 1D vectors as inputs and must return one value indicating the distance between those vectors. This works for Scipy’s metrics, but is less efficient than passing the metric name as a string.

Distance matrices are not supported.

Parameter for the Minkowski metric from sklearn.metrics.pairwise.pairwise_distances. When p = 1, this is equivalent to using manhattan_distance (l1), and euclidean_distance (l2) for p = 2. For arbitrary p, minkowski_distance (l_p) is used. This parameter is expected to be positive.

Additional keyword arguments for the metric function.

The number of parallel jobs to run for neighbors search. If -1, then the number of jobs is set to the number of CPU cores.

The distance metric used. It will be same as the metric parameter or a synonym of it, e.g. ‘euclidean’ if the metric parameter set to ‘minkowski’ and p parameter set to 2.

Additional keyword arguments for the metric function. For most metrics will be same with metric_params parameter, but may also contain the p parameter value if the effective_metric_ attribute is set to ‘minkowski’.

Number of features seen during fit.

Added in version 0.24.

Names of features seen during fit. Defined only when X has feature names that are all strings.

Added in version 1.0.

Number of samples in the fitted data.

Compute the weighted graph of k-neighbors for points in X.

Transform X into a weighted graph of k nearest neighbors.

Fit the radius neighbors transformer from the training dataset.

Not used, present for API consistency by convention.

The fitted radius neighbors transformer.

Fit to data, then transform it.

Fits transformer to X and y with optional parameters fit_params and returns a transformed version of X.

Not used, present for API consistency by convention.

Xt[i, j] is assigned the weight of edge that connects i to j. Only the neighbors have an explicit value. The diagonal is always explicit. The matrix is of CSR format.

Get output feature names for transformation.

The feature names out will prefixed by the lowercased class name. For example, if the transformer outputs 3 features, then the feature names out are: ["class_name0", "class_name1", "class_name2"].

Only used to validate feature names with the names seen in fit.

Transformed feature names.

Get metadata routing of this object.

Please check User Guide on how the routing mechanism works.

A MetadataRequest encapsulating routing information.

Get parameters for this estimator.

If True, will return the parameters for this estimator and contained subobjects that are estimators.

Parameter names mapped to their values.

Find the neighbors within a given radius of a point or points.

Return the indices and distances of each point from the dataset lying in a ball with size radius around the points of the query array. Points lying on the boundary are included in the results.

The result points are not necessarily sorted by distance to their query point.

The query point or points. If not provided, neighbors of each indexed point are returned. In this case, the query point is not considered its own neighbor.

Limiting distance of neighbors to return. The default is the value passed to the constructor.

Whether or not to return the distances.

If True, the distances and indices will be sorted by increasing distances before being returned. If False, the results may not be sorted. If return_distance=False, setting sort_results=True will result in an error.

Added in version 0.22.

Array representing the distances to each point, only present if return_distance=True. The distance values are computed according to the metric constructor parameter.

An array of arrays of indices of the approximate nearest points from the population matrix that lie within a ball of size radius around the query points.

Because the number of neighbors of each point is not necessarily equal, the results for multiple query points cannot be fit in a standard data array. For efficiency, radius_neighbors returns arrays of objects, where each object is a 1D array of indices or distances.

In the following example, we construct a NeighborsClassifier class from an array representing our data set and ask who’s the closest point to [1, 1, 1]:

The first array returned contains the distances to all points which are closer than 1.6, while the second array returned contains their indices. In general, multiple points can be queried at the same time.

Compute the (weighted) graph of Neighbors for points in X.

Neighborhoods are restricted the points at a distance lower than radius.

The query point or points. If not provided, neighbors of each indexed point are returned. In this case, the query point is not considered its own neighbor.

Radius of neighborhoods. The default is the value passed to the constructor.

Type of returned matrix: ‘connectivity’ will return the connectivity matrix with ones and zeros, in ‘distance’ the edges are distances between points, type of distance depends on the selected metric parameter in NearestNeighbors class.

If True, in each row of the result, the non-zero entries will be sorted by increasing distances. If False, the non-zero entries may not be sorted. Only used with mode=’distance’.

Added in version 0.22.

n_samples_fit is the number of samples in the fitted data. A[i, j] gives the weight of the edge connecting i to j. The matrix is of CSR format.

Compute the (weighted) graph of k-Neighbors for points in X.

Set output container.

See Introducing the set_output API for an example on how to use the API.

Configure output of transform and fit_transform.

"default": Default output format of a transformer

"pandas": DataFrame output

"polars": Polars output

None: Transform configuration is unchanged

Added in version 1.4: "polars" option was added.

Set the parameters of this estimator.

The method works on simple estimators as well as on nested objects (such as Pipeline). The latter have parameters of the form <component>__<parameter> so that it’s possible to update each component of a nested object.

Estimator parameters.

Compute the (weighted) graph of Neighbors for points in X.

Xt[i, j] is assigned the weight of edge that connects i to j. Only the neighbors have an explicit value. The diagonal is always explicit. The matrix is of CSR format.

**Examples:**

Example 1 (python):
```python
>>> import numpy as np
>>> from sklearn.datasets import load_wine
>>> from sklearn.cluster import DBSCAN
>>> from sklearn.neighbors import RadiusNeighborsTransformer
>>> from sklearn.pipeline import make_pipeline
>>> X, _ = load_wine(return_X_y=True)
>>> estimator = make_pipeline(
...     RadiusNeighborsTransformer(radius=42.0, mode='distance'),
...     DBSCAN(eps=25.0, metric='precomputed'))
>>> X_clustered = estimator.fit_predict(X)
>>> clusters, counts = np.unique(X_clustered, return_counts=True)
>>> print(counts)
[ 29  15 111  11  12]
```

Example 2 (python):
```python
>>> import numpy as np
>>> samples = [[0., 0., 0.], [0., .5, 0.], [1., 1., .5]]
>>> from sklearn.neighbors import NearestNeighbors
>>> neigh = NearestNeighbors(radius=1.6)
>>> neigh.fit(samples)
NearestNeighbors(radius=1.6)
>>> rng = neigh.radius_neighbors([[1., 1., 1.]])
>>> print(np.asarray(rng[0][0]))
[1.5 0.5]
>>> print(np.asarray(rng[1][0]))
[1 2]
```

Example 3 (sql):
```sql
>>> X = [[0], [3], [1]]
>>> from sklearn.neighbors import NearestNeighbors
>>> neigh = NearestNeighbors(radius=1.5)
>>> neigh.fit(X)
NearestNeighbors(radius=1.5)
>>> A = neigh.radius_neighbors_graph(X)
>>> A.toarray()
array([[1., 0., 1.],
       [0., 1., 0.],
       [1., 0., 1.]])
```

---

## SparseCoder#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.SparseCoder.html

**Contents:**
- SparseCoder#
- Gallery examples#

Finds a sparse representation of data against a fixed, precomputed dictionary.

Each row of the result is the solution to a sparse coding problem. The goal is to find a sparse array code such that:

Read more in the User Guide.

The dictionary atoms used for sparse coding. Lines are assumed to be normalized to unit norm.

Algorithm used to transform the data:

'lars': uses the least angle regression method (linear_model.lars_path);

'lasso_lars': uses Lars to compute the Lasso solution;

'lasso_cd': uses the coordinate descent method to compute the Lasso solution (linear_model.Lasso). 'lasso_lars' will be faster if the estimated components are sparse;

'omp': uses orthogonal matching pursuit to estimate the sparse solution;

'threshold': squashes to zero all coefficients less than alpha from the projection dictionary * X'.

Number of nonzero coefficients to target in each column of the solution. This is only used by algorithm='lars' and algorithm='omp' and is overridden by alpha in the omp case. If None, then transform_n_nonzero_coefs=int(n_features / 10).

If algorithm='lasso_lars' or algorithm='lasso_cd', alpha is the penalty applied to the L1 norm. If algorithm='threshold', alpha is the absolute value of the threshold below which coefficients will be squashed to zero. If algorithm='omp', alpha is the tolerance parameter: the value of the reconstruction error targeted. In this case, it overrides n_nonzero_coefs. If None, default to 1.

Whether to split the sparse feature vector into the concatenation of its negative part and its positive part. This can improve the performance of downstream classifiers.

Number of parallel jobs to run. None means 1 unless in a joblib.parallel_backend context. -1 means using all processors. See Glossary for more details.

Whether to enforce positivity when finding the code.

Added in version 0.20.

Maximum number of iterations to perform if algorithm='lasso_cd' or lasso_lars.

Added in version 0.22.

Number of features seen during fit.

Added in version 0.24.

Names of features seen during fit. Defined only when X has feature names that are all strings.

Added in version 1.0.

Find a dictionary that sparsely encodes data.

A faster, less accurate, version of the dictionary learning algorithm.

Mini-batch Sparse Principal Components Analysis.

Sparse Principal Components Analysis.

Sparse coding where each row of the result is the solution to a sparse coding problem.

Only validate the parameters of the estimator.

This method allows to: (i) validate the parameters of the estimator and (ii) be consistent with the scikit-learn transformer API.

Training data. Only used for input validation.

Not used, present for API consistency by convention.

Returns the instance itself.

Fit to data, then transform it.

Fits transformer to X and y with optional parameters fit_params and returns a transformed version of X.

Target values (None for unsupervised transformations).

Additional fit parameters. Pass only if the estimator accepts additional params in its fit method.

Get output feature names for transformation.

The feature names out will prefixed by the lowercased class name. For example, if the transformer outputs 3 features, then the feature names out are: ["class_name0", "class_name1", "class_name2"].

Only used to validate feature names with the names seen in fit.

Transformed feature names.

Get metadata routing of this object.

Please check User Guide on how the routing mechanism works.

A MetadataRequest encapsulating routing information.

Get parameters for this estimator.

If True, will return the parameters for this estimator and contained subobjects that are estimators.

Parameter names mapped to their values.

Transform data back to its original space.

Data to be transformed back. Must have the same number of components as the data used to train the model.

Set output container.

See Introducing the set_output API for an example on how to use the API.

Configure output of transform and fit_transform.

"default": Default output format of a transformer

"pandas": DataFrame output

"polars": Polars output

None: Transform configuration is unchanged

Added in version 1.4: "polars" option was added.

Set the parameters of this estimator.

The method works on simple estimators as well as on nested objects (such as Pipeline). The latter have parameters of the form <component>__<parameter> so that it’s possible to update each component of a nested object.

Estimator parameters.

Encode the data as a sparse combination of the dictionary atoms.

Coding method is determined by the object parameter transform_algorithm.

Training vector, where n_samples is the number of samples and n_features is the number of features.

Not used, present for API consistency by convention.

Sparse coding with a precomputed dictionary

**Examples:**

Example 1 (unknown):
```unknown
X ~= code * dictionary
```

Example 2 (csharp):
```csharp
>>> import numpy as np
>>> from sklearn.decomposition import SparseCoder
>>> X = np.array([[-1, -1, -1], [0, 0, 3]])
>>> dictionary = np.array(
...     [[0, 1, 0],
...      [-1, -1, 2],
...      [1, 1, 1],
...      [0, 1, 1],
...      [0, 2, 1]],
...    dtype=np.float64
... )
>>> coder = SparseCoder(
...     dictionary=dictionary, transform_algorithm='lasso_lars',
...     transform_alpha=1e-10,
... )
>>> coder.transform(X)
array([[ 0.,  0., -1.,  0.,  0.],
       [ 0.,  1.,  1.,  0.,  0.]])
```

---

## 

**URL:** https://scikit-learn.org/stable/_sources/modules/calibration.rst.txt

---

## OutputCodeClassifier#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.multiclass.OutputCodeClassifier.html

**Contents:**
- OutputCodeClassifier#
- Gallery examples#

(Error-Correcting) Output-Code multiclass strategy.

Output-code based strategies consist in representing each class with a binary code (an array of 0s and 1s). At fitting time, one binary classifier per bit in the code book is fitted. At prediction time, the classifiers are used to project new points in the class space and the class closest to the points is chosen. The main advantage of these strategies is that the number of classifiers used can be controlled by the user, either for compressing the model (0 < code_size < 1) or for making the model more robust to errors (code_size > 1). See the documentation for more details.

Read more in the User Guide.

An estimator object implementing fit and one of decision_function or predict_proba.

Percentage of the number of classes to be used to create the code book. A number between 0 and 1 will require fewer classifiers than one-vs-the-rest. A number greater than 1 will require more classifiers than one-vs-the-rest.

The generator used to initialize the codebook. Pass an int for reproducible output across multiple function calls. See Glossary.

The number of jobs to use for the computation: the multiclass problems are computed in parallel.

None means 1 unless in a joblib.parallel_backend context. -1 means using all processors. See Glossary for more details.

Estimators used for predictions.

Array containing labels.

Binary array containing the code of each class.

Number of features seen during fit. Only defined if the underlying estimator exposes such an attribute when fit.

Added in version 0.24.

Names of features seen during fit. Only defined if the underlying estimator exposes such an attribute when fit.

Added in version 1.0.

One-vs-all multiclass strategy.

One-vs-one multiclass strategy.

“Solving multiclass learning problems via error-correcting output codes”, Dietterich T., Bakiri G., Journal of Artificial Intelligence Research 2, 1995.

“The error coding method and PICTs”, James G., Hastie T., Journal of Computational and Graphical statistics 7, 1998.

“The Elements of Statistical Learning”, Hastie T., Tibshirani R., Friedman J., page 606 (second-edition) 2008.

Fit underlying estimators.

Parameters passed to the estimator.fit method of each sub-estimator.

Added in version 1.4: Only available if enable_metadata_routing=True. See Metadata Routing User Guide for more details.

Returns a fitted instance of self.

Get metadata routing of this object.

Please check User Guide on how the routing mechanism works.

Added in version 1.4.

A MetadataRouter encapsulating routing information.

Get parameters for this estimator.

If True, will return the parameters for this estimator and contained subobjects that are estimators.

Parameter names mapped to their values.

Predict multi-class targets using underlying estimators.

Predicted multi-class targets.

Return accuracy on provided data and labels.

In multi-label classification, this is the subset accuracy which is a harsh metric since you require for each sample that each label set be correctly predicted.

Mean accuracy of self.predict(X) w.r.t. y.

Set the parameters of this estimator.

The method works on simple estimators as well as on nested objects (such as Pipeline). The latter have parameters of the form <component>__<parameter> so that it’s possible to update each component of a nested object.

Estimator parameters.

Configure whether metadata should be requested to be passed to the score method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to score if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to score.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Added in version 1.3.

Metadata routing for sample_weight parameter in score.

Overview of multiclass training meta-estimators

**Examples:**

Example 1 (sql):
```sql
>>> from sklearn.multiclass import OutputCodeClassifier
>>> from sklearn.ensemble import RandomForestClassifier
>>> from sklearn.datasets import make_classification
>>> X, y = make_classification(n_samples=100, n_features=4,
...                            n_informative=2, n_redundant=0,
...                            random_state=0, shuffle=False)
>>> clf = OutputCodeClassifier(
...     estimator=RandomForestClassifier(random_state=0),
...     random_state=0).fit(X, y)
>>> clf.predict([[0, 0, 0, 0]])
array([1])
```

---

## HDBSCAN#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.cluster.HDBSCAN.html

**Contents:**
- HDBSCAN#
- Gallery examples#

Cluster data using hierarchical density-based clustering.

HDBSCAN - Hierarchical Density-Based Spatial Clustering of Applications with Noise. Performs DBSCAN over varying epsilon values and integrates the result to find a clustering that gives the best stability over epsilon. This allows HDBSCAN to find clusters of varying densities (unlike DBSCAN), and be more robust to parameter selection. Read more in the User Guide.

Added in version 1.3.

The minimum number of samples in a group for that group to be considered a cluster; groupings smaller than this size will be left as noise.

The parameter k used to calculate the distance between a point x_p and its k-th nearest neighbor. When None, defaults to min_cluster_size.

A distance threshold. Clusters below this value will be merged. See [5] for more information.

A limit to the size of clusters returned by the "eom" cluster selection algorithm. There is no limit when max_cluster_size=None. Has no effect if cluster_selection_method="leaf".

The metric to use when calculating distance between instances in a feature array.

If metric is a string or callable, it must be one of the options allowed by pairwise_distances for its metric parameter.

If metric is “precomputed”, X is assumed to be a distance matrix and must be square.

Arguments passed to the distance metric.

A distance scaling parameter as used in robust single linkage. See [3] for more information.

Exactly which algorithm to use for computing core distances; By default this is set to "auto" which attempts to use a KDTree tree if possible, otherwise it uses a BallTree tree. Both "kd_tree" and "ball_tree" algorithms use the NearestNeighbors estimator.

If the X passed during fit is sparse or metric is invalid for both KDTree and BallTree, then it resolves to use the "brute" algorithm.

Leaf size for trees responsible for fast nearest neighbour queries when a KDTree or a BallTree are used as core-distance algorithms. A large dataset size and small leaf_size may induce excessive memory usage. If you are running out of memory consider increasing the leaf_size parameter. Ignored for algorithm="brute".

Number of jobs to run in parallel to calculate distances. None means 1 unless in a joblib.parallel_backend context. -1 means using all processors. See Glossary for more details.

The method used to select clusters from the condensed tree. The standard approach for HDBSCAN* is to use an Excess of Mass ("eom") algorithm to find the most persistent clusters. Alternatively you can instead select the clusters at the leaves of the tree – this provides the most fine grained and homogeneous clusters.

By default HDBSCAN* will not produce a single cluster, setting this to True will override this and allow single cluster results in the case that you feel this is a valid result for your dataset.

Which, if any, cluster centers to compute and store. The options are:

None which does not compute nor store any centers.

"centroid" which calculates the center by taking the weighted average of their positions. Note that the algorithm uses the euclidean metric and does not guarantee that the output will be an observed data point.

"medoid" which calculates the center by taking the point in the fitted data which minimizes the distance to all other points in the cluster. This is slower than “centroid” since it requires computing additional pairwise distances between points of the same cluster but guarantees the output is an observed data point. The medoid is also well-defined for arbitrary metrics, and does not depend on a euclidean metric.

"both" which computes and stores both forms of centers.

If copy=True then any time an in-place modifications would be made that would overwrite data passed to fit, a copy will first be made, guaranteeing that the original data will be unchanged. Currently, it only applies when metric="precomputed", when passing a dense array or a CSR sparse matrix and when algorithm="brute".

Changed in version 1.10: The default value for copy will change from False to True in version 1.10.

Cluster labels for each point in the dataset given to fit. Outliers are labeled as follows:

Noisy samples are given the label -1.

Samples with infinite elements (+/- np.inf) are given the label -2.

Samples with missing data are given the label -3, even if they also have infinite elements.

The strength with which each sample is a member of its assigned cluster.

Clustered samples have probabilities proportional to the degree that they persist as part of the cluster.

Noisy samples have probability zero.

Samples with infinite elements (+/- np.inf) have probability 0.

Samples with missing data have probability np.nan.

Number of features seen during fit.

Names of features seen during fit. Defined only when X has feature names that are all strings.

A collection containing the centroid of each cluster calculated under the standard euclidean metric. The centroids may fall “outside” their respective clusters if the clusters themselves are non-convex.

Note that n_clusters only counts non-outlier clusters. That is to say, the -1, -2, -3 labels for the outlier clusters are excluded.

A collection containing the medoid of each cluster calculated under the whichever metric was passed to the metric parameter. The medoids are points in the original cluster which minimize the average distance to all other points in that cluster under the chosen metric. These can be thought of as the result of projecting the metric-based centroid back onto the cluster.

Note that n_clusters only counts non-outlier clusters. That is to say, the -1, -2, -3 labels for the outlier clusters are excluded.

Density-Based Spatial Clustering of Applications with Noise.

Ordering Points To Identify the Clustering Structure.

Memory-efficient, online-learning algorithm.

The min_samples parameter includes the point itself, whereas the implementation in scikit-learn-contrib/hdbscan does not. To get the same results in both versions, the value of min_samples here must be 1 greater than the value used in scikit-learn-contrib/hdbscan.

Campello, R. J., Moulavi, D., & Sander, J. Density-based clustering based on hierarchical density estimates.

Campello, R. J., Moulavi, D., Zimek, A., & Sander, J. Hierarchical density estimates for data clustering, visualization, and outlier detection.

Chaudhuri, K., & Dasgupta, S. Rates of convergence for the cluster tree.

Moulavi, D., Jaskowiak, P.A., Campello, R.J., Zimek, A. and Sander, J. Density-Based Clustering Validation.

Malzer, C., & Baum, M. “A Hybrid Approach To Hierarchical Density-based Cluster Selection.”.

Return clustering given by DBSCAN without border points.

Return clustering that would be equivalent to running DBSCAN* for a particular cut_distance (or epsilon) DBSCAN* can be thought of as DBSCAN without the border points. As such these results may differ slightly from cluster.DBSCAN due to the difference in implementation over the non-core points.

This can also be thought of as a flat clustering derived from constant height cut through the single linkage tree.

This represents the result of selecting a cut value for robust single linkage clustering. The min_cluster_size allows the flat clustering to declare noise points (and cluster smaller than min_cluster_size).

The mutual reachability distance cut value to use to generate a flat clustering.

Clusters smaller than this value with be called ‘noise’ and remain unclustered in the resulting flat clustering.

An array of cluster labels, one per datapoint. Outliers are labeled as follows:

Noisy samples are given the label -1.

Samples with infinite elements (+/- np.inf) are given the label -2.

Samples with missing data are given the label -3, even if they also have infinite elements.

Find clusters based on hierarchical density-based clustering.

A feature array, or array of distances between samples if metric='precomputed'.

Cluster X and return the associated cluster labels.

A feature array, or array of distances between samples if metric='precomputed'.

Get metadata routing of this object.

Please check User Guide on how the routing mechanism works.

A MetadataRequest encapsulating routing information.

Get parameters for this estimator.

If True, will return the parameters for this estimator and contained subobjects that are estimators.

Parameter names mapped to their values.

Set the parameters of this estimator.

The method works on simple estimators as well as on nested objects (such as Pipeline). The latter have parameters of the form <component>__<parameter> so that it’s possible to update each component of a nested object.

Estimator parameters.

Comparing different clustering algorithms on toy datasets

Demo of HDBSCAN clustering algorithm

Release Highlights for scikit-learn 1.3

**Examples:**

Example 1 (sql):
```sql
>>> import numpy as np
>>> from sklearn.cluster import HDBSCAN
>>> from sklearn.datasets import load_digits
>>> X, _ = load_digits(return_X_y=True)
>>> hdb = HDBSCAN(copy=True, min_cluster_size=20)
>>> hdb.fit(X)
HDBSCAN(copy=True, min_cluster_size=20)
>>> hdb.labels_.shape == (X.shape[0],)
True
>>> np.unique(hdb.labels_).tolist()
[-1, 0, 1, 2, 3, 4, 5, 6, 7]
```

---

## silhouette_score#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.metrics.silhouette_score.html

**Contents:**
- silhouette_score#
- Gallery examples#

Compute the mean Silhouette Coefficient of all samples.

The Silhouette Coefficient is calculated using the mean intra-cluster distance (a) and the mean nearest-cluster distance (b) for each sample. The Silhouette Coefficient for a sample is (b - a) / max(a, b). To clarify, b is the distance between a sample and the nearest cluster that the sample is not a part of. Note that Silhouette Coefficient is only defined if number of labels is 2 <= n_labels <= n_samples - 1.

This function returns the mean Silhouette Coefficient over all samples. To obtain the values for each sample, use silhouette_samples.

The best value is 1 and the worst value is -1. Values near 0 indicate overlapping clusters. Negative values generally indicate that a sample has been assigned to the wrong cluster, as a different cluster is more similar.

Read more in the User Guide.

An array of pairwise distances between samples, or a feature array.

Predicted labels for each sample.

The metric to use when calculating distance between instances in a feature array. If metric is a string, it must be one of the options allowed by pairwise_distances. If X is the distance array itself, use metric="precomputed".

The size of the sample to use when computing the Silhouette Coefficient on a random subset of the data. If sample_size is None, no sampling is used.

Determines random number generation for selecting a subset of samples. Used when sample_size is not None. Pass an int for reproducible results across multiple function calls. See Glossary.

Any further parameters are passed directly to the distance function. If using a scipy.spatial.distance metric, the parameters are still metric dependent. See the scipy docs for usage examples.

Mean Silhouette Coefficient for all samples.

Peter J. Rousseeuw (1987). “Silhouettes: a Graphical Aid to the Interpretation and Validation of Cluster Analysis”. Computational and Applied Mathematics 20: 53-65.

Wikipedia entry on the Silhouette Coefficient

Demo of affinity propagation clustering algorithm

Demo of DBSCAN clustering algorithm

A demo of K-Means clustering on the handwritten digits data

Selecting the number of clusters with silhouette analysis on KMeans clustering

Clustering text documents using k-means

**Examples:**

Example 1 (sql):
```sql
>>> from sklearn.datasets import make_blobs
>>> from sklearn.cluster import KMeans
>>> from sklearn.metrics import silhouette_score
>>> X, y = make_blobs(random_state=42)
>>> kmeans = KMeans(n_clusters=2, random_state=42)
>>> silhouette_score(X, kmeans.fit_predict(X))
0.49...
```

---

## spectral_embedding#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.manifold.spectral_embedding.html

**Contents:**
- spectral_embedding#

Project the sample on the first eigenvectors of the graph Laplacian.

The adjacency matrix is used to compute a normalized graph Laplacian whose spectrum (especially the eigenvectors associated to the smallest eigenvalues) has an interpretation in terms of minimal number of cuts necessary to split the graph into comparably sized components.

This embedding can also ‘work’ even if the adjacency variable is not strictly the adjacency matrix of a graph but more generally an affinity or similarity matrix between samples (for instance the heat kernel of a euclidean distance matrix or a k-NN matrix).

However care must taken to always make the affinity matrix symmetric so that the eigenvector decomposition works as expected.

Note : Laplacian Eigenmaps is the actual algorithm implemented here.

Read more in the User Guide.

The adjacency matrix of the graph to embed.

The dimension of the projection subspace.

The eigenvalue decomposition strategy to use. AMG requires pyamg to be installed. It can be faster on very large, sparse problems, but may also lead to instabilities. If None, then 'arpack' is used.

A pseudo random number generator used for the initialization of the lobpcg eigen vectors decomposition when eigen_solver == 'amg', and for the K-Means initialization. Use an int to make the results deterministic across calls (See Glossary).

When using eigen_solver == 'amg', it is necessary to also fix the global numpy seed with np.random.seed(int) to get deterministic results. See pyamg/pyamg#139 for further information.

Stopping criterion for eigendecomposition of the Laplacian matrix. If eigen_tol="auto" then the passed tolerance will depend on the eigen_solver:

If eigen_solver="arpack", then eigen_tol=0.0;

If eigen_solver="lobpcg" or eigen_solver="amg", then eigen_tol=None which configures the underlying lobpcg solver to automatically resolve the value according to their heuristics. See, scipy.sparse.linalg.lobpcg for details.

Note that when using eigen_solver="amg" values of tol<1e-5 may lead to convergence issues and should be avoided.

Added in version 1.2: Added ‘auto’ option.

If True, then compute symmetric normalized Laplacian.

Whether to drop the first eigenvector. For spectral embedding, this should be True as the first eigenvector should be constant vector for connected graph, but for spectral clustering, this should be kept as False to retain the first eigenvector.

Spectral Embedding (Laplacian Eigenmaps) is most useful when the graph has one connected component. If there graph has many components, the first few eigenvectors will simply uncover the connected components of the graph.

https://en.wikipedia.org/wiki/LOBPCG

“Toward the Optimal Preconditioned Eigensolver: Locally Optimal Block Preconditioned Conjugate Gradient Method”, Andrew V. Knyazev

**Examples:**

Example 1 (sql):
```sql
>>> from sklearn.datasets import load_digits
>>> from sklearn.neighbors import kneighbors_graph
>>> from sklearn.manifold import spectral_embedding
>>> X, _ = load_digits(return_X_y=True)
>>> X = X[:100]
>>> affinity_matrix = kneighbors_graph(
...     X, n_neighbors=int(X.shape[0] / 10), include_self=True
... )
>>> # make the matrix symmetric
>>> affinity_matrix = 0.5 * (affinity_matrix + affinity_matrix.T)
>>> embedding = spectral_embedding(affinity_matrix, n_components=2, random_state=42)
>>> embedding.shape
(100, 2)
```

---

## ARDRegression#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.ARDRegression.html

**Contents:**
- ARDRegression#
- Gallery examples#

Bayesian ARD regression.

Fit the weights of a regression model, using an ARD prior. The weights of the regression model are assumed to be in Gaussian distributions. Also estimate the parameters lambda (precisions of the distributions of the weights) and alpha (precision of the distribution of the noise). The estimation is done by an iterative procedures (Evidence Maximization)

Read more in the User Guide.

Maximum number of iterations.

Changed in version 1.3.

Stop the algorithm if w has converged.

Hyper-parameter : shape parameter for the Gamma distribution prior over the alpha parameter.

Hyper-parameter : inverse scale parameter (rate parameter) for the Gamma distribution prior over the alpha parameter.

Hyper-parameter : shape parameter for the Gamma distribution prior over the lambda parameter.

Hyper-parameter : inverse scale parameter (rate parameter) for the Gamma distribution prior over the lambda parameter.

If True, compute the objective function at each step of the model.

Threshold for removing (pruning) weights with high precision from the computation.

Whether to calculate the intercept for this model. If set to false, no intercept will be used in calculations (i.e. data is expected to be centered).

If True, X will be copied; else, it may be overwritten.

Verbose mode when fitting the model.

Coefficients of the regression model (mean of distribution)

estimated precision of the noise.

estimated precisions of the weights.

estimated variance-covariance matrix of the weights

if computed, value of the objective function (to be maximized)

The actual number of iterations to reach the stopping criterion.

Added in version 1.3.

Independent term in decision function. Set to 0.0 if fit_intercept = False.

If fit_intercept=True, offset subtracted for centering data to a zero mean. Set to np.zeros(n_features) otherwise.

Set to np.ones(n_features).

Number of features seen during fit.

Added in version 0.24.

Names of features seen during fit. Defined only when X has feature names that are all strings.

Added in version 1.0.

Bayesian ridge regression.

D. J. C. MacKay, Bayesian nonlinear modeling for the prediction competition, ASHRAE Transactions, 1994.

R. Salakhutdinov, Lecture notes on Statistical Machine Learning, http://www.utstat.toronto.edu/~rsalakhu/sta4273/notes/Lecture2.pdf#page=15 Their beta is our self.alpha_ Their alpha is our self.lambda_ ARD is a little different than the slide: only dimensions/features for which self.lambda_ < self.threshold_lambda are kept and the rest are discarded.

Comparing Linear Bayesian Regressors demonstrates ARD Regression.

L1-based models for Sparse Signals showcases ARD Regression alongside Lasso and Elastic-Net for sparse, correlated signals, in the presence of noise.

Fit the model according to the given training data and parameters.

Iterative procedure to maximize the evidence

Training vector, where n_samples is the number of samples and n_features is the number of features.

Target values (integers). Will be cast to X’s dtype if necessary.

Get metadata routing of this object.

Please check User Guide on how the routing mechanism works.

A MetadataRequest encapsulating routing information.

Get parameters for this estimator.

If True, will return the parameters for this estimator and contained subobjects that are estimators.

Parameter names mapped to their values.

Predict using the linear model.

In addition to the mean of the predictive distribution, also its standard deviation can be returned.

Whether to return the standard deviation of posterior prediction.

Mean of predictive distribution of query points.

Standard deviation of predictive distribution of query points.

Return coefficient of determination on test data.

The coefficient of determination, \(R^2\), is defined as \((1 - \frac{u}{v})\), where \(u\) is the residual sum of squares ((y_true - y_pred)** 2).sum() and \(v\) is the total sum of squares ((y_true - y_true.mean()) ** 2).sum(). The best possible score is 1.0 and it can be negative (because the model can be arbitrarily worse). A constant model that always predicts the expected value of y, disregarding the input features, would get a \(R^2\) score of 0.0.

Test samples. For some estimators this may be a precomputed kernel matrix or a list of generic objects instead with shape (n_samples, n_samples_fitted), where n_samples_fitted is the number of samples used in the fitting for the estimator.

\(R^2\) of self.predict(X) w.r.t. y.

The \(R^2\) score used when calling score on a regressor uses multioutput='uniform_average' from version 0.23 to keep consistent with default value of r2_score. This influences the score method of all the multioutput regressors (except for MultiOutputRegressor).

Set the parameters of this estimator.

The method works on simple estimators as well as on nested objects (such as Pipeline). The latter have parameters of the form <component>__<parameter> so that it’s possible to update each component of a nested object.

Estimator parameters.

Configure whether metadata should be requested to be passed to the predict method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to predict if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to predict.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Added in version 1.3.

Metadata routing for return_std parameter in predict.

Configure whether metadata should be requested to be passed to the score method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to score if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to score.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Added in version 1.3.

Metadata routing for sample_weight parameter in score.

Comparing Linear Bayesian Regressors

L1-based models for Sparse Signals

**Examples:**

Example 1 (python):
```python
>>> from sklearn import linear_model
>>> clf = linear_model.ARDRegression()
>>> clf.fit([[0,0], [1, 1], [2, 2]], [0, 1, 2])
ARDRegression()
>>> clf.predict([[1, 1]])
array([1.])
```

---

## StackingClassifier#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.StackingClassifier.html

**Contents:**
- StackingClassifier#
- Gallery examples#

Stack of estimators with a final classifier.

Stacked generalization consists in stacking the output of individual estimator and use a classifier to compute the final prediction. Stacking allows to use the strength of each individual estimator by using their output as input of a final estimator.

Note that estimators_ are fitted on the full X while final_estimator_ is trained using cross-validated predictions of the base estimators using cross_val_predict.

Read more in the User Guide.

Added in version 0.22.

Base estimators which will be stacked together. Each element of the list is defined as a tuple of string (i.e. name) and an estimator instance. An estimator can be set to ‘drop’ using set_params.

The type of estimator is generally expected to be a classifier. However, one can pass a regressor for some use case (e.g. ordinal regression).

A classifier which will be used to combine the base estimators. The default classifier is a LogisticRegression.

Determines the cross-validation splitting strategy used in cross_val_predict to train final_estimator. Possible inputs for cv are:

None, to use the default 5-fold cross validation,

integer, to specify the number of folds in a (Stratified) KFold,

An object to be used as a cross-validation generator,

An iterable yielding train, test splits,

"prefit", to assume the estimators are prefit. In this case, the estimators will not be refitted.

For integer/None inputs, if the estimator is a classifier and y is either binary or multiclass, StratifiedKFold is used. In all other cases, KFold is used. These splitters are instantiated with shuffle=False so the splits will be the same across calls.

Refer User Guide for the various cross-validation strategies that can be used here.

If “prefit” is passed, it is assumed that all estimators have been fitted already. The final_estimator_ is trained on the estimators predictions on the full training set and are not cross validated predictions. Please note that if the models have been trained on the same data to train the stacking model, there is a very high risk of overfitting.

Added in version 1.1: The ‘prefit’ option was added in 1.1

A larger number of split will provide no benefits if the number of training samples is large enough. Indeed, the training time will increase. cv is not used for model evaluation but for prediction.

Methods called for each base estimator. It can be:

if ‘auto’, it will try to invoke, for each estimator, 'predict_proba', 'decision_function' or 'predict' in that order.

otherwise, one of 'predict_proba', 'decision_function' or 'predict'. If the method is not implemented by the estimator, it will raise an error.

The number of jobs to run in parallel for fit of all estimators. None means 1 unless in a joblib.parallel_backend context. -1 means using all processors. See Glossary for more details.

When False, only the predictions of estimators will be used as training data for final_estimator. When True, the final_estimator is trained on the predictions as well as the original training data.

The elements of the estimators parameter, having been fitted on the training data. If an estimator has been set to 'drop', it will not appear in estimators_. When cv="prefit", estimators_ is set to estimators and is not fitted again.

Attribute to access any fitted sub-estimators by name.

Number of features seen during fit.

Names of features seen during fit. Only defined if the underlying estimators expose such an attribute when fit.

Added in version 1.0.

The classifier fit on the output of estimators_ and responsible for final predictions.

The method used by each base estimator.

Stack of estimators with a final regressor.

When predict_proba is used by each estimator (i.e. most of the time for stack_method='auto' or specifically for stack_method='predict_proba'), the first column predicted by each estimator will be dropped in the case of a binary classification problem. Indeed, both feature will be perfectly collinear.

In some cases (e.g. ordinal regression), one can pass regressors as the first layer of the StackingClassifier. However, note that y will be internally encoded in a numerically increasing order or lexicographic order. If this ordering is not adequate, one should manually numerically encode the classes in the desired order.

Wolpert, David H. “Stacked generalization.” Neural networks 5.2 (1992): 241-259.

Decision function for samples in X using the final estimator.

Training vectors, where n_samples is the number of samples and n_features is the number of features.

The decision function computed the final estimator.

Training vectors, where n_samples is the number of samples and n_features is the number of features.

Target values. Note that y will be internally encoded in numerically increasing order or lexicographic order. If the order matter (e.g. for ordinal regression), one should numerically encode the target y before calling fit.

Parameters to pass to the underlying estimators.

Added in version 1.6: Only available if enable_metadata_routing=True, which can be set by using sklearn.set_config(enable_metadata_routing=True). See Metadata Routing User Guide for more details.

Returns a fitted instance of estimator.

Fit to data, then transform it.

Fits transformer to X and y with optional parameters fit_params and returns a transformed version of X.

Target values (None for unsupervised transformations).

Additional fit parameters. Pass only if the estimator accepts additional params in its fit method.

Get output feature names for transformation.

Input features. The input feature names are only used when passthrough is True.

If input_features is None, then feature_names_in_ is used as feature names in. If feature_names_in_ is not defined, then names are generated: [x0, x1, ..., x(n_features_in_ - 1)].

If input_features is an array-like, then input_features must match feature_names_in_ if feature_names_in_ is defined.

If passthrough is False, then only the names of estimators are used to generate the output feature names.

Transformed feature names.

Get metadata routing of this object.

Please check User Guide on how the routing mechanism works.

Added in version 1.6.

A MetadataRouter encapsulating routing information.

Get the parameters of an estimator from the ensemble.

Returns the parameters given in the constructor as well as the estimators contained within the estimators parameter.

Setting it to True gets the various estimators and the parameters of the estimators as well.

Parameter and estimator names mapped to their values or parameter names mapped to their values.

Dictionary to access any fitted sub-estimators by name.

Predict target for X.

Training vectors, where n_samples is the number of samples and n_features is the number of features.

Parameters to the predict called by the final_estimator. Note that this may be used to return uncertainties from some estimators with return_std or return_cov. Be aware that it will only account for uncertainty in the final estimator.

If enable_metadata_routing=False (default): Parameters directly passed to the predict method of the final_estimator.

If enable_metadata_routing=True: Parameters safely routed to the predict method of the final_estimator. See Metadata Routing User Guide for more details.

Changed in version 1.6: **predict_params can be routed via metadata routing API.

Predict class probabilities for X using the final estimator.

Training vectors, where n_samples is the number of samples and n_features is the number of features.

The class probabilities of the input samples.

Return accuracy on provided data and labels.

In multi-label classification, this is the subset accuracy which is a harsh metric since you require for each sample that each label set be correctly predicted.

Mean accuracy of self.predict(X) w.r.t. y.

Set output container.

See Introducing the set_output API for an example on how to use the API.

Configure output of transform and fit_transform.

"default": Default output format of a transformer

"pandas": DataFrame output

"polars": Polars output

None: Transform configuration is unchanged

Added in version 1.4: "polars" option was added.

Set the parameters of an estimator from the ensemble.

Valid parameter keys can be listed with get_params(). Note that you can directly set the parameters of the estimators contained in estimators.

Specific parameters using e.g. set_params(parameter_name=new_value). In addition, to setting the parameters of the estimator, the individual estimator of the estimators can also be set, or can be removed by setting them to ‘drop’.

Configure whether metadata should be requested to be passed to the score method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to score if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to score.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Added in version 1.3.

Metadata routing for sample_weight parameter in score.

Return class labels or probabilities for X for each estimator.

Training vectors, where n_samples is the number of samples and n_features is the number of features.

Prediction outputs for each estimator.

Release Highlights for scikit-learn 0.22

**Examples:**

Example 1 (sql):
```sql
>>> from sklearn.datasets import load_iris
>>> from sklearn.ensemble import RandomForestClassifier
>>> from sklearn.svm import LinearSVC
>>> from sklearn.linear_model import LogisticRegression
>>> from sklearn.preprocessing import StandardScaler
>>> from sklearn.pipeline import make_pipeline
>>> from sklearn.ensemble import StackingClassifier
>>> X, y = load_iris(return_X_y=True)
>>> estimators = [
...     ('rf', RandomForestClassifier(n_estimators=10, random_state=42)),
...     ('svr', make_pipeline(StandardScaler(),
...                           LinearSVC(random_state=42)))
... ]
>>> clf = StackingClassifier(
...     estimators=estimators, final_estimator=LogisticRegression()
... )
>>> from sklearn.model_selection import train_test_split
>>> X_train, X_test, y_train, y_test = train_test_split(
...     X, y, stratify=y, random_state=42
... )
>>> clf.fit(X_train, y_train).score(X_test, y_test)
0.9...
```

---

## DecisionTreeRegressor#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html

**Contents:**
- DecisionTreeRegressor#
- Gallery examples#

A decision tree regressor.

Read more in the User Guide.

The function to measure the quality of a split. Supported criteria are “squared_error” for the mean squared error, which is equal to variance reduction as feature selection criterion and minimizes the L2 loss using the mean of each terminal node, “friedman_mse”, which uses mean squared error with Friedman’s improvement score for potential splits, “absolute_error” for the mean absolute error, which minimizes the L1 loss using the median of each terminal node, and “poisson” which uses reduction in the half mean Poisson deviance to find splits.

Added in version 0.18: Mean Absolute Error (MAE) criterion.

Added in version 0.24: Poisson deviance criterion.

The strategy used to choose the split at each node. Supported strategies are “best” to choose the best split and “random” to choose the best random split.

The maximum depth of the tree. If None, then nodes are expanded until all leaves are pure or until all leaves contain less than min_samples_split samples.

For an example of how max_depth influences the model, see Decision Tree Regression.

The minimum number of samples required to split an internal node:

If int, then consider min_samples_split as the minimum number.

If float, then min_samples_split is a fraction and ceil(min_samples_split * n_samples) are the minimum number of samples for each split.

Changed in version 0.18: Added float values for fractions.

The minimum number of samples required to be at a leaf node. A split point at any depth will only be considered if it leaves at least min_samples_leaf training samples in each of the left and right branches. This may have the effect of smoothing the model, especially in regression.

If int, then consider min_samples_leaf as the minimum number.

If float, then min_samples_leaf is a fraction and ceil(min_samples_leaf * n_samples) are the minimum number of samples for each node.

Changed in version 0.18: Added float values for fractions.

The minimum weighted fraction of the sum total of weights (of all the input samples) required to be at a leaf node. Samples have equal weight when sample_weight is not provided.

The number of features to consider when looking for the best split:

If int, then consider max_features features at each split.

If float, then max_features is a fraction and max(1, int(max_features * n_features_in_)) features are considered at each split.

If “sqrt”, then max_features=sqrt(n_features).

If “log2”, then max_features=log2(n_features).

If None, then max_features=n_features.

Note: the search for a split does not stop until at least one valid partition of the node samples is found, even if it requires to effectively inspect more than max_features features.

Controls the randomness of the estimator. The features are always randomly permuted at each split, even if splitter is set to "best". When max_features < n_features, the algorithm will select max_features at random at each split before finding the best split among them. But the best found split may vary across different runs, even if max_features=n_features. That is the case, if the improvement of the criterion is identical for several splits and one split has to be selected at random. To obtain a deterministic behaviour during fitting, random_state has to be fixed to an integer. See Glossary for details.

Grow a tree with max_leaf_nodes in best-first fashion. Best nodes are defined as relative reduction in impurity. If None then unlimited number of leaf nodes.

A node will be split if this split induces a decrease of the impurity greater than or equal to this value.

The weighted impurity decrease equation is the following:

where N is the total number of samples, N_t is the number of samples at the current node, N_t_L is the number of samples in the left child, and N_t_R is the number of samples in the right child.

N, N_t, N_t_R and N_t_L all refer to the weighted sum, if sample_weight is passed.

Added in version 0.19.

Complexity parameter used for Minimal Cost-Complexity Pruning. The subtree with the largest cost complexity that is smaller than ccp_alpha will be chosen. By default, no pruning is performed. See Minimal Cost-Complexity Pruning for details. See Post pruning decision trees with cost complexity pruning for an example of such pruning.

Added in version 0.22.

1: monotonic increase

-1: monotonic decrease

If monotonic_cst is None, no constraints are applied.

multioutput regressions (i.e. when n_outputs_ > 1),

regressions trained on data with missing values.

Read more in the User Guide.

Added in version 1.4.

Return the feature importances.

The inferred value of max_features.

Number of features seen during fit.

Added in version 0.24.

Names of features seen during fit. Defined only when X has feature names that are all strings.

Added in version 1.0.

The number of outputs when fit is performed.

The underlying Tree object. Please refer to help(sklearn.tree._tree.Tree) for attributes of Tree object and Understanding the decision tree structure for basic usage of these attributes.

A decision tree classifier.

The default values for the parameters controlling the size of the trees (e.g. max_depth, min_samples_leaf, etc.) lead to fully grown and unpruned trees which can potentially be very large on some data sets. To reduce memory consumption, the complexity and size of the trees should be controlled by setting those parameter values.

https://en.wikipedia.org/wiki/Decision_tree_learning

L. Breiman, J. Friedman, R. Olshen, and C. Stone, “Classification and Regression Trees”, Wadsworth, Belmont, CA, 1984.

T. Hastie, R. Tibshirani and J. Friedman. “Elements of Statistical Learning”, Springer, 2009.

L. Breiman, and A. Cutler, “Random Forests”, https://www.stat.berkeley.edu/~breiman/RandomForests/cc_home.htm

Return the index of the leaf that each sample is predicted as.

Added in version 0.17.

The input samples. Internally, it will be converted to dtype=np.float32 and if a sparse matrix is provided to a sparse csr_matrix.

Allow to bypass several input checking. Don’t use this parameter unless you know what you’re doing.

For each datapoint x in X, return the index of the leaf x ends up in. Leaves are numbered within [0; self.tree_.node_count), possibly with gaps in the numbering.

Compute the pruning path during Minimal Cost-Complexity Pruning.

See Minimal Cost-Complexity Pruning for details on the pruning process.

The training input samples. Internally, it will be converted to dtype=np.float32 and if a sparse matrix is provided to a sparse csc_matrix.

The target values (class labels) as integers or strings.

Sample weights. If None, then samples are equally weighted. Splits that would create child nodes with net zero or negative weight are ignored while searching for a split in each node. Splits are also ignored if they would result in any single class carrying a negative weight in either child node.

Dictionary-like object, with the following attributes.

Effective alphas of subtree during pruning.

Sum of the impurities of the subtree leaves for the corresponding alpha value in ccp_alphas.

Return the decision path in the tree.

Added in version 0.18.

The input samples. Internally, it will be converted to dtype=np.float32 and if a sparse matrix is provided to a sparse csr_matrix.

Allow to bypass several input checking. Don’t use this parameter unless you know what you’re doing.

Return a node indicator CSR matrix where non zero elements indicates that the samples goes through the nodes.

Build a decision tree regressor from the training set (X, y).

The training input samples. Internally, it will be converted to dtype=np.float32 and if a sparse matrix is provided to a sparse csc_matrix.

The target values (real numbers). Use dtype=np.float64 and order='C' for maximum efficiency.

Sample weights. If None, then samples are equally weighted. Splits that would create child nodes with net zero or negative weight are ignored while searching for a split in each node.

Allow to bypass several input checking. Don’t use this parameter unless you know what you’re doing.

Return the depth of the decision tree.

The depth of a tree is the maximum distance between the root and any leaf.

The maximum depth of the tree.

Get metadata routing of this object.

Please check User Guide on how the routing mechanism works.

A MetadataRequest encapsulating routing information.

Return the number of leaves of the decision tree.

Get parameters for this estimator.

If True, will return the parameters for this estimator and contained subobjects that are estimators.

Parameter names mapped to their values.

Predict class or regression value for X.

For a classification model, the predicted class for each sample in X is returned. For a regression model, the predicted value based on X is returned.

The input samples. Internally, it will be converted to dtype=np.float32 and if a sparse matrix is provided to a sparse csr_matrix.

Allow to bypass several input checking. Don’t use this parameter unless you know what you’re doing.

The predicted classes, or the predict values.

Return coefficient of determination on test data.

The coefficient of determination, \(R^2\), is defined as \((1 - \frac{u}{v})\), where \(u\) is the residual sum of squares ((y_true - y_pred)** 2).sum() and \(v\) is the total sum of squares ((y_true - y_true.mean()) ** 2).sum(). The best possible score is 1.0 and it can be negative (because the model can be arbitrarily worse). A constant model that always predicts the expected value of y, disregarding the input features, would get a \(R^2\) score of 0.0.

Test samples. For some estimators this may be a precomputed kernel matrix or a list of generic objects instead with shape (n_samples, n_samples_fitted), where n_samples_fitted is the number of samples used in the fitting for the estimator.

\(R^2\) of self.predict(X) w.r.t. y.

The \(R^2\) score used when calling score on a regressor uses multioutput='uniform_average' from version 0.23 to keep consistent with default value of r2_score. This influences the score method of all the multioutput regressors (except for MultiOutputRegressor).

Configure whether metadata should be requested to be passed to the fit method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to fit if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to fit.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Added in version 1.3.

Metadata routing for sample_weight parameter in fit.

Set the parameters of this estimator.

The method works on simple estimators as well as on nested objects (such as Pipeline). The latter have parameters of the form <component>__<parameter> so that it’s possible to update each component of a nested object.

Estimator parameters.

Configure whether metadata should be requested to be passed to the score method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to score if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to score.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Added in version 1.3.

Metadata routing for sample_weight parameter in score.

Decision Tree Regression with AdaBoost

Single estimator versus bagging: bias-variance decomposition

Advanced Plotting With Partial Dependence

Using KBinsDiscretizer to discretize continuous features

Release Highlights for scikit-learn 0.22

Release Highlights for scikit-learn 0.24

Release Highlights for scikit-learn 1.8

Decision Tree Regression

**Examples:**

Example 1 (yaml):
```yaml
N_t / N * (impurity - N_t_R / N_t * right_impurity
                    - N_t_L / N_t * left_impurity)
```

Example 2 (sql):
```sql
>>> from sklearn.datasets import load_diabetes
>>> from sklearn.model_selection import cross_val_score
>>> from sklearn.tree import DecisionTreeRegressor
>>> X, y = load_diabetes(return_X_y=True)
>>> regressor = DecisionTreeRegressor(random_state=0)
>>> cross_val_score(regressor, X, y, cv=10)
...
...
array([-0.39, -0.46,  0.02,  0.06, -0.50,
       0.16,  0.11, -0.73, -0.30, -0.00])
```

---

## grid_to_graph#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.image.grid_to_graph.html

**Contents:**
- grid_to_graph#

Graph of the pixel-to-pixel connections.

Edges exist if 2 voxels are connected.

Read more in the User Guide.

An optional mask of the image, to consider only part of the pixels.

The class to use to build the returned adjacency matrix.

The data of the returned sparse matrix. By default it is int.

The computed adjacency matrix.

**Examples:**

Example 1 (jsx):
```jsx
>>> import numpy as np
>>> from sklearn.feature_extraction.image import grid_to_graph
>>> shape_img = (4, 4, 1)
>>> mask = np.zeros(shape=shape_img, dtype=bool)
>>> mask[[1, 2], [1, 2], :] = True
>>> graph = grid_to_graph(*shape_img, mask=mask)
>>> print(graph)
<COOrdinate sparse matrix of dtype 'int64'
  with 2 stored elements and shape (2, 2)>
  Coords    Values
  (0, 0)    1
  (1, 1)    1
```

---

## NearestCentroid#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.NearestCentroid.html

**Contents:**
- NearestCentroid#
- Gallery examples#

Nearest centroid classifier.

Each class is represented by its centroid, with test samples classified to the class with the nearest centroid.

Read more in the User Guide.

Metric to use for distance computation.

If metric="euclidean", the centroid for the samples corresponding to each class is the arithmetic mean, which minimizes the sum of squared L1 distances. If metric="manhattan", the centroid is the feature-wise median, which minimizes the sum of L1 distances.

Changed in version 1.5: All metrics but "euclidean" and "manhattan" were deprecated and now raise an error.

Changed in version 0.19: metric='precomputed' was deprecated and now raises an error

Threshold for shrinking centroids to remove features.

The class prior probabilities. By default, the class proportions are inferred from the training data.

Added in version 1.6.

Centroid of each class.

The unique classes labels.

Number of features seen during fit.

Added in version 0.24.

Names of features seen during fit. Defined only when X has feature names that are all strings.

Added in version 1.0.

Deviations (or shrinkages) of the centroids of each class from the overall centroid. Equal to eq. (18.4) if shrink_threshold=None, else (18.5) p. 653 of [2]. Can be used to identify features used for classification.

Added in version 1.6.

Pooled or within-class standard deviation of input data.

Added in version 1.6.

The class prior probabilities.

Added in version 1.6.

Nearest neighbors classifier.

When used for text classification with tf-idf vectors, this classifier is also known as the Rocchio classifier.

[1] Tibshirani, R., Hastie, T., Narasimhan, B., & Chu, G. (2002). Diagnosis of multiple cancer types by shrunken centroids of gene expression. Proceedings of the National Academy of Sciences of the United States of America, 99(10), 6567-6572. The National Academy of Sciences.

[2] Hastie, T., Tibshirani, R., Friedman, J. (2009). The Elements of Statistical Learning Data Mining, Inference, and Prediction. 2nd Edition. New York, Springer.

Apply decision function to an array of samples.

Array of samples (test vectors).

Decision function values related to each class, per sample. In the two-class case, the shape is (n_samples,), giving the log likelihood ratio of the positive class.

Fit the NearestCentroid model according to the given training data.

Training vector, where n_samples is the number of samples and n_features is the number of features. Note that centroid shrinking cannot be used with sparse matrices.

Get metadata routing of this object.

Please check User Guide on how the routing mechanism works.

A MetadataRequest encapsulating routing information.

Get parameters for this estimator.

If True, will return the parameters for this estimator and contained subobjects that are estimators.

Parameter names mapped to their values.

Perform classification on an array of test vectors X.

The predicted class C for each sample in X is returned.

The predicted classes.

Estimate log class probabilities.

Estimated log probabilities.

Estimate class probabilities.

Probability estimate of the sample for each class in the model, where classes are ordered as they are in self.classes_.

Return accuracy on provided data and labels.

In multi-label classification, this is the subset accuracy which is a harsh metric since you require for each sample that each label set be correctly predicted.

Mean accuracy of self.predict(X) w.r.t. y.

Set the parameters of this estimator.

The method works on simple estimators as well as on nested objects (such as Pipeline). The latter have parameters of the form <component>__<parameter> so that it’s possible to update each component of a nested object.

Estimator parameters.

Configure whether metadata should be requested to be passed to the score method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to score if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to score.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Added in version 1.3.

Metadata routing for sample_weight parameter in score.

Nearest Centroid Classification

Classification of text documents using sparse features

**Examples:**

Example 1 (python):
```python
>>> from sklearn.neighbors import NearestCentroid
>>> import numpy as np
>>> X = np.array([[-1, -1], [-2, -1], [-3, -2], [1, 1], [2, 1], [3, 2]])
>>> y = np.array([1, 1, 1, 2, 2, 2])
>>> clf = NearestCentroid()
>>> clf.fit(X, y)
NearestCentroid()
>>> print(clf.predict([[-0.8, -1]]))
[1]
```

---

## GraphicalLasso#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.covariance.GraphicalLasso.html

**Contents:**
- GraphicalLasso#

Sparse inverse covariance estimation with an l1-penalized estimator.

For a usage example see Visualizing the stock market structure.

Read more in the User Guide.

Changed in version v0.20: GraphLasso has been renamed to GraphicalLasso

The regularization parameter: the higher alpha, the more regularization, the sparser the inverse covariance. Range is (0, inf].

The Lasso solver to use: coordinate descent or LARS. Use LARS for very sparse underlying graphs, where p > n. Elsewhere prefer cd which is more numerically stable.

If covariance is “precomputed”, the input data in fit is assumed to be the covariance matrix. If None, the empirical covariance is estimated from the data X.

Added in version 1.3.

The tolerance to declare convergence: if the dual gap goes below this value, iterations are stopped. Range is (0, inf].

The tolerance for the elastic net solver used to calculate the descent direction. This parameter controls the accuracy of the search direction for a given column update, not of the overall parameter estimate. Only used for mode=’cd’. Range is (0, inf].

The maximum number of iterations.

If verbose is True, the objective function and dual gap are plotted at each iteration.

The machine-precision regularization in the computation of the Cholesky diagonal factors. Increase this for very ill-conditioned systems. Default is np.finfo(np.float64).eps.

Added in version 1.3.

If True, data are not centered before computation. Useful when working with data whose mean is almost, but not exactly zero. If False, data are centered before computation.

Estimated location, i.e. the estimated mean.

Estimated covariance matrix

Estimated pseudo inverse matrix.

Number of iterations run.

The list of values of the objective function and the dual gap at each iteration. Returned only if return_costs is True.

Added in version 1.3.

Number of features seen during fit.

Added in version 0.24.

Names of features seen during fit. Defined only when X has feature names that are all strings.

Added in version 1.0.

L1-penalized covariance estimator.

Sparse inverse covariance with cross-validated choice of the l1 penalty.

Compute the Mean Squared Error between two covariance estimators.

The covariance to compare with.

The type of norm used to compute the error. Available error types: - ‘frobenius’ (default): sqrt(tr(A^t.A)) - ‘spectral’: sqrt(max(eigenvalues(A^t.A)) where A is the error (comp_cov - self.covariance_).

If True (default), the squared error norm is divided by n_features. If False, the squared error norm is not rescaled.

Whether to compute the squared error norm or the error norm. If True (default), the squared error norm is returned. If False, the error norm is returned.

The Mean Squared Error (in the sense of the Frobenius norm) between self and comp_cov covariance estimators.

Fit the GraphicalLasso model to X.

Data from which to compute the covariance estimate.

Not used, present for API consistency by convention.

Returns the instance itself.

Get metadata routing of this object.

Please check User Guide on how the routing mechanism works.

A MetadataRequest encapsulating routing information.

Get parameters for this estimator.

If True, will return the parameters for this estimator and contained subobjects that are estimators.

Parameter names mapped to their values.

Getter for the precision matrix.

The precision matrix associated to the current covariance object.

Compute the squared Mahalanobis distances of given observations.

For a detailed example of how outliers affects the Mahalanobis distance, see Robust covariance estimation and Mahalanobis distances relevance.

The observations, the Mahalanobis distances of the which we compute. Observations are assumed to be drawn from the same distribution than the data used in fit.

Squared Mahalanobis distances of the observations.

Compute the log-likelihood of X_test under the estimated Gaussian model.

The Gaussian model is defined by its mean and covariance matrix which are represented respectively by self.location_ and self.covariance_.

Test data of which we compute the likelihood, where n_samples is the number of samples and n_features is the number of features. X_test is assumed to be drawn from the same distribution than the data used in fit (including centering).

Not used, present for API consistency by convention.

The log-likelihood of X_test with self.location_ and self.covariance_ as estimators of the Gaussian model mean and covariance matrix respectively.

Set the parameters of this estimator.

The method works on simple estimators as well as on nested objects (such as Pipeline). The latter have parameters of the form <component>__<parameter> so that it’s possible to update each component of a nested object.

Estimator parameters.

**Examples:**

Example 1 (sql):
```sql
>>> import numpy as np
>>> from sklearn.covariance import GraphicalLasso
>>> true_cov = np.array([[0.8, 0.0, 0.2, 0.0],
...                      [0.0, 0.4, 0.0, 0.0],
...                      [0.2, 0.0, 0.3, 0.1],
...                      [0.0, 0.0, 0.1, 0.7]])
>>> np.random.seed(0)
>>> X = np.random.multivariate_normal(mean=[0, 0, 0, 0],
...                                   cov=true_cov,
...                                   size=200)
>>> cov = GraphicalLasso().fit(X)
>>> np.around(cov.covariance_, decimals=3)
array([[0.816, 0.049, 0.218, 0.019],
       [0.049, 0.364, 0.017, 0.034],
       [0.218, 0.017, 0.322, 0.093],
       [0.019, 0.034, 0.093, 0.69 ]])
>>> np.around(cov.location_, decimals=3)
array([0.073, 0.04 , 0.038, 0.143])
```

---

## 2.8. Density Estimation#

**URL:** https://scikit-learn.org/stable/modules/density.html

**Contents:**
- 2.8. Density Estimation#
- 2.8.1. Density Estimation: Histograms#
- 2.8.2. Kernel Density Estimation#

Density estimation walks the line between unsupervised learning, feature engineering, and data modeling. Some of the most popular and useful density estimation techniques are mixture models such as Gaussian Mixtures (GaussianMixture), and neighbor-based approaches such as the kernel density estimate (KernelDensity). Gaussian Mixtures are discussed more fully in the context of clustering, because the technique is also useful as an unsupervised clustering scheme.

Density estimation is a very simple concept, and most people are already familiar with one common density estimation technique: the histogram.

A histogram is a simple visualization of data where bins are defined, and the number of data points within each bin is tallied. An example of a histogram can be seen in the upper-left panel of the following figure:

A major problem with histograms, however, is that the choice of binning can have a disproportionate effect on the resulting visualization. Consider the upper-right panel of the above figure. It shows a histogram over the same data, with the bins shifted right. The results of the two visualizations look entirely different, and might lead to different interpretations of the data.

Intuitively, one can also think of a histogram as a stack of blocks, one block per point. By stacking the blocks in the appropriate grid space, we recover the histogram. But what if, instead of stacking the blocks on a regular grid, we center each block on the point it represents, and sum the total height at each location? This idea leads to the lower-left visualization. It is perhaps not as clean as a histogram, but the fact that the data drive the block locations mean that it is a much better representation of the underlying data.

This visualization is an example of a kernel density estimation, in this case with a top-hat kernel (i.e. a square block at each point). We can recover a smoother distribution by using a smoother kernel. The bottom-right plot shows a Gaussian kernel density estimate, in which each point contributes a Gaussian curve to the total. The result is a smooth density estimate which is derived from the data, and functions as a powerful non-parametric model of the distribution of points.

Kernel density estimation in scikit-learn is implemented in the KernelDensity estimator, which uses the Ball Tree or KD Tree for efficient queries (see Nearest Neighbors for a discussion of these). Though the above example uses a 1D data set for simplicity, kernel density estimation can be performed in any number of dimensions, though in practice the curse of dimensionality causes its performance to degrade in high dimensions.

In the following figure, 100 points are drawn from a bimodal distribution, and the kernel density estimates are shown for three choices of kernels:

It’s clear how the kernel shape affects the smoothness of the resulting distribution. The scikit-learn kernel density estimator can be used as follows:

Here we have used kernel='gaussian', as seen above. Mathematically, a kernel is a positive function \(K(x;h)\) which is controlled by the bandwidth parameter \(h\). Given this kernel form, the density estimate at a point \(y\) within a group of points \(x_i; i=1, \cdots, N\) is given by:

The bandwidth here acts as a smoothing parameter, controlling the tradeoff between bias and variance in the result. A large bandwidth leads to a very smooth (i.e. high-bias) density distribution. A small bandwidth leads to an unsmooth (i.e. high-variance) density distribution.

The parameter bandwidth controls this smoothing. One can either set manually this parameter or use Scott’s and Silverman’s estimation methods.

KernelDensity implements several common kernel forms, which are shown in the following figure:

The form of these kernels is as follows:

Gaussian kernel (kernel = 'gaussian')

\(K(x; h) \propto \exp(- \frac{x^2}{2h^2} )\)

Tophat kernel (kernel = 'tophat')

\(K(x; h) \propto 1\) if \(x < h\)

Epanechnikov kernel (kernel = 'epanechnikov')

\(K(x; h) \propto 1 - \frac{x^2}{h^2}\)

Exponential kernel (kernel = 'exponential')

\(K(x; h) \propto \exp(-x/h)\)

Linear kernel (kernel = 'linear')

\(K(x; h) \propto 1 - x/h\) if \(x < h\)

Cosine kernel (kernel = 'cosine')

\(K(x; h) \propto \cos(\frac{\pi x}{2h})\) if \(x < h\)

The kernel density estimator can be used with any of the valid distance metrics (see DistanceMetric for a list of available metrics), though the results are properly normalized only for the Euclidean metric. One particularly useful metric is the Haversine distance which measures the angular distance between points on a sphere. Here is an example of using a kernel density estimate for a visualization of geospatial data, in this case the distribution of observations of two different species on the South American continent:

One other useful application of kernel density estimation is to learn a non-parametric generative model of a dataset in order to efficiently draw new samples from this generative model. Here is an example of using this process to create a new set of hand-written digits, using a Gaussian kernel learned on a PCA projection of the data:

The “new” data consists of linear combinations of the input data, with weights probabilistically drawn given the KDE model.

Simple 1D Kernel Density Estimation: computation of simple kernel density estimates in one dimension.

Kernel Density Estimation: an example of using Kernel Density estimation to learn a generative model of the hand-written digits data, and drawing new samples from this model.

Kernel Density Estimate of Species Distributions: an example of Kernel Density estimation using the Haversine distance metric to visualize geospatial data

**Examples:**

Example 1 (sql):
```sql
>>> from sklearn.neighbors import KernelDensity
>>> import numpy as np
>>> X = np.array([[-1, -1], [-2, -1], [-3, -2], [1, 1], [2, 1], [3, 2]])
>>> kde = KernelDensity(kernel='gaussian', bandwidth=0.2).fit(X)
>>> kde.score_samples(X)
array([-0.41075698, -0.41075698, -0.41076071, -0.41075698, -0.41075698,
       -0.41076071])
```

---

## plot_tree#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.tree.plot_tree.html

**Contents:**
- plot_tree#
- Gallery examples#

Plot a decision tree.

The sample counts that are shown are weighted with any sample_weights that might be present.

The visualization is fit automatically to the size of the axis. Use the figsize or dpi arguments of plt.figure to control the size of the rendering.

Read more in the User Guide.

Added in version 0.21.

The decision tree to be plotted.

The maximum depth of the representation. If None, the tree is fully generated.

Names of each of the features. If None, generic names will be used (“x[0]”, “x[1]”, …).

Names of each of the target classes in ascending numerical order. Only relevant for classification and not supported for multi-output. If True, shows a symbolic representation of the class name.

Whether to show informative labels for impurity, etc. Options include ‘all’ to show at every node, ‘root’ to show only at the top root node, or ‘none’ to not show at any node.

When set to True, paint nodes to indicate majority class for classification, extremity of values for regression, or purity of node for multi-output.

When set to True, show the impurity at each node.

When set to True, show the ID number on each node.

When set to True, change the display of ‘values’ and/or ‘samples’ to be proportions and percentages respectively.

When set to True, draw node boxes with rounded corners and use Helvetica fonts instead of Times-Roman.

Number of digits of precision for floating point in the values of impurity, threshold and value attributes of each node.

Axes to plot to. If None, use current axis. Any previous content is cleared.

Size of text font. If None, determined automatically to fit figure.

List containing the artists for the annotation boxes making up the tree.

Plot the decision surface of decision trees trained on the iris dataset

Understanding the decision tree structure

**Examples:**

Example 1 (python):
```python
>>> from sklearn.datasets import load_iris
>>> from sklearn import tree
```

Example 2 (unknown):
```unknown
>>> clf = tree.DecisionTreeClassifier(random_state=0)
>>> iris = load_iris()
```

Example 3 (json):
```json
>>> clf = clf.fit(iris.data, iris.target)
>>> tree.plot_tree(clf)
[...]
```

---

## HistGradientBoostingClassifier#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.HistGradientBoostingClassifier.html

**Contents:**
- HistGradientBoostingClassifier#
- Gallery examples#

Histogram-based Gradient Boosting Classification Tree.

This estimator is much faster than GradientBoostingClassifier for big datasets (n_samples >= 10 000).

This estimator has native support for missing values (NaNs). During training, the tree grower learns at each split point whether samples with missing values should go to the left or right child, based on the potential gain. When predicting, samples with missing values are assigned to the left or right child consequently. If no missing values were encountered for a given feature during training, then samples with missing values are mapped to whichever child has the most samples.

This implementation is inspired by LightGBM.

Read more in the User Guide.

Added in version 0.21.

The loss function to use in the boosting process.

For binary classification problems, ‘log_loss’ is also known as logistic loss, binomial deviance or binary crossentropy. Internally, the model fits one tree per boosting iteration and uses the logistic sigmoid function (expit) as inverse link function to compute the predicted positive class probability.

For multiclass classification problems, ‘log_loss’ is also known as multinomial deviance or categorical crossentropy. Internally, the model fits one tree per boosting iteration and per class and uses the softmax function as inverse link function to compute the predicted probabilities of the classes.

The learning rate, also known as shrinkage. This is used as a multiplicative factor for the leaves values. Use 1 for no shrinkage.

The maximum number of iterations of the boosting process, i.e. the maximum number of trees for binary classification. For multiclass classification, n_classes trees per iteration are built.

The maximum number of leaves for each tree. Must be strictly greater than 1. If None, there is no maximum limit.

The maximum depth of each tree. The depth of a tree is the number of edges to go from the root to the deepest leaf. Depth isn’t constrained by default.

The minimum number of samples per leaf. For small datasets with less than a few hundred samples, it is recommended to lower this value since only very shallow trees would be built.

The L2 regularization parameter penalizing leaves with small hessians. Use 0 for no regularization (default).

Proportion of randomly chosen features in each and every node split. This is a form of regularization, smaller values make the trees weaker learners and might prevent overfitting. If interaction constraints from interaction_cst are present, only allowed features are taken into account for the subsampling.

Added in version 1.4.

The maximum number of bins to use for non-missing values. Before training, each feature of the input array X is binned into integer-valued bins, which allows for a much faster training stage. Features with a small number of unique values may use less than max_bins bins. In addition to the max_bins bins, one more bin is always reserved for missing values. Must be no larger than 255.

Indicates the categorical features.

None : no feature will be considered categorical.

boolean array-like : boolean mask indicating categorical features.

integer array-like : integer indices indicating categorical features.

str array-like: names of categorical features (assuming the training data has feature names).

"from_dtype": dataframe columns with dtype “category” are considered to be categorical features. The input must be an object exposing a __dataframe__ method such as pandas or polars DataFrames to use this feature.

For each categorical feature, there must be at most max_bins unique categories. Negative values for categorical features encoded as numeric dtypes are treated as missing values. All categorical values are converted to floating point numbers. This means that categorical values of 1.0 and 1 are treated as the same category.

Read more in the User Guide.

Added in version 0.24.

Changed in version 1.2: Added support for feature names.

Changed in version 1.4: Added "from_dtype" option.

Changed in version 1.6: The default value changed from None to "from_dtype".

Monotonic constraint to enforce on each feature are specified using the following integer values:

1: monotonic increase

-1: monotonic decrease

If a dict with str keys, map feature to monotonic constraints by name. If an array, the features are mapped to constraints by position. See Using feature names to specify monotonic constraints for a usage example.

The constraints are only valid for binary classifications and hold over the probability of the positive class. Read more in the User Guide.

Added in version 0.23.

Changed in version 1.2: Accept dict of constraints with feature names as keys.

Specify interaction constraints, the sets of features which can interact with each other in child node splits.

Each item specifies the set of feature indices that are allowed to interact with each other. If there are more features than specified in these constraints, they are treated as if they were specified as an additional set.

The strings “pairwise” and “no_interactions” are shorthands for allowing only pairwise or no interactions, respectively.

For instance, with 5 features in total, interaction_cst=[{0, 1}] is equivalent to interaction_cst=[{0, 1}, {2, 3, 4}], and specifies that each branch of a tree will either only split on features 0 and 1 or only split on features 2, 3 and 4.

See this example on how to use interaction_cst.

Added in version 1.2.

When set to True, reuse the solution of the previous call to fit and add more estimators to the ensemble. For results to be valid, the estimator should be re-trained on the same data only. See the Glossary.

If ‘auto’, early stopping is enabled if the sample size is larger than 10000 or if X_val and y_val are passed to fit. If True, early stopping is enabled, otherwise early stopping is disabled.

Added in version 0.23.

Scoring method to use for early stopping. Only used if early_stopping is enabled. Options:

str: see String name scorers for options.

callable: a scorer callable object (e.g., function) with signature scorer(estimator, X, y). See Callable scorers for details.

None: accuracy is used.

‘loss’: early stopping is checked w.r.t the loss value.

Proportion (or absolute size) of training data to set aside as validation data for early stopping. If None, early stopping is done on the training data. The value is ignored if either early stopping is not performed, e.g. early_stopping=False, or if X_val and y_val are passed to fit.

Used to determine when to “early stop”. The fitting process is stopped when none of the last n_iter_no_change scores are better than the n_iter_no_change - 1 -th-to-last one, up to some tolerance. Only used if early stopping is performed.

The absolute tolerance to use when comparing scores. The higher the tolerance, the more likely we are to early stop: higher tolerance means that it will be harder for subsequent iterations to be considered an improvement upon the reference score.

The verbosity level. If not zero, print some information about the fitting process. 1 prints only summary info, 2 prints info per iteration.

Pseudo-random number generator to control the subsampling in the binning process, and the train/validation data split if early stopping is enabled. Pass an int for reproducible output across multiple function calls. See Glossary.

Weights associated with classes in the form {class_label: weight}. If not given, all classes are supposed to have weight one. The “balanced” mode uses the values of y to automatically adjust weights inversely proportional to class frequencies in the input data as n_samples / (n_classes * np.bincount(y)). Note that these weights will be multiplied with sample_weight (passed through the fit method) if sample_weight is specified.

Added in version 1.2.

Indicates whether early stopping is used during training.

Number of iterations of the boosting process.

The number of tree that are built at each iteration. This is equal to 1 for binary classification, and to n_classes for multiclass classification.

The scores at each iteration on the training data. The first entry is the score of the ensemble before the first iteration. Scores are computed according to the scoring parameter. If scoring is not ‘loss’, scores are computed on a subset of at most 10 000 samples. Empty if no early stopping.

The scores at each iteration on the held-out validation data. The first entry is the score of the ensemble before the first iteration. Scores are computed according to the scoring parameter. Empty if no early stopping or if validation_fraction is None.

Boolean mask for the categorical features. None if there are no categorical features.

Number of features seen during fit.

Added in version 0.24.

Names of features seen during fit. Defined only when X has feature names that are all strings.

Added in version 1.0.

Exact gradient boosting method that does not scale as good on datasets with a large number of samples.

A decision tree classifier.

A meta-estimator that fits a number of decision tree classifiers on various sub-samples of the dataset and uses averaging to improve the predictive accuracy and control over-fitting.

A meta-estimator that begins by fitting a classifier on the original dataset and then fits additional copies of the classifier on the same dataset where the weights of incorrectly classified instances are adjusted such that subsequent classifiers focus more on difficult cases.

Compute the decision function of X.

The raw predicted values (i.e. the sum of the trees leaves) for each sample. n_trees_per_iteration is equal to the number of classes in multiclass classification.

Fit the gradient boosting model.

Weights of training data.

Added in version 0.23.

Additional sample of features for validation used in early stopping. In a Pipeline, X_val can be transformed the same way as X with Pipeline(..., transform_input=["X_val"]).

Added in version 1.7.

Additional sample of target values for validation used in early stopping.

Added in version 1.7.

Additional weights for validation used in early stopping.

Added in version 1.7.

Get metadata routing of this object.

Please check User Guide on how the routing mechanism works.

A MetadataRequest encapsulating routing information.

Get parameters for this estimator.

If True, will return the parameters for this estimator and contained subobjects that are estimators.

Parameter names mapped to their values.

Predict classes for X.

The predicted classes.

Predict class probabilities for X.

The class probabilities of the input samples.

Return accuracy on provided data and labels.

In multi-label classification, this is the subset accuracy which is a harsh metric since you require for each sample that each label set be correctly predicted.

Mean accuracy of self.predict(X) w.r.t. y.

Configure whether metadata should be requested to be passed to the fit method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to fit if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to fit.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Added in version 1.3.

Metadata routing for X_val parameter in fit.

Metadata routing for sample_weight parameter in fit.

Metadata routing for sample_weight_val parameter in fit.

Metadata routing for y_val parameter in fit.

Set the parameters of this estimator.

The method works on simple estimators as well as on nested objects (such as Pipeline). The latter have parameters of the form <component>__<parameter> so that it’s possible to update each component of a nested object.

Estimator parameters.

Configure whether metadata should be requested to be passed to the score method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to score if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to score.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Added in version 1.3.

Metadata routing for sample_weight parameter in score.

Compute decision function of X for each iteration.

This method allows monitoring (i.e. determine error on testing set) after each stage.

The decision function of the input samples, which corresponds to the raw values predicted from the trees of the ensemble . The classes corresponds to that in the attribute classes_.

Predict classes at each iteration.

This method allows monitoring (i.e. determine error on testing set) after each stage.

Added in version 0.24.

The predicted classes of the input samples, for each iteration.

Predict class probabilities at each iteration.

This method allows monitoring (i.e. determine error on testing set) after each stage.

The predicted class probabilities of the input samples, for each iteration.

Plot classification probability

Feature transformations with ensembles of trees

Comparing Random Forests and Histogram Gradient Boosting models

Post-tuning the decision threshold for cost-sensitive learning

Release Highlights for scikit-learn 0.22

Release Highlights for scikit-learn 0.23

Release Highlights for scikit-learn 0.24

Release Highlights for scikit-learn 1.4

Release Highlights for scikit-learn 1.7

**Examples:**

Example 1 (sql):
```sql
>>> from sklearn.ensemble import HistGradientBoostingClassifier
>>> from sklearn.datasets import load_iris
>>> X, y = load_iris(return_X_y=True)
>>> clf = HistGradientBoostingClassifier().fit(X, y)
>>> clf.score(X, y)
1.0
```

---

## RFECV#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFECV.html

**Contents:**
- RFECV#
- Gallery examples#

Recursive feature elimination with cross-validation to select features.

The number of features selected is tuned automatically by fitting an RFE selector on the different cross-validation splits (provided by the cv parameter). The performance of each RFE selector is evaluated using scoring for different numbers of selected features and aggregated together. Finally, the scores are averaged across folds and the number of features selected is set to the number of features that maximize the cross-validation score.

See glossary entry for cross-validation estimator.

Read more in the User Guide.

A supervised learning estimator with a fit method that provides information about feature importance either through a coef_ attribute or through a feature_importances_ attribute.

If greater than or equal to 1, then step corresponds to the (integer) number of features to remove at each iteration. If within (0.0, 1.0), then step corresponds to the percentage (rounded down) of features to remove at each iteration. Note that the last iteration may remove fewer than step features in order to reach min_features_to_select.

The minimum number of features to be selected. This number of features will always be scored, even if the difference between the original feature count and min_features_to_select isn’t divisible by step.

Added in version 0.20.

Determines the cross-validation splitting strategy. Possible inputs for cv are:

None, to use the default 5-fold cross-validation,

integer, to specify the number of folds.

An iterable yielding (train, test) splits as arrays of indices.

For integer/None inputs, if y is binary or multiclass, StratifiedKFold is used. If the estimator is not a classifier or if y is neither binary nor multiclass, KFold is used.

Refer User Guide for the various cross-validation strategies that can be used here.

Changed in version 0.22: cv default value of None changed from 3-fold to 5-fold.

Scoring method to evaluate the RFE selectors’ performance. Options:

str: see String name scorers for options.

callable: a scorer callable object (e.g., function) with signature scorer(estimator, X, y). See Callable scorers for details.

None: the estimator’s default evaluation criterion is used.

Controls verbosity of output.

Number of cores to run in parallel while fitting across folds. None means 1 unless in a joblib.parallel_backend context. -1 means using all processors. See Glossary for more details.

Added in version 0.18.

If ‘auto’, uses the feature importance either through a coef_ or feature_importances_ attributes of estimator.

Also accepts a string that specifies an attribute name/path for extracting feature importance. For example, give regressor_.coef_ in case of TransformedTargetRegressor or named_steps.clf.feature_importances_ in case of Pipeline with its last step named clf.

If callable, overrides the default feature importance getter. The callable is passed with the fitted estimator and it should return importance for each feature.

Added in version 0.24.

Classes labels available when estimator is a classifier.

The fitted estimator used to select features.

All arrays (values of the dictionary) are sorted in ascending order by the number of features used (i.e., the first element of the array represents the models that used the least number of features, while the last element represents the models that used all available features).

Added in version 1.0.

This dictionary contains the following keys:

The cross-validation scores across (k)th fold.

Mean of scores over the folds.

Standard deviation of scores over the folds.

Number of features used at each step.

Added in version 1.5.

The cross-validation rankings across (k)th fold. Selected (i.e., estimated best) features are assigned rank 1. Illustration in Recursive feature elimination with cross-validation

Added in version 1.7.

The cross-validation supports across (k)th fold. The support is the mask of selected features.

Added in version 1.7.

The number of selected features with cross-validation.

Number of features seen during fit. Only defined if the underlying estimator exposes such an attribute when fit.

Added in version 0.24.

Names of features seen during fit. Defined only when X has feature names that are all strings.

Added in version 1.0.

The feature ranking, such that ranking_[i] corresponds to the ranking position of the i-th feature. Selected (i.e., estimated best) features are assigned rank 1.

The mask of selected features.

Recursive feature elimination.

The size of all values in cv_results_ is equal to ceil((n_features - min_features_to_select) / step) + 1, where step is the number of features removed at each iteration.

Allows NaN/Inf in the input if the underlying estimator does as well.

Guyon, I., Weston, J., Barnhill, S., & Vapnik, V., “Gene selection for cancer classification using support vector machines”, Mach. Learn., 46(1-3), 389–422, 2002.

The following example shows how to retrieve the a-priori not known 5 informative features in the Friedman #1 dataset.

For a detailed example of using RFECV to select features when training a LogisticRegression, see Recursive feature elimination with cross-validation.

Compute the decision function of X.

The input samples. Internally, it will be converted to dtype=np.float32 and if a sparse matrix is provided to a sparse csr_matrix.

The decision function of the input samples. The order of the classes corresponds to that in the attribute classes_. Regression and binary classification produce an array of shape [n_samples].

Fit the RFE model and automatically tune the number of selected features.

Training vector, where n_samples is the number of samples and n_features is the total number of features.

Target values (integers for classification, real numbers for regression).

Parameters passed to the fit method of the estimator, the scorer, and the CV splitter.

Added in version 1.6: Only available if enable_metadata_routing=True, which can be set by using sklearn.set_config(enable_metadata_routing=True). See Metadata Routing User Guide for more details.

Fit to data, then transform it.

Fits transformer to X and y with optional parameters fit_params and returns a transformed version of X.

Target values (None for unsupervised transformations).

Additional fit parameters. Pass only if the estimator accepts additional params in its fit method.

Mask feature names according to selected features.

If input_features is None, then feature_names_in_ is used as feature names in. If feature_names_in_ is not defined, then the following input feature names are generated: ["x0", "x1", ..., "x(n_features_in_ - 1)"].

If input_features is an array-like, then input_features must match feature_names_in_ if feature_names_in_ is defined.

Transformed feature names.

Get metadata routing of this object.

Please check User Guide on how the routing mechanism works.

Added in version 1.6.

A MetadataRouter encapsulating routing information.

Get parameters for this estimator.

If True, will return the parameters for this estimator and contained subobjects that are estimators.

Parameter names mapped to their values.

Get a mask, or integer index, of the features selected.

If True, the return value will be an array of integers, rather than a boolean mask.

An index that selects the retained features from a feature vector. If indices is False, this is a boolean array of shape [# input features], in which an element is True iff its corresponding feature is selected for retention. If indices is True, this is an integer array of shape [# output features] whose values are indices into the input feature vector.

Reverse the transformation operation.

X with columns of zeros inserted where features would have been removed by transform.

Reduce X to the selected features and predict using the estimator.

Parameters to route to the predict method of the underlying estimator.

Added in version 1.6: Only available if enable_metadata_routing=True, which can be set by using sklearn.set_config(enable_metadata_routing=True). See Metadata Routing User Guide for more details.

The predicted target values.

Predict class log-probabilities for X.

The class log-probabilities of the input samples. The order of the classes corresponds to that in the attribute classes_.

Predict class probabilities for X.

The input samples. Internally, it will be converted to dtype=np.float32 and if a sparse matrix is provided to a sparse csr_matrix.

The class probabilities of the input samples. The order of the classes corresponds to that in the attribute classes_.

Score using the scoring option on the given test data and labels.

Parameters to pass to the score method of the underlying scorer.

Added in version 1.6: Only available if enable_metadata_routing=True, which can be set by using sklearn.set_config(enable_metadata_routing=True). See Metadata Routing User Guide for more details.

Score of self.predict(X) w.r.t. y defined by scoring.

Set output container.

See Introducing the set_output API for an example on how to use the API.

Configure output of transform and fit_transform.

"default": Default output format of a transformer

"pandas": DataFrame output

"polars": Polars output

None: Transform configuration is unchanged

Added in version 1.4: "polars" option was added.

Set the parameters of this estimator.

The method works on simple estimators as well as on nested objects (such as Pipeline). The latter have parameters of the form <component>__<parameter> so that it’s possible to update each component of a nested object.

Estimator parameters.

Reduce X to the selected features.

The input samples with only the selected features.

Recursive feature elimination with cross-validation

**Examples:**

Example 1 (sql):
```sql
>>> from sklearn.datasets import make_friedman1
>>> from sklearn.feature_selection import RFECV
>>> from sklearn.svm import SVR
>>> X, y = make_friedman1(n_samples=50, n_features=10, random_state=0)
>>> estimator = SVR(kernel="linear")
>>> selector = RFECV(estimator, step=1, cv=5)
>>> selector = selector.fit(X, y)
>>> selector.support_
array([ True,  True,  True,  True,  True, False, False, False, False,
       False])
>>> selector.ranking_
array([1, 1, 1, 1, 1, 6, 4, 3, 2, 5])
```

---

## lars_path#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.lars_path.html

**Contents:**
- lars_path#
- Gallery examples#

Compute Least Angle Regression or Lasso path using the LARS algorithm.

The optimization objective for the case method=’lasso’ is:

in the case of method=’lar’, the objective function is only known in the form of an implicit equation (see discussion in [1]).

Read more in the User Guide.

Input data. If X is None, Gram must also be None. If only the Gram matrix is available, use lars_path_gram instead.

Xy = X.T @ y that can be precomputed. It is useful only when the Gram matrix is precomputed.

Precomputed Gram matrix X.T @ X, if 'auto', the Gram matrix is precomputed from the given X, if there are more samples than features.

Maximum number of iterations to perform, set to infinity for no limit.

Minimum correlation along the path. It corresponds to the regularization parameter alpha in the Lasso.

Specifies the returned model. Select 'lar' for Least Angle Regression, 'lasso' for the Lasso.

If False, X is overwritten.

The machine-precision regularization in the computation of the Cholesky diagonal factors. Increase this for very ill-conditioned systems. Unlike the tol parameter in some iterative optimization-based algorithms, this parameter does not control the tolerance of the optimization.

If False, Gram is overwritten.

Controls output verbosity.

If True, returns the entire path, else returns only the last point of the path.

Whether to return the number of iterations.

Restrict coefficients to be >= 0. This option is only allowed with method ‘lasso’. Note that the model coefficients will not converge to the ordinary-least-squares solution for small values of alpha. Only coefficients up to the smallest alpha value (alphas_[alphas_ > 0.].min() when fit_path=True) reached by the stepwise Lars-Lasso algorithm are typically in congruence with the solution of the coordinate descent lasso_path function.

Maximum of covariances (in absolute value) at each iteration. n_alphas is either max_iter, n_features, or the number of nodes in the path with alpha >= alpha_min, whichever is smaller.

Indices of active variables at the end of the path.

Coefficients along the path.

Number of iterations run. Returned only if return_n_iter is set to True.

Compute LARS path in the sufficient stats mode.

Compute Lasso path with coordinate descent.

Lasso model fit with Least Angle Regression a.k.a. Lars.

Least Angle Regression model a.k.a. LAR.

Cross-validated Lasso, using the LARS algorithm.

Cross-validated Least Angle Regression model.

“Least Angle Regression”, Efron et al. http://statweb.stanford.edu/~tibs/ftp/lars.pdf

Wikipedia entry on the Least-angle regression

Wikipedia entry on the Lasso

Lasso, Lasso-LARS, and Elastic Net paths

**Examples:**

Example 1 (unknown):
```unknown
(1 / (2 * n_samples)) * ||y - Xw||^2_2 + alpha * ||w||_1
```

Example 2 (sql):
```sql
>>> from sklearn.linear_model import lars_path
>>> from sklearn.datasets import make_regression
>>> X, y, true_coef = make_regression(
...    n_samples=100, n_features=5, n_informative=2, coef=True, random_state=0
... )
>>> true_coef
array([ 0.        ,  0.        ,  0.        , 97.9, 45.7])
>>> alphas, _, estimated_coef = lars_path(X, y)
>>> alphas.shape
(3,)
>>> estimated_coef
array([[ 0.     ,  0.     ,  0.     ],
       [ 0.     ,  0.     ,  0.     ],
       [ 0.     ,  0.     ,  0.     ],
       [ 0.     , 46.96, 97.99],
       [ 0.     ,  0.     , 45.70]])
```

---

## 

**URL:** https://scikit-learn.org/stable/_sources/modules/ensemble.rst.txt

---

## NuSVR#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.svm.NuSVR.html

**Contents:**
- NuSVR#
- Gallery examples#

Nu Support Vector Regression.

Similar to NuSVC, for regression, uses a parameter nu to control the number of support vectors. However, unlike NuSVC, where nu replaces C, here nu replaces the parameter epsilon of epsilon-SVR.

The implementation is based on libsvm.

Read more in the User Guide.

An upper bound on the fraction of training errors and a lower bound of the fraction of support vectors. Should be in the interval (0, 1]. By default 0.5 will be taken.

Penalty parameter C of the error term. For an intuitive visualization of the effects of scaling the regularization parameter C, see Scaling the regularization parameter for SVCs.

Specifies the kernel type to be used in the algorithm. If none is given, ‘rbf’ will be used. If a callable is given it is used to precompute the kernel matrix. For an intuitive visualization of different kernel types see See Support Vector Regression (SVR) using linear and non-linear kernels

Degree of the polynomial kernel function (‘poly’). Must be non-negative. Ignored by all other kernels.

Kernel coefficient for ‘rbf’, ‘poly’ and ‘sigmoid’.

if gamma='scale' (default) is passed then it uses 1 / (n_features * X.var()) as value of gamma,

if ‘auto’, uses 1 / n_features

if float, must be non-negative.

Changed in version 0.22: The default value of gamma changed from ‘auto’ to ‘scale’.

Independent term in kernel function. It is only significant in ‘poly’ and ‘sigmoid’.

Whether to use the shrinking heuristic. See the User Guide.

Tolerance for stopping criterion.

Specify the size of the kernel cache (in MB).

Enable verbose output. Note that this setting takes advantage of a per-process runtime setting in libsvm that, if enabled, may not work properly in a multithreaded context.

Hard limit on iterations within solver, or -1 for no limit.

Weights assigned to the features when kernel="linear".

Coefficients of the support vector in the decision function.

0 if correctly fitted, 1 otherwise (will raise warning)

Constants in decision function.

Number of features seen during fit.

Added in version 0.24.

Names of features seen during fit. Defined only when X has feature names that are all strings.

Added in version 1.0.

Number of iterations run by the optimization routine to fit the model.

Added in version 1.1.

Number of support vectors for each class.

Array dimensions of training vector X.

Indices of support vectors.

Support Vector Machine for classification implemented with libsvm with a parameter to control the number of support vectors.

Epsilon Support Vector Machine for regression implemented with libsvm.

LIBSVM: A Library for Support Vector Machines

Platt, John (1999). “Probabilistic Outputs for Support Vector Machines and Comparisons to Regularized Likelihood Methods”

Fit the SVM model according to the given training data.

Training vectors, where n_samples is the number of samples and n_features is the number of features. For kernel=”precomputed”, the expected shape of X is (n_samples, n_samples).

Target values (class labels in classification, real numbers in regression).

Per-sample weights. Rescale C per sample. Higher weights force the classifier to put more emphasis on these points.

If X and y are not C-ordered and contiguous arrays of np.float64 and X is not a scipy.sparse.csr_matrix, X and/or y may be copied.

If X is a dense array, then the other methods will not support sparse matrices as input.

Get metadata routing of this object.

Please check User Guide on how the routing mechanism works.

A MetadataRequest encapsulating routing information.

Get parameters for this estimator.

If True, will return the parameters for this estimator and contained subobjects that are estimators.

Parameter names mapped to their values.

Perform regression on samples in X.

For a one-class model, +1 (inlier) or -1 (outlier) is returned.

For kernel=”precomputed”, the expected shape of X is (n_samples_test, n_samples_train).

The predicted values.

Return coefficient of determination on test data.

The coefficient of determination, \(R^2\), is defined as \((1 - \frac{u}{v})\), where \(u\) is the residual sum of squares ((y_true - y_pred)** 2).sum() and \(v\) is the total sum of squares ((y_true - y_true.mean()) ** 2).sum(). The best possible score is 1.0 and it can be negative (because the model can be arbitrarily worse). A constant model that always predicts the expected value of y, disregarding the input features, would get a \(R^2\) score of 0.0.

Test samples. For some estimators this may be a precomputed kernel matrix or a list of generic objects instead with shape (n_samples, n_samples_fitted), where n_samples_fitted is the number of samples used in the fitting for the estimator.

\(R^2\) of self.predict(X) w.r.t. y.

The \(R^2\) score used when calling score on a regressor uses multioutput='uniform_average' from version 0.23 to keep consistent with default value of r2_score. This influences the score method of all the multioutput regressors (except for MultiOutputRegressor).

Configure whether metadata should be requested to be passed to the fit method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to fit if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to fit.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Added in version 1.3.

Metadata routing for sample_weight parameter in fit.

Set the parameters of this estimator.

The method works on simple estimators as well as on nested objects (such as Pipeline). The latter have parameters of the form <component>__<parameter> so that it’s possible to update each component of a nested object.

Estimator parameters.

Configure whether metadata should be requested to be passed to the score method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to score if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to score.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Added in version 1.3.

Metadata routing for sample_weight parameter in score.

Model Complexity Influence

**Examples:**

Example 1 (sql):
```sql
>>> from sklearn.svm import NuSVR
>>> from sklearn.pipeline import make_pipeline
>>> from sklearn.preprocessing import StandardScaler
>>> import numpy as np
>>> n_samples, n_features = 10, 5
>>> np.random.seed(0)
>>> y = np.random.randn(n_samples)
>>> X = np.random.randn(n_samples, n_features)
>>> regr = make_pipeline(StandardScaler(), NuSVR(C=1.0, nu=0.1))
>>> regr.fit(X, y)
Pipeline(steps=[('standardscaler', StandardScaler()),
                ('nusvr', NuSVR(nu=0.1))])
```

---

## MiniBatchNMF#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.MiniBatchNMF.html

**Contents:**
- MiniBatchNMF#
- Gallery examples#

Mini-Batch Non-Negative Matrix Factorization (NMF).

Added in version 1.1.

Find two non-negative matrices, i.e. matrices with all non-negative elements, (W, H) whose product approximates the non-negative matrix X. This factorization can be used for example for dimensionality reduction, source separation or topic extraction.

The objective function is:

where \(||A||_{Fro}^2 = \sum_{i,j} A_{ij}^2\) (Frobenius norm) and \(||vec(A)||_1 = \sum_{i,j} abs(A_{ij})\) (Elementwise L1 norm).

The generic norm \(||X - WH||_{loss}^2\) may represent the Frobenius norm or another supported beta-divergence loss. The choice between options is controlled by the beta_loss parameter.

The objective function is minimized with an alternating minimization of W and H.

Note that the transformed data is named W and the components matrix is named H. In the NMF literature, the naming convention is usually the opposite since the data matrix X is transposed.

Read more in the User Guide.

Number of components. If None, all features are kept. If n_components='auto', the number of components is automatically inferred from W or H shapes.

Changed in version 1.4: Added 'auto' value.

Changed in version 1.6: Default value changed from None to 'auto'.

Method used to initialize the procedure. Valid options:

None: ‘nndsvda’ if n_components <= min(n_samples, n_features), otherwise random.

'random': non-negative random matrices, scaled with: sqrt(X.mean() / n_components)

'nndsvd': Nonnegative Double Singular Value Decomposition (NNDSVD) initialization (better for sparseness).

'nndsvda': NNDSVD with zeros filled with the average of X (better when sparsity is not desired).

'nndsvdar' NNDSVD with zeros filled with small random values (generally faster, less accurate alternative to NNDSVDa for when sparsity is not desired).

'custom': Use custom matrices W and H which must both be provided.

Number of samples in each mini-batch. Large batch sizes give better long-term convergence at the cost of a slower start.

Beta divergence to be minimized, measuring the distance between X and the dot product WH. Note that values different from ‘frobenius’ (or 2) and ‘kullback-leibler’ (or 1) lead to significantly slower fits. Note that for beta_loss <= 0 (or ‘itakura-saito’), the input matrix X cannot contain zeros.

Control early stopping based on the norm of the differences in H between 2 steps. To disable early stopping based on changes in H, set tol to 0.0.

Control early stopping based on the consecutive number of mini batches that does not yield an improvement on the smoothed cost function. To disable convergence detection based on cost function, set max_no_improvement to None.

Maximum number of iterations over the complete dataset before timing out.

Constant that multiplies the regularization terms of W. Set it to zero (default) to have no regularization on W.

Constant that multiplies the regularization terms of H. Set it to zero to have no regularization on H. If “same” (default), it takes the same value as alpha_W.

The regularization mixing parameter, with 0 <= l1_ratio <= 1. For l1_ratio = 0 the penalty is an elementwise L2 penalty (aka Frobenius Norm). For l1_ratio = 1 it is an elementwise L1 penalty. For 0 < l1_ratio < 1, the penalty is a combination of L1 and L2.

Amount of rescaling of past information. Its value could be 1 with finite datasets. Choosing values < 1 is recommended with online learning as more recent batches will weight more than past batches.

Whether to completely solve for W at each step. Doing fresh restarts will likely lead to a better solution for a same number of iterations but it is much slower.

Maximum number of iterations when solving for W at each step. Only used when doing fresh restarts. These iterations may be stopped early based on a small change of W controlled by tol.

Maximum number of iterations when solving for W at transform time. If None, it defaults to max_iter.

Used for initialisation (when init == ‘nndsvdar’ or ‘random’), and in Coordinate Descent. Pass an int for reproducible results across multiple function calls. See Glossary.

Whether to be verbose.

Factorization matrix, sometimes called ‘dictionary’.

The number of components. It is same as the n_components parameter if it was given. Otherwise, it will be same as the number of features.

Frobenius norm of the matrix difference, or beta-divergence, between the training data X and the reconstructed data WH from the fitted model.

Actual number of started iterations over the whole dataset.

Number of mini-batches processed.

Number of features seen during fit.

Names of features seen during fit. Defined only when X has feature names that are all strings.

Non-negative matrix factorization.

Finds a dictionary that can best be used to represent data using a sparse code.

“Fast local algorithms for large scale nonnegative matrix and tensor factorizations” Cichocki, Andrzej, and P. H. A. N. Anh-Huy. IEICE transactions on fundamentals of electronics, communications and computer sciences 92.3: 708-721, 2009.

“Algorithms for nonnegative matrix factorization with the beta-divergence” Fevotte, C., & Idier, J. (2011). Neural Computation, 23(9).

“Online algorithms for nonnegative matrix factorization with the Itakura-Saito divergence” Lefevre, A., Bach, F., Fevotte, C. (2011). WASPA.

Learn a NMF model for the data X.

Training vector, where n_samples is the number of samples and n_features is the number of features.

Not used, present for API consistency by convention.

Parameters (keyword arguments) and values passed to the fit_transform instance.

Returns the instance itself.

Learn a NMF model for the data X and returns the transformed data.

This is more efficient than calling fit followed by transform.

Data matrix to be decomposed.

Not used, present here for API consistency by convention.

If init='custom', it is used as initial guess for the solution. If None, uses the initialisation method specified in init.

If init='custom', it is used as initial guess for the solution. If None, uses the initialisation method specified in init.

Get output feature names for transformation.

The feature names out will prefixed by the lowercased class name. For example, if the transformer outputs 3 features, then the feature names out are: ["class_name0", "class_name1", "class_name2"].

Only used to validate feature names with the names seen in fit.

Transformed feature names.

Get metadata routing of this object.

Please check User Guide on how the routing mechanism works.

A MetadataRequest encapsulating routing information.

Get parameters for this estimator.

If True, will return the parameters for this estimator and contained subobjects that are estimators.

Parameter names mapped to their values.

Transform data back to its original space.

Added in version 0.18.

Transformed data matrix.

Returns a data matrix of the original shape.

Update the model using the data in X as a mini-batch.

This method is expected to be called several times consecutively on different chunks of a dataset so as to implement out-of-core or online learning.

This is especially useful when the whole dataset is too big to fit in memory at once (see Strategies to scale computationally: bigger data).

Data matrix to be decomposed.

Not used, present here for API consistency by convention.

If init='custom', it is used as initial guess for the solution. Only used for the first call to partial_fit.

If init='custom', it is used as initial guess for the solution. Only used for the first call to partial_fit.

Returns the instance itself.

Set output container.

See Introducing the set_output API for an example on how to use the API.

Configure output of transform and fit_transform.

"default": Default output format of a transformer

"pandas": DataFrame output

"polars": Polars output

None: Transform configuration is unchanged

Added in version 1.4: "polars" option was added.

Set the parameters of this estimator.

The method works on simple estimators as well as on nested objects (such as Pipeline). The latter have parameters of the form <component>__<parameter> so that it’s possible to update each component of a nested object.

Estimator parameters.

Configure whether metadata should be requested to be passed to the partial_fit method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to partial_fit if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to partial_fit.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Added in version 1.3.

Metadata routing for H parameter in partial_fit.

Metadata routing for W parameter in partial_fit.

Transform the data X according to the fitted MiniBatchNMF model.

Data matrix to be transformed by the model.

Topic extraction with Non-negative Matrix Factorization and Latent Dirichlet Allocation

Release Highlights for scikit-learn 1.1

**Examples:**

Example 1 (sql):
```sql
>>> import numpy as np
>>> X = np.array([[1, 1], [2, 1], [3, 1.2], [4, 1], [5, 0.8], [6, 1]])
>>> from sklearn.decomposition import MiniBatchNMF
>>> model = MiniBatchNMF(n_components=2, init='random', random_state=0)
>>> W = model.fit_transform(X)
>>> H = model.components_
```

---

## completeness_score#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.metrics.completeness_score.html

**Contents:**
- completeness_score#
- Gallery examples#

Compute completeness metric of a cluster labeling given a ground truth.

A clustering result satisfies completeness if all the data points that are members of a given class are elements of the same cluster.

This metric is independent of the absolute values of the labels: a permutation of the class or cluster label values won’t change the score value in any way.

This metric is not symmetric: switching label_true with label_pred will return the homogeneity_score which will be different in general.

Read more in the User Guide.

Ground truth class labels to be used as a reference.

Cluster labels to evaluate.

Score between 0.0 and 1.0. 1.0 stands for perfectly complete labeling.

Homogeneity metric of cluster labeling.

V-Measure (NMI with arithmetic mean option).

Andrew Rosenberg and Julia Hirschberg, 2007. V-Measure: A conditional entropy-based external cluster evaluation measure

Perfect labelings are complete:

Non-perfect labelings that assign all classes members to the same clusters are still complete:

If classes members are split across different clusters, the assignment cannot be complete:

Demo of affinity propagation clustering algorithm

Demo of DBSCAN clustering algorithm

A demo of K-Means clustering on the handwritten digits data

Release Highlights for scikit-learn 0.23

Clustering text documents using k-means

**Examples:**

Example 1 (sql):
```sql
>>> from sklearn.metrics.cluster import completeness_score
>>> completeness_score([0, 0, 1, 1], [1, 1, 0, 0])
1.0
```

Example 2 (unknown):
```unknown
>>> print(completeness_score([0, 0, 1, 1], [0, 0, 0, 0]))
1.0
>>> print(completeness_score([0, 1, 2, 3], [0, 0, 1, 1]))
0.999
```

Example 3 (unknown):
```unknown
>>> print(completeness_score([0, 0, 1, 1], [0, 1, 0, 1]))
0.0
>>> print(completeness_score([0, 0, 0, 0], [0, 1, 2, 3]))
0.0
```

---

## NMF#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.NMF.html

**Contents:**
- NMF#
- Gallery examples#

Non-Negative Matrix Factorization (NMF).

Find two non-negative matrices, i.e. matrices with all non-negative elements, (W, H) whose product approximates the non-negative matrix X. This factorization can be used for example for dimensionality reduction, source separation or topic extraction.

The objective function is:

where \(||A||_{Fro}^2 = \sum_{i,j} A_{ij}^2\) (Frobenius norm) and \(||vec(A)||_1 = \sum_{i,j} abs(A_{ij})\) (Elementwise L1 norm).

The generic norm \(||X - WH||_{loss}\) may represent the Frobenius norm or another supported beta-divergence loss. The choice between options is controlled by the beta_loss parameter.

The regularization terms are scaled by n_features for W and by n_samples for H to keep their impact balanced with respect to one another and to the data fit term as independent as possible of the size n_samples of the training set.

The objective function is minimized with an alternating minimization of W and H.

Note that the transformed data is named W and the components matrix is named H. In the NMF literature, the naming convention is usually the opposite since the data matrix X is transposed.

Read more in the User Guide.

Number of components. If None, all features are kept. If n_components='auto', the number of components is automatically inferred from W or H shapes.

Changed in version 1.4: Added 'auto' value.

Changed in version 1.6: Default value changed from None to 'auto'.

Method used to initialize the procedure. Valid options:

None: ‘nndsvda’ if n_components <= min(n_samples, n_features), otherwise random.

'random': non-negative random matrices, scaled with: sqrt(X.mean() / n_components)

'nndsvd': Nonnegative Double Singular Value Decomposition (NNDSVD) initialization (better for sparseness)

'nndsvda': NNDSVD with zeros filled with the average of X (better when sparsity is not desired)

'nndsvdar' NNDSVD with zeros filled with small random values (generally faster, less accurate alternative to NNDSVDa for when sparsity is not desired)

'custom': Use custom matrices W and H which must both be provided.

Changed in version 1.1: When init=None and n_components is less than n_samples and n_features defaults to nndsvda instead of nndsvd.

Numerical solver to use:

‘cd’ is a Coordinate Descent solver.

‘mu’ is a Multiplicative Update solver.

Added in version 0.17: Coordinate Descent solver.

Added in version 0.19: Multiplicative Update solver.

Beta divergence to be minimized, measuring the distance between X and the dot product WH. Note that values different from ‘frobenius’ (or 2) and ‘kullback-leibler’ (or 1) lead to significantly slower fits. Note that for beta_loss <= 0 (or ‘itakura-saito’), the input matrix X cannot contain zeros. Used only in ‘mu’ solver.

Added in version 0.19.

Tolerance of the stopping condition.

Maximum number of iterations before timing out.

Used for initialisation (when init == ‘nndsvdar’ or ‘random’), and in Coordinate Descent. Pass an int for reproducible results across multiple function calls. See Glossary.

Constant that multiplies the regularization terms of W. Set it to zero (default) to have no regularization on W.

Added in version 1.0.

Constant that multiplies the regularization terms of H. Set it to zero to have no regularization on H. If “same” (default), it takes the same value as alpha_W.

Added in version 1.0.

The regularization mixing parameter, with 0 <= l1_ratio <= 1. For l1_ratio = 0 the penalty is an elementwise L2 penalty (aka Frobenius Norm). For l1_ratio = 1 it is an elementwise L1 penalty. For 0 < l1_ratio < 1, the penalty is a combination of L1 and L2.

Added in version 0.17: Regularization parameter l1_ratio used in the Coordinate Descent solver.

Whether to be verbose.

If true, randomize the order of coordinates in the CD solver.

Added in version 0.17: shuffle parameter used in the Coordinate Descent solver.

Factorization matrix, sometimes called ‘dictionary’.

The number of components. It is same as the n_components parameter if it was given. Otherwise, it will be same as the number of features.

Frobenius norm of the matrix difference, or beta-divergence, between the training data X and the reconstructed data WH from the fitted model.

Actual number of iterations.

Number of features seen during fit.

Added in version 0.24.

Names of features seen during fit. Defined only when X has feature names that are all strings.

Added in version 1.0.

Find a dictionary that sparsely encodes data.

Mini-batch Sparse Principal Components Analysis.

Principal component analysis.

Find a sparse representation of data from a fixed, precomputed dictionary.

Sparse Principal Components Analysis.

Dimensionality reduction using truncated SVD.

“Fast local algorithms for large scale nonnegative matrix and tensor factorizations” Cichocki, Andrzej, and P. H. A. N. Anh-Huy. IEICE transactions on fundamentals of electronics, communications and computer sciences 92.3: 708-721, 2009.

“Algorithms for nonnegative matrix factorization with the beta-divergence” Fevotte, C., & Idier, J. (2011). Neural Computation, 23(9).

Learn a NMF model for the data X.

Training vector, where n_samples is the number of samples and n_features is the number of features.

Not used, present for API consistency by convention.

Parameters (keyword arguments) and values passed to the fit_transform instance.

Returns the instance itself.

Learn a NMF model for the data X and returns the transformed data.

This is more efficient than calling fit followed by transform.

Training vector, where n_samples is the number of samples and n_features is the number of features.

Not used, present for API consistency by convention.

If init='custom', it is used as initial guess for the solution. If None, uses the initialisation method specified in init.

If init='custom', it is used as initial guess for the solution. If None, uses the initialisation method specified in init.

Get output feature names for transformation.

The feature names out will prefixed by the lowercased class name. For example, if the transformer outputs 3 features, then the feature names out are: ["class_name0", "class_name1", "class_name2"].

Only used to validate feature names with the names seen in fit.

Transformed feature names.

Get metadata routing of this object.

Please check User Guide on how the routing mechanism works.

A MetadataRequest encapsulating routing information.

Get parameters for this estimator.

If True, will return the parameters for this estimator and contained subobjects that are estimators.

Parameter names mapped to their values.

Transform data back to its original space.

Added in version 0.18.

Transformed data matrix.

Returns a data matrix of the original shape.

Set output container.

See Introducing the set_output API for an example on how to use the API.

Configure output of transform and fit_transform.

"default": Default output format of a transformer

"pandas": DataFrame output

"polars": Polars output

None: Transform configuration is unchanged

Added in version 1.4: "polars" option was added.

Set the parameters of this estimator.

The method works on simple estimators as well as on nested objects (such as Pipeline). The latter have parameters of the form <component>__<parameter> so that it’s possible to update each component of a nested object.

Estimator parameters.

Transform the data X according to the fitted NMF model.

Training vector, where n_samples is the number of samples and n_features is the number of features.

Topic extraction with Non-negative Matrix Factorization and Latent Dirichlet Allocation

Selecting dimensionality reduction with Pipeline and GridSearchCV

Faces dataset decompositions

**Examples:**

Example 1 (sql):
```sql
>>> import numpy as np
>>> X = np.array([[1, 1], [2, 1], [3, 1.2], [4, 1], [5, 0.8], [6, 1]])
>>> from sklearn.decomposition import NMF
>>> model = NMF(n_components=2, init='random', random_state=0)
>>> W = model.fit_transform(X)
>>> H = model.components_
```

---

## WhiteKernel#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.gaussian_process.kernels.WhiteKernel.html

**Contents:**
- WhiteKernel#
- Gallery examples#

The main use-case of this kernel is as part of a sum-kernel where it explains the noise of the signal as independently and identically normally-distributed. The parameter noise_level equals the variance of this noise.

Read more in the User Guide.

Added in version 0.18.

Parameter controlling the noise level (variance)

The lower and upper bound on ‘noise_level’. If set to “fixed”, ‘noise_level’ cannot be changed during hyperparameter tuning.

Return the kernel k(X, Y) and optionally its gradient.

Left argument of the returned kernel k(X, Y)

Right argument of the returned kernel k(X, Y). If None, k(X, X) is evaluated instead.

Determines whether the gradient with respect to the log of the kernel hyperparameter is computed. Only supported when Y is None.

The gradient of the kernel k(X, X) with respect to the log of the hyperparameter of the kernel. Only returned when eval_gradient is True.

Returns the log-transformed bounds on the theta.

The log-transformed bounds on the kernel’s hyperparameters theta

Returns a clone of self with given hyperparameters theta.

Returns the diagonal of the kernel k(X, X).

The result of this method is identical to np.diag(self(X)); however, it can be evaluated more efficiently since only the diagonal is evaluated.

Argument to the kernel.

Diagonal of kernel k(X, X)

Get parameters of this kernel.

If True, will return the parameters for this estimator and contained subobjects that are estimators.

Parameter names mapped to their values.

Returns a list of all hyperparameter specifications.

Returns whether the kernel is stationary.

Returns the number of non-fixed hyperparameters of the kernel.

Whether the kernel works only on fixed-length feature vectors.

Set the parameters of this kernel.

The method works on simple kernels as well as on nested kernels. The latter have parameters of the form <component>__<parameter> so that it’s possible to update each component of a nested object.

Returns the (flattened, log-transformed) non-fixed hyperparameters.

Note that theta are typically the log-transformed values of the kernel’s hyperparameters as this representation of the search space is more amenable for hyperparameter search, as hyperparameters like length-scales naturally live on a log-scale.

The non-fixed, log-transformed hyperparameters of the kernel

Comparison of kernel ridge and Gaussian process regression

Forecasting of CO2 level on Mona Loa dataset using Gaussian process regression (GPR)

Ability of Gaussian process regression (GPR) to estimate data noise-level

**Examples:**

Example 1 (sql):
```sql
>>> from sklearn.datasets import make_friedman2
>>> from sklearn.gaussian_process import GaussianProcessRegressor
>>> from sklearn.gaussian_process.kernels import DotProduct, WhiteKernel
>>> X, y = make_friedman2(n_samples=500, noise=0, random_state=0)
>>> kernel = DotProduct() + WhiteKernel(noise_level=0.5)
>>> gpr = GaussianProcessRegressor(kernel=kernel,
...         random_state=0).fit(X, y)
>>> gpr.score(X, y)
0.3680
>>> gpr.predict(X[:2,:], return_std=True)
(array([653.0, 592.1 ]), array([316.6, 316.6]))
```

---

## LinearRegression#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html

**Contents:**
- LinearRegression#
- Gallery examples#

Ordinary least squares Linear Regression.

LinearRegression fits a linear model with coefficients w = (w1, …, wp) to minimize the residual sum of squares between the observed targets in the dataset, and the targets predicted by the linear approximation.

Whether to calculate the intercept for this model. If set to False, no intercept will be used in calculations (i.e. data is expected to be centered).

If True, X will be copied; else, it may be overwritten.

The precision of the solution (coef_) is determined by tol which specifies a different convergence criterion for the lsqr solver. tol is set as atol and btol of scipy.sparse.linalg.lsqr when fitting on sparse training data. This parameter has no effect when fitting on dense data.

Added in version 1.7.

The number of jobs to use for the computation. This will only provide speedup in case of sufficiently large problems, that is if firstly n_targets > 1 and secondly X is sparse or if positive is set to True. None means 1 unless in a joblib.parallel_backend context. -1 means using all processors. See Glossary for more details.

When set to True, forces the coefficients to be positive. This option is only supported for dense arrays.

For a comparison between a linear regression model with positive constraints on the regression coefficients and a linear regression without such constraints, see Non-negative least squares.

Added in version 0.24.

Estimated coefficients for the linear regression problem. If multiple targets are passed during the fit (y 2D), this is a 2D array of shape (n_targets, n_features), while if only one target is passed, this is a 1D array of length n_features.

Rank of matrix X. Only available when X is dense.

Singular values of X. Only available when X is dense.

Independent term in the linear model. Set to 0.0 if fit_intercept = False.

Number of features seen during fit.

Added in version 0.24.

Names of features seen during fit. Defined only when X has feature names that are all strings.

Added in version 1.0.

Ridge regression addresses some of the problems of Ordinary Least Squares by imposing a penalty on the size of the coefficients with l2 regularization.

The Lasso is a linear model that estimates sparse coefficients with l1 regularization.

Elastic-Net is a linear regression model trained with both l1 and l2 -norm regularization of the coefficients.

From the implementation point of view, this is just plain Ordinary Least Squares (scipy.linalg.lstsq) or Non Negative Least Squares (scipy.optimize.nnls) wrapped as a predictor object.

Target values. Will be cast to X’s dtype if necessary.

Individual weights for each sample.

Added in version 0.17: parameter sample_weight support to LinearRegression.

Get metadata routing of this object.

Please check User Guide on how the routing mechanism works.

A MetadataRequest encapsulating routing information.

Get parameters for this estimator.

If True, will return the parameters for this estimator and contained subobjects that are estimators.

Parameter names mapped to their values.

Predict using the linear model.

Returns predicted values.

Return coefficient of determination on test data.

The coefficient of determination, \(R^2\), is defined as \((1 - \frac{u}{v})\), where \(u\) is the residual sum of squares ((y_true - y_pred)** 2).sum() and \(v\) is the total sum of squares ((y_true - y_true.mean()) ** 2).sum(). The best possible score is 1.0 and it can be negative (because the model can be arbitrarily worse). A constant model that always predicts the expected value of y, disregarding the input features, would get a \(R^2\) score of 0.0.

Test samples. For some estimators this may be a precomputed kernel matrix or a list of generic objects instead with shape (n_samples, n_samples_fitted), where n_samples_fitted is the number of samples used in the fitting for the estimator.

\(R^2\) of self.predict(X) w.r.t. y.

The \(R^2\) score used when calling score on a regressor uses multioutput='uniform_average' from version 0.23 to keep consistent with default value of r2_score. This influences the score method of all the multioutput regressors (except for MultiOutputRegressor).

Configure whether metadata should be requested to be passed to the fit method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to fit if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to fit.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Added in version 1.3.

Metadata routing for sample_weight parameter in fit.

Set the parameters of this estimator.

The method works on simple estimators as well as on nested objects (such as Pipeline). The latter have parameters of the form <component>__<parameter> so that it’s possible to update each component of a nested object.

Estimator parameters.

Configure whether metadata should be requested to be passed to the score method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to score if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to score.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Added in version 1.3.

Metadata routing for sample_weight parameter in score.

Principal Component Regression vs Partial Least Squares Regression

Plot individual and voting regression predictions

Failure of Machine Learning to infer causal effects

Comparing Linear Bayesian Regressors

Non-negative least squares

Ordinary Least Squares and Ridge Regression

Robust linear model estimation using RANSAC

Robust linear estimator fitting

Face completion with a multi-output estimators

Plotting Cross-Validated Predictions

Underfitting vs. Overfitting

Using KBinsDiscretizer to discretize continuous features

**Examples:**

Example 1 (sql):
```sql
>>> import numpy as np
>>> from sklearn.linear_model import LinearRegression
>>> X = np.array([[1, 1], [1, 2], [2, 2], [2, 3]])
>>> # y = 1 * x_0 + 2 * x_1 + 3
>>> y = np.dot(X, np.array([1, 2])) + 3
>>> reg = LinearRegression().fit(X, y)
>>> reg.score(X, y)
1.0
>>> reg.coef_
array([1., 2.])
>>> reg.intercept_
np.float64(3.0)
>>> reg.predict(np.array([[3, 5]]))
array([16.])
```

---

## 2.7. Novelty and Outlier Detection#

**URL:** https://scikit-learn.org/stable/modules/outlier_detection.html

**Contents:**
- 2.7. Novelty and Outlier Detection#
- 2.7.1. Overview of outlier detection methods#
- 2.7.2. Novelty Detection#
  - 2.7.2.1. Scaling up the One-Class SVM#
- 2.7.3. Outlier Detection#
  - 2.7.3.1. Fitting an elliptic envelope#
  - 2.7.3.2. Isolation Forest#
  - 2.7.3.3. Local Outlier Factor#
- 2.7.4. Novelty detection with Local Outlier Factor#

Many applications require being able to decide whether a new observation belongs to the same distribution as existing observations (it is an inlier), or should be considered as different (it is an outlier). Often, this ability is used to clean real data sets. Two important distinctions must be made:

The training data contains outliers which are defined as observations that are far from the others. Outlier detection estimators thus try to fit the regions where the training data is the most concentrated, ignoring the deviant observations.

The training data is not polluted by outliers and we are interested in detecting whether a new observation is an outlier. In this context an outlier is also called a novelty.

Outlier detection and novelty detection are both used for anomaly detection, where one is interested in detecting abnormal or unusual observations. Outlier detection is then also known as unsupervised anomaly detection and novelty detection as semi-supervised anomaly detection. In the context of outlier detection, the outliers/anomalies cannot form a dense cluster as available estimators assume that the outliers/anomalies are located in low density regions. On the contrary, in the context of novelty detection, novelties/anomalies can form a dense cluster as long as they are in a low density region of the training data, considered as normal in this context.

The scikit-learn project provides a set of machine learning tools that can be used both for novelty or outlier detection. This strategy is implemented with objects learning in an unsupervised way from the data:

new observations can then be sorted as inliers or outliers with a predict method:

Inliers are labeled 1, while outliers are labeled -1. The predict method makes use of a threshold on the raw scoring function computed by the estimator. This scoring function is accessible through the score_samples method, while the threshold can be controlled by the contamination parameter.

The decision_function method is also defined from the scoring function, in such a way that negative values are outliers and non-negative ones are inliers:

Note that neighbors.LocalOutlierFactor does not support predict, decision_function and score_samples methods by default but only a fit_predict method, as this estimator was originally meant to be applied for outlier detection. The scores of abnormality of the training samples are accessible through the negative_outlier_factor_ attribute.

If you really want to use neighbors.LocalOutlierFactor for novelty detection, i.e. predict labels or compute the score of abnormality of new unseen data, you can instantiate the estimator with the novelty parameter set to True before fitting the estimator. In this case, fit_predict is not available.

Novelty detection with Local Outlier Factor

When novelty is set to True be aware that you must only use predict, decision_function and score_samples on new unseen data and not on the training samples as this would lead to wrong results. I.e., the result of predict will not be the same as fit_predict. The scores of abnormality of the training samples are always accessible through the negative_outlier_factor_ attribute.

The behavior of neighbors.LocalOutlierFactor is summarized in the following table.

Use negative_outlier_factor_

negative_outlier_factor_

A comparison of the outlier detection algorithms in scikit-learn. Local Outlier Factor (LOF) does not show a decision boundary in black as it has no predict method to be applied on new data when it is used for outlier detection.

ensemble.IsolationForest and neighbors.LocalOutlierFactor perform reasonably well on the data sets considered here. The svm.OneClassSVM is known to be sensitive to outliers and thus does not perform very well for outlier detection. That being said, outlier detection in high-dimension, or without any assumptions on the distribution of the inlying data is very challenging. svm.OneClassSVM may still be used with outlier detection but requires fine-tuning of its hyperparameter nu to handle outliers and prevent overfitting. linear_model.SGDOneClassSVM provides an implementation of a linear One-Class SVM with a linear complexity in the number of samples. This implementation is here used with a kernel approximation technique to obtain results similar to svm.OneClassSVM which uses a Gaussian kernel by default. Finally, covariance.EllipticEnvelope assumes the data is Gaussian and learns an ellipse. For more details on the different estimators refer to the example Comparing anomaly detection algorithms for outlier detection on toy datasets and the sections hereunder.

See Comparing anomaly detection algorithms for outlier detection on toy datasets for a comparison of the svm.OneClassSVM, the ensemble.IsolationForest, the neighbors.LocalOutlierFactor and covariance.EllipticEnvelope.

See Evaluation of outlier detection estimators for an example showing how to evaluate outlier detection estimators, the neighbors.LocalOutlierFactor and the ensemble.IsolationForest, using ROC curves from metrics.RocCurveDisplay.

Consider a data set of \(n\) observations from the same distribution described by \(p\) features. Consider now that we add one more observation to that data set. Is the new observation so different from the others that we can doubt it is regular? (i.e. does it come from the same distribution?) Or on the contrary, is it so similar to the other that we cannot distinguish it from the original observations? This is the question addressed by the novelty detection tools and methods.

In general, it is about to learn a rough, close frontier delimiting the contour of the initial observations distribution, plotted in embedding \(p\)-dimensional space. Then, if further observations lay within the frontier-delimited subspace, they are considered as coming from the same population as the initial observations. Otherwise, if they lay outside the frontier, we can say that they are abnormal with a given confidence in our assessment.

The One-Class SVM has been introduced by Schölkopf et al. for that purpose and implemented in the Support Vector Machines module in the svm.OneClassSVM object. It requires the choice of a kernel and a scalar parameter to define a frontier. The RBF kernel is usually chosen although there exists no exact formula or algorithm to set its bandwidth parameter. This is the default in the scikit-learn implementation. The nu parameter, also known as the margin of the One-Class SVM, corresponds to the probability of finding a new, but regular, observation outside the frontier.

Estimating the support of a high-dimensional distribution Schölkopf, Bernhard, et al. Neural computation 13.7 (2001): 1443-1471.

See One-class SVM with non-linear kernel (RBF) for visualizing the frontier learned around some data by a svm.OneClassSVM object.

Species distribution modeling

An online linear version of the One-Class SVM is implemented in linear_model.SGDOneClassSVM. This implementation scales linearly with the number of samples and can be used with a kernel approximation to approximate the solution of a kernelized svm.OneClassSVM whose complexity is at best quadratic in the number of samples. See section Online One-Class SVM for more details.

See One-Class SVM versus One-Class SVM using Stochastic Gradient Descent for an illustration of the approximation of a kernelized One-Class SVM with the linear_model.SGDOneClassSVM combined with kernel approximation.

Outlier detection is similar to novelty detection in the sense that the goal is to separate a core of regular observations from some polluting ones, called outliers. Yet, in the case of outlier detection, we don’t have a clean data set representing the population of regular observations that can be used to train any tool.

One common way of performing outlier detection is to assume that the regular data come from a known distribution (e.g. data are Gaussian distributed). From this assumption, we generally try to define the “shape” of the data, and can define outlying observations as observations which stand far enough from the fit shape.

The scikit-learn provides an object covariance.EllipticEnvelope that fits a robust covariance estimate to the data, and thus fits an ellipse to the central data points, ignoring points outside the central mode.

For instance, assuming that the inlier data are Gaussian distributed, it will estimate the inlier location and covariance in a robust way (i.e. without being influenced by outliers). The Mahalanobis distances obtained from this estimate are used to derive a measure of outlyingness. This strategy is illustrated below.

See Robust covariance estimation and Mahalanobis distances relevance for an illustration of the difference between using a standard (covariance.EmpiricalCovariance) or a robust estimate (covariance.MinCovDet) of location and covariance to assess the degree of outlyingness of an observation.

See Outlier detection on a real data set for an example of robust covariance estimation on a real data set.

Rousseeuw, P.J., Van Driessen, K. “A fast algorithm for the minimum covariance determinant estimator” Technometrics 41(3), 212 (1999)

One efficient way of performing outlier detection in high-dimensional datasets is to use random forests. The ensemble.IsolationForest ‘isolates’ observations by randomly selecting a feature and then randomly selecting a split value between the maximum and minimum values of the selected feature.

Since recursive partitioning can be represented by a tree structure, the number of splittings required to isolate a sample is equivalent to the path length from the root node to the terminating node.

This path length, averaged over a forest of such random trees, is a measure of normality and our decision function.

Random partitioning produces noticeably shorter paths for anomalies. Hence, when a forest of random trees collectively produce shorter path lengths for particular samples, they are highly likely to be anomalies.

The implementation of ensemble.IsolationForest is based on an ensemble of tree.ExtraTreeRegressor. Following Isolation Forest original paper, the maximum depth of each tree is set to \(\lceil \log_2(n) \rceil\) where \(n\) is the number of samples used to build the tree (see [1] for more details).

This algorithm is illustrated below.

The ensemble.IsolationForest supports warm_start=True which allows you to add more trees to an already fitted model:

See IsolationForest example for an illustration of the use of IsolationForest.

See Comparing anomaly detection algorithms for outlier detection on toy datasets for a comparison of ensemble.IsolationForest with neighbors.LocalOutlierFactor, svm.OneClassSVM (tuned to perform like an outlier detection method), linear_model.SGDOneClassSVM, and a covariance-based outlier detection with covariance.EllipticEnvelope.

F. T. Liu, K. M. Ting and Z. -H. Zhou. “Isolation forest.” 2008 Eighth IEEE International Conference on Data Mining (ICDM), 2008, pp. 413-422.

Another efficient way to perform outlier detection on moderately high dimensional datasets is to use the Local Outlier Factor (LOF) algorithm.

The neighbors.LocalOutlierFactor (LOF) algorithm computes a score (called local outlier factor) reflecting the degree of abnormality of the observations. It measures the local density deviation of a given data point with respect to its neighbors. The idea is to detect the samples that have a substantially lower density than their neighbors.

In practice the local density is obtained from the k-nearest neighbors. The LOF score of an observation is equal to the ratio of the average local density of its k-nearest neighbors, and its own local density: a normal instance is expected to have a local density similar to that of its neighbors, while abnormal data are expected to have much smaller local density.

The number k of neighbors considered, (alias parameter n_neighbors) is typically chosen 1) greater than the minimum number of objects a cluster has to contain, so that other objects can be local outliers relative to this cluster, and 2) smaller than the maximum number of close by objects that can potentially be local outliers. In practice, such information is generally not available, and taking n_neighbors=20 appears to work well in general. When the proportion of outliers is high (i.e. greater than 10 %, as in the example below), n_neighbors should be greater (n_neighbors=35 in the example below).

The strength of the LOF algorithm is that it takes both local and global properties of datasets into consideration: it can perform well even in datasets where abnormal samples have different underlying densities. The question is not, how isolated the sample is, but how isolated it is with respect to the surrounding neighborhood.

When applying LOF for outlier detection, there are no predict, decision_function and score_samples methods but only a fit_predict method. The scores of abnormality of the training samples are accessible through the negative_outlier_factor_ attribute. Note that predict, decision_function and score_samples can be used on new unseen data when LOF is applied for novelty detection, i.e. when the novelty parameter is set to True, but the result of predict may differ from that of fit_predict. See Novelty detection with Local Outlier Factor.

This strategy is illustrated below.

See Outlier detection with Local Outlier Factor (LOF) for an illustration of the use of neighbors.LocalOutlierFactor.

See Comparing anomaly detection algorithms for outlier detection on toy datasets for a comparison with other anomaly detection methods.

Breunig, Kriegel, Ng, and Sander (2000) LOF: identifying density-based local outliers. Proc. ACM SIGMOD

To use neighbors.LocalOutlierFactor for novelty detection, i.e. predict labels or compute the score of abnormality of new unseen data, you need to instantiate the estimator with the novelty parameter set to True before fitting the estimator:

Note that fit_predict is not available in this case to avoid inconsistencies.

Novelty detection with Local Outlier Factor

When novelty is set to True be aware that you must only use predict, decision_function and score_samples on new unseen data and not on the training samples as this would lead to wrong results. I.e., the result of predict will not be the same as fit_predict. The scores of abnormality of the training samples are always accessible through the negative_outlier_factor_ attribute.

Novelty detection with neighbors.LocalOutlierFactor is illustrated below (see Novelty detection with Local Outlier Factor (LOF)).

**Examples:**

Example 1 (unknown):
```unknown
estimator.fit(X_train)
```

Example 2 (unknown):
```unknown
estimator.predict(X_test)
```

Example 3 (unknown):
```unknown
estimator.decision_function(X_test)
```

Example 4 (sql):
```sql
>>> from sklearn.ensemble import IsolationForest
>>> import numpy as np
>>> X = np.array([[-1, -1], [-2, -1], [-3, -2], [0, 0], [-20, 50], [3, 5]])
>>> clf = IsolationForest(n_estimators=10, warm_start=True)
>>> clf.fit(X)  # fit 10 trees
>>> clf.set_params(n_estimators=20)  # add 10 more trees
>>> clf.fit(X)  # fit the added trees
```

---

## Perceptron#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Perceptron.html

**Contents:**
- Perceptron#
- Gallery examples#

Linear perceptron classifier.

The implementation is a wrapper around SGDClassifier by fixing the loss and learning_rate parameters as:

Other available parameters are described below and are forwarded to SGDClassifier.

Read more in the User Guide.

The penalty (aka regularization term) to be used.

Constant that multiplies the regularization term if regularization is used.

The Elastic Net mixing parameter, with 0 <= l1_ratio <= 1. l1_ratio=0 corresponds to L2 penalty, l1_ratio=1 to L1. Only used if penalty='elasticnet'.

Added in version 0.24.

Whether the intercept should be estimated or not. If False, the data is assumed to be already centered.

The maximum number of passes over the training data (aka epochs). It only impacts the behavior in the fit method, and not the partial_fit method.

Added in version 0.19.

The stopping criterion. If it is not None, the iterations will stop when (loss > previous_loss - tol).

Added in version 0.19.

Whether or not the training data should be shuffled after each epoch.

Constant by which the updates are multiplied.

The number of CPUs to use to do the OVA (One Versus All, for multi-class problems) computation. None means 1 unless in a joblib.parallel_backend context. -1 means using all processors. See Glossary for more details.

Used to shuffle the training data, when shuffle is set to True. Pass an int for reproducible output across multiple function calls. See Glossary.

Whether to use early stopping to terminate training when validation score is not improving. If set to True, it will automatically set aside a stratified fraction of training data as validation and terminate training when validation score is not improving by at least tol for n_iter_no_change consecutive epochs.

Added in version 0.20.

The proportion of training data to set aside as validation set for early stopping. Must be between 0 and 1. Only used if early_stopping is True.

Added in version 0.20.

Number of iterations with no improvement to wait before early stopping.

Added in version 0.20.

Preset for the class_weight fit parameter.

Weights associated with classes. If not given, all classes are supposed to have weight one.

The “balanced” mode uses the values of y to automatically adjust weights inversely proportional to class frequencies in the input data as n_samples / (n_classes * np.bincount(y)).

When set to True, reuse the solution of the previous call to fit as initialization, otherwise, just erase the previous solution. See the Glossary.

The unique classes labels.

Weights assigned to the features.

Constants in decision function.

Number of features seen during fit.

Added in version 0.24.

Names of features seen during fit. Defined only when X has feature names that are all strings.

Added in version 1.0.

The actual number of iterations to reach the stopping criterion. For multiclass fits, it is the maximum over every binary fit.

Number of weight updates performed during training. Same as (n_iter_ * n_samples + 1).

Linear classifiers (SVM, logistic regression, etc.) with SGD training.

Perceptron is a classification algorithm which shares the same underlying implementation with SGDClassifier. In fact, Perceptron() is equivalent to SGDClassifier(loss="perceptron", eta0=1, learning_rate="constant", penalty=None).

https://en.wikipedia.org/wiki/Perceptron and references therein.

Predict confidence scores for samples.

The confidence score for a sample is proportional to the signed distance of that sample to the hyperplane.

The data matrix for which we want to get the confidence scores.

Confidence scores per (n_samples, n_classes) combination. In the binary case, confidence score for self.classes_[1] where >0 means this class would be predicted.

Convert coefficient matrix to dense array format.

Converts the coef_ member (back) to a numpy.ndarray. This is the default format of coef_ and is required for fitting, so calling this method is only required on models that have previously been sparsified; otherwise, it is a no-op.

Fit linear model with Stochastic Gradient Descent.

The initial coefficients to warm-start the optimization.

The initial intercept to warm-start the optimization.

Weights applied to individual samples. If not provided, uniform weights are assumed. These weights will be multiplied with class_weight (passed through the constructor) if class_weight is specified.

Returns an instance of self.

Get metadata routing of this object.

Please check User Guide on how the routing mechanism works.

A MetadataRequest encapsulating routing information.

Get parameters for this estimator.

If True, will return the parameters for this estimator and contained subobjects that are estimators.

Parameter names mapped to their values.

Perform one epoch of stochastic gradient descent on given samples.

Internally, this method uses max_iter = 1. Therefore, it is not guaranteed that a minimum of the cost function is reached after calling it once. Matters such as objective convergence, early stopping, and learning rate adjustments should be handled by the user.

Subset of the training data.

Subset of the target values.

Classes across all calls to partial_fit. Can be obtained by via np.unique(y_all), where y_all is the target vector of the entire dataset. This argument is required for the first call to partial_fit and can be omitted in the subsequent calls. Note that y doesn’t need to contain all labels in classes.

Weights applied to individual samples. If not provided, uniform weights are assumed.

Returns an instance of self.

Predict class labels for samples in X.

The data matrix for which we want to get the predictions.

Vector containing the class labels for each sample.

Return accuracy on provided data and labels.

In multi-label classification, this is the subset accuracy which is a harsh metric since you require for each sample that each label set be correctly predicted.

Mean accuracy of self.predict(X) w.r.t. y.

Configure whether metadata should be requested to be passed to the fit method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to fit if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to fit.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Added in version 1.3.

Metadata routing for coef_init parameter in fit.

Metadata routing for intercept_init parameter in fit.

Metadata routing for sample_weight parameter in fit.

Set the parameters of this estimator.

The method works on simple estimators as well as on nested objects (such as Pipeline). The latter have parameters of the form <component>__<parameter> so that it’s possible to update each component of a nested object.

Estimator parameters.

Configure whether metadata should be requested to be passed to the partial_fit method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to partial_fit if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to partial_fit.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Added in version 1.3.

Metadata routing for classes parameter in partial_fit.

Metadata routing for sample_weight parameter in partial_fit.

Configure whether metadata should be requested to be passed to the score method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to score if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to score.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Added in version 1.3.

Metadata routing for sample_weight parameter in score.

Convert coefficient matrix to sparse format.

Converts the coef_ member to a scipy.sparse matrix, which for L1-regularized models can be much more memory- and storage-efficient than the usual numpy.ndarray representation.

The intercept_ member is not converted.

For non-sparse models, i.e. when there are not many zeros in coef_, this may actually increase memory usage, so use this method with care. A rule of thumb is that the number of zero elements, which can be computed with (coef_ == 0).sum(), must be more than 50% for this to provide significant benefits.

After calling this method, further fitting with the partial_fit method (if any) will not work until you call densify.

Out-of-core classification of text documents

**Examples:**

Example 1 (unknown):
```unknown
SGDClassifier(loss="perceptron", learning_rate="constant")
```

Example 2 (sql):
```sql
>>> from sklearn.datasets import load_digits
>>> from sklearn.linear_model import Perceptron
>>> X, y = load_digits(return_X_y=True)
>>> clf = Perceptron(tol=1e-3, random_state=0)
>>> clf.fit(X, y)
Perceptron()
>>> clf.score(X, y)
0.939...
```

---

## TSNE#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html

**Contents:**
- TSNE#
- Gallery examples#

T-distributed Stochastic Neighbor Embedding.

t-SNE [1] is a tool to visualize high-dimensional data. It converts similarities between data points to joint probabilities and tries to minimize the Kullback-Leibler divergence between the joint probabilities of the low-dimensional embedding and the high-dimensional data. t-SNE has a cost function that is not convex, i.e. with different initializations we can get different results.

It is highly recommended to use another dimensionality reduction method (e.g. PCA for dense data or TruncatedSVD for sparse data) to reduce the number of dimensions to a reasonable amount (e.g. 50) if the number of features is very high. This will suppress some noise and speed up the computation of pairwise distances between samples. For more tips see Laurens van der Maaten’s FAQ [2].

Read more in the User Guide.

Dimension of the embedded space.

The perplexity is related to the number of nearest neighbors that is used in other manifold learning algorithms. Larger datasets usually require a larger perplexity. Consider selecting a value between 5 and 50. Different values can result in significantly different results. The perplexity must be less than the number of samples.

Controls how tight natural clusters in the original space are in the embedded space and how much space will be between them. For larger values, the space between natural clusters will be larger in the embedded space. Again, the choice of this parameter is not very critical. If the cost function increases during initial optimization, the early exaggeration factor or the learning rate might be too high.

The learning rate for t-SNE is usually in the range [10.0, 1000.0]. If the learning rate is too high, the data may look like a ‘ball’ with any point approximately equidistant from its nearest neighbours. If the learning rate is too low, most points may look compressed in a dense cloud with few outliers. If the cost function gets stuck in a bad local minimum increasing the learning rate may help. Note that many other t-SNE implementations (bhtsne, FIt-SNE, openTSNE, etc.) use a definition of learning_rate that is 4 times smaller than ours. So our learning_rate=200 corresponds to learning_rate=800 in those other implementations. The ‘auto’ option sets the learning_rate to max(N / early_exaggeration / 4, 50) where N is the sample size, following [4] and [5].

Changed in version 1.2: The default value changed to "auto".

Maximum number of iterations for the optimization. Should be at least 250.

Changed in version 1.5: Parameter name changed from n_iter to max_iter.

Maximum number of iterations without progress before we abort the optimization, used after 250 initial iterations with early exaggeration. Note that progress is only checked every 50 iterations so this value is rounded to the next multiple of 50.

Added in version 0.17: parameter n_iter_without_progress to control stopping criteria.

If the gradient norm is below this threshold, the optimization will be stopped.

The metric to use when calculating distance between instances in a feature array. If metric is a string, it must be one of the options allowed by scipy.spatial.distance.pdist for its metric parameter, or a metric listed in pairwise.PAIRWISE_DISTANCE_FUNCTIONS. If metric is “precomputed”, X is assumed to be a distance matrix. Alternatively, if metric is a callable function, it is called on each pair of instances (rows) and the resulting value recorded. The callable should take two arrays from X as input and return a value indicating the distance between them. The default is “euclidean” which is interpreted as squared euclidean distance.

Additional keyword arguments for the metric function.

Added in version 1.1.

Initialization of embedding. PCA initialization cannot be used with precomputed distances and is usually more globally stable than random initialization.

Changed in version 1.2: The default value changed to "pca".

Determines the random number generator. Pass an int for reproducible results across multiple function calls. Note that different initializations might result in different local minima of the cost function. See Glossary.

By default the gradient calculation algorithm uses Barnes-Hut approximation running in O(NlogN) time. method=’exact’ will run on the slower, but exact, algorithm in O(N^2) time. The exact algorithm should be used when nearest-neighbor errors need to be better than 3%. However, the exact method cannot scale to millions of examples.

Added in version 0.17: Approximate optimization method via the Barnes-Hut.

Only used if method=’barnes_hut’ This is the trade-off between speed and accuracy for Barnes-Hut T-SNE. ‘angle’ is the angular size (referred to as theta in [3]) of a distant node as measured from a point. If this size is below ‘angle’ then it is used as a summary node of all points contained within it. This method is not very sensitive to changes in this parameter in the range of 0.2 - 0.8. Angle less than 0.2 has quickly increasing computation time and angle greater 0.8 has quickly increasing error.

The number of parallel jobs to run for neighbors search. This parameter has no impact when metric="precomputed" or (metric="euclidean" and method="exact"). None means 1 unless in a joblib.parallel_backend context. -1 means using all processors. See Glossary for more details.

Added in version 0.22.

Stores the embedding vectors.

Kullback-Leibler divergence after optimization.

Number of features seen during fit.

Added in version 0.24.

Names of features seen during fit. Defined only when X has feature names that are all strings.

Added in version 1.0.

Effective learning rate.

Added in version 1.2.

Number of iterations run.

Principal component analysis that is a linear dimensionality reduction method.

Non-linear dimensionality reduction using kernels and PCA.

Manifold learning using multidimensional scaling.

Manifold learning based on Isometric Mapping.

Manifold learning using Locally Linear Embedding.

Spectral embedding for non-linear dimensionality.

For an example of using TSNE in combination with KNeighborsTransformer see Approximate nearest neighbors in TSNE.

Using t-SNE. Journal of Machine Learning Research 9:2579-2605, 2008.

https://lvdmaaten.github.io/tsne/

Journal of Machine Learning Research 15(Oct):3221-3245, 2014. https://lvdmaaten.github.io/publications/papers/JMLR_2014.pdf

& Snyder-Cappione, J. E. (2019). Automated optimized parameters for T-distributed stochastic neighbor embedding improve visualization and analysis of large datasets. Nature Communications, 10(1), 1-12.

transcriptomics. Nature Communications, 10(1), 1-14.

Fit X into an embedded space.

If the metric is ‘precomputed’ X must be a square distance matrix. Otherwise it contains a sample per row. If the method is ‘exact’, X may be a sparse matrix of type ‘csr’, ‘csc’ or ‘coo’. If the method is ‘barnes_hut’ and the metric is ‘precomputed’, X may be a precomputed sparse graph.

Fit X into an embedded space and return that transformed output.

If the metric is ‘precomputed’ X must be a square distance matrix. Otherwise it contains a sample per row. If the method is ‘exact’, X may be a sparse matrix of type ‘csr’, ‘csc’ or ‘coo’. If the method is ‘barnes_hut’ and the metric is ‘precomputed’, X may be a precomputed sparse graph.

Embedding of the training data in low-dimensional space.

Get output feature names for transformation.

The feature names out will prefixed by the lowercased class name. For example, if the transformer outputs 3 features, then the feature names out are: ["class_name0", "class_name1", "class_name2"].

Only used to validate feature names with the names seen in fit.

Transformed feature names.

Get metadata routing of this object.

Please check User Guide on how the routing mechanism works.

A MetadataRequest encapsulating routing information.

Get parameters for this estimator.

If True, will return the parameters for this estimator and contained subobjects that are estimators.

Parameter names mapped to their values.

Set output container.

See Introducing the set_output API for an example on how to use the API.

Configure output of transform and fit_transform.

"default": Default output format of a transformer

"pandas": DataFrame output

"polars": Polars output

None: Transform configuration is unchanged

Added in version 1.4: "polars" option was added.

Set the parameters of this estimator.

The method works on simple estimators as well as on nested objects (such as Pipeline). The latter have parameters of the form <component>__<parameter> so that it’s possible to update each component of a nested object.

Estimator parameters.

Comparison of Manifold Learning methods

Manifold learning on handwritten digits: Locally Linear Embedding, Isomap…

Manifold Learning methods on a severed sphere

Swiss Roll And Swiss-Hole Reduction

t-SNE: The effect of various perplexity values on the shape

Approximate nearest neighbors in TSNE

**Examples:**

Example 1 (sql):
```sql
>>> import numpy as np
>>> from sklearn.manifold import TSNE
>>> X = np.array([[0, 0, 0], [0, 1, 1], [1, 0, 1], [1, 1, 1]])
>>> X_embedded = TSNE(n_components=2, learning_rate='auto',
...                   init='random', perplexity=3).fit_transform(X)
>>> X_embedded.shape
(4, 2)
```

---

## Hyperparameter#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.gaussian_process.kernels.Hyperparameter.html

**Contents:**
- Hyperparameter#
- Gallery examples#

A kernel hyperparameter’s specification in form of a namedtuple.

Added in version 0.18.

The name of the hyperparameter. Note that a kernel using a hyperparameter with name “x” must have the attributes self.x and self.x_bounds

The type of the hyperparameter. Currently, only “numeric” hyperparameters are supported.

The lower and upper bound on the parameter. If n_elements>1, a pair of 1d array with n_elements each may be given alternatively. If the string “fixed” is passed as bounds, the hyperparameter’s value cannot be changed.

The number of elements of the hyperparameter value. Defaults to 1, which corresponds to a scalar hyperparameter. n_elements > 1 corresponds to a hyperparameter which is vector-valued, such as, e.g., anisotropic length-scales.

Whether the value of this hyperparameter is fixed, i.e., cannot be changed during hyperparameter tuning. If None is passed, the “fixed” is derived based on the given bounds.

We can access each hyperparameter:

Alias for field number 2

Return number of occurrences of value.

Alias for field number 4

Return first index of value.

Raises ValueError if the value is not present.

Alias for field number 3

Alias for field number 0

Alias for field number 1

Gaussian processes on discrete data structures

**Examples:**

Example 1 (sql):
```sql
>>> from sklearn.gaussian_process.kernels import ConstantKernel
>>> from sklearn.datasets import make_friedman2
>>> from sklearn.gaussian_process import GaussianProcessRegressor
>>> from sklearn.gaussian_process.kernels import Hyperparameter
>>> X, y = make_friedman2(n_samples=50, noise=0, random_state=0)
>>> kernel = ConstantKernel(constant_value=1.0,
...    constant_value_bounds=(0.0, 10.0))
```

Example 2 (python):
```python
>>> for hyperparameter in kernel.hyperparameters:
...    print(hyperparameter)
Hyperparameter(name='constant_value', value_type='numeric',
bounds=array([[ 0., 10.]]), n_elements=1, fixed=False)
```

Example 3 (json):
```json
>>> params = kernel.get_params()
>>> for key in sorted(params): print(f"{key} : {params[key]}")
constant_value : 1.0
constant_value_bounds : (0.0, 10.0)
```

---

## 1.13. Feature selection#

**URL:** https://scikit-learn.org/stable/modules/feature_selection.html

**Contents:**
- 1.13. Feature selection#
- 1.13.1. Removing features with low variance#
- 1.13.2. Univariate feature selection#
- 1.13.3. Recursive feature elimination#
- 1.13.4. Feature selection using SelectFromModel#
  - 1.13.4.1. L1-based feature selection#
  - 1.13.4.2. Tree-based feature selection#
- 1.13.5. Sequential Feature Selection#
- 1.13.6. Feature selection as part of a pipeline#

The classes in the sklearn.feature_selection module can be used for feature selection/dimensionality reduction on sample sets, either to improve estimators’ accuracy scores or to boost their performance on very high-dimensional datasets.

VarianceThreshold is a simple baseline approach to feature selection. It removes all features whose variance doesn’t meet some threshold. By default, it removes all zero-variance features, i.e. features that have the same value in all samples.

As an example, suppose that we have a dataset with boolean features, and we want to remove all features that are either one or zero (on or off) in more than 80% of the samples. Boolean features are Bernoulli random variables, and the variance of such variables is given by

so we can select using the threshold .8 * (1 - .8):

As expected, VarianceThreshold has removed the first column, which has a probability \(p = 5/6 > .8\) of containing a zero.

Univariate feature selection works by selecting the best features based on univariate statistical tests. It can be seen as a preprocessing step to an estimator. Scikit-learn exposes feature selection routines as objects that implement the transform method:

SelectKBest removes all but the \(k\) highest scoring features

SelectPercentile removes all but a user-specified highest scoring percentage of features

using common univariate statistical tests for each feature: false positive rate SelectFpr, false discovery rate SelectFdr, or family wise error SelectFwe.

GenericUnivariateSelect allows to perform univariate feature selection with a configurable strategy. This allows to select the best univariate selection strategy with hyper-parameter search estimator.

For instance, we can use a F-test to retrieve the two best features for a dataset as follows:

These objects take as input a scoring function that returns univariate scores and p-values (or only scores for SelectKBest and SelectPercentile):

For regression: r_regression, f_regression, mutual_info_regression

For classification: chi2, f_classif, mutual_info_classif

The methods based on F-test estimate the degree of linear dependency between two random variables. On the other hand, mutual information methods can capture any kind of statistical dependency, but being nonparametric, they require more samples for accurate estimation. Note that the \(\chi^2\)-test should only be applied to non-negative features, such as frequencies.

Feature selection with sparse data

If you use sparse data (i.e. data represented as sparse matrices), chi2, mutual_info_regression, mutual_info_classif will deal with the data without making it dense.

Beware not to use a regression scoring function with a classification problem, you will get useless results.

The SelectPercentile and SelectKBest support unsupervised feature selection as well. One needs to provide a score_func where y=None. The score_func should use internally X to compute the scores.

Univariate Feature Selection

Comparison of F-test and mutual information

Given an external estimator that assigns weights to features (e.g., the coefficients of a linear model), the goal of recursive feature elimination (RFE) is to select features by recursively considering smaller and smaller sets of features. First, the estimator is trained on the initial set of features and the importance of each feature is obtained either through any specific attribute (such as coef_, feature_importances_) or callable. Then, the least important features are pruned from the current set of features. That procedure is recursively repeated on the pruned set until the desired number of features to select is eventually reached.

RFECV performs RFE in a cross-validation loop to find the optimal number of features. In more details, the number of features selected is tuned automatically by fitting an RFE selector on the different cross-validation splits (provided by the cv parameter). The performance of the RFE selector is evaluated using scorer for different numbers of selected features and aggregated together. Finally, the scores are averaged across folds and the number of features selected is set to the number of features that maximize the cross-validation score.

Recursive feature elimination: A recursive feature elimination example showing the relevance of pixels in a digit classification task.

Recursive feature elimination with cross-validation: A recursive feature elimination example with automatic tuning of the number of features selected with cross-validation.

SelectFromModel is a meta-transformer that can be used alongside any estimator that assigns importance to each feature through a specific attribute (such as coef_, feature_importances_) or via an importance_getter callable after fitting. The features are considered unimportant and removed if the corresponding importance of the feature values is below the provided threshold parameter. Apart from specifying the threshold numerically, there are built-in heuristics for finding a threshold using a string argument. Available heuristics are “mean”, “median” and float multiples of these like “0.1*mean”. In combination with the threshold criteria, one can use the max_features parameter to set a limit on the number of features to select.

For examples on how it is to be used refer to the sections below.

Model-based and sequential feature selection

Linear models penalized with the L1 norm have sparse solutions: many of their estimated coefficients are zero. When the goal is to reduce the dimensionality of the data to use with another classifier, they can be used along with SelectFromModel to select the non-zero coefficients. In particular, sparse estimators useful for this purpose are the Lasso for regression, and of LogisticRegression and LinearSVC for classification:

With SVMs and logistic regression, the parameter C controls the sparsity: the smaller C the fewer features selected. With Lasso, the higher the alpha parameter, the fewer features selected.

Lasso on dense and sparse data.

For a good choice of alpha, the Lasso can fully recover the exact set of non-zero variables using only few observations, provided certain specific conditions are met. In particular, the number of samples should be “sufficiently large”, or L1 models will perform at random, where “sufficiently large” depends on the number of non-zero coefficients, the logarithm of the number of features, the amount of noise, the smallest absolute value of non-zero coefficients, and the structure of the design matrix X. In addition, the design matrix must display certain specific properties, such as not being too correlated. On the use of Lasso for sparse signal recovery, see this example on compressive sensing: Compressive sensing: tomography reconstruction with L1 prior (Lasso).

There is no general rule to select an alpha parameter for recovery of non-zero coefficients. It can be set by cross-validation (LassoCV or LassoLarsCV), though this may lead to under-penalized models: including a small number of non-relevant variables is not detrimental to prediction score. BIC (LassoLarsIC) tends, on the opposite, to set high values of alpha.

Richard G. Baraniuk “Compressive Sensing”, IEEE Signal Processing Magazine [120] July 2007 http://users.isr.ist.utl.pt/~aguiar/CS_notes.pdf

Tree-based estimators (see the sklearn.tree module and forest of trees in the sklearn.ensemble module) can be used to compute impurity-based feature importances, which in turn can be used to discard irrelevant features (when coupled with the SelectFromModel meta-transformer):

Feature importances with a forest of trees: example on synthetic data showing the recovery of the actually meaningful features.

Permutation Importance vs Random Forest Feature Importance (MDI): example discussing the caveats of using impurity-based feature importances as a proxy for feature relevance.

Sequential Feature Selection [sfs] (SFS) is available in the SequentialFeatureSelector transformer. SFS can be either forward or backward:

Forward-SFS is a greedy procedure that iteratively finds the best new feature to add to the set of selected features. Concretely, we initially start with zero features and find the one feature that maximizes a cross-validated score when an estimator is trained on this single feature. Once that first feature is selected, we repeat the procedure by adding a new feature to the set of selected features. The procedure stops when the desired number of selected features is reached, as determined by the n_features_to_select parameter.

Backward-SFS follows the same idea but works in the opposite direction: instead of starting with no features and greedily adding features, we start with all the features and greedily remove features from the set. The direction parameter controls whether forward or backward SFS is used.

In general, forward and backward selection do not yield equivalent results. Also, one may be much faster than the other depending on the requested number of selected features: if we have 10 features and ask for 7 selected features, forward selection would need to perform 7 iterations while backward selection would only need to perform 3.

SFS differs from RFE and SelectFromModel in that it does not require the underlying model to expose a coef_ or feature_importances_ attribute. It may however be slower considering that more models need to be evaluated, compared to the other approaches. For example in backward selection, the iteration going from m features to m - 1 features using k-fold cross-validation requires fitting m * k models, while RFE would require only a single fit, and SelectFromModel always just does a single fit and requires no iterations.

Ferri et al, Comparative study of techniques for large-scale feature selection.

Model-based and sequential feature selection

Feature selection is usually used as a pre-processing step before doing the actual learning. The recommended way to do this in scikit-learn is to use a Pipeline:

In this snippet we make use of a LinearSVC coupled with SelectFromModel to evaluate feature importances and select the most relevant features. Then, a RandomForestClassifier is trained on the transformed output, i.e. using only relevant features. You can perform similar operations with the other feature selection methods and also classifiers that provide a way to evaluate feature importances of course. See the Pipeline examples for more details.

**Examples:**

Example 1 (sql):
```sql
>>> from sklearn.feature_selection import VarianceThreshold
>>> X = [[0, 0, 1], [0, 1, 0], [1, 0, 0], [0, 1, 1], [0, 1, 0], [0, 1, 1]]
>>> sel = VarianceThreshold(threshold=(.8 * (1 - .8)))
>>> sel.fit_transform(X)
array([[0, 1],
       [1, 0],
       [0, 0],
       [1, 1],
       [1, 0],
       [1, 1]])
```

Example 2 (sql):
```sql
>>> from sklearn.datasets import load_iris
>>> from sklearn.feature_selection import SelectKBest
>>> from sklearn.feature_selection import f_classif
>>> X, y = load_iris(return_X_y=True)
>>> X.shape
(150, 4)
>>> X_new = SelectKBest(f_classif, k=2).fit_transform(X, y)
>>> X_new.shape
(150, 2)
```

Example 3 (csharp):
```csharp
>>> from sklearn.svm import LinearSVC
>>> from sklearn.datasets import load_iris
>>> from sklearn.feature_selection import SelectFromModel
>>> X, y = load_iris(return_X_y=True)
>>> X.shape
(150, 4)
>>> lsvc = LinearSVC(C=0.01, penalty="l1", dual=False).fit(X, y)
>>> model = SelectFromModel(lsvc, prefit=True)
>>> X_new = model.transform(X)
>>> X_new.shape
(150, 3)
```

Example 4 (csharp):
```csharp
>>> from sklearn.ensemble import ExtraTreesClassifier
>>> from sklearn.datasets import load_iris
>>> from sklearn.feature_selection import SelectFromModel
>>> X, y = load_iris(return_X_y=True)
>>> X.shape
(150, 4)
>>> clf = ExtraTreesClassifier(n_estimators=50)
>>> clf = clf.fit(X, y)
>>> clf.feature_importances_
array([ 0.04,  0.05,  0.4,  0.4])
>>> model = SelectFromModel(clf, prefit=True)
>>> X_new = model.transform(X)
>>> X_new.shape
(150, 2)
```

---

## SelectKBest#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectKBest.html

**Contents:**
- SelectKBest#
- Gallery examples#

Select features according to the k highest scores.

Read more in the User Guide.

Function taking two arrays X and y, and returning a pair of arrays (scores, pvalues) or a single array with scores. Default is f_classif (see below “See Also”). The default function only works with classification tasks.

Added in version 0.18.

Number of top features to select. The “all” option bypasses selection, for use in a parameter search.

p-values of feature scores, None if score_func returned only scores.

Number of features seen during fit.

Added in version 0.24.

Names of features seen during fit. Defined only when X has feature names that are all strings.

Added in version 1.0.

ANOVA F-value between label/feature for classification tasks.

Mutual information for a discrete target.

Chi-squared stats of non-negative features for classification tasks.

F-value between label/feature for regression tasks.

Mutual information for a continuous target.

Select features based on percentile of the highest scores.

Select features based on a false positive rate test.

Select features based on an estimated false discovery rate.

Select features based on family-wise error rate.

Univariate feature selector with configurable mode.

Ties between features with equal scores will be broken in an unspecified way.

This filter supports unsupervised feature selection that only requests X for computing the scores.

Run score function on (X, y) and get the appropriate features.

The training input samples.

The target values (class labels in classification, real numbers in regression). If the selector is unsupervised then y can be set to None.

Returns the instance itself.

Fit to data, then transform it.

Fits transformer to X and y with optional parameters fit_params and returns a transformed version of X.

Target values (None for unsupervised transformations).

Additional fit parameters. Pass only if the estimator accepts additional params in its fit method.

Mask feature names according to selected features.

If input_features is None, then feature_names_in_ is used as feature names in. If feature_names_in_ is not defined, then the following input feature names are generated: ["x0", "x1", ..., "x(n_features_in_ - 1)"].

If input_features is an array-like, then input_features must match feature_names_in_ if feature_names_in_ is defined.

Transformed feature names.

Get metadata routing of this object.

Please check User Guide on how the routing mechanism works.

A MetadataRequest encapsulating routing information.

Get parameters for this estimator.

If True, will return the parameters for this estimator and contained subobjects that are estimators.

Parameter names mapped to their values.

Get a mask, or integer index, of the features selected.

If True, the return value will be an array of integers, rather than a boolean mask.

An index that selects the retained features from a feature vector. If indices is False, this is a boolean array of shape [# input features], in which an element is True iff its corresponding feature is selected for retention. If indices is True, this is an integer array of shape [# output features] whose values are indices into the input feature vector.

Reverse the transformation operation.

X with columns of zeros inserted where features would have been removed by transform.

Set output container.

See Introducing the set_output API for an example on how to use the API.

Configure output of transform and fit_transform.

"default": Default output format of a transformer

"pandas": DataFrame output

"polars": Polars output

None: Transform configuration is unchanged

Added in version 1.4: "polars" option was added.

Set the parameters of this estimator.

The method works on simple estimators as well as on nested objects (such as Pipeline). The latter have parameters of the form <component>__<parameter> so that it’s possible to update each component of a nested object.

Estimator parameters.

Reduce X to the selected features.

The input samples with only the selected features.

Selecting dimensionality reduction with Pipeline and GridSearchCV

Concatenating multiple feature extraction methods

Univariate Feature Selection

Release Highlights for scikit-learn 1.1

**Examples:**

Example 1 (sql):
```sql
>>> from sklearn.datasets import load_digits
>>> from sklearn.feature_selection import SelectKBest, chi2
>>> X, y = load_digits(return_X_y=True)
>>> X.shape
(1797, 64)
>>> X_new = SelectKBest(chi2, k=20).fit_transform(X, y)
>>> X_new.shape
(1797, 20)
```

---

## GradientBoostingClassifier#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html

**Contents:**
- GradientBoostingClassifier#
- Gallery examples#

Gradient Boosting for classification.

This algorithm builds an additive model in a forward stage-wise fashion; it allows for the optimization of arbitrary differentiable loss functions. In each stage n_classes_ regression trees are fit on the negative gradient of the loss function, e.g. binary or multiclass log loss. Binary classification is a special case where only a single regression tree is induced.

HistGradientBoostingClassifier is a much faster variant of this algorithm for intermediate and large datasets (n_samples >= 10_000) and supports monotonic constraints.

Read more in the User Guide.

The loss function to be optimized. ‘log_loss’ refers to binomial and multinomial deviance, the same as used in logistic regression. It is a good choice for classification with probabilistic outputs. For loss ‘exponential’, gradient boosting recovers the AdaBoost algorithm.

Learning rate shrinks the contribution of each tree by learning_rate. There is a trade-off between learning_rate and n_estimators. Values must be in the range [0.0, inf).

For an example of the effects of this parameter and its interaction with subsample, see Gradient Boosting regularization.

The number of boosting stages to perform. Gradient boosting is fairly robust to over-fitting so a large number usually results in better performance. Values must be in the range [1, inf).

The fraction of samples to be used for fitting the individual base learners. If smaller than 1.0 this results in Stochastic Gradient Boosting. subsample interacts with the parameter n_estimators. Choosing subsample < 1.0 leads to a reduction of variance and an increase in bias. Values must be in the range (0.0, 1.0].

The function to measure the quality of a split. Supported criteria are ‘friedman_mse’ for the mean squared error with improvement score by Friedman, ‘squared_error’ for mean squared error. The default value of ‘friedman_mse’ is generally the best as it can provide a better approximation in some cases.

Added in version 0.18.

The minimum number of samples required to split an internal node:

If int, values must be in the range [2, inf).

If float, values must be in the range (0.0, 1.0] and min_samples_split will be ceil(min_samples_split * n_samples).

Changed in version 0.18: Added float values for fractions.

The minimum number of samples required to be at a leaf node. A split point at any depth will only be considered if it leaves at least min_samples_leaf training samples in each of the left and right branches. This may have the effect of smoothing the model, especially in regression.

If int, values must be in the range [1, inf).

If float, values must be in the range (0.0, 1.0) and min_samples_leaf will be ceil(min_samples_leaf * n_samples).

Changed in version 0.18: Added float values for fractions.

The minimum weighted fraction of the sum total of weights (of all the input samples) required to be at a leaf node. Samples have equal weight when sample_weight is not provided. Values must be in the range [0.0, 0.5].

Maximum depth of the individual regression estimators. The maximum depth limits the number of nodes in the tree. Tune this parameter for best performance; the best value depends on the interaction of the input variables. If None, then nodes are expanded until all leaves are pure or until all leaves contain less than min_samples_split samples. If int, values must be in the range [1, inf).

A node will be split if this split induces a decrease of the impurity greater than or equal to this value. Values must be in the range [0.0, inf).

The weighted impurity decrease equation is the following:

where N is the total number of samples, N_t is the number of samples at the current node, N_t_L is the number of samples in the left child, and N_t_R is the number of samples in the right child.

N, N_t, N_t_R and N_t_L all refer to the weighted sum, if sample_weight is passed.

Added in version 0.19.

An estimator object that is used to compute the initial predictions. init has to provide fit and predict_proba. If ‘zero’, the initial raw predictions are set to zero. By default, a DummyEstimator predicting the classes priors is used.

Controls the random seed given to each Tree estimator at each boosting iteration. In addition, it controls the random permutation of the features at each split (see Notes for more details). It also controls the random splitting of the training data to obtain a validation set if n_iter_no_change is not None. Pass an int for reproducible output across multiple function calls. See Glossary.

The number of features to consider when looking for the best split:

If int, values must be in the range [1, inf).

If float, values must be in the range (0.0, 1.0] and the features considered at each split will be max(1, int(max_features * n_features_in_)).

If ‘sqrt’, then max_features=sqrt(n_features).

If ‘log2’, then max_features=log2(n_features).

If None, then max_features=n_features.

Choosing max_features < n_features leads to a reduction of variance and an increase in bias.

Note: the search for a split does not stop until at least one valid partition of the node samples is found, even if it requires to effectively inspect more than max_features features.

Enable verbose output. If 1 then it prints progress and performance once in a while (the more trees the lower the frequency). If greater than 1 then it prints progress and performance for every tree. Values must be in the range [0, inf).

Grow trees with max_leaf_nodes in best-first fashion. Best nodes are defined as relative reduction in impurity. Values must be in the range [2, inf). If None, then unlimited number of leaf nodes.

When set to True, reuse the solution of the previous call to fit and add more estimators to the ensemble, otherwise, just erase the previous solution. See the Glossary.

The proportion of training data to set aside as validation set for early stopping. Values must be in the range (0.0, 1.0). Only used if n_iter_no_change is set to an integer.

Added in version 0.20.

n_iter_no_change is used to decide if early stopping will be used to terminate training when validation score is not improving. By default it is set to None to disable early stopping. If set to a number, it will set aside validation_fraction size of the training data as validation and terminate training when validation score is not improving in all of the previous n_iter_no_change numbers of iterations. The split is stratified. Values must be in the range [1, inf). See Early stopping in Gradient Boosting.

Added in version 0.20.

Tolerance for the early stopping. When the loss is not improving by at least tol for n_iter_no_change iterations (if set to a number), the training stops. Values must be in the range [0.0, inf).

Added in version 0.20.

Complexity parameter used for Minimal Cost-Complexity Pruning. The subtree with the largest cost complexity that is smaller than ccp_alpha will be chosen. By default, no pruning is performed. Values must be in the range [0.0, inf). See Minimal Cost-Complexity Pruning for details. See Post pruning decision trees with cost complexity pruning for an example of such pruning.

Added in version 0.22.

The number of estimators as selected by early stopping (if n_iter_no_change is specified). Otherwise it is set to n_estimators.

Added in version 0.20.

The number of trees that are built at each iteration. For binary classifiers, this is always 1.

Added in version 1.4.0.

The impurity-based feature importances.

The improvement in loss on the out-of-bag samples relative to the previous iteration. oob_improvement_[0] is the improvement in loss of the first stage over the init estimator. Only available if subsample < 1.0.

The full history of the loss values on the out-of-bag samples. Only available if subsample < 1.0.

Added in version 1.3.

The last value of the loss on the out-of-bag samples. It is the same as oob_scores_[-1]. Only available if subsample < 1.0.

Added in version 1.3.

The i-th score train_score_[i] is the loss of the model at iteration i on the in-bag sample. If subsample == 1 this is the loss on the training data.

The estimator that provides the initial predictions. Set via the init argument.

The collection of fitted sub-estimators. n_trees_per_iteration_ is 1 for binary classification, otherwise n_classes.

Number of features seen during fit.

Added in version 0.24.

Names of features seen during fit. Defined only when X has feature names that are all strings.

Added in version 1.0.

The number of classes.

The inferred value of max_features.

Histogram-based Gradient Boosting Classification Tree.

A decision tree classifier.

A meta-estimator that fits a number of decision tree classifiers on various sub-samples of the dataset and uses averaging to improve the predictive accuracy and control over-fitting.

A meta-estimator that begins by fitting a classifier on the original dataset and then fits additional copies of the classifier on the same dataset where the weights of incorrectly classified instances are adjusted such that subsequent classifiers focus more on difficult cases.

The features are always randomly permuted at each split. Therefore, the best found split may vary, even with the same training data and max_features=n_features, if the improvement of the criterion is identical for several splits enumerated during the search of the best split. To obtain a deterministic behaviour during fitting, random_state has to be fixed.

J. Friedman, Greedy Function Approximation: A Gradient Boosting Machine, The Annals of Statistics, Vol. 29, No. 5, 2001.

Friedman, Stochastic Gradient Boosting, 1999

T. Hastie, R. Tibshirani and J. Friedman. Elements of Statistical Learning Ed. 2, Springer, 2009.

The following example shows how to fit a gradient boosting classifier with 100 decision stumps as weak learners.

Apply trees in the ensemble to X, return leaf indices.

Added in version 0.17.

The input samples. Internally, its dtype will be converted to dtype=np.float32. If a sparse matrix is provided, it will be converted to a sparse csr_matrix.

For each datapoint x in X and for each tree in the ensemble, return the index of the leaf x ends up in each estimator. In the case of binary classification n_classes is 1.

Compute the decision function of X.

The input samples. Internally, it will be converted to dtype=np.float32 and if a sparse matrix is provided to a sparse csr_matrix.

The decision function of the input samples, which corresponds to the raw values predicted from the trees of the ensemble . The order of the classes corresponds to that in the attribute classes_. Regression and binary classification produce an array of shape (n_samples,).

Fit the gradient boosting model.

The input samples. Internally, it will be converted to dtype=np.float32 and if a sparse matrix is provided to a sparse csr_matrix.

Target values (strings or integers in classification, real numbers in regression) For classification, labels must correspond to classes.

Sample weights. If None, then samples are equally weighted. Splits that would create child nodes with net zero or negative weight are ignored while searching for a split in each node. In the case of classification, splits are also ignored if they would result in any single class carrying a negative weight in either child node.

The monitor is called after each iteration with the current iteration, a reference to the estimator and the local variables of _fit_stages as keyword arguments callable(i, self, locals()). If the callable returns True the fitting procedure is stopped. The monitor can be used for various things such as computing held-out estimates, early stopping, model introspect, and snapshotting.

Get metadata routing of this object.

Please check User Guide on how the routing mechanism works.

A MetadataRequest encapsulating routing information.

Get parameters for this estimator.

If True, will return the parameters for this estimator and contained subobjects that are estimators.

Parameter names mapped to their values.

The input samples. Internally, it will be converted to dtype=np.float32 and if a sparse matrix is provided to a sparse csr_matrix.

The predicted values.

Predict class log-probabilities for X.

The input samples. Internally, it will be converted to dtype=np.float32 and if a sparse matrix is provided to a sparse csr_matrix.

The class log-probabilities of the input samples. The order of the classes corresponds to that in the attribute classes_.

If the loss does not support probabilities.

Predict class probabilities for X.

The input samples. Internally, it will be converted to dtype=np.float32 and if a sparse matrix is provided to a sparse csr_matrix.

The class probabilities of the input samples. The order of the classes corresponds to that in the attribute classes_.

If the loss does not support probabilities.

Return accuracy on provided data and labels.

In multi-label classification, this is the subset accuracy which is a harsh metric since you require for each sample that each label set be correctly predicted.

Mean accuracy of self.predict(X) w.r.t. y.

Configure whether metadata should be requested to be passed to the fit method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to fit if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to fit.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Added in version 1.3.

Metadata routing for monitor parameter in fit.

Metadata routing for sample_weight parameter in fit.

Set the parameters of this estimator.

The method works on simple estimators as well as on nested objects (such as Pipeline). The latter have parameters of the form <component>__<parameter> so that it’s possible to update each component of a nested object.

Estimator parameters.

Configure whether metadata should be requested to be passed to the score method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to score if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to score.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Added in version 1.3.

Metadata routing for sample_weight parameter in score.

Compute decision function of X for each iteration.

This method allows monitoring (i.e. determine error on testing set) after each stage.

The input samples. Internally, it will be converted to dtype=np.float32 and if a sparse matrix is provided to a sparse csr_matrix.

The decision function of the input samples, which corresponds to the raw values predicted from the trees of the ensemble . The classes corresponds to that in the attribute classes_. Regression and binary classification are special cases with k == 1, otherwise k==n_classes.

Predict class at each stage for X.

This method allows monitoring (i.e. determine error on testing set) after each stage.

The input samples. Internally, it will be converted to dtype=np.float32 and if a sparse matrix is provided to a sparse csr_matrix.

The predicted value of the input samples.

Predict class probabilities at each stage for X.

This method allows monitoring (i.e. determine error on testing set) after each stage.

The input samples. Internally, it will be converted to dtype=np.float32 and if a sparse matrix is provided to a sparse csr_matrix.

The predicted value of the input samples.

Feature transformations with ensembles of trees

Gradient Boosting Out-of-Bag estimates

Gradient Boosting regularization

Feature discretization

**Examples:**

Example 1 (yaml):
```yaml
N_t / N * (impurity - N_t_R / N_t * right_impurity
                    - N_t_L / N_t * left_impurity)
```

Example 2 (sql):
```sql
>>> from sklearn.datasets import make_hastie_10_2
>>> from sklearn.ensemble import GradientBoostingClassifier
```

Example 3 (json):
```json
>>> X, y = make_hastie_10_2(random_state=0)
>>> X_train, X_test = X[:2000], X[2000:]
>>> y_train, y_test = y[:2000], y[2000:]
```

Example 4 (unknown):
```unknown
>>> clf = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0,
...     max_depth=1, random_state=0).fit(X_train, y_train)
>>> clf.score(X_test, y_test)
0.913
```

---

## GaussianMixture#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.mixture.GaussianMixture.html

**Contents:**
- GaussianMixture#
- Gallery examples#

Representation of a Gaussian mixture model probability distribution. This class allows to estimate the parameters of a Gaussian mixture distribution.

Read more in the User Guide.

Added in version 0.18.

The number of mixture components.

String describing the type of covariance parameters to use. Must be one of:

‘full’: each component has its own general covariance matrix.

‘tied’: all components share the same general covariance matrix.

‘diag’: each component has its own diagonal covariance matrix.

‘spherical’: each component has its own single variance.

For an example of using covariance_type, refer to Gaussian Mixture Model Selection.

The convergence threshold. EM iterations will stop when the lower bound average gain is below this threshold.

Non-negative regularization added to the diagonal of covariance. Allows to assure that the covariance matrices are all positive.

The number of EM iterations to perform.

The number of initializations to perform. The best results are kept.

The method used to initialize the weights, the means and the precisions. String must be one of:

‘kmeans’ : responsibilities are initialized using kmeans.

‘k-means++’ : use the k-means++ method to initialize.

‘random’ : responsibilities are initialized randomly.

‘random_from_data’ : initial means are randomly selected data points.

Changed in version v1.1: init_params now accepts ‘random_from_data’ and ‘k-means++’ as initialization methods.

The user-provided initial weights. If it is None, weights are initialized using the init_params method.

The user-provided initial means, If it is None, means are initialized using the init_params method.

The user-provided initial precisions (inverse of the covariance matrices). If it is None, precisions are initialized using the ‘init_params’ method. The shape depends on ‘covariance_type’:

Controls the random seed given to the method chosen to initialize the parameters (see init_params). In addition, it controls the generation of random samples from the fitted distribution (see the method sample). Pass an int for reproducible output across multiple function calls. See Glossary.

If ‘warm_start’ is True, the solution of the last fitting is used as initialization for the next call of fit(). This can speed up convergence when fit is called several times on similar problems. In that case, ‘n_init’ is ignored and only a single initialization occurs upon the first call. See the Glossary.

Enable verbose output. If 1 then it prints the current initialization and each iteration step. If greater than 1 then it prints also the log probability and the time needed for each step.

Number of iteration done before the next print.

The weights of each mixture components.

The mean of each mixture component.

The covariance of each mixture component. The shape depends on covariance_type:

For an example of using covariances, refer to GMM covariances.

The precision matrices for each component in the mixture. A precision matrix is the inverse of a covariance matrix. A covariance matrix is symmetric positive definite so the mixture of Gaussian can be equivalently parameterized by the precision matrices. Storing the precision matrices instead of the covariance matrices makes it more efficient to compute the log-likelihood of new samples at test time. The shape depends on covariance_type:

The Cholesky decomposition of the precision matrices of each mixture component. A precision matrix is the inverse of a covariance matrix. A covariance matrix is symmetric positive definite so the mixture of Gaussian can be equivalently parameterized by the precision matrices. Storing the precision matrices instead of the covariance matrices makes it more efficient to compute the log-likelihood of new samples at test time. The shape depends on covariance_type:

True when convergence of the best fit of EM was reached, False otherwise.

Number of step used by the best fit of EM to reach the convergence.

Lower bound value on the log-likelihood (of the training data with respect to the model) of the best fit of EM.

The list of lower bound values on the log-likelihood from each iteration of the best fit of EM.

Number of features seen during fit.

Added in version 0.24.

Names of features seen during fit. Defined only when X has feature names that are all strings.

Added in version 1.0.

Gaussian mixture model fit with a variational inference.

For a comparison of Gaussian Mixture with other clustering algorithms, see Comparing different clustering algorithms on toy datasets.

For an illustration of the negative log-likelihood surface of a GaussianMixture Model, see Density Estimation for a Gaussian mixture.

Akaike information criterion for the current model on the input X.

You can refer to this mathematical section for more details regarding the formulation of the AIC used.

The lower the better.

Bayesian information criterion for the current model on the input X.

You can refer to this mathematical section for more details regarding the formulation of the BIC used.

For an example of GMM selection using bic information criterion, refer to Gaussian Mixture Model Selection.

The lower the better.

Estimate model parameters with the EM algorithm.

The method fits the model n_init times and sets the parameters with which the model has the largest likelihood or lower bound. Within each trial, the method iterates between E-step and M-step for max_iter times until the change of likelihood or lower bound is less than tol, otherwise, a ConvergenceWarning is raised. If warm_start is True, then n_init is ignored and a single initialization is performed upon the first call. Upon consecutive calls, training starts where it left off.

List of n_features-dimensional data points. Each row corresponds to a single data point.

Not used, present for API consistency by convention.

Estimate model parameters using X and predict the labels for X.

The method fits the model n_init times and sets the parameters with which the model has the largest likelihood or lower bound. Within each trial, the method iterates between E-step and M-step for max_iter times until the change of likelihood or lower bound is less than tol, otherwise, a ConvergenceWarning is raised. After fitting, it predicts the most probable label for the input data points.

Added in version 0.20.

List of n_features-dimensional data points. Each row corresponds to a single data point.

Not used, present for API consistency by convention.

Get metadata routing of this object.

Please check User Guide on how the routing mechanism works.

A MetadataRequest encapsulating routing information.

Get parameters for this estimator.

If True, will return the parameters for this estimator and contained subobjects that are estimators.

Parameter names mapped to their values.

Predict the labels for the data samples in X using trained model.

List of n_features-dimensional data points. Each row corresponds to a single data point.

Evaluate the components’ density for each sample.

List of n_features-dimensional data points. Each row corresponds to a single data point.

Density of each Gaussian component for each sample in X.

Generate random samples from the fitted Gaussian distribution.

Number of samples to generate.

Randomly generated sample.

Compute the per-sample average log-likelihood of the given data X.

List of n_features-dimensional data points. Each row corresponds to a single data point.

Not used, present for API consistency by convention.

Log-likelihood of X under the Gaussian mixture model.

Compute the log-likelihood of each sample.

List of n_features-dimensional data points. Each row corresponds to a single data point.

Log-likelihood of each sample in X under the current model.

Set the parameters of this estimator.

The method works on simple estimators as well as on nested objects (such as Pipeline). The latter have parameters of the form <component>__<parameter> so that it’s possible to update each component of a nested object.

Estimator parameters.

Comparing different clustering algorithms on toy datasets

Demonstration of k-means assumptions

Gaussian Mixture Model Ellipsoids

GMM Initialization Methods

Density Estimation for a Gaussian mixture

Gaussian Mixture Model Selection

Gaussian Mixture Model Sine Curve

**Examples:**

Example 1 (unknown):
```unknown
(n_components,)                        if 'spherical',
(n_features, n_features)               if 'tied',
(n_components, n_features)             if 'diag',
(n_components, n_features, n_features) if 'full'
```

Example 2 (unknown):
```unknown
(n_components,)                        if 'spherical',
(n_features, n_features)               if 'tied',
(n_components, n_features)             if 'diag',
(n_components, n_features, n_features) if 'full'
```

Example 3 (unknown):
```unknown
(n_components,)                        if 'spherical',
(n_features, n_features)               if 'tied',
(n_components, n_features)             if 'diag',
(n_components, n_features, n_features) if 'full'
```

Example 4 (unknown):
```unknown
(n_components,)                        if 'spherical',
(n_features, n_features)               if 'tied',
(n_components, n_features)             if 'diag',
(n_components, n_features, n_features) if 'full'
```

---

## 1.8. Cross decomposition#

**URL:** https://scikit-learn.org/stable/modules/cross_decomposition.html

**Contents:**
- 1.8. Cross decomposition#
- 1.8.1. PLSCanonical#
- 1.8.2. PLSSVD#
- 1.8.3. PLSRegression#
- 1.8.4. Canonical Correlation Analysis#

The cross decomposition module contains supervised estimators for dimensionality reduction and regression, belonging to the “Partial Least Squares” family.

Cross decomposition algorithms find the fundamental relations between two matrices (X and Y). They are latent variable approaches to modeling the covariance structures in these two spaces. They will try to find the multidimensional direction in the X space that explains the maximum multidimensional variance direction in the Y space. In other words, PLS projects both X and Y into a lower-dimensional subspace such that the covariance between transformed(X) and transformed(Y) is maximal.

PLS draws similarities with Principal Component Regression (PCR), where the samples are first projected into a lower-dimensional subspace, and the targets y are predicted using transformed(X). One issue with PCR is that the dimensionality reduction is unsupervised, and may lose some important variables: PCR would keep the features with the most variance, but it’s possible that features with small variances are relevant for predicting the target. In a way, PLS allows for the same kind of dimensionality reduction, but by taking into account the targets y. An illustration of this fact is given in the following example: * Principal Component Regression vs Partial Least Squares Regression.

Apart from CCA, the PLS estimators are particularly suited when the matrix of predictors has more variables than observations, and when there is multicollinearity among the features. By contrast, standard linear regression would fail in these cases unless it is regularized.

Classes included in this module are PLSRegression, PLSCanonical, CCA and PLSSVD

We here describe the algorithm used in PLSCanonical. The other estimators use variants of this algorithm, and are detailed below. We recommend section [1] for more details and comparisons between these algorithms. In [1], PLSCanonical corresponds to “PLSW2A”.

Given two centered matrices \(X \in \mathbb{R}^{n \times d}\) and \(Y \in \mathbb{R}^{n \times t}\), and a number of components \(K\), PLSCanonical proceeds as follows:

Set \(X_1\) to \(X\) and \(Y_1\) to \(Y\). Then, for each \(k \in [1, K]\):

a) compute \(u_k \in \mathbb{R}^d\) and \(v_k \in \mathbb{R}^t\), the first left and right singular vectors of the cross-covariance matrix \(C = X_k^T Y_k\). \(u_k\) and \(v_k\) are called the weights. By definition, \(u_k\) and \(v_k\) are chosen so that they maximize the covariance between the projected \(X_k\) and the projected target, that is \(\text{Cov}(X_k u_k, Y_k v_k)\).

b) Project \(X_k\) and \(Y_k\) on the singular vectors to obtain scores: \(\xi_k = X_k u_k\) and \(\omega_k = Y_k v_k\)

c) Regress \(X_k\) on \(\xi_k\), i.e. find a vector \(\gamma_k \in \mathbb{R}^d\) such that the rank-1 matrix \(\xi_k \gamma_k^T\) is as close as possible to \(X_k\). Do the same on \(Y_k\) with \(\omega_k\) to obtain \(\delta_k\). The vectors \(\gamma_k\) and \(\delta_k\) are called the loadings.

d) deflate \(X_k\) and \(Y_k\), i.e. subtract the rank-1 approximations: \(X_{k+1} = X_k - \xi_k \gamma_k^T\), and \(Y_{k + 1} = Y_k - \omega_k \delta_k^T\).

At the end, we have approximated \(X\) as a sum of rank-1 matrices: \(X = \Xi \Gamma^T\) where \(\Xi \in \mathbb{R}^{n \times K}\) contains the scores in its columns, and \(\Gamma^T \in \mathbb{R}^{K \times d}\) contains the loadings in its rows. Similarly for \(Y\), we have \(Y = \Omega \Delta^T\).

Note that the scores matrices \(\Xi\) and \(\Omega\) correspond to the projections of the training data \(X\) and \(Y\), respectively.

Step a) may be performed in two ways: either by computing the whole SVD of \(C\) and only retaining the singular vectors with the biggest singular values, or by directly computing the singular vectors using the power method (cf section 11.3 in [1]), which corresponds to the 'nipals' option of the algorithm parameter.

To transform \(X\) into \(\bar{X}\), we need to find a projection matrix \(P\) such that \(\bar{X} = XP\). We know that for the training data, \(\Xi = XP\), and \(X = \Xi \Gamma^T\). Setting \(P = U(\Gamma^T U)^{-1}\) where \(U\) is the matrix with the \(u_k\) in the columns, we have \(XP = X U(\Gamma^T U)^{-1} = \Xi (\Gamma^T U) (\Gamma^T U)^{-1} = \Xi\) as desired. The rotation matrix \(P\) can be accessed from the x_rotations_ attribute.

Similarly, \(Y\) can be transformed using the rotation matrix \(V(\Delta^T V)^{-1}\), accessed via the y_rotations_ attribute.

To predict the targets of some data \(X\), we are looking for a coefficient matrix \(\beta \in R^{d \times t}\) such that \(Y = X\beta\).

The idea is to try to predict the transformed targets \(\Omega\) as a function of the transformed samples \(\Xi\), by computing \(\alpha \in \mathbb{R}\) such that \(\Omega = \alpha \Xi\).

Then, we have \(Y = \Omega \Delta^T = \alpha \Xi \Delta^T\), and since \(\Xi\) is the transformed training data we have that \(Y = X \alpha P \Delta^T\), and as a result the coefficient matrix \(\beta = \alpha P \Delta^T\).

\(\beta\) can be accessed through the coef_ attribute.

PLSSVD is a simplified version of PLSCanonical described earlier: instead of iteratively deflating the matrices \(X_k\) and \(Y_k\), PLSSVD computes the SVD of \(C = X^TY\) only once, and stores the n_components singular vectors corresponding to the biggest singular values in the matrices U and V, corresponding to the x_weights_ and y_weights_ attributes. Here, the transformed data is simply transformed(X) = XU and transformed(Y) = YV.

If n_components == 1, PLSSVD and PLSCanonical are strictly equivalent.

The PLSRegression estimator is similar to PLSCanonical with algorithm='nipals', with 2 significant differences:

at step a) in the power method to compute \(u_k\) and \(v_k\), \(v_k\) is never normalized.

at step c), the targets \(Y_k\) are approximated using the projection of \(X_k\) (i.e. \(\xi_k\)) instead of the projection of \(Y_k\) (i.e. \(\omega_k\)). In other words, the loadings computation is different. As a result, the deflation in step d) will also be affected.

These two modifications affect the output of predict and transform, which are not the same as for PLSCanonical. Also, while the number of components is limited by min(n_samples, n_features, n_targets) in PLSCanonical, here the limit is the rank of \(X^TX\), i.e. min(n_samples, n_features).

PLSRegression is also known as PLS1 (single targets) and PLS2 (multiple targets). Much like Lasso, PLSRegression is a form of regularized linear regression where the number of components controls the strength of the regularization.

Canonical Correlation Analysis was developed prior and independently to PLS. But it turns out that CCA is a special case of PLS, and corresponds to PLS in “Mode B” in the literature.

CCA differs from PLSCanonical in the way the weights \(u_k\) and \(v_k\) are computed in the power method of step a). Details can be found in section 10 of [1].

Since CCA involves the inversion of \(X_k^TX_k\) and \(Y_k^TY_k\), this estimator can be unstable if the number of features or targets is greater than the number of samples.

A survey of Partial Least Squares (PLS) methods, with emphasis on the two-block case, JA Wegelin

Compare cross decomposition methods

Principal Component Regression vs Partial Least Squares Regression

---

## 1.16. Probability calibration#

**URL:** https://scikit-learn.org/stable/modules/calibration.html

**Contents:**
- 1.16. Probability calibration#
- 1.16.1. Calibration curves#
- 1.16.2. Calibrating a classifier#
- 1.16.3. Usage#
  - 1.16.3.1. Sigmoid#
  - 1.16.3.2. Isotonic#
  - 1.16.3.3. Multiclass support#
  - 1.16.3.4. Temperature Scaling#

When performing classification you often want not only to predict the class label, but also obtain a probability of the respective label. This probability gives you some kind of confidence on the prediction. Some models can give you poor estimates of the class probabilities and some even do not support probability prediction (e.g., some instances of SGDClassifier). The calibration module allows you to better calibrate the probabilities of a given model, or to add support for probability prediction.

Well calibrated classifiers are probabilistic classifiers for which the output of the predict_proba method can be directly interpreted as a confidence level. For instance, a well calibrated (binary) classifier should classify the samples such that among the samples to which it gave a predict_proba value close to, say, 0.8, approximately 80% actually belong to the positive class.

Before we show how to re-calibrate a classifier, we first need a way to detect how good a classifier is calibrated.

Strictly proper scoring rules for probabilistic predictions like sklearn.metrics.brier_score_loss and sklearn.metrics.log_loss assess calibration (reliability) and discriminative power (resolution) of a model, as well as the randomness of the data (uncertainty) at the same time. This follows from the well-known Brier score decomposition of Murphy [1]. As it is not clear which term dominates, the score is of limited use for assessing calibration alone (unless one computes each term of the decomposition). A lower Brier loss, for instance, does not necessarily mean a better calibrated model, it could also mean a worse calibrated model with much more discriminatory power, e.g. using many more features.

Calibration curves, also referred to as reliability diagrams (Wilks 1995 [2]), compare how well the probabilistic predictions of a binary classifier are calibrated. It plots the frequency of the positive label (to be more precise, an estimation of the conditional event probability \(P(Y=1|\text{predict_proba})\)) on the y-axis against the predicted probability predict_proba of a model on the x-axis. The tricky part is to get values for the y-axis. In scikit-learn, this is accomplished by binning the predictions such that the x-axis represents the average predicted probability in each bin. The y-axis is then the fraction of positives given the predictions of that bin, i.e. the proportion of samples whose class is the positive class (in each bin).

The top calibration curve plot is created with CalibrationDisplay.from_estimator, which uses calibration_curve to calculate the per bin average predicted probabilities and fraction of positives. CalibrationDisplay.from_estimator takes as input a fitted classifier, which is used to calculate the predicted probabilities. The classifier thus must have predict_proba method. For the few classifiers that do not have a predict_proba method, it is possible to use CalibratedClassifierCV to calibrate the classifier outputs to probabilities.

The bottom histogram gives some insight into the behavior of each classifier by showing the number of samples in each predicted probability bin.

LogisticRegression is more likely to return well calibrated predictions by itself as it has a canonical link function for its loss, i.e. the logit-link for the Log loss. In the unpenalized case, this leads to the so-called balance property, see [8] and Logistic regression. In the plot above, data is generated according to a linear mechanism, which is consistent with the LogisticRegression model (the model is ‘well specified’), and the value of the regularization parameter C is tuned to be appropriate (neither too strong nor too low). As a consequence, this model returns accurate predictions from its predict_proba method. In contrast to that, the other shown models return biased probabilities; with different biases per model.

GaussianNB (Naive Bayes) tends to push probabilities to 0 or 1 (note the counts in the histograms). This is mainly because it makes the assumption that features are conditionally independent given the class, which is not the case in this dataset which contains 2 redundant features.

RandomForestClassifier shows the opposite behavior: the histograms show peaks at probabilities approximately 0.2 and 0.9, while probabilities close to 0 or 1 are very rare. An explanation for this is given by Niculescu-Mizil and Caruana [3]: “Methods such as bagging and random forests that average predictions from a base set of models can have difficulty making predictions near 0 and 1 because variance in the underlying base models will bias predictions that should be near zero or one away from these values. Because predictions are restricted to the interval [0,1], errors caused by variance tend to be one-sided near zero and one. For example, if a model should predict \(p = 0\) for a case, the only way bagging can achieve this is if all bagged trees predict zero. If we add noise to the trees that bagging is averaging over, this noise will cause some trees to predict values larger than 0 for this case, thus moving the average prediction of the bagged ensemble away from 0. We observe this effect most strongly with random forests because the base-level trees trained with random forests have relatively high variance due to feature subsetting.” As a result, the calibration curve shows a characteristic sigmoid shape, indicating that the classifier could trust its “intuition” more and return probabilities closer to 0 or 1 typically.

LinearSVC (SVC) shows an even more sigmoid curve than the random forest, which is typical for maximum-margin methods (compare Niculescu-Mizil and Caruana [3]), which focus on difficult to classify samples that are close to the decision boundary (the support vectors).

Calibrating a classifier consists of fitting a regressor (called a calibrator) that maps the output of the classifier (as given by decision_function or predict_proba) to a calibrated probability in [0, 1]. Denoting the output of the classifier for a given sample by \(f_i\), the calibrator tries to predict the conditional event probability \(P(y_i = 1 | f_i)\).

Ideally, the calibrator is fit on a dataset independent of the training data used to fit the classifier in the first place. This is because performance of the classifier on its training data would be better than for novel data. Using the classifier output of training data to fit the calibrator would thus result in a biased calibrator that maps to probabilities closer to 0 and 1 than it should.

The CalibratedClassifierCV class is used to calibrate a classifier.

CalibratedClassifierCV uses a cross-validation approach to ensure unbiased data is always used to fit the calibrator. The data is split into \(k\) (train_set, test_set) couples (as determined by cv). When ensemble=True (default), the following procedure is repeated independently for each cross-validation split:

a clone of base_estimator is trained on the train subset

the trained base_estimator makes predictions on the test subset

the predictions are used to fit a calibrator (either a sigmoid or isotonic regressor) (when the data is multiclass, a calibrator is fit for every class)

This results in an ensemble of \(k\) (classifier, calibrator) couples where each calibrator maps the output of its corresponding classifier into [0, 1]. Each couple is exposed in the calibrated_classifiers_ attribute, where each entry is a calibrated classifier with a predict_proba method that outputs calibrated probabilities. The output of predict_proba for the main CalibratedClassifierCV instance corresponds to the average of the predicted probabilities of the \(k\) estimators in the calibrated_classifiers_ list. The output of predict is the class that has the highest probability.

It is important to choose cv carefully when using ensemble=True. All classes should be present in both train and test subsets for every split. When a class is absent in the train subset, the predicted probability for that class will default to 0 for the (classifier, calibrator) couple of that split. This skews the predict_proba as it averages across all couples. When a class is absent in the test subset, the calibrator for that class (within the (classifier, calibrator) couple of that split) is fit on data with no positive class. This results in ineffective calibration.

When ensemble=False, cross-validation is used to obtain ‘unbiased’ predictions for all the data, via cross_val_predict. These unbiased predictions are then used to train the calibrator. The attribute calibrated_classifiers_ consists of only one (classifier, calibrator) couple where the classifier is the base_estimator trained on all the data. In this case the output of predict_proba for CalibratedClassifierCV is the predicted probabilities obtained from the single (classifier, calibrator) couple.

The main advantage of ensemble=True is to benefit from the traditional ensembling effect (similar to Bagging meta-estimator). The resulting ensemble should both be well calibrated and slightly more accurate than with ensemble=False. The main advantage of using ensemble=False is computational: it reduces the overall fit time by training only a single base classifier and calibrator pair, decreases the final model size and increases prediction speed.

Alternatively an already fitted classifier can be calibrated by using a FrozenEstimator as CalibratedClassifierCV(estimator=FrozenEstimator(estimator)). It is up to the user to make sure that the data used for fitting the classifier is disjoint from the data used for fitting the regressor.

CalibratedClassifierCV supports the use of two regression techniques for calibration via the method parameter: "sigmoid" and "isotonic".

The sigmoid regressor, method="sigmoid" is based on Platt’s logistic model [4]:

where \(y_i\) is the true label of sample \(i\) and \(f_i\) is the output of the un-calibrated classifier for sample \(i\). \(A\) and \(B\) are real numbers to be determined when fitting the regressor via maximum likelihood.

The sigmoid method assumes the calibration curve can be corrected by applying a sigmoid function to the raw predictions. This assumption has been empirically justified in the case of Support Vector Machines with common kernel functions on various benchmark datasets in section 2.1 of Platt 1999 [4] but does not necessarily hold in general. Additionally, the logistic model works best if the calibration error is symmetrical, meaning the classifier output for each binary class is normally distributed with the same variance [7]. This can be a problem for highly imbalanced classification problems, where outputs do not have equal variance.

In general this method is most effective for small sample sizes or when the un-calibrated model is under-confident and has similar calibration errors for both high and low outputs.

The method="isotonic" fits a non-parametric isotonic regressor, which outputs a step-wise non-decreasing function, see sklearn.isotonic. It minimizes:

subject to \(\hat{f}_i \geq \hat{f}_j\) whenever \(f_i \geq f_j\). \(y_i\) is the true label of sample \(i\) and \(\hat{f}_i\) is the output of the calibrated classifier for sample \(i\) (i.e., the calibrated probability). This method is more general when compared to 'sigmoid' as the only restriction is that the mapping function is monotonically increasing. It is thus more powerful as it can correct any monotonic distortion of the un-calibrated model. However, it is more prone to overfitting, especially on small datasets [6].

Overall, 'isotonic' will perform as well as or better than 'sigmoid' when there is enough data (greater than ~ 1000 samples) to avoid overfitting [3].

Impact on ranking metrics like AUC

It is generally expected that calibration does not affect ranking metrics such as ROC-AUC. However, these metrics might differ after calibration when using method="isotonic" since isotonic regression introduces ties in the predicted probabilities. This can be seen as within the uncertainty of the model predictions. In case, you strictly want to keep the ranking and thus AUC scores, use method="sigmoid" which is a strictly monotonic transformation and thus keeps the ranking.

Both isotonic and sigmoid regressors only support 1-dimensional data (e.g., binary classification output) but are extended for multiclass classification if the base_estimator supports multiclass predictions. For multiclass predictions, CalibratedClassifierCV calibrates for each class separately in a OneVsRestClassifier fashion [5]. When predicting probabilities, the calibrated probabilities for each class are predicted separately. As those probabilities do not necessarily sum to one, a postprocessing is performed to normalize them.

On the other hand, temperature scaling naturally supports multiclass predictions by working with logits and finally applying the softmax function.

For a multi-class classification problem with \(n\) classes, temperature scaling [9], method="temperature", produces class probabilities by modifying the softmax function with a temperature parameter \(T\):

where, for a given sample, \(z\) is the vector of logits for each class as predicted by the estimator to be calibrated. In terms of scikit-learn’s API, this corresponds to the output of decision_function or to the logarithm of predict_proba. Probabilities are converted to logits by first adding a tiny positive constant to avoid numerical issues with logarithm of zero, and then applying the natural logarithm.

The parameter \(T\) is learned by minimizing log_loss, i.e. cross-entropy loss, on a hold-out (calibration) set. Note that \(T\) does not affect the location of the maximum in the softmax output. Therefore, temperature scaling does not alter the accuracy of the calibrating estimator.

The main advantage of temperature scaling over other calibration methods is that it provides a natural way to obtain (better) calibrated multi-class probabilities with just one free parameter in contrast to using a “One-vs-Rest” scheme that adds more parameters for each single class.

Probability Calibration curves

Probability Calibration for 3-class classification

Probability calibration of classifiers

Comparison of Calibration of Classifiers

Allan H. Murphy (1973). “A New Vector Partition of the Probability Score” Journal of Applied Meteorology and Climatology

On the combination of forecast probabilities for consecutive precipitation periods. Wea. Forecasting, 5, 640–650., Wilks, D. S., 1990a

Predicting Good Probabilities with Supervised Learning, A. Niculescu-Mizil & R. Caruana, ICML 2005

Probabilistic Outputs for Support Vector Machines and Comparisons to Regularized Likelihood Methods. J. Platt, (1999)

Transforming Classifier Scores into Accurate Multiclass Probability Estimates. B. Zadrozny & C. Elkan, (KDD 2002)

Predicting accurate probabilities with a ranking loss. Menon AK, Jiang XJ, Vembu S, Elkan C, Ohno-Machado L. Proc Int Conf Mach Learn. 2012;2012:703-710

Beyond sigmoids: How to obtain well-calibrated probabilities from binary classifiers with beta calibration Kull, M., Silva Filho, T. M., & Flach, P. (2017).

Mario V. Wüthrich, Michael Merz (2023). “Statistical Foundations of Actuarial Learning and its Applications” Springer Actuarial

On Calibration of Modern Neural Networks, C. Guo, G. Pleiss, Y. Sun, & K. Q. Weinberger, ICML 2017.

---

## LogisticRegressionCV#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegressionCV.html

**Contents:**
- LogisticRegressionCV#
- Gallery examples#

Logistic Regression CV (aka logit, MaxEnt) classifier.

See glossary entry for cross-validation estimator.

This class implements regularized logistic regression with implicit cross validation for the penalty parameters C and l1_ratio, see LogisticRegression, using a set of available solvers.

The solvers ‘lbfgs’, ‘newton-cg’, ‘newton-cholesky’ and ‘sag’ support only L2 regularization with primal formulation. The ‘liblinear’ solver supports both L1 and L2 regularization (but not both, i.e. elastic-net), with a dual formulation only for the L2 penalty. The Elastic-Net (combination of L1 and L2) regularization is only supported by the ‘saga’ solver.

For the grid of Cs values and l1_ratios values, the best hyperparameter is selected by the cross-validator StratifiedKFold, but it can be changed using the cv parameter. All solvers except ‘liblinear’ can warm-start the coefficients (see Glossary).

Read more in the User Guide.

Each of the values in Cs describes the inverse of regularization strength. If Cs is as an int, then a grid of Cs values are chosen in a logarithmic scale between 1e-4 and 1e4. Like in support vector machines, smaller values specify stronger regularization.

Floats between 0 and 1 passed as Elastic-Net mixing parameter (scaling between L1 and L2 penalties). For l1_ratio = 0 the penalty is an L2 penalty. For l1_ratio = 1 it is an L1 penalty. For 0 < l1_ratio < 1, the penalty is a combination of L1 and L2. All the values of the given array-like are tested by cross-validation and the one giving the best prediction score is used.

Certain values of l1_ratios, i.e. some penalties, may not work with some solvers. See the parameter solver below, to know the compatibility between the penalty and solver.

Deprecated since version 1.8: l1_ratios=None is deprecated in 1.8 and will raise an error in version 1.10. Default value will change from None to (0.0,) in version 1.10.

Specifies if a constant (a.k.a. bias or intercept) should be added to the decision function.

The default cross-validation generator used is Stratified K-Folds. If an integer is provided, it specifies the number of folds, n_folds, used. See the module sklearn.model_selection module for the list of possible cross-validation objects.

Changed in version 0.22: cv default value if None changed from 3-fold to 5-fold.

Dual (constrained) or primal (regularized, see also this equation) formulation. Dual formulation is only implemented for l2 penalty with liblinear solver. Prefer dual=False when n_samples > n_features.

Specify the norm of the penalty:

'l2': add a L2 penalty term (used by default);

'l1': add a L1 penalty term;

'elasticnet': both L1 and L2 penalty terms are added.

Some penalties may not work with some solvers. See the parameter solver below, to know the compatibility between the penalty and solver.

Deprecated since version 1.8: penalty was deprecated in version 1.8 and will be removed in 1.10. Use l1_ratio instead. l1_ratio=0 for penalty='l2', l1_ratio=1 for penalty='l1' and l1_ratio set to any float between 0 and 1 for 'penalty='elasticnet'.

The scoring method to use for cross-validation. Options:

str: see String name scorers for options.

callable: a scorer callable object (e.g., function) with signature scorer(estimator, X, y). See Callable scorers for details.

None: accuracy is used.

Algorithm to use in the optimization problem. Default is ‘lbfgs’. To choose a solver, you might want to consider the following aspects:

‘lbfgs’ is a good default solver because it works reasonably well for a wide class of problems.

For multiclass problems (n_classes >= 3), all solvers except ‘liblinear’ minimize the full multinomial loss, ‘liblinear’ will raise an error.

‘newton-cholesky’ is a good choice for n_samples >> n_features * n_classes, especially with one-hot encoded categorical features with rare categories. Be aware that the memory usage of this solver has a quadratic dependency on n_features * n_classes because it explicitly computes the full Hessian matrix.

For small datasets, ‘liblinear’ is a good choice, whereas ‘sag’ and ‘saga’ are faster for large ones;

‘liblinear’ might be slower in LogisticRegressionCV because it does not handle warm-starting.

‘liblinear’ can only handle binary classification by default. To apply a one-versus-rest scheme for the multiclass setting one can wrap it with the OneVsRestClassifier.

The choice of the algorithm depends on the penalty (l1_ratio=0 for L2-penalty, l1_ratio=1 for L1-penalty and 0 < l1_ratio < 1 for Elastic-Net) chosen and on (multinomial) multiclass support:

multinomial multiclass

l1_ratio=1 or l1_ratio=0

‘sag’ and ‘saga’ fast convergence is only guaranteed on features with approximately the same scale. You can preprocess the data with a scaler from sklearn.preprocessing.

Added in version 0.17: Stochastic Average Gradient (SAG) descent solver. Multinomial support in version 0.18.

Added in version 0.19: SAGA solver.

Added in version 1.2: newton-cholesky solver. Multinomial support in version 1.6.

Tolerance for stopping criteria.

Maximum number of iterations of the optimization algorithm.

Weights associated with classes in the form {class_label: weight}. If not given, all classes are supposed to have weight one.

The “balanced” mode uses the values of y to automatically adjust weights inversely proportional to class frequencies in the input data as n_samples / (n_classes * np.bincount(y)).

Note that these weights will be multiplied with sample_weight (passed through the fit method) if sample_weight is specified.

Added in version 0.17: class_weight == ‘balanced’

Number of CPU cores used during the cross-validation loop. None means 1 unless in a joblib.parallel_backend context. -1 means using all processors. See Glossary for more details.

For the ‘liblinear’, ‘sag’ and ‘lbfgs’ solvers set verbose to any positive number for verbosity.

If set to True, the scores are averaged across all folds, and the coefs and the C that corresponds to the best score is taken, and a final refit is done using these parameters. Otherwise the coefs, intercepts and C that correspond to the best scores across folds are averaged.

Useful only when the solver liblinear is used and self.fit_intercept is set to True. In this case, x becomes [x, self.intercept_scaling], i.e. a “synthetic” feature with constant value equal to intercept_scaling is appended to the instance vector. The intercept becomes intercept_scaling * synthetic_feature_weight.

The synthetic feature weight is subject to L1 or L2 regularization as all other features. To lessen the effect of regularization on synthetic feature weight (and therefore on the intercept) intercept_scaling has to be increased.

Used when solver='sag', ‘saga’ or ‘liblinear’ to shuffle the data. Note that this only applies to the solver and not the cross-validation generator. See Glossary for details.

If True, use legacy values for attributes:

C_ is an ndarray of shape (n_classes,) with the same value repeated

l1_ratio_ is an ndarray of shape (n_classes,) with the same value repeated

coefs_paths_ is a dict with class labels as keys and ndarrays as values

scores_ is a dict with class labels as keys and ndarrays as values

n_iter_ is an ndarray of shape (1, n_folds, n_cs) or similar

If False, use new values for attributes:

coefs_paths_ is an ndarray of shape (n_folds, n_l1_ratios, n_cs, n_classes, n_features) For binary problems (n_classes=2), the 2nd last dimension is 1.

scores_ is an ndarray of shape (n_folds, n_l1_ratios, n_cs)

n_iter_ is an ndarray of shape (n_folds, n_l1_ratios, n_cs)

Changed in version 1.10: The default will change from True to False in version 1.10.

Deprecated since version 1.10: use_legacy_attributes will be deprecated in version 1.10 and be removed in 1.12.

A list of class labels known to the classifier.

Coefficient of the features in the decision function.

coef_ is of shape (1, n_features) when the given problem is binary.

Intercept (a.k.a. bias) added to the decision function.

If fit_intercept is set to False, the intercept is set to zero. intercept_ is of shape (1,) when the problem is binary.

Array of C i.e. inverse of regularization parameter values used for cross-validation.

Array of l1_ratios used for cross-validation. If l1_ratios=None is used (i.e. penalty is not ‘elasticnet’), this is set to [None]

A dict with classes as the keys, and the path of coefficients obtained during cross-validating across each fold (n_folds) and then across each Cs (n_cs). The size of the coefficients is the number of degrees of freedom (n_dof), i.e. without intercept n_dof=n_features and with intercept n_dof=n_features+1. If penalty='elasticnet', there is an additional dimension for the number of l1_ratio values (n_l1_ratios), which gives a shape of (n_folds, n_cs, n_l1_ratios_, n_dof). See also parameter use_legacy_attributes.

A dict with classes as the keys, and the values as the grid of scores obtained during cross-validating each fold. The same score is repeated across all classes. Each dict value has shape (n_folds, n_cs) or (n_folds, n_cs, n_l1_ratios) if penalty='elasticnet'. See also parameter use_legacy_attributes.

The value of C that maps to the best score, repeated n_classes times. If refit is set to False, the best C is the average of the C’s that correspond to the best score for each fold. C_ is of shape (1,) when the problem is binary. See also parameter use_legacy_attributes.

The value of l1_ratio that maps to the best score, repeated n_classes times. If refit is set to False, the best l1_ratio is the average of the l1_ratio’s that correspond to the best score for each fold. l1_ratio_ is of shape (1,) when the problem is binary. See also parameter use_legacy_attributes.

Actual number of iterations for all classes, folds and Cs. If penalty='elasticnet', the shape is (1, n_folds, n_cs, n_l1_ratios). See also parameter use_legacy_attributes.

Number of features seen during fit.

Added in version 0.24.

Names of features seen during fit. Defined only when X has feature names that are all strings.

Added in version 1.0.

Logistic regression without tuning the hyperparameter C.

Predict confidence scores for samples.

The confidence score for a sample is proportional to the signed distance of that sample to the hyperplane.

The data matrix for which we want to get the confidence scores.

Confidence scores per (n_samples, n_classes) combination. In the binary case, confidence score for self.classes_[1] where >0 means this class would be predicted.

Convert coefficient matrix to dense array format.

Converts the coef_ member (back) to a numpy.ndarray. This is the default format of coef_ and is required for fitting, so calling this method is only required on models that have previously been sparsified; otherwise, it is a no-op.

Fit the model according to the given training data.

Training vector, where n_samples is the number of samples and n_features is the number of features.

Target vector relative to X.

Array of weights that are assigned to individual samples. If not provided, then each sample is given unit weight.

Parameters to pass to the underlying splitter and scorer.

Added in version 1.4.

Fitted LogisticRegressionCV estimator.

Get metadata routing of this object.

Please check User Guide on how the routing mechanism works.

Added in version 1.4.

A MetadataRouter encapsulating routing information.

Get parameters for this estimator.

If True, will return the parameters for this estimator and contained subobjects that are estimators.

Parameter names mapped to their values.

Predict class labels for samples in X.

The data matrix for which we want to get the predictions.

Vector containing the class labels for each sample.

Predict logarithm of probability estimates.

The returned estimates for all classes are ordered by the label of classes.

Vector to be scored, where n_samples is the number of samples and n_features is the number of features.

Returns the log-probability of the sample for each class in the model, where classes are ordered as they are in self.classes_.

Probability estimates.

The returned estimates for all classes are ordered by the label of classes.

For a multiclass / multinomial problem the softmax function is used to find the predicted probability of each class.

Vector to be scored, where n_samples is the number of samples and n_features is the number of features.

Returns the probability of the sample for each class in the model, where classes are ordered as they are in self.classes_.

Score using the scoring option on the given test data and labels.

Parameters to pass to the score method of the underlying scorer.

Added in version 1.4.

Score of self.predict(X) w.r.t. y.

Configure whether metadata should be requested to be passed to the fit method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to fit if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to fit.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Added in version 1.3.

Metadata routing for sample_weight parameter in fit.

Set the parameters of this estimator.

The method works on simple estimators as well as on nested objects (such as Pipeline). The latter have parameters of the form <component>__<parameter> so that it’s possible to update each component of a nested object.

Estimator parameters.

Configure whether metadata should be requested to be passed to the score method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to score if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to score.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Added in version 1.3.

Metadata routing for sample_weight parameter in score.

Convert coefficient matrix to sparse format.

Converts the coef_ member to a scipy.sparse matrix, which for L1-regularized models can be much more memory- and storage-efficient than the usual numpy.ndarray representation.

The intercept_ member is not converted.

For non-sparse models, i.e. when there are not many zeros in coef_, this may actually increase memory usage, so use this method with care. A rule of thumb is that the number of zero elements, which can be computed with (coef_ == 0).sum(), must be more than 50% for this to provide significant benefits.

After calling this method, further fitting with the partial_fit method (if any) will not work until you call densify.

Comparison of Calibration of Classifiers

Importance of Feature Scaling

**Examples:**

Example 1 (sql):
```sql
>>> from sklearn.datasets import load_iris
>>> from sklearn.linear_model import LogisticRegressionCV
>>> X, y = load_iris(return_X_y=True)
>>> clf = LogisticRegressionCV(
...     cv=5, random_state=0, use_legacy_attributes=False, l1_ratios=(0,)
... ).fit(X, y)
>>> clf.predict(X[:2, :])
array([0, 0])
>>> clf.predict_proba(X[:2, :]).shape
(2, 3)
>>> clf.score(X, y)
0.98...
```

---

## LinearDiscriminantAnalysis#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.discriminant_analysis.LinearDiscriminantAnalysis.html

**Contents:**
- LinearDiscriminantAnalysis#
- Gallery examples#

Linear Discriminant Analysis.

A classifier with a linear decision boundary, generated by fitting class conditional densities to the data and using Bayes’ rule.

The model fits a Gaussian density to each class, assuming that all classes share the same covariance matrix.

The fitted model can also be used to reduce the dimensionality of the input by projecting it to the most discriminative directions, using the transform method.

Added in version 0.17.

For a comparison between LinearDiscriminantAnalysis and QuadraticDiscriminantAnalysis, see Linear and Quadratic Discriminant Analysis with covariance ellipsoid.

Read more in the User Guide.

‘svd’: Singular value decomposition (default). Does not compute the covariance matrix, therefore this solver is recommended for data with a large number of features.

‘lsqr’: Least squares solution. Can be combined with shrinkage or custom covariance estimator.

‘eigen’: Eigenvalue decomposition. Can be combined with shrinkage or custom covariance estimator.

Changed in version 1.2: solver="svd" now has experimental Array API support. See the Array API User Guide for more details.

None: no shrinkage (default).

‘auto’: automatic shrinkage using the Ledoit-Wolf lemma.

float between 0 and 1: fixed shrinkage parameter.

This should be left to None if covariance_estimator is used. Note that shrinkage works only with ‘lsqr’ and ‘eigen’ solvers.

For a usage example, see Normal, Ledoit-Wolf and OAS Linear Discriminant Analysis for classification.

The class prior probabilities. By default, the class proportions are inferred from the training data.

Number of components (<= min(n_classes - 1, n_features)) for dimensionality reduction. If None, will be set to min(n_classes - 1, n_features). This parameter only affects the transform method.

For a usage example, see Comparison of LDA and PCA 2D projection of Iris dataset.

If True, explicitly compute the weighted within-class covariance matrix when solver is ‘svd’. The matrix is always computed and stored for the other solvers.

Added in version 0.17.

Absolute threshold for a singular value of X to be considered significant, used to estimate the rank of X. Dimensions whose singular values are non-significant are discarded. Only used if solver is ‘svd’.

Added in version 0.17.

If not None, covariance_estimator is used to estimate the covariance matrices instead of relying on the empirical covariance estimator (with potential shrinkage). The object should have a fit method and a covariance_ attribute like the estimators in sklearn.covariance. if None the shrinkage parameter drives the estimate.

This should be left to None if shrinkage is used. Note that covariance_estimator works only with ‘lsqr’ and ‘eigen’ solvers.

Added in version 0.24.

Weighted within-class covariance matrix. It corresponds to sum_k prior_k * C_k where C_k is the covariance matrix of the samples in class k. The C_k are estimated using the (potentially shrunk) biased estimator of covariance. If solver is ‘svd’, only exists when store_covariance is True.

Percentage of variance explained by each of the selected components. If n_components is not set then all components are stored and the sum of explained variances is equal to 1.0. Only available when eigen or svd solver is used.

Class priors (sum to 1).

Scaling of the features in the space spanned by the class centroids. Only available for ‘svd’ and ‘eigen’ solvers.

Overall mean. Only present if solver is ‘svd’.

Number of features seen during fit.

Added in version 0.24.

Names of features seen during fit. Defined only when X has feature names that are all strings.

Added in version 1.0.

Quadratic Discriminant Analysis.

Apply decision function to an array of samples.

The decision function is equal (up to a constant factor) to the log-posterior of the model, i.e. log p(y = k | x). In a binary classification setting this instead corresponds to the difference log p(y = 1 | x) - log p(y = 0 | x). See Mathematical formulation of the LDA and QDA classifiers.

Array of samples (test vectors).

Decision function values related to each class, per sample. In the two-class case, the shape is (n_samples,), giving the log likelihood ratio of the positive class.

Fit the Linear Discriminant Analysis model.

Changed in version 0.19: store_covariance and tol has been moved to main constructor.

Fit to data, then transform it.

Fits transformer to X and y with optional parameters fit_params and returns a transformed version of X.

Target values (None for unsupervised transformations).

Additional fit parameters. Pass only if the estimator accepts additional params in its fit method.

Get output feature names for transformation.

The feature names out will prefixed by the lowercased class name. For example, if the transformer outputs 3 features, then the feature names out are: ["class_name0", "class_name1", "class_name2"].

Only used to validate feature names with the names seen in fit.

Transformed feature names.

Get metadata routing of this object.

Please check User Guide on how the routing mechanism works.

A MetadataRequest encapsulating routing information.

Get parameters for this estimator.

If True, will return the parameters for this estimator and contained subobjects that are estimators.

Parameter names mapped to their values.

Predict class labels for samples in X.

The data matrix for which we want to get the predictions.

Vector containing the class labels for each sample.

Estimate log probability.

Estimated log probabilities.

Estimate probability.

Estimated probabilities.

Return accuracy on provided data and labels.

In multi-label classification, this is the subset accuracy which is a harsh metric since you require for each sample that each label set be correctly predicted.

Mean accuracy of self.predict(X) w.r.t. y.

Set output container.

See Introducing the set_output API for an example on how to use the API.

Configure output of transform and fit_transform.

"default": Default output format of a transformer

"pandas": DataFrame output

"polars": Polars output

None: Transform configuration is unchanged

Added in version 1.4: "polars" option was added.

Set the parameters of this estimator.

The method works on simple estimators as well as on nested objects (such as Pipeline). The latter have parameters of the form <component>__<parameter> so that it’s possible to update each component of a nested object.

Estimator parameters.

Configure whether metadata should be requested to be passed to the score method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to score if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to score.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Added in version 1.3.

Metadata routing for sample_weight parameter in score.

Project data to maximize class separation.

Transformed data. In the case of the ‘svd’ solver, the shape is (n_samples, min(rank, n_components)).

Normal, Ledoit-Wolf and OAS Linear Discriminant Analysis for classification

Linear and Quadratic Discriminant Analysis with covariance ellipsoid

Comparison of LDA and PCA 2D projection of Iris dataset

Manifold learning on handwritten digits: Locally Linear Embedding, Isomap…

Dimensionality Reduction with Neighborhood Components Analysis

**Examples:**

Example 1 (python):
```python
>>> import numpy as np
>>> from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
>>> X = np.array([[-1, -1], [-2, -1], [-3, -2], [1, 1], [2, 1], [3, 2]])
>>> y = np.array([1, 1, 1, 2, 2, 2])
>>> clf = LinearDiscriminantAnalysis()
>>> clf.fit(X, y)
LinearDiscriminantAnalysis()
>>> print(clf.predict([[-0.8, -1]]))
[1]
```

---

## LassoLarsCV#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LassoLarsCV.html

**Contents:**
- LassoLarsCV#
- Gallery examples#

Cross-validated Lasso, using the LARS algorithm.

See glossary entry for cross-validation estimator.

The optimization objective for Lasso is:

Read more in the User Guide.

Whether to calculate the intercept for this model. If set to false, no intercept will be used in calculations (i.e. data is expected to be centered).

Sets the verbosity amount.

Maximum number of iterations to perform.

Whether to use a precomputed Gram matrix to speed up calculations. If set to 'auto' let us decide. The Gram matrix cannot be passed as argument since we will use only subsets of X.

Determines the cross-validation splitting strategy. Possible inputs for cv are:

None, to use the default 5-fold cross-validation,

integer, to specify the number of folds.

An iterable yielding (train, test) splits as arrays of indices.

For integer/None inputs, KFold is used.

Refer User Guide for the various cross-validation strategies that can be used here.

Changed in version 0.22: cv default value if None changed from 3-fold to 5-fold.

The maximum number of points on the path used to compute the residuals in the cross-validation.

Number of CPUs to use during the cross validation. None means 1 unless in a joblib.parallel_backend context. -1 means using all processors. See Glossary for more details.

The machine-precision regularization in the computation of the Cholesky diagonal factors. Increase this for very ill-conditioned systems. Unlike the tol parameter in some iterative optimization-based algorithms, this parameter does not control the tolerance of the optimization.

If True, X will be copied; else, it may be overwritten.

Restrict coefficients to be >= 0. Be aware that you might want to remove fit_intercept which is set True by default. Under the positive restriction the model coefficients do not converge to the ordinary-least-squares solution for small values of alpha. Only coefficients up to the smallest alpha value (alphas_[alphas_ > 0.].min() when fit_path=True) reached by the stepwise Lars-Lasso algorithm are typically in congruence with the solution of the coordinate descent Lasso estimator. As a consequence using LassoLarsCV only makes sense for problems where a sparse solution is expected and/or reached.

parameter vector (w in the formulation formula)

independent term in decision function.

the varying values of the coefficients along the path

the estimated regularization parameter alpha

the different values of alpha along the path

all the values of alpha along the path for the different folds

the mean square error on left-out for each fold along the path (alpha values given by cv_alphas)

the number of iterations run by Lars with the optimal alpha.

Indices of active variables at the end of the path.

Number of features seen during fit.

Added in version 0.24.

Names of features seen during fit. Defined only when X has feature names that are all strings.

Added in version 1.0.

Compute Least Angle Regression or Lasso path using LARS algorithm.

Compute Lasso path with coordinate descent.

Linear Model trained with L1 prior as regularizer (aka the Lasso).

Lasso linear model with iterative fitting along a regularization path.

Lasso model fit with Least Angle Regression a.k.a. Lars.

Lasso model fit with Lars using BIC or AIC for model selection.

The object solves the same problem as the LassoCV object. However, unlike the LassoCV, it find the relevant alphas values by itself. In general, because of this property, it will be more stable. However, it is more fragile to heavily multicollinear datasets.

It is more efficient than the LassoCV if only a small number of features are selected compared to the total number, for instance if there are very few samples compared to the number of features.

In fit, once the best parameter alpha is found through cross-validation, the model is fit again using the entire training set.

Fit the model using X, y as training data.

Parameters to be passed to the CV splitter.

Added in version 1.4: Only available if enable_metadata_routing=True, which can be set by using sklearn.set_config(enable_metadata_routing=True). See Metadata Routing User Guide for more details.

Returns an instance of self.

Get metadata routing of this object.

Please check User Guide on how the routing mechanism works.

Added in version 1.4.

A MetadataRouter encapsulating routing information.

Get parameters for this estimator.

If True, will return the parameters for this estimator and contained subobjects that are estimators.

Parameter names mapped to their values.

Predict using the linear model.

Returns predicted values.

Return coefficient of determination on test data.

The coefficient of determination, \(R^2\), is defined as \((1 - \frac{u}{v})\), where \(u\) is the residual sum of squares ((y_true - y_pred)** 2).sum() and \(v\) is the total sum of squares ((y_true - y_true.mean()) ** 2).sum(). The best possible score is 1.0 and it can be negative (because the model can be arbitrarily worse). A constant model that always predicts the expected value of y, disregarding the input features, would get a \(R^2\) score of 0.0.

Test samples. For some estimators this may be a precomputed kernel matrix or a list of generic objects instead with shape (n_samples, n_samples_fitted), where n_samples_fitted is the number of samples used in the fitting for the estimator.

\(R^2\) of self.predict(X) w.r.t. y.

The \(R^2\) score used when calling score on a regressor uses multioutput='uniform_average' from version 0.23 to keep consistent with default value of r2_score. This influences the score method of all the multioutput regressors (except for MultiOutputRegressor).

Configure whether metadata should be requested to be passed to the fit method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to fit if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to fit.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Added in version 1.3.

Metadata routing for Xy parameter in fit.

Set the parameters of this estimator.

The method works on simple estimators as well as on nested objects (such as Pipeline). The latter have parameters of the form <component>__<parameter> so that it’s possible to update each component of a nested object.

Estimator parameters.

Configure whether metadata should be requested to be passed to the score method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to score if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to score.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Added in version 1.3.

Metadata routing for sample_weight parameter in score.

Lasso model selection: AIC-BIC / cross-validation

**Examples:**

Example 1 (unknown):
```unknown
(1 / (2 * n_samples)) * ||y - Xw||^2_2 + alpha * ||w||_1
```

Example 2 (sql):
```sql
>>> from sklearn.linear_model import LassoLarsCV
>>> from sklearn.datasets import make_regression
>>> X, y = make_regression(noise=4.0, random_state=0)
>>> reg = LassoLarsCV(cv=5).fit(X, y)
>>> reg.score(X, y)
0.9993
>>> reg.alpha_
np.float64(0.3972)
>>> reg.predict(X[:1,])
array([-78.4831])
```

---

## SpectralCoclustering#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.cluster.SpectralCoclustering.html

**Contents:**
- SpectralCoclustering#
- Gallery examples#

Spectral Co-Clustering algorithm (Dhillon, 2001) [1].

Clusters rows and columns of an array X to solve the relaxed normalized cut of the bipartite graph created from X as follows: the edge between row vertex i and column vertex j has weight X[i, j].

The resulting bicluster structure is block-diagonal, since each row and each column belongs to exactly one bicluster.

Supports sparse matrices, as long as they are nonnegative.

Read more in the User Guide.

The number of biclusters to find.

Selects the algorithm for finding singular vectors. May be ‘randomized’ or ‘arpack’. If ‘randomized’, use sklearn.utils.extmath.randomized_svd, which may be faster for large matrices. If ‘arpack’, use scipy.sparse.linalg.svds, which is more accurate, but possibly slower in some cases.

Number of vectors to use in calculating the SVD. Corresponds to ncv when svd_method=arpack and n_oversamples when svd_method is ‘randomized`.

Whether to use mini-batch k-means, which is faster but may get different results.

Method for initialization of k-means algorithm; defaults to ‘k-means++’.

Number of random initializations that are tried with the k-means algorithm.

If mini-batch k-means is used, the best initialization is chosen and the algorithm runs once. Otherwise, the algorithm is run for each initialization and the best solution chosen.

Used for randomizing the singular value decomposition and the k-means initialization. Use an int to make the randomness deterministic. See Glossary.

Results of the clustering. rows[i, r] is True if cluster i contains row r. Available only after calling fit.

Results of the clustering, like rows.

The bicluster label of each row.

The bicluster label of each column.

Convenient way to get row and column indicators together.

Number of features seen during fit.

Added in version 0.24.

Names of features seen during fit. Defined only when X has feature names that are all strings.

Added in version 1.0.

Partitions rows and columns under the assumption that the data has an underlying checkerboard structure.

Dhillon, Inderjit S, 2001. Co-clustering documents and words using bipartite spectral graph partitioning.

For a more detailed example, see the following: A demo of the Spectral Co-Clustering algorithm.

Create a biclustering for X.

Not used, present for API consistency by convention.

SpectralBiclustering instance.

Row and column indices of the i’th bicluster.

Only works if rows_ and columns_ attributes exist.

The index of the cluster.

Indices of rows in the dataset that belong to the bicluster.

Indices of columns in the dataset that belong to the bicluster.

Get metadata routing of this object.

Please check User Guide on how the routing mechanism works.

A MetadataRequest encapsulating routing information.

Get parameters for this estimator.

If True, will return the parameters for this estimator and contained subobjects that are estimators.

Parameter names mapped to their values.

Shape of the i’th bicluster.

The index of the cluster.

Number of rows in the bicluster.

Number of columns in the bicluster.

Return the submatrix corresponding to bicluster i.

The index of the cluster.

The submatrix corresponding to bicluster i.

Works with sparse matrices. Only works if rows_ and columns_ attributes exist.

Set the parameters of this estimator.

The method works on simple estimators as well as on nested objects (such as Pipeline). The latter have parameters of the form <component>__<parameter> so that it’s possible to update each component of a nested object.

Estimator parameters.

Biclustering documents with the Spectral Co-clustering algorithm

A demo of the Spectral Co-Clustering algorithm

**Examples:**

Example 1 (sql):
```sql
>>> from sklearn.cluster import SpectralCoclustering
>>> import numpy as np
>>> X = np.array([[1, 1], [2, 1], [1, 0],
...               [4, 7], [3, 5], [3, 6]])
>>> clustering = SpectralCoclustering(n_clusters=2, random_state=0).fit(X)
>>> clustering.row_labels_
array([0, 1, 1, 0, 0, 0], dtype=int32)
>>> clustering.column_labels_
array([0, 0], dtype=int32)
>>> clustering
SpectralCoclustering(n_clusters=2, random_state=0)
```

---

## 

**URL:** https://scikit-learn.org/stable/_sources/modules/cross_decomposition.rst.txt

---

## 2.2. Manifold learning#

**URL:** https://scikit-learn.org/stable/modules/manifold.html

**Contents:**
- 2.2. Manifold learning#
- 2.2.1. Introduction#
- 2.2.2. Isomap#
- 2.2.3. Locally Linear Embedding#
- 2.2.4. Modified Locally Linear Embedding#
- 2.2.5. Hessian Eigenmapping#
- 2.2.6. Spectral Embedding#
- 2.2.7. Local Tangent Space Alignment#
- 2.2.8. Multi-dimensional Scaling (MDS)#
- 2.2.9. t-distributed Stochastic Neighbor Embedding (t-SNE)#

Manifold learning is an approach to non-linear dimensionality reduction. Algorithms for this task are based on the idea that the dimensionality of many data sets is only artificially high.

High-dimensional datasets can be very difficult to visualize. While data in two or three dimensions can be plotted to show the inherent structure of the data, equivalent high-dimensional plots are much less intuitive. To aid visualization of the structure of a dataset, the dimension must be reduced in some way.

The simplest way to accomplish this dimensionality reduction is by taking a random projection of the data. Though this allows some degree of visualization of the data structure, the randomness of the choice leaves much to be desired. In a random projection, it is likely that the more interesting structure within the data will be lost.

To address this concern, a number of supervised and unsupervised linear dimensionality reduction frameworks have been designed, such as Principal Component Analysis (PCA), Independent Component Analysis, Linear Discriminant Analysis, and others. These algorithms define specific rubrics to choose an “interesting” linear projection of the data. These methods can be powerful, but often miss important non-linear structure in the data.

Manifold Learning can be thought of as an attempt to generalize linear frameworks like PCA to be sensitive to non-linear structure in data. Though supervised variants exist, the typical manifold learning problem is unsupervised: it learns the high-dimensional structure of the data from the data itself, without the use of predetermined classifications.

See Manifold learning on handwritten digits: Locally Linear Embedding, Isomap… for an example of dimensionality reduction on handwritten digits.

See Comparison of Manifold Learning methods for an example of dimensionality reduction on a toy “S-curve” dataset.

See Visualizing the stock market structure for an example of using manifold learning to map the stock market structure based on historical stock prices.

See Manifold Learning methods on a severed sphere for an example of manifold learning techniques applied to a spherical data-set.

See Swiss Roll And Swiss-Hole Reduction for an example of using manifold learning techniques on a Swiss Roll dataset.

The manifold learning implementations available in scikit-learn are summarized below

One of the earliest approaches to manifold learning is the Isomap algorithm, short for Isometric Mapping. Isomap can be viewed as an extension of Multi-dimensional Scaling (MDS) or Kernel PCA. Isomap seeks a lower-dimensional embedding which maintains geodesic distances between all points. Isomap can be performed with the object Isomap.

The Isomap algorithm comprises three stages:

Nearest neighbor search. Isomap uses BallTree for efficient neighbor search. The cost is approximately \(O[D \log(k) N \log(N)]\), for \(k\) nearest neighbors of \(N\) points in \(D\) dimensions.

Shortest-path graph search. The most efficient known algorithms for this are Dijkstra’s Algorithm, which is approximately \(O[N^2(k + \log(N))]\), or the Floyd-Warshall algorithm, which is \(O[N^3]\). The algorithm can be selected by the user with the path_method keyword of Isomap. If unspecified, the code attempts to choose the best algorithm for the input data.

Partial eigenvalue decomposition. The embedding is encoded in the eigenvectors corresponding to the \(d\) largest eigenvalues of the \(N \times N\) isomap kernel. For a dense solver, the cost is approximately \(O[d N^2]\). This cost can often be improved using the ARPACK solver. The eigensolver can be specified by the user with the eigen_solver keyword of Isomap. If unspecified, the code attempts to choose the best algorithm for the input data.

The overall complexity of Isomap is \(O[D \log(k) N \log(N)] + O[N^2(k + \log(N))] + O[d N^2]\).

\(N\) : number of training data points

\(D\) : input dimension

\(k\) : number of nearest neighbors

\(d\) : output dimension

“A global geometric framework for nonlinear dimensionality reduction” Tenenbaum, J.B.; De Silva, V.; & Langford, J.C. Science 290 (5500)

Locally linear embedding (LLE) seeks a lower-dimensional projection of the data which preserves distances within local neighborhoods. It can be thought of as a series of local Principal Component Analyses which are globally compared to find the best non-linear embedding.

Locally linear embedding can be performed with function locally_linear_embedding or its object-oriented counterpart LocallyLinearEmbedding.

The standard LLE algorithm comprises three stages:

Nearest Neighbors Search. See discussion under Isomap above.

Weight Matrix Construction. \(O[D N k^3]\). The construction of the LLE weight matrix involves the solution of a \(k \times k\) linear equation for each of the \(N\) local neighborhoods.

Partial Eigenvalue Decomposition. See discussion under Isomap above.

The overall complexity of standard LLE is \(O[D \log(k) N \log(N)] + O[D N k^3] + O[d N^2]\).

\(N\) : number of training data points

\(D\) : input dimension

\(k\) : number of nearest neighbors

\(d\) : output dimension

“Nonlinear dimensionality reduction by locally linear embedding” Roweis, S. & Saul, L. Science 290:2323 (2000)

One well-known issue with LLE is the regularization problem. When the number of neighbors is greater than the number of input dimensions, the matrix defining each local neighborhood is rank-deficient. To address this, standard LLE applies an arbitrary regularization parameter \(r\), which is chosen relative to the trace of the local weight matrix. Though it can be shown formally that as \(r \to 0\), the solution converges to the desired embedding, there is no guarantee that the optimal solution will be found for \(r > 0\). This problem manifests itself in embeddings which distort the underlying geometry of the manifold.

One method to address the regularization problem is to use multiple weight vectors in each neighborhood. This is the essence of modified locally linear embedding (MLLE). MLLE can be performed with function locally_linear_embedding or its object-oriented counterpart LocallyLinearEmbedding, with the keyword method = 'modified'. It requires n_neighbors > n_components.

The MLLE algorithm comprises three stages:

Nearest Neighbors Search. Same as standard LLE

Weight Matrix Construction. Approximately \(O[D N k^3] + O[N (k-D) k^2]\). The first term is exactly equivalent to that of standard LLE. The second term has to do with constructing the weight matrix from multiple weights. In practice, the added cost of constructing the MLLE weight matrix is relatively small compared to the cost of stages 1 and 3.

Partial Eigenvalue Decomposition. Same as standard LLE

The overall complexity of MLLE is \(O[D \log(k) N \log(N)] + O[D N k^3] + O[N (k-D) k^2] + O[d N^2]\).

\(N\) : number of training data points

\(D\) : input dimension

\(k\) : number of nearest neighbors

\(d\) : output dimension

“MLLE: Modified Locally Linear Embedding Using Multiple Weights” Zhang, Z. & Wang, J.

Hessian Eigenmapping (also known as Hessian-based LLE: HLLE) is another method of solving the regularization problem of LLE. It revolves around a hessian-based quadratic form at each neighborhood which is used to recover the locally linear structure. Though other implementations note its poor scaling with data size, sklearn implements some algorithmic improvements which make its cost comparable to that of other LLE variants for small output dimension. HLLE can be performed with function locally_linear_embedding or its object-oriented counterpart LocallyLinearEmbedding, with the keyword method = 'hessian'. It requires n_neighbors > n_components * (n_components + 3) / 2.

The HLLE algorithm comprises three stages:

Nearest Neighbors Search. Same as standard LLE

Weight Matrix Construction. Approximately \(O[D N k^3] + O[N d^6]\). The first term reflects a similar cost to that of standard LLE. The second term comes from a QR decomposition of the local hessian estimator.

Partial Eigenvalue Decomposition. Same as standard LLE.

The overall complexity of standard HLLE is \(O[D \log(k) N \log(N)] + O[D N k^3] + O[N d^6] + O[d N^2]\).

\(N\) : number of training data points

\(D\) : input dimension

\(k\) : number of nearest neighbors

\(d\) : output dimension

“Hessian Eigenmaps: Locally linear embedding techniques for high-dimensional data” Donoho, D. & Grimes, C. Proc Natl Acad Sci USA. 100:5591 (2003)

Spectral Embedding is an approach to calculating a non-linear embedding. Scikit-learn implements Laplacian Eigenmaps, which finds a low dimensional representation of the data using a spectral decomposition of the graph Laplacian. The graph generated can be considered as a discrete approximation of the low dimensional manifold in the high dimensional space. Minimization of a cost function based on the graph ensures that points close to each other on the manifold are mapped close to each other in the low dimensional space, preserving local distances. Spectral embedding can be performed with the function spectral_embedding or its object-oriented counterpart SpectralEmbedding.

The Spectral Embedding (Laplacian Eigenmaps) algorithm comprises three stages:

Weighted Graph Construction. Transform the raw input data into graph representation using affinity (adjacency) matrix representation.

Graph Laplacian Construction. unnormalized Graph Laplacian is constructed as \(L = D - A\) for and normalized one as \(L = D^{-\frac{1}{2}} (D - A) D^{-\frac{1}{2}}\).

Partial Eigenvalue Decomposition. Eigenvalue decomposition is done on graph Laplacian.

The overall complexity of spectral embedding is \(O[D \log(k) N \log(N)] + O[D N k^3] + O[d N^2]\).

\(N\) : number of training data points

\(D\) : input dimension

\(k\) : number of nearest neighbors

\(d\) : output dimension

“Laplacian Eigenmaps for Dimensionality Reduction and Data Representation” M. Belkin, P. Niyogi, Neural Computation, June 2003; 15 (6):1373-1396.

Though not technically a variant of LLE, Local tangent space alignment (LTSA) is algorithmically similar enough to LLE that it can be put in this category. Rather than focusing on preserving neighborhood distances as in LLE, LTSA seeks to characterize the local geometry at each neighborhood via its tangent space, and performs a global optimization to align these local tangent spaces to learn the embedding. LTSA can be performed with function locally_linear_embedding or its object-oriented counterpart LocallyLinearEmbedding, with the keyword method = 'ltsa'.

The LTSA algorithm comprises three stages:

Nearest Neighbors Search. Same as standard LLE

Weight Matrix Construction. Approximately \(O[D N k^3] + O[k^2 d]\). The first term reflects a similar cost to that of standard LLE.

Partial Eigenvalue Decomposition. Same as standard LLE

The overall complexity of standard LTSA is \(O[D \log(k) N \log(N)] + O[D N k^3] + O[k^2 d] + O[d N^2]\).

\(N\) : number of training data points

\(D\) : input dimension

\(k\) : number of nearest neighbors

\(d\) : output dimension

“Principal manifolds and nonlinear dimensionality reduction via tangent space alignment” Zhang, Z. & Zha, H. Journal of Shanghai Univ. 8:406 (2004)

Multidimensional scaling (MDS and ClassicalMDS) seeks a low-dimensional representation of the data in which the distances approximate the distances in the original high-dimensional space.

In general, MDS is a technique used for analyzing dissimilarity data. It attempts to model dissimilarities as distances in a Euclidean space. The data can be ratings of dissimilarity between objects, interaction frequencies of molecules, or trade indices between countries.

There exist three types of MDS algorithm: metric, non-metric, and classical. In scikit-learn, the class MDS implements metric and non-metric MDS, while ClassicalMDS implements classical MDS. In metric MDS, the distances in the embedding space are set as close as possible to the dissimilarity data. In the non-metric version, the algorithm will try to preserve the order of the distances, and hence seek for a monotonic relationship between the distances in the embedded space and the input dissimilarities. Finally, classical MDS is close to PCA and, instead of approximating distances, approximates pairwise scalar products, which is an easier optimization problem with an analytic solution in terms of eigendecomposition.

Let \(\delta_{ij}\) be the dissimilarity matrix between the \(n\) input points (possibly arising as some pairwise distances \(d_{ij}(X)\) between the coordinates \(X\) of the input points). Disparities \(\hat{d}_{ij} = f(\delta_{ij})\) are some transformation of the dissimilarities. The MDS objective, called the raw stress, is then defined by \(\sum_{i < j} (\hat{d}_{ij} - d_{ij}(Z))^2\), where \(d_{ij}(Z)\) are the pairwise distances between the coordinates \(Z\) of the embedded points.

In the metric MDS model (sometimes also called absolute MDS), disparities are simply equal to the input dissimilarities \(\hat{d}_{ij} = \delta_{ij}\).

Non-metric MDS focuses on the ordination of the data. If \(\delta_{ij} > \delta_{kl}\), then the embedding seeks to enforce \(d_{ij}(Z) > d_{kl}(Z)\). A simple algorithm to enforce proper ordination is to use an isotonic regression of \(d_{ij}(Z)\) on \(\delta_{ij}\), yielding disparities \(\hat{d}_{ij}\) that are a monotonic transformation of dissimilarities \(\delta_{ij}\) and hence having the same ordering. This is done repeatedly after every step of the optimization algorithm. In order to avoid the trivial solution where all embedding points are overlapping, the disparities \(\hat{d}_{ij}\) are normalized.

Note that since we only care about relative ordering, our objective should be invariant to simple translation and scaling, however the stress used in metric MDS is sensitive to scaling. To address this, non-metric MDS returns normalized stress, also known as Stress-1, defined as

Normalized Stress-1 is returned if normalized_stress=True.

Classical MDS, also known as principal coordinates analysis (PCoA) or Torgerson’s scaling, is implemented in the separate ClassicalMDS class. Classical MDS replaces the stress loss function with a different loss function called strain, which has an exact solution in terms of eigendecomposition. If the dissimilarity matrix consists of the pairwise Euclidean distances between some vectors, then classical MDS is equivalent to PCA applied to this set of vectors.

Formally, the loss function of classical MDS (strain) is given by

where \(Z\) is the \(n \times d\) embedding matrix whose rows are \(z_i^T\), \(\|\cdot\|_F\) denotes the Frobenius norm, and \(B\) is the Gram matrix with elements \(b_{ij}\), given by \(B = -\frac{1}{2}C\Delta C\). Here \(C\Delta C\) is the double-centered matrix of squared dissimilarities, with \(\Delta\) being the matrix of squared input dissimilarities \(\delta^2_{ij}\) and \(C=I-J/n\) is the centering matrix (identity matrix minus a matrix of all ones divided by \(n\)). This can be minimized exactly using the eigendecomposition of \(B\).

“More on Multidimensional Scaling and Unfolding in R: smacof Version 2” Mair P, Groenen P., de Leeuw J. Journal of Statistical Software (2022)

“Modern Multidimensional Scaling - Theory and Applications” Borg, I.; Groenen P. Springer Series in Statistics (1997)

“Nonmetric multidimensional scaling: a numerical method” Kruskal, J. Psychometrika, 29 (1964)

“Multidimensional scaling by optimizing goodness of fit to a nonmetric hypothesis” Kruskal, J. Psychometrika, 29, (1964)

t-SNE (TSNE) converts affinities of data points to probabilities. The affinities in the original space are represented by Gaussian joint probabilities and the affinities in the embedded space are represented by Student’s t-distributions. This allows t-SNE to be particularly sensitive to local structure and has a few other advantages over existing techniques:

Revealing the structure at many scales on a single map

Revealing data that lie in multiple, different, manifolds or clusters

Reducing the tendency to crowd points together at the center

While Isomap, LLE and variants are best suited to unfold a single continuous low dimensional manifold, t-SNE will focus on the local structure of the data and will tend to extract clustered local groups of samples as highlighted on the S-curve example. This ability to group samples based on the local structure might be beneficial to visually disentangle a dataset that comprises several manifolds at once as is the case in the digits dataset.

The Kullback-Leibler (KL) divergence of the joint probabilities in the original space and the embedded space will be minimized by gradient descent. Note that the KL divergence is not convex, i.e. multiple restarts with different initializations will end up in local minima of the KL divergence. Hence, it is sometimes useful to try different seeds and select the embedding with the lowest KL divergence.

The disadvantages to using t-SNE are roughly:

t-SNE is computationally expensive, and can take several hours on million-sample datasets where PCA will finish in seconds or minutes

The Barnes-Hut t-SNE method is limited to two or three dimensional embeddings.

The algorithm is stochastic and multiple restarts with different seeds can yield different embeddings. However, it is perfectly legitimate to pick the embedding with the least error.

Global structure is not explicitly preserved. This problem is mitigated by initializing points with PCA (using init='pca').

The main purpose of t-SNE is visualization of high-dimensional data. Hence, it works best when the data will be embedded on two or three dimensions.

Optimizing the KL divergence can be a little bit tricky sometimes. There are five parameters that control the optimization of t-SNE and therefore possibly the quality of the resulting embedding:

early exaggeration factor

maximum number of iterations

angle (not used in the exact method)

The perplexity is defined as \(k=2^{(S)}\) where \(S\) is the Shannon entropy of the conditional probability distribution. The perplexity of a \(k\)-sided die is \(k\), so that \(k\) is effectively the number of nearest neighbors t-SNE considers when generating the conditional probabilities. Larger perplexities lead to more nearest neighbors and less sensitive to small structure. Conversely a lower perplexity considers a smaller number of neighbors, and thus ignores more global information in favour of the local neighborhood. As dataset sizes get larger more points will be required to get a reasonable sample of the local neighborhood, and hence larger perplexities may be required. Similarly noisier datasets will require larger perplexity values to encompass enough local neighbors to see beyond the background noise.

The maximum number of iterations is usually high enough and does not need any tuning. The optimization consists of two phases: the early exaggeration phase and the final optimization. During early exaggeration the joint probabilities in the original space will be artificially increased by multiplication with a given factor. Larger factors result in larger gaps between natural clusters in the data. If the factor is too high, the KL divergence could increase during this phase. Usually it does not have to be tuned. A critical parameter is the learning rate. If it is too low gradient descent will get stuck in a bad local minimum. If it is too high the KL divergence will increase during optimization. A heuristic suggested in Belkina et al. (2019) is to set the learning rate to the sample size divided by the early exaggeration factor. We implement this heuristic as learning_rate='auto' argument. More tips can be found in Laurens van der Maaten’s FAQ (see references). The last parameter, angle, is a tradeoff between performance and accuracy. Larger angles imply that we can approximate larger regions by a single point, leading to better speed but less accurate results.

“How to Use t-SNE Effectively” provides a good discussion of the effects of the various parameters, as well as interactive plots to explore the effects of different parameters.

The Barnes-Hut t-SNE that has been implemented here is usually much slower than other manifold learning algorithms. The optimization is quite difficult and the computation of the gradient is \(O[d N log(N)]\), where \(d\) is the number of output dimensions and \(N\) is the number of samples. The Barnes-Hut method improves on the exact method where t-SNE complexity is \(O[d N^2]\), but has several other notable differences:

The Barnes-Hut implementation only works when the target dimensionality is 3 or less. The 2D case is typical when building visualizations.

Barnes-Hut only works with dense input data. Sparse data matrices can only be embedded with the exact method or can be approximated by a dense low rank projection for instance using PCA

Barnes-Hut is an approximation of the exact method. The approximation is parameterized with the angle parameter, therefore the angle parameter is unused when method=”exact”

Barnes-Hut is significantly more scalable. Barnes-Hut can be used to embed hundreds of thousands of data points while the exact method can handle thousands of samples before becoming computationally intractable

For visualization purpose (which is the main use case of t-SNE), using the Barnes-Hut method is strongly recommended. The exact t-SNE method is useful for checking the theoretical properties of the embedding possibly in higher dimensional space but limited to small datasets due to computational constraints.

Also note that the digits labels roughly match the natural grouping found by t-SNE while the linear 2D projection of the PCA model yields a representation where label regions largely overlap. This is a strong clue that this data can be well separated by non linear methods that focus on the local structure (e.g. an SVM with a Gaussian RBF kernel). However, failing to visualize well separated homogeneously labeled groups with t-SNE in 2D does not necessarily imply that the data cannot be correctly classified by a supervised model. It might be the case that 2 dimensions are not high enough to accurately represent the internal structure of the data.

“Visualizing High-Dimensional Data Using t-SNE” van der Maaten, L.J.P.; Hinton, G. Journal of Machine Learning Research (2008)

“t-Distributed Stochastic Neighbor Embedding” van der Maaten, L.J.P.

“Accelerating t-SNE using Tree-Based Algorithms” van der Maaten, L.J.P.; Journal of Machine Learning Research 15(Oct):3221-3245, 2014.

“Automated optimized parameters for T-distributed stochastic neighbor embedding improve visualization and analysis of large datasets” Belkina, A.C., Ciccolella, C.O., Anno, R., Halpert, R., Spidlen, J., Snyder-Cappione, J.E., Nature Communications 10, 5415 (2019).

Make sure the same scale is used over all features. Because manifold learning methods are based on a nearest-neighbor search, the algorithm may perform poorly otherwise. See StandardScaler for convenient ways of scaling heterogeneous data.

The reconstruction error computed by each routine can be used to choose the optimal output dimension. For a \(d\)-dimensional manifold embedded in a \(D\)-dimensional parameter space, the reconstruction error will decrease as n_components is increased until n_components == d.

Note that noisy data can “short-circuit” the manifold, in essence acting as a bridge between parts of the manifold that would otherwise be well-separated. Manifold learning on noisy and/or incomplete data is an active area of research.

Certain input configurations can lead to singular weight matrices, for example when more than two points in the dataset are identical, or when the data is split into disjointed groups. In this case, solver='arpack' will fail to find the null space. The easiest way to address this is to use solver='dense' which will work on a singular matrix, though it may be very slow depending on the number of input points. Alternatively, one can attempt to understand the source of the singularity: if it is due to disjoint sets, increasing n_neighbors may help. If it is due to identical points in the dataset, removing these points may help.

Totally Random Trees Embedding can also be useful to derive non-linear representations of feature space, but it does not perform dimensionality reduction.

---

## 

**URL:** https://scikit-learn.org/stable/_sources/modules/semi_supervised.rst.txt

---

## RationalQuadratic#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.gaussian_process.kernels.RationalQuadratic.html

**Contents:**
- RationalQuadratic#
- Gallery examples#

Rational Quadratic kernel.

The RationalQuadratic kernel can be seen as a scale mixture (an infinite sum) of RBF kernels with different characteristic length scales. It is parameterized by a length scale parameter \(l>0\) and a scale mixture parameter \(\alpha>0\). Only the isotropic variant where length_scale \(l\) is a scalar is supported at the moment. The kernel is given by:

where \(\alpha\) is the scale mixture parameter, \(l\) is the length scale of the kernel and \(d(\cdot,\cdot)\) is the Euclidean distance. For advice on how to set the parameters, see e.g. [1].

Read more in the User Guide.

Added in version 0.18.

The length scale of the kernel.

Scale mixture parameter

The lower and upper bound on ‘length_scale’. If set to “fixed”, ‘length_scale’ cannot be changed during hyperparameter tuning.

The lower and upper bound on ‘alpha’. If set to “fixed”, ‘alpha’ cannot be changed during hyperparameter tuning.

David Duvenaud (2014). “The Kernel Cookbook: Advice on Covariance functions”.

Return the kernel k(X, Y) and optionally its gradient.

Left argument of the returned kernel k(X, Y)

Right argument of the returned kernel k(X, Y). If None, k(X, X) if evaluated instead.

Determines whether the gradient with respect to the log of the kernel hyperparameter is computed. Only supported when Y is None.

The gradient of the kernel k(X, X) with respect to the log of the hyperparameter of the kernel. Only returned when eval_gradient is True.

Returns the log-transformed bounds on the theta.

The log-transformed bounds on the kernel’s hyperparameters theta

Returns a clone of self with given hyperparameters theta.

Returns the diagonal of the kernel k(X, X).

The result of this method is identical to np.diag(self(X)); however, it can be evaluated more efficiently since only the diagonal is evaluated.

Left argument of the returned kernel k(X, Y)

Diagonal of kernel k(X, X)

Get parameters of this kernel.

If True, will return the parameters for this estimator and contained subobjects that are estimators.

Parameter names mapped to their values.

Returns a list of all hyperparameter specifications.

Returns whether the kernel is stationary.

Returns the number of non-fixed hyperparameters of the kernel.

Returns whether the kernel is defined on fixed-length feature vectors or generic objects. Defaults to True for backward compatibility.

Set the parameters of this kernel.

The method works on simple kernels as well as on nested kernels. The latter have parameters of the form <component>__<parameter> so that it’s possible to update each component of a nested object.

Returns the (flattened, log-transformed) non-fixed hyperparameters.

Note that theta are typically the log-transformed values of the kernel’s hyperparameters as this representation of the search space is more amenable for hyperparameter search, as hyperparameters like length-scales naturally live on a log-scale.

The non-fixed, log-transformed hyperparameters of the kernel

Forecasting of CO2 level on Mona Loa dataset using Gaussian process regression (GPR)

Illustration of prior and posterior Gaussian process for different kernels

**Examples:**

Example 1 (json):
```json
>>> from sklearn.datasets import load_iris
>>> from sklearn.gaussian_process import GaussianProcessClassifier
>>> from sklearn.gaussian_process.kernels import RationalQuadratic
>>> X, y = load_iris(return_X_y=True)
>>> kernel = RationalQuadratic(length_scale=1.0, alpha=1.5)
>>> gpc = GaussianProcessClassifier(kernel=kernel,
...         random_state=0).fit(X, y)
>>> gpc.score(X, y)
0.9733
>>> gpc.predict_proba(X[:2,:])
array([[0.8881, 0.0566, 0.05518],
        [0.8678, 0.0707 , 0.0614]])
```

---

## calibration_curve#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.calibration.calibration_curve.html

**Contents:**
- calibration_curve#

Compute true and predicted probabilities for a calibration curve.

The method assumes the inputs come from a binary classifier, and discretize the [0, 1] interval into bins.

Calibration curves may also be referred to as reliability diagrams.

Read more in the User Guide.

Probabilities of the positive class.

The label of the positive class.

Added in version 1.1.

Number of bins to discretize the [0, 1] interval. A bigger number requires more data. Bins with no samples (i.e. without corresponding values in y_prob) will not be returned, thus the returned arrays may have less than n_bins values.

Strategy used to define the widths of the bins.

The bins have identical widths.

The bins have the same number of samples and depend on y_prob.

The proportion of samples whose class is the positive class, in each bin (fraction of positives).

The mean predicted probability in each bin.

Plot calibration curve using true and predicted labels.

Plot calibration curve using an estimator and data.

Alexandru Niculescu-Mizil and Rich Caruana (2005) Predicting Good Probabilities With Supervised Learning, in Proceedings of the 22nd International Conference on Machine Learning (ICML). See section 4 (Qualitative Analysis of Predictions).

**Examples:**

Example 1 (sql):
```sql
>>> import numpy as np
>>> from sklearn.calibration import calibration_curve
>>> y_true = np.array([0, 0, 0, 0, 1, 1, 1, 1, 1])
>>> y_pred = np.array([0.1, 0.2, 0.3, 0.4, 0.65, 0.7, 0.8, 0.9,  1.])
>>> prob_true, prob_pred = calibration_curve(y_true, y_pred, n_bins=3)
>>> prob_true
array([0. , 0.5, 1. ])
>>> prob_pred
array([0.2  , 0.525, 0.85 ])
```

---

## KNeighborsTransformer#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsTransformer.html

**Contents:**
- KNeighborsTransformer#
- Gallery examples#

Transform X into a (weighted) graph of k nearest neighbors.

The transformed data is a sparse graph as returned by kneighbors_graph.

Read more in the User Guide.

Added in version 0.22.

Type of returned matrix: ‘connectivity’ will return the connectivity matrix with ones and zeros, and ‘distance’ will return the distances between neighbors according to the given metric.

Number of neighbors for each sample in the transformed sparse graph. For compatibility reasons, as each sample is considered as its own neighbor, one extra neighbor will be computed when mode == ‘distance’. In this case, the sparse graph contains (n_neighbors + 1) neighbors.

Algorithm used to compute the nearest neighbors:

‘ball_tree’ will use BallTree

‘kd_tree’ will use KDTree

‘brute’ will use a brute-force search.

‘auto’ will attempt to decide the most appropriate algorithm based on the values passed to fit method.

Note: fitting on sparse input will override the setting of this parameter, using brute force.

Leaf size passed to BallTree or KDTree. This can affect the speed of the construction and query, as well as the memory required to store the tree. The optimal value depends on the nature of the problem.

Metric to use for distance computation. Default is “minkowski”, which results in the standard Euclidean distance when p = 2. See the documentation of scipy.spatial.distance and the metrics listed in distance_metrics for valid metric values.

If metric is a callable function, it takes two arrays representing 1D vectors as inputs and must return one value indicating the distance between those vectors. This works for Scipy’s metrics, but is less efficient than passing the metric name as a string.

Distance matrices are not supported.

Parameter for the Minkowski metric from sklearn.metrics.pairwise.pairwise_distances. When p = 1, this is equivalent to using manhattan_distance (l1), and euclidean_distance (l2) for p = 2. For arbitrary p, minkowski_distance (l_p) is used. This parameter is expected to be positive.

Additional keyword arguments for the metric function.

The number of parallel jobs to run for neighbors search. If -1, then the number of jobs is set to the number of CPU cores.

The distance metric used. It will be same as the metric parameter or a synonym of it, e.g. ‘euclidean’ if the metric parameter set to ‘minkowski’ and p parameter set to 2.

Additional keyword arguments for the metric function. For most metrics will be same with metric_params parameter, but may also contain the p parameter value if the effective_metric_ attribute is set to ‘minkowski’.

Number of features seen during fit.

Added in version 0.24.

Names of features seen during fit. Defined only when X has feature names that are all strings.

Added in version 1.0.

Number of samples in the fitted data.

Compute the weighted graph of k-neighbors for points in X.

Transform X into a weighted graph of neighbors nearer than a radius.

For an example of using KNeighborsTransformer in combination with TSNE see Approximate nearest neighbors in TSNE.

Fit the k-nearest neighbors transformer from the training dataset.

Not used, present for API consistency by convention.

The fitted k-nearest neighbors transformer.

Fit to data, then transform it.

Fits transformer to X and y with optional parameters fit_params and returns a transformed version of X.

Not used, present for API consistency by convention.

Xt[i, j] is assigned the weight of edge that connects i to j. Only the neighbors have an explicit value. The diagonal is always explicit. The matrix is of CSR format.

Get output feature names for transformation.

The feature names out will prefixed by the lowercased class name. For example, if the transformer outputs 3 features, then the feature names out are: ["class_name0", "class_name1", "class_name2"].

Only used to validate feature names with the names seen in fit.

Transformed feature names.

Get metadata routing of this object.

Please check User Guide on how the routing mechanism works.

A MetadataRequest encapsulating routing information.

Get parameters for this estimator.

If True, will return the parameters for this estimator and contained subobjects that are estimators.

Parameter names mapped to their values.

Find the K-neighbors of a point.

Returns indices of and distances to the neighbors of each point.

The query point or points. If not provided, neighbors of each indexed point are returned. In this case, the query point is not considered its own neighbor.

Number of neighbors required for each sample. The default is the value passed to the constructor.

Whether or not to return the distances.

Array representing the lengths to points, only present if return_distance=True.

Indices of the nearest points in the population matrix.

In the following example, we construct a NearestNeighbors class from an array representing our data set and ask who’s the closest point to [1,1,1]

As you can see, it returns [[0.5]], and [[2]], which means that the element is at distance 0.5 and is the third element of samples (indexes start at 0). You can also query for multiple points:

Compute the (weighted) graph of k-Neighbors for points in X.

The query point or points. If not provided, neighbors of each indexed point are returned. In this case, the query point is not considered its own neighbor. For metric='precomputed' the shape should be (n_queries, n_indexed). Otherwise the shape should be (n_queries, n_features).

Number of neighbors for each sample. The default is the value passed to the constructor.

Type of returned matrix: ‘connectivity’ will return the connectivity matrix with ones and zeros, in ‘distance’ the edges are distances between points, type of distance depends on the selected metric parameter in NearestNeighbors class.

n_samples_fit is the number of samples in the fitted data. A[i, j] gives the weight of the edge connecting i to j. The matrix is of CSR format.

Compute the (weighted) graph of Neighbors for points in X.

Set output container.

See Introducing the set_output API for an example on how to use the API.

Configure output of transform and fit_transform.

"default": Default output format of a transformer

"pandas": DataFrame output

"polars": Polars output

None: Transform configuration is unchanged

Added in version 1.4: "polars" option was added.

Set the parameters of this estimator.

The method works on simple estimators as well as on nested objects (such as Pipeline). The latter have parameters of the form <component>__<parameter> so that it’s possible to update each component of a nested object.

Estimator parameters.

Compute the (weighted) graph of Neighbors for points in X.

Xt[i, j] is assigned the weight of edge that connects i to j. Only the neighbors have an explicit value. The diagonal is always explicit. The matrix is of CSR format.

Approximate nearest neighbors in TSNE

Caching nearest neighbors

Release Highlights for scikit-learn 0.22

**Examples:**

Example 1 (sql):
```sql
>>> from sklearn.datasets import load_wine
>>> from sklearn.neighbors import KNeighborsTransformer
>>> X, _ = load_wine(return_X_y=True)
>>> X.shape
(178, 13)
>>> transformer = KNeighborsTransformer(n_neighbors=5, mode='distance')
>>> X_dist_graph = transformer.fit_transform(X)
>>> X_dist_graph.shape
(178, 178)
```

Example 2 (python):
```python
>>> samples = [[0., 0., 0.], [0., .5, 0.], [1., 1., .5]]
>>> from sklearn.neighbors import NearestNeighbors
>>> neigh = NearestNeighbors(n_neighbors=1)
>>> neigh.fit(samples)
NearestNeighbors(n_neighbors=1)
>>> print(neigh.kneighbors([[1., 1., 1.]]))
(array([[0.5]]), array([[2]]))
```

Example 3 (json):
```json
>>> X = [[0., 1., 0.], [1., 0., 1.]]
>>> neigh.kneighbors(X, return_distance=False)
array([[1],
       [2]]...)
```

Example 4 (sql):
```sql
>>> X = [[0], [3], [1]]
>>> from sklearn.neighbors import NearestNeighbors
>>> neigh = NearestNeighbors(n_neighbors=2)
>>> neigh.fit(X)
NearestNeighbors(n_neighbors=2)
>>> A = neigh.kneighbors_graph(X)
>>> A.toarray()
array([[1., 0., 1.],
       [0., 1., 1.],
       [1., 0., 1.]])
```

---

## RegressorChain#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.multioutput.RegressorChain.html

**Contents:**
- RegressorChain#

A multi-label model that arranges regressions into a chain.

Each model makes a prediction in the order specified by the chain using all of the available features provided to the model plus the predictions of models that are earlier in the chain.

Read more in the User Guide.

Added in version 0.20.

The base estimator from which the regressor chain is built.

If None, the order will be determined by the order of columns in the label matrix Y.:

The order of the chain can be explicitly set by providing a list of integers. For example, for a chain of length 5.:

means that the first model in the chain will make predictions for column 1 in the Y matrix, the second model will make predictions for column 3, etc.

If order is ‘random’ a random ordering will be used.

Determines whether to use cross validated predictions or true labels for the results of previous estimators in the chain. Possible inputs for cv are:

None, to use true labels when fitting,

integer, to specify the number of folds in a (Stratified)KFold,

An iterable yielding (train, test) splits as arrays of indices.

If order='random', determines random number generation for the chain order. In addition, it controls the random seed given at each base_estimator at each chaining iteration. Thus, it is only used when base_estimator exposes a random_state. Pass an int for reproducible output across multiple function calls. See Glossary.

If True, chain progress is output as each model is completed.

Added in version 1.2.

Use estimator instead.

Deprecated since version 1.7: base_estimator is deprecated and will be removed in 1.9. Use estimator instead.

A list of clones of base_estimator.

The order of labels in the classifier chain.

Number of features seen during fit. Only defined if the underlying base_estimator exposes such an attribute when fit.

Added in version 0.24.

Names of features seen during fit. Defined only when X has feature names that are all strings.

Added in version 1.0.

Equivalent for classification.

Learns each output independently rather than chaining.

Fit the model to data matrix X and targets Y.

Parameters passed to the fit method at each step of the regressor chain.

Added in version 0.23.

Returns a fitted instance.

Get metadata routing of this object.

Please check User Guide on how the routing mechanism works.

Added in version 1.3.

A MetadataRouter encapsulating routing information.

Get parameters for this estimator.

If True, will return the parameters for this estimator and contained subobjects that are estimators.

Parameter names mapped to their values.

Predict on the data matrix X using the ClassifierChain model.

The predicted values.

Return coefficient of determination on test data.

The coefficient of determination, \(R^2\), is defined as \((1 - \frac{u}{v})\), where \(u\) is the residual sum of squares ((y_true - y_pred)** 2).sum() and \(v\) is the total sum of squares ((y_true - y_true.mean()) ** 2).sum(). The best possible score is 1.0 and it can be negative (because the model can be arbitrarily worse). A constant model that always predicts the expected value of y, disregarding the input features, would get a \(R^2\) score of 0.0.

Test samples. For some estimators this may be a precomputed kernel matrix or a list of generic objects instead with shape (n_samples, n_samples_fitted), where n_samples_fitted is the number of samples used in the fitting for the estimator.

\(R^2\) of self.predict(X) w.r.t. y.

The \(R^2\) score used when calling score on a regressor uses multioutput='uniform_average' from version 0.23 to keep consistent with default value of r2_score. This influences the score method of all the multioutput regressors (except for MultiOutputRegressor).

Set the parameters of this estimator.

The method works on simple estimators as well as on nested objects (such as Pipeline). The latter have parameters of the form <component>__<parameter> so that it’s possible to update each component of a nested object.

Estimator parameters.

Configure whether metadata should be requested to be passed to the score method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to score if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to score.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Added in version 1.3.

Metadata routing for sample_weight parameter in score.

**Examples:**

Example 1 (unknown):
```unknown
order = [0, 1, 2, ..., Y.shape[1] - 1]
```

Example 2 (unknown):
```unknown
order = [1, 3, 2, 4, 0]
```

Example 3 (sql):
```sql
>>> from sklearn.multioutput import RegressorChain
>>> from sklearn.linear_model import LogisticRegression
>>> logreg = LogisticRegression(solver='lbfgs')
>>> X, Y = [[1, 0], [0, 1], [1, 1]], [[0, 2], [1, 1], [2, 0]]
>>> chain = RegressorChain(logreg, order=[0, 1]).fit(X, Y)
>>> chain.predict(X)
array([[0., 2.],
       [1., 1.],
       [2., 0.]])
```

---

## MultiOutputClassifier#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.multioutput.MultiOutputClassifier.html

**Contents:**
- MultiOutputClassifier#

Multi target classification.

This strategy consists of fitting one classifier per target. This is a simple strategy for extending classifiers that do not natively support multi-target classification.

An estimator object implementing fit and predict. A predict_proba method will be exposed only if estimator implements it.

The number of jobs to run in parallel. fit, predict and partial_fit (if supported by the passed estimator) will be parallelized for each target.

When individual estimators are fast to train or predict, using n_jobs > 1 can result in slower performance due to the parallelism overhead.

None means 1 unless in a joblib.parallel_backend context. -1 means using all available processes / threads. See Glossary for more details.

Changed in version 0.20: n_jobs default changed from 1 to None.

Estimators used for predictions.

Number of features seen during fit. Only defined if the underlying estimator exposes such an attribute when fit.

Added in version 0.24.

Names of features seen during fit. Only defined if the underlying estimators expose such an attribute when fit.

Added in version 1.0.

A multi-label model that arranges binary classifiers into a chain.

Fits one regressor per target variable.

Fit the model to data matrix X and targets Y.

Sample weights. If None, then samples are equally weighted. Only supported if the underlying classifier supports sample weights.

Parameters passed to the estimator.fit method of each step.

Added in version 0.23.

Returns a fitted instance.

Get metadata routing of this object.

Please check User Guide on how the routing mechanism works.

Added in version 1.3.

A MetadataRouter encapsulating routing information.

Get parameters for this estimator.

If True, will return the parameters for this estimator and contained subobjects that are estimators.

Parameter names mapped to their values.

Incrementally fit a separate model for each class output.

Multi-output targets.

Each array is unique classes for one output in str/int. Can be obtained via [np.unique(y[:, i]) for i in range(y.shape[1])], where y is the target matrix of the entire dataset. This argument is required for the first call to partial_fit and can be omitted in the subsequent calls. Note that y doesn’t need to contain all labels in classes.

Sample weights. If None, then samples are equally weighted. Only supported if the underlying regressor supports sample weights.

Parameters passed to the estimator.partial_fit method of each sub-estimator.

Only available if enable_metadata_routing=True. See the User Guide.

Added in version 1.3.

Returns a fitted instance.

Predict multi-output variable using model for each target variable.

Multi-output targets predicted across multiple predictors. Note: Separate models are generated for each predictor.

Return prediction probabilities for each class of each output.

This method will raise a ValueError if any of the estimators do not have predict_proba.

The class probabilities of the input samples. The order of the classes corresponds to that in the attribute classes_.

Changed in version 0.19: This function now returns a list of arrays where the length of the list is n_outputs, and each array is (n_samples, n_classes) for that particular output.

Return the mean accuracy on the given test data and labels.

Mean accuracy of predicted target versus true target.

Configure whether metadata should be requested to be passed to the fit method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to fit if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to fit.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Added in version 1.3.

Metadata routing for sample_weight parameter in fit.

Set the parameters of this estimator.

The method works on simple estimators as well as on nested objects (such as Pipeline). The latter have parameters of the form <component>__<parameter> so that it’s possible to update each component of a nested object.

Estimator parameters.

Configure whether metadata should be requested to be passed to the partial_fit method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to partial_fit if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to partial_fit.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Added in version 1.3.

Metadata routing for classes parameter in partial_fit.

Metadata routing for sample_weight parameter in partial_fit.

**Examples:**

Example 1 (sql):
```sql
>>> import numpy as np
>>> from sklearn.datasets import make_multilabel_classification
>>> from sklearn.multioutput import MultiOutputClassifier
>>> from sklearn.linear_model import LogisticRegression
>>> X, y = make_multilabel_classification(n_classes=3, random_state=0)
>>> clf = MultiOutputClassifier(LogisticRegression()).fit(X, y)
>>> clf.predict(X[-2:])
array([[1, 1, 1],
       [1, 0, 1]])
```

---

## RandomForestClassifier#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html

**Contents:**
- RandomForestClassifier#
- Gallery examples#

A random forest classifier.

A random forest is a meta estimator that fits a number of decision tree classifiers on various sub-samples of the dataset and uses averaging to improve the predictive accuracy and control over-fitting. Trees in the forest use the best split strategy, i.e. equivalent to passing splitter="best" to the underlying DecisionTreeClassifier. The sub-sample size is controlled with the max_samples parameter if bootstrap=True (default), otherwise the whole dataset is used to build each tree.

For a comparison between tree-based ensemble models see the example Comparing Random Forests and Histogram Gradient Boosting models.

This estimator has native support for missing values (NaNs). During training, the tree grower learns at each split point whether samples with missing values should go to the left or right child, based on the potential gain. When predicting, samples with missing values are assigned to the left or right child consequently. If no missing values were encountered for a given feature during training, then samples with missing values are mapped to whichever child has the most samples.

Read more in the User Guide.

The number of trees in the forest.

Changed in version 0.22: The default value of n_estimators changed from 10 to 100 in 0.22.

The function to measure the quality of a split. Supported criteria are “gini” for the Gini impurity and “log_loss” and “entropy” both for the Shannon information gain, see Mathematical formulation. Note: This parameter is tree-specific.

The maximum depth of the tree. If None, then nodes are expanded until all leaves are pure or until all leaves contain less than min_samples_split samples.

The minimum number of samples required to split an internal node:

If int, then consider min_samples_split as the minimum number.

If float, then min_samples_split is a fraction and ceil(min_samples_split * n_samples) are the minimum number of samples for each split.

Changed in version 0.18: Added float values for fractions.

The minimum number of samples required to be at a leaf node. A split point at any depth will only be considered if it leaves at least min_samples_leaf training samples in each of the left and right branches. This may have the effect of smoothing the model, especially in regression.

If int, then consider min_samples_leaf as the minimum number.

If float, then min_samples_leaf is a fraction and ceil(min_samples_leaf * n_samples) are the minimum number of samples for each node.

Changed in version 0.18: Added float values for fractions.

The minimum weighted fraction of the sum total of weights (of all the input samples) required to be at a leaf node. Samples have equal weight when sample_weight is not provided.

The number of features to consider when looking for the best split:

If int, then consider max_features features at each split.

If float, then max_features is a fraction and max(1, int(max_features * n_features_in_)) features are considered at each split.

If “sqrt”, then max_features=sqrt(n_features).

If “log2”, then max_features=log2(n_features).

If None, then max_features=n_features.

Changed in version 1.1: The default of max_features changed from "auto" to "sqrt".

Note: the search for a split does not stop until at least one valid partition of the node samples is found, even if it requires to effectively inspect more than max_features features.

Grow trees with max_leaf_nodes in best-first fashion. Best nodes are defined as relative reduction in impurity. If None then unlimited number of leaf nodes.

A node will be split if this split induces a decrease of the impurity greater than or equal to this value.

The weighted impurity decrease equation is the following:

where N is the total number of samples, N_t is the number of samples at the current node, N_t_L is the number of samples in the left child, and N_t_R is the number of samples in the right child.

N, N_t, N_t_R and N_t_L all refer to the weighted sum, if sample_weight is passed.

Added in version 0.19.

Whether bootstrap samples are used when building trees. If False, the whole dataset is used to build each tree.

Whether to use out-of-bag samples to estimate the generalization score. By default, accuracy_score is used. Provide a callable with signature metric(y_true, y_pred) to use a custom metric. Only available if bootstrap=True.

For an illustration of out-of-bag (OOB) error estimation, see the example OOB Errors for Random Forests.

The number of jobs to run in parallel. fit, predict, decision_path and apply are all parallelized over the trees. None means 1 unless in a joblib.parallel_backend context. -1 means using all processors. See Glossary for more details.

Controls both the randomness of the bootstrapping of the samples used when building trees (if bootstrap=True) and the sampling of the features to consider when looking for the best split at each node (if max_features < n_features). See Glossary for details.

Controls the verbosity when fitting and predicting.

When set to True, reuse the solution of the previous call to fit and add more estimators to the ensemble, otherwise, just fit a whole new forest. See Glossary and Fitting additional trees for details.

Weights associated with classes in the form {class_label: weight}. If not given, all classes are supposed to have weight one. For multi-output problems, a list of dicts can be provided in the same order as the columns of y.

Note that for multioutput (including multilabel) weights should be defined for each class of every column in its own dict. For example, for four-class multilabel classification weights should be [{0: 1, 1: 1}, {0: 1, 1: 5}, {0: 1, 1: 1}, {0: 1, 1: 1}] instead of [{1:1}, {2:5}, {3:1}, {4:1}].

The “balanced” mode uses the values of y to automatically adjust weights inversely proportional to class frequencies in the input data as n_samples / (n_classes * np.bincount(y))

The “balanced_subsample” mode is the same as “balanced” except that weights are computed based on the bootstrap sample for every tree grown.

For multi-output, the weights of each column of y will be multiplied.

Note that these weights will be multiplied with sample_weight (passed through the fit method) if sample_weight is specified.

Complexity parameter used for Minimal Cost-Complexity Pruning. The subtree with the largest cost complexity that is smaller than ccp_alpha will be chosen. By default, no pruning is performed. See Minimal Cost-Complexity Pruning for details. See Post pruning decision trees with cost complexity pruning for an example of such pruning.

Added in version 0.22.

If bootstrap is True, the number of samples to draw from X to train each base estimator.

If None (default), then draw X.shape[0] samples.

If int, then draw max_samples samples.

If float, then draw max(round(n_samples * max_samples), 1) samples. Thus, max_samples should be in the interval (0.0, 1.0].

Added in version 0.22.

1: monotonic increase

-1: monotonic decrease

If monotonic_cst is None, no constraints are applied.

multiclass classifications (i.e. when n_classes > 2),

multioutput classifications (i.e. when n_outputs_ > 1),

classifications trained on data with missing values.

The constraints hold over the probability of the positive class.

Read more in the User Guide.

Added in version 1.4.

The child estimator template used to create the collection of fitted sub-estimators.

Added in version 1.2: base_estimator_ was renamed to estimator_.

The collection of fitted sub-estimators.

The classes labels (single output problem), or a list of arrays of class labels (multi-output problem).

The number of classes (single output problem), or a list containing the number of classes for each output (multi-output problem).

Number of features seen during fit.

Added in version 0.24.

Names of features seen during fit. Defined only when X has feature names that are all strings.

Added in version 1.0.

The number of outputs when fit is performed.

The impurity-based feature importances.

Score of the training dataset obtained using an out-of-bag estimate. This attribute exists only when oob_score is True.

Decision function computed with out-of-bag estimate on the training set. If n_estimators is small it might be possible that a data point was never left out during the bootstrap. In this case, oob_decision_function_ might contain NaN. This attribute exists only when oob_score is True.

The subset of drawn samples for each base estimator.

A decision tree classifier.

Ensemble of extremely randomized tree classifiers.

A Histogram-based Gradient Boosting Classification Tree, very fast for big datasets (n_samples >= 10_000).

The default values for the parameters controlling the size of the trees (e.g. max_depth, min_samples_leaf, etc.) lead to fully grown and unpruned trees which can potentially be very large on some data sets. To reduce memory consumption, the complexity and size of the trees should be controlled by setting those parameter values.

The features are always randomly permuted at each split. Therefore, the best found split may vary, even with the same training data, max_features=n_features and bootstrap=False, if the improvement of the criterion is identical for several splits enumerated during the search of the best split. To obtain a deterministic behaviour during fitting, random_state has to be fixed.

L. Breiman, “Random Forests”, Machine Learning, 45(1), 5-32, 2001.

Apply trees in the forest to X, return leaf indices.

The input samples. Internally, its dtype will be converted to dtype=np.float32. If a sparse matrix is provided, it will be converted into a sparse csr_matrix.

For each datapoint x in X and for each tree in the forest, return the index of the leaf x ends up in.

Return the decision path in the forest.

Added in version 0.18.

The input samples. Internally, its dtype will be converted to dtype=np.float32. If a sparse matrix is provided, it will be converted into a sparse csr_matrix.

Return a node indicator matrix where non zero elements indicates that the samples goes through the nodes. The matrix is of CSR format.

The columns from indicator[n_nodes_ptr[i]:n_nodes_ptr[i+1]] gives the indicator value for the i-th estimator.

Build a forest of trees from the training set (X, y).

The training input samples. Internally, its dtype will be converted to dtype=np.float32. If a sparse matrix is provided, it will be converted into a sparse csc_matrix.

The target values (class labels in classification, real numbers in regression).

Sample weights. If None, then samples are equally weighted. Splits that would create child nodes with net zero or negative weight are ignored while searching for a split in each node. In the case of classification, splits are also ignored if they would result in any single class carrying a negative weight in either child node.

Get metadata routing of this object.

Please check User Guide on how the routing mechanism works.

A MetadataRequest encapsulating routing information.

Get parameters for this estimator.

If True, will return the parameters for this estimator and contained subobjects that are estimators.

Parameter names mapped to their values.

The predicted class of an input sample is a vote by the trees in the forest, weighted by their probability estimates. That is, the predicted class is the one with highest mean probability estimate across the trees.

The input samples. Internally, its dtype will be converted to dtype=np.float32. If a sparse matrix is provided, it will be converted into a sparse csr_matrix.

The predicted classes.

Predict class log-probabilities for X.

The predicted class log-probabilities of an input sample is computed as the log of the mean predicted class probabilities of the trees in the forest.

The input samples. Internally, its dtype will be converted to dtype=np.float32. If a sparse matrix is provided, it will be converted into a sparse csr_matrix.

The class probabilities of the input samples. The order of the classes corresponds to that in the attribute classes_.

Predict class probabilities for X.

The predicted class probabilities of an input sample are computed as the mean predicted class probabilities of the trees in the forest. The class probability of a single tree is the fraction of samples of the same class in a leaf.

The input samples. Internally, its dtype will be converted to dtype=np.float32. If a sparse matrix is provided, it will be converted into a sparse csr_matrix.

The class probabilities of the input samples. The order of the classes corresponds to that in the attribute classes_.

Return accuracy on provided data and labels.

In multi-label classification, this is the subset accuracy which is a harsh metric since you require for each sample that each label set be correctly predicted.

Mean accuracy of self.predict(X) w.r.t. y.

Configure whether metadata should be requested to be passed to the fit method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to fit if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to fit.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Added in version 1.3.

Metadata routing for sample_weight parameter in fit.

Set the parameters of this estimator.

The method works on simple estimators as well as on nested objects (such as Pipeline). The latter have parameters of the form <component>__<parameter> so that it’s possible to update each component of a nested object.

Estimator parameters.

Configure whether metadata should be requested to be passed to the score method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to score if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to score.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Added in version 1.3.

Metadata routing for sample_weight parameter in score.

Probability Calibration for 3-class classification

Comparison of Calibration of Classifiers

Classifier comparison

OOB Errors for Random Forests

Feature transformations with ensembles of trees

Comparing Random Forests and Histogram Gradient Boosting models

Feature importances with a forest of trees

Plot the decision surfaces of ensembles of trees on the iris dataset

Permutation Importance vs Random Forest Feature Importance (MDI)

Permutation Importance with Multicollinear or Correlated Features

ROC Curve with Visualization API

Detection error tradeoff (DET) curve

Successive Halving Iterations

Release Highlights for scikit-learn 0.22

Release Highlights for scikit-learn 0.24

Release Highlights for scikit-learn 1.4

Classification of text documents using sparse features

**Examples:**

Example 1 (yaml):
```yaml
N_t / N * (impurity - N_t_R / N_t * right_impurity
                    - N_t_L / N_t * left_impurity)
```

Example 2 (python):
```python
>>> from sklearn.ensemble import RandomForestClassifier
>>> from sklearn.datasets import make_classification
>>> X, y = make_classification(n_samples=1000, n_features=4,
...                            n_informative=2, n_redundant=0,
...                            random_state=0, shuffle=False)
>>> clf = RandomForestClassifier(max_depth=2, random_state=0)
>>> clf.fit(X, y)
RandomForestClassifier(...)
>>> print(clf.predict([[0, 0, 0, 0]]))
[1]
```

---

## ElasticNetCV#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.ElasticNetCV.html

**Contents:**
- ElasticNetCV#
- Gallery examples#

Elastic Net model with iterative fitting along a regularization path.

See glossary entry for cross-validation estimator.

Read more in the User Guide.

Float between 0 and 1 passed to ElasticNet (scaling between l1 and l2 penalties). For l1_ratio = 0 the penalty is an L2 penalty. For l1_ratio = 1 it is an L1 penalty. For 0 < l1_ratio < 1, the penalty is a combination of L1 and L2 This parameter can be a list, in which case the different values are tested by cross-validation and the one giving the best prediction score is used. Note that a good choice of list of values for l1_ratio is often to put more values close to 1 (i.e. Lasso) and less close to 0 (i.e. Ridge), as in [.1, .5, .7, .9, .95, .99, 1].

Length of the path. eps=1e-3 means that alpha_min / alpha_max = 1e-3.

Number of alphas along the regularization path, used for each l1_ratio.

Deprecated since version 1.7: n_alphas was deprecated in 1.7 and will be removed in 1.9. Use alphas instead.

Values of alphas to test along the regularization path, used for each l1_ratio. If int, alphas values are generated automatically. If array-like, list of alpha values to use.

Changed in version 1.7: alphas accepts an integer value which removes the need to pass n_alphas.

Deprecated since version 1.7: alphas=None was deprecated in 1.7 and will be removed in 1.9, at which point the default value will be set to 100.

Whether to calculate the intercept for this model. If set to false, no intercept will be used in calculations (i.e. data is expected to be centered).

Whether to use a precomputed Gram matrix to speed up calculations. If set to 'auto' let us decide. The Gram matrix can also be passed as argument.

The maximum number of iterations.

The tolerance for the optimization: if the updates are smaller or equal to tol, the optimization code checks the dual gap for optimality and continues until it is smaller or equal to tol.

Determines the cross-validation splitting strategy. Possible inputs for cv are:

None, to use the default 5-fold cross-validation,

int, to specify the number of folds.

An iterable yielding (train, test) splits as arrays of indices.

For int/None inputs, KFold is used.

Refer User Guide for the various cross-validation strategies that can be used here.

Changed in version 0.22: cv default value if None changed from 3-fold to 5-fold.

If True, X will be copied; else, it may be overwritten.

Number of CPUs to use during the cross validation. None means 1 unless in a joblib.parallel_backend context. -1 means using all processors. See Glossary for more details.

When set to True, forces the coefficients to be positive.

The seed of the pseudo random number generator that selects a random feature to update. Used when selection == ‘random’. Pass an int for reproducible output across multiple function calls. See Glossary.

If set to ‘random’, a random coefficient is updated every iteration rather than looping over features sequentially by default. This (setting to ‘random’) often leads to significantly faster convergence especially when tol is higher than 1e-4.

The amount of penalization chosen by cross validation.

The compromise between l1 and l2 penalization chosen by cross validation.

Parameter vector (w in the cost function formula).

Independent term in the decision function.

Mean square error for the test set on each fold, varying l1_ratio and alpha.

The grid of alphas used for fitting, for each l1_ratio.

The dual gaps at the end of the optimization for the optimal alpha.

Number of iterations run by the coordinate descent solver to reach the specified tolerance for the optimal alpha.

Number of features seen during fit.

Added in version 0.24.

Names of features seen during fit. Defined only when X has feature names that are all strings.

Added in version 1.0.

Compute elastic net path with coordinate descent.

Linear regression with combined L1 and L2 priors as regularizer.

In fit, once the best parameters l1_ratio and alpha are found through cross-validation, the model is fit again using the entire training set.

To avoid unnecessary memory duplication the X argument of the fit method should be directly passed as a Fortran-contiguous numpy array.

The parameter l1_ratio corresponds to alpha in the glmnet R package while alpha corresponds to the lambda parameter in glmnet. More specifically, the optimization objective is:

If you are interested in controlling the L1 and L2 penalty separately, keep in mind that this is equivalent to:

For an example, see examples/linear_model/plot_lasso_model_selection.py.

The underlying coordinate descent solver uses gap safe screening rules to speedup fitting time, see User Guide on coordinate descent.

Fit ElasticNet model with coordinate descent.

Fit is on grid of alphas and best alpha estimated by cross-validation.

Training data. Pass directly as Fortran-contiguous data to avoid unnecessary memory duplication. If y is mono-output, X can be sparse. Note that large sparse matrices and arrays requiring int64 indices are not accepted.

Sample weights used for fitting and evaluation of the weighted mean squared error of each cv-fold. Note that the cross validated MSE that is finally used to find the best model is the unweighted mean over the (weighted) MSEs of each test fold.

Parameters to be passed to the CV splitter.

Added in version 1.4: Only available if enable_metadata_routing=True, which can be set by using sklearn.set_config(enable_metadata_routing=True). See Metadata Routing User Guide for more details.

Returns an instance of fitted model.

Get metadata routing of this object.

Please check User Guide on how the routing mechanism works.

Added in version 1.4.

A MetadataRouter encapsulating routing information.

Get parameters for this estimator.

If True, will return the parameters for this estimator and contained subobjects that are estimators.

Parameter names mapped to their values.

Compute elastic net path with coordinate descent.

The elastic net optimization function varies for mono and multi-outputs.

For mono-output tasks it is:

For multi-output tasks it is:

i.e. the sum of norm of each row.

Read more in the User Guide.

Training data. Pass directly as Fortran-contiguous data to avoid unnecessary memory duplication. If y is mono-output then X can be sparse.

Number between 0 and 1 passed to elastic net (scaling between l1 and l2 penalties). l1_ratio=1 corresponds to the Lasso.

Length of the path. eps=1e-3 means that alpha_min / alpha_max = 1e-3.

Number of alphas along the regularization path.

List of alphas where to compute the models. If None alphas are set automatically.

Whether to use a precomputed Gram matrix to speed up calculations. If set to 'auto' let us decide. The Gram matrix can also be passed as argument.

Xy = np.dot(X.T, y) that can be precomputed. It is useful only when the Gram matrix is precomputed.

If True, X will be copied; else, it may be overwritten.

The initial values of the coefficients.

Whether to return the number of iterations or not.

If set to True, forces coefficients to be positive. (Only allowed when y.ndim == 1).

If set to False, the input validation checks are skipped (including the Gram matrix when provided). It is assumed that they are handled by the caller.

Keyword arguments passed to the coordinate descent solver.

The alphas along the path where models are computed.

Coefficients along the path.

The dual gaps at the end of the optimization for each alpha.

The number of iterations taken by the coordinate descent optimizer to reach the specified tolerance for each alpha. (Is returned when return_n_iter is set to True).

Multi-task ElasticNet model trained with L1/L2 mixed-norm as regularizer.

Multi-task L1/L2 ElasticNet with built-in cross-validation.

Linear regression with combined L1 and L2 priors as regularizer.

Elastic Net model with iterative fitting along a regularization path.

For an example, see examples/linear_model/plot_lasso_lasso_lars_elasticnet_path.py.

The underlying coordinate descent solver uses gap safe screening rules to speedup fitting time, see User Guide on coordinate descent.

Predict using the linear model.

Returns predicted values.

Return coefficient of determination on test data.

The coefficient of determination, \(R^2\), is defined as \((1 - \frac{u}{v})\), where \(u\) is the residual sum of squares ((y_true - y_pred)** 2).sum() and \(v\) is the total sum of squares ((y_true - y_true.mean()) ** 2).sum(). The best possible score is 1.0 and it can be negative (because the model can be arbitrarily worse). A constant model that always predicts the expected value of y, disregarding the input features, would get a \(R^2\) score of 0.0.

Test samples. For some estimators this may be a precomputed kernel matrix or a list of generic objects instead with shape (n_samples, n_samples_fitted), where n_samples_fitted is the number of samples used in the fitting for the estimator.

\(R^2\) of self.predict(X) w.r.t. y.

The \(R^2\) score used when calling score on a regressor uses multioutput='uniform_average' from version 0.23 to keep consistent with default value of r2_score. This influences the score method of all the multioutput regressors (except for MultiOutputRegressor).

Configure whether metadata should be requested to be passed to the fit method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to fit if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to fit.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Added in version 1.3.

Metadata routing for sample_weight parameter in fit.

Set the parameters of this estimator.

The method works on simple estimators as well as on nested objects (such as Pipeline). The latter have parameters of the form <component>__<parameter> so that it’s possible to update each component of a nested object.

Estimator parameters.

Configure whether metadata should be requested to be passed to the score method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to score if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to score.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Added in version 1.3.

Metadata routing for sample_weight parameter in score.

L1-based models for Sparse Signals

Release Highlights for scikit-learn 1.8

**Examples:**

Example 1 (unknown):
```unknown
1 / (2 * n_samples) * ||y - Xw||^2_2
+ alpha * l1_ratio * ||w||_1
+ 0.5 * alpha * (1 - l1_ratio) * ||w||^2_2
```

Example 2 (unknown):
```unknown
a * L1 + b * L2
```

Example 3 (unknown):
```unknown
alpha = a + b and l1_ratio = a / (a + b).
```

Example 4 (sql):
```sql
>>> from sklearn.linear_model import ElasticNetCV
>>> from sklearn.datasets import make_regression
```

---

## mutual_info_score#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mutual_info_score.html

**Contents:**
- mutual_info_score#
- Gallery examples#

Mutual Information between two clusterings.

The Mutual Information is a measure of the similarity between two labels of the same data. Where \(|U_i|\) is the number of the samples in cluster \(U_i\) and \(|V_j|\) is the number of the samples in cluster \(V_j\), the Mutual Information between clusterings \(U\) and \(V\) is given as:

This metric is independent of the absolute values of the labels: a permutation of the class or cluster label values won’t change the score value in any way.

This metric is furthermore symmetric: switching \(U\) (i.e label_true) with \(V\) (i.e. label_pred) will return the same score value. This can be useful to measure the agreement of two independent label assignments strategies on the same dataset when the real ground truth is not known.

Read more in the User Guide.

A clustering of the data into disjoint subsets, called \(U\) in the above formula.

A clustering of the data into disjoint subsets, called \(V\) in the above formula.

A contingency matrix given by the contingency_matrix function. If value is None, it will be computed, otherwise the given value is used, with labels_true and labels_pred ignored.

Mutual information, a non-negative value, measured in nats using the natural logarithm.

Adjusted against chance Mutual Information.

Normalized Mutual Information.

The logarithm used is the natural logarithm (base-e).

Adjustment for chance in clustering performance evaluation

**Examples:**

Example 1 (sql):
```sql
>>> from sklearn.metrics import mutual_info_score
>>> labels_true = [0, 1, 1, 0, 1, 0]
>>> labels_pred = [0, 1, 0, 0, 1, 1]
>>> mutual_info_score(labels_true, labels_pred)
0.0566
```

---

## AffinityPropagation#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.cluster.AffinityPropagation.html

**Contents:**
- AffinityPropagation#
- Gallery examples#

Perform Affinity Propagation Clustering of data.

Read more in the User Guide.

Damping factor in the range [0.5, 1.0) is the extent to which the current value is maintained relative to incoming values (weighted 1 - damping). This in order to avoid numerical oscillations when updating these values (messages).

Maximum number of iterations.

Number of iterations with no change in the number of estimated clusters that stops the convergence.

Make a copy of input data.

Preferences for each point - points with larger values of preferences are more likely to be chosen as exemplars. The number of exemplars, ie of clusters, is influenced by the input preferences value. If the preferences are not passed as arguments, they will be set to the median of the input similarities.

Which affinity to use. At the moment ‘precomputed’ and euclidean are supported. ‘euclidean’ uses the negative squared euclidean distance between points.

Whether to be verbose.

Pseudo-random number generator to control the starting state. Use an int for reproducible results across function calls. See the Glossary.

Added in version 0.23: this parameter was previously hardcoded as 0.

Indices of cluster centers.

Cluster centers (if affinity != precomputed).

Labels of each point.

Stores the affinity matrix used in fit.

Number of iterations taken to converge.

Number of features seen during fit.

Added in version 0.24.

Names of features seen during fit. Defined only when X has feature names that are all strings.

Added in version 1.0.

Recursively merges the pair of clusters that minimally increases a given linkage distance.

Similar to AgglomerativeClustering, but recursively merges features instead of samples.

Mini-Batch K-Means clustering.

Mean shift clustering using a flat kernel.

Apply clustering to a projection of the normalized Laplacian.

The algorithmic complexity of affinity propagation is quadratic in the number of points.

When the algorithm does not converge, it will still return an array of cluster_center_indices and labels if there are any exemplars/clusters, however they may be degenerate and should be used with caution.

When fit does not converge, cluster_centers_ is still populated however it may be degenerate. In such a case, proceed with caution. If fit does not converge and fails to produce any cluster_centers_ then predict will label every sample as -1.

When all training samples have equal similarities and equal preferences, the assignment of cluster centers and labels depends on the preference. If the preference is smaller than the similarities, fit will result in a single cluster center and label 0 for every sample. Otherwise, every training sample becomes its own cluster center and is assigned a unique label.

Brendan J. Frey and Delbert Dueck, “Clustering by Passing Messages Between Data Points”, Science Feb. 2007

For an example usage, see Demo of affinity propagation clustering algorithm.

For a comparison of Affinity Propagation with other clustering algorithms, see Comparing different clustering algorithms on toy datasets

Fit the clustering from features, or affinity matrix.

Training instances to cluster, or similarities / affinities between instances if affinity='precomputed'. If a sparse feature matrix is provided, it will be converted into a sparse csr_matrix.

Not used, present here for API consistency by convention.

Returns the instance itself.

Fit clustering from features/affinity matrix; return cluster labels.

Training instances to cluster, or similarities / affinities between instances if affinity='precomputed'. If a sparse feature matrix is provided, it will be converted into a sparse csr_matrix.

Not used, present here for API consistency by convention.

Get metadata routing of this object.

Please check User Guide on how the routing mechanism works.

A MetadataRequest encapsulating routing information.

Get parameters for this estimator.

If True, will return the parameters for this estimator and contained subobjects that are estimators.

Parameter names mapped to their values.

Predict the closest cluster each sample in X belongs to.

New data to predict. If a sparse matrix is provided, it will be converted into a sparse csr_matrix.

Set the parameters of this estimator.

The method works on simple estimators as well as on nested objects (such as Pipeline). The latter have parameters of the form <component>__<parameter> so that it’s possible to update each component of a nested object.

Estimator parameters.

Demo of affinity propagation clustering algorithm

Comparing different clustering algorithms on toy datasets

**Examples:**

Example 1 (sql):
```sql
>>> from sklearn.cluster import AffinityPropagation
>>> import numpy as np
>>> X = np.array([[1, 2], [1, 4], [1, 0],
...               [4, 2], [4, 4], [4, 0]])
>>> clustering = AffinityPropagation(random_state=5).fit(X)
>>> clustering
AffinityPropagation(random_state=5)
>>> clustering.labels_
array([0, 0, 0, 1, 1, 1])
>>> clustering.predict([[0, 0], [4, 4]])
array([0, 1])
>>> clustering.cluster_centers_
array([[1, 2],
       [4, 2]])
```

---

## RidgeCV#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.RidgeCV.html

**Contents:**
- RidgeCV#
- Gallery examples#

Ridge regression with built-in cross-validation.

See glossary entry for cross-validation estimator.

By default, it performs efficient Leave-One-Out Cross-Validation.

Read more in the User Guide.

Array of alpha values to try. Regularization strength; must be a positive float. Regularization improves the conditioning of the problem and reduces the variance of the estimates. Larger values specify stronger regularization. Alpha corresponds to 1 / (2C) in other linear models such as LogisticRegression or LinearSVC. If using Leave-One-Out cross-validation, alphas must be strictly positive.

Whether to calculate the intercept for this model. If set to false, no intercept will be used in calculations (i.e. data is expected to be centered).

The scoring method to use for cross-validation. Options:

str: see String name scorers for options.

callable: a scorer callable object (e.g., function) with signature scorer(estimator, X, y). See Callable scorers for details.

None: negative mean squared error if cv is None (i.e. when using leave-one-out cross-validation), or coefficient of determination (\(R^2\)) otherwise.

Determines the cross-validation splitting strategy. Possible inputs for cv are:

None, to use the efficient Leave-One-Out cross-validation

integer, to specify the number of folds.

An iterable yielding (train, test) splits as arrays of indices.

For integer/None inputs, if y is binary or multiclass, StratifiedKFold is used, else, KFold is used.

Refer User Guide for the various cross-validation strategies that can be used here.

Flag indicating which strategy to use when performing Leave-One-Out Cross-Validation. Options are:

The ‘auto’ mode is the default and is intended to pick the cheaper option of the two depending on the shape of the training data.

Flag indicating if the cross-validation values corresponding to each alpha should be stored in the cv_results_ attribute (see below). This flag is only compatible with cv=None (i.e. using Leave-One-Out Cross-Validation).

Changed in version 1.5: Parameter name changed from store_cv_values to store_cv_results.

Flag indicating whether to optimize the alpha value (picked from the alphas parameter list) for each target separately (for multi-output settings: multiple prediction targets). When set to True, after fitting, the alpha_ attribute will contain a value for each target. When set to False, a single alpha is used for all targets.

Added in version 0.24.

Cross-validation values for each alpha (only available if store_cv_results=True and cv=None). After fit() has been called, this attribute will contain the mean squared errors if scoring is None otherwise it will contain standardized per point prediction values.

Changed in version 1.5: cv_values_ changed to cv_results_.

Independent term in decision function. Set to 0.0 if fit_intercept = False.

Estimated regularization parameter, or, if alpha_per_target=True, the estimated regularization parameter for each target.

Score of base estimator with best alpha, or, if alpha_per_target=True, a score for each target.

Added in version 0.23.

Number of features seen during fit.

Added in version 0.24.

Names of features seen during fit. Defined only when X has feature names that are all strings.

Added in version 1.0.

Classifier based on ridge regression on {-1, 1} labels.

Ridge classifier with built-in cross validation.

Fit Ridge regression model with cv.

Training data. If using GCV, will be cast to float64 if necessary.

Target values. Will be cast to X’s dtype if necessary.

Individual weights for each sample. If given a float, every sample will have the same weight.

Parameters to be passed to the underlying scorer.

Added in version 1.5: Only available if enable_metadata_routing=True, which can be set by using sklearn.set_config(enable_metadata_routing=True). See Metadata Routing User Guide for more details.

When sample_weight is provided, the selected hyperparameter may depend on whether we use leave-one-out cross-validation (cv=None) or another form of cross-validation, because only leave-one-out cross-validation takes the sample weights into account when computing the validation score.

Get metadata routing of this object.

Please check User Guide on how the routing mechanism works.

Added in version 1.5.

A MetadataRouter encapsulating routing information.

Get parameters for this estimator.

If True, will return the parameters for this estimator and contained subobjects that are estimators.

Parameter names mapped to their values.

Predict using the linear model.

Returns predicted values.

Return coefficient of determination on test data.

The coefficient of determination, \(R^2\), is defined as \((1 - \frac{u}{v})\), where \(u\) is the residual sum of squares ((y_true - y_pred)** 2).sum() and \(v\) is the total sum of squares ((y_true - y_true.mean()) ** 2).sum(). The best possible score is 1.0 and it can be negative (because the model can be arbitrarily worse). A constant model that always predicts the expected value of y, disregarding the input features, would get a \(R^2\) score of 0.0.

Test samples. For some estimators this may be a precomputed kernel matrix or a list of generic objects instead with shape (n_samples, n_samples_fitted), where n_samples_fitted is the number of samples used in the fitting for the estimator.

\(R^2\) of self.predict(X) w.r.t. y.

The \(R^2\) score used when calling score on a regressor uses multioutput='uniform_average' from version 0.23 to keep consistent with default value of r2_score. This influences the score method of all the multioutput regressors (except for MultiOutputRegressor).

Configure whether metadata should be requested to be passed to the fit method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to fit if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to fit.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Added in version 1.3.

Metadata routing for sample_weight parameter in fit.

Set the parameters of this estimator.

The method works on simple estimators as well as on nested objects (such as Pipeline). The latter have parameters of the form <component>__<parameter> so that it’s possible to update each component of a nested object.

Estimator parameters.

Configure whether metadata should be requested to be passed to the score method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to score if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to score.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Added in version 1.3.

Metadata routing for sample_weight parameter in score.

Time-related feature engineering

Effect of transforming the targets in regression model

Combine predictors using stacking

Model-based and sequential feature selection

Common pitfalls in the interpretation of coefficients of linear models

Face completion with a multi-output estimators

**Examples:**

Example 1 (unknown):
```unknown
'auto' : use 'svd' if n_samples > n_features, otherwise use 'eigen'
'svd' : force use of singular value decomposition of X when X is
    dense, eigenvalue decomposition of X^T.X when X is sparse.
'eigen' : force computation via eigendecomposition of X.X^T
```

Example 2 (sql):
```sql
>>> from sklearn.datasets import load_diabetes
>>> from sklearn.linear_model import RidgeCV
>>> X, y = load_diabetes(return_X_y=True)
>>> clf = RidgeCV(alphas=[1e-3, 1e-2, 1e-1, 1]).fit(X, y)
>>> clf.score(X, y)
0.5166...
```

---

## 1.10. Decision Trees#

**URL:** https://scikit-learn.org/stable/modules/tree.html

**Contents:**
- 1.10. Decision Trees#
- 1.10.1. Classification#
- 1.10.2. Regression#
- 1.10.3. Multi-output problems#
- 1.10.4. Complexity#
- 1.10.5. Tips on practical use#
- 1.10.6. Tree algorithms: ID3, C4.5, C5.0 and CART#
- 1.10.7. Mathematical formulation#
  - 1.10.7.1. Classification criteria#
  - 1.10.7.2. Regression criteria#

Decision Trees (DTs) are a non-parametric supervised learning method used for classification and regression. The goal is to create a model that predicts the value of a target variable by learning simple decision rules inferred from the data features. A tree can be seen as a piecewise constant approximation.

For instance, in the example below, decision trees learn from data to approximate a sine curve with a set of if-then-else decision rules. The deeper the tree, the more complex the decision rules and the fitter the model.

Some advantages of decision trees are:

Simple to understand and to interpret. Trees can be visualized.

Requires little data preparation. Other techniques often require data normalization, dummy variables need to be created and blank values to be removed. Some tree and algorithm combinations support missing values.

The cost of using the tree (i.e., predicting data) is logarithmic in the number of data points used to train the tree.

Able to handle both numerical and categorical data. However, the scikit-learn implementation does not support categorical variables for now. Other techniques are usually specialized in analyzing datasets that have only one type of variable. See algorithms for more information.

Able to handle multi-output problems.

Uses a white box model. If a given situation is observable in a model, the explanation for the condition is easily explained by boolean logic. By contrast, in a black box model (e.g., in an artificial neural network), results may be more difficult to interpret.

Possible to validate a model using statistical tests. That makes it possible to account for the reliability of the model.

Performs well even if its assumptions are somewhat violated by the true model from which the data were generated.

The disadvantages of decision trees include:

Decision-tree learners can create over-complex trees that do not generalize the data well. This is called overfitting. Mechanisms such as pruning, setting the minimum number of samples required at a leaf node or setting the maximum depth of the tree are necessary to avoid this problem.

Decision trees can be unstable because small variations in the data might result in a completely different tree being generated. This problem is mitigated by using decision trees within an ensemble.

Predictions of decision trees are neither smooth nor continuous, but piecewise constant approximations as seen in the above figure. Therefore, they are not good at extrapolation.

The problem of learning an optimal decision tree is known to be NP-complete under several aspects of optimality and even for simple concepts. Consequently, practical decision-tree learning algorithms are based on heuristic algorithms such as the greedy algorithm where locally optimal decisions are made at each node. Such algorithms cannot guarantee to return the globally optimal decision tree. This can be mitigated by training multiple trees in an ensemble learner, where the features and samples are randomly sampled with replacement.

There are concepts that are hard to learn because decision trees do not express them easily, such as XOR, parity or multiplexer problems.

Decision tree learners create biased trees if some classes dominate. It is therefore recommended to balance the dataset prior to fitting with the decision tree.

DecisionTreeClassifier is a class capable of performing multi-class classification on a dataset.

As with other classifiers, DecisionTreeClassifier takes as input two arrays: an array X, sparse or dense, of shape (n_samples, n_features) holding the training samples, and an array Y of integer values, shape (n_samples,), holding the class labels for the training samples:

After being fitted, the model can then be used to predict the class of samples:

In case that there are multiple classes with the same and highest probability, the classifier will predict the class with the lowest index amongst those classes.

As an alternative to outputting a specific class, the probability of each class can be predicted, which is the fraction of training samples of the class in a leaf:

DecisionTreeClassifier is capable of both binary (where the labels are [-1, 1]) classification and multiclass (where the labels are [0, …, K-1]) classification.

Using the Iris dataset, we can construct a tree as follows:

Once trained, you can plot the tree with the plot_tree function:

We can also export the tree in Graphviz format using the export_graphviz exporter. If you use the conda package manager, the graphviz binaries and the python package can be installed with conda install python-graphviz.

Alternatively binaries for graphviz can be downloaded from the graphviz project homepage, and the Python wrapper installed from pypi with pip install graphviz.

Below is an example graphviz export of the above tree trained on the entire iris dataset; the results are saved in an output file iris.pdf:

The export_graphviz exporter also supports a variety of aesthetic options, including coloring nodes by their class (or value for regression) and using explicit variable and class names if desired. Jupyter notebooks also render these plots inline automatically:

Alternatively, the tree can also be exported in textual format with the function export_text. This method doesn’t require the installation of external libraries and is more compact:

Plot the decision surface of decision trees trained on the iris dataset

Understanding the decision tree structure

Decision trees can also be applied to regression problems, using the DecisionTreeRegressor class.

As in the classification setting, the fit method will take as argument arrays X and y, only that in this case y is expected to have floating point values instead of integer values:

Decision Tree Regression

A multi-output problem is a supervised learning problem with several outputs to predict, that is when Y is a 2d array of shape (n_samples, n_outputs).

When there is no correlation between the outputs, a very simple way to solve this kind of problem is to build n independent models, i.e. one for each output, and then to use those models to independently predict each one of the n outputs. However, because it is likely that the output values related to the same input are themselves correlated, an often better way is to build a single model capable of predicting simultaneously all n outputs. First, it requires lower training time since only a single estimator is built. Second, the generalization accuracy of the resulting estimator may often be increased.

With regard to decision trees, this strategy can readily be used to support multi-output problems. This requires the following changes:

Store n output values in leaves, instead of 1;

Use splitting criteria that compute the average reduction across all n outputs.

This module offers support for multi-output problems by implementing this strategy in both DecisionTreeClassifier and DecisionTreeRegressor. If a decision tree is fit on an output array Y of shape (n_samples, n_outputs) then the resulting estimator will:

Output n_output values upon predict;

Output a list of n_output arrays of class probabilities upon predict_proba.

The use of multi-output trees for regression is demonstrated in Decision Tree Regression. In this example, the input X is a single real value and the outputs Y are the sine and cosine of X.

The use of multi-output trees for classification is demonstrated in Face completion with a multi-output estimators. In this example, the inputs X are the pixels of the upper half of faces and the outputs Y are the pixels of the lower half of those faces.

Face completion with a multi-output estimators

M. Dumont et al, Fast multi-class image annotation with random subwindows and multiple output randomized trees, International Conference on Computer Vision Theory and Applications 2009

The following table shows the worst-case complexity estimates for a balanced binary tree:

\(\mathcal{O}(n_{features} \, n^2_{samples} \log(n_{samples}))\)

\(\mathcal{O}(\log(n_{samples}))\)

\(\mathcal{O}(n_{features} \, n^2_{samples})\)

\(\mathcal{O}(\log(n_{samples}))\)

In general, the training cost to construct a balanced binary tree at each node is

The first term is the cost of sorting \(n_{samples}\) repeated for \(n_{features}\). The second term is the linear scan over candidate split points to find the feature that offers the largest reduction in the impurity criterion. The latter is sub-leading for the greedy splitter strategy “best”, and is therefore typically discarded.

Regardless of the splitting strategy, after summing the cost over all internal nodes, the total complexity scales linearly with \(n_{nodes}=n_{leaves}-1\), which is \(\mathcal{O}(n_{samples})\) in the worst-case complexity, that is, when the tree is grown until each sample ends up in its own leaf.

Many implementations such as scikit-learn use efficient caching tricks to keep track of the general order of indices at each node such that the features do not need to be re-sorted at each node; hence, the time complexity of these implementations is just \(\mathcal{O}(n_{features}n_{samples}\log(n_{samples}))\) [1].

Inference cost is independent of the splitter strategy. It depends only on the tree depth, \(\mathcal{O}(\text{depth})\). In an approximately balanced binary tree, each split halves the data, and then the number of such halvings grows with the depth as powers of two. If this process continues until each sample is isolated in its own leaf, the resulting depth is \(\mathcal{O}(\log(n_{samples}))\).

S. Raschka, Stat 451: Machine learning lecture notes. University of Wisconsin-Madison (2020).

Decision trees tend to overfit on data with a large number of features. Getting the right ratio of samples to number of features is important, since a tree with few samples in high dimensional space is very likely to overfit.

Consider performing dimensionality reduction (PCA, ICA, or Feature selection) beforehand to give your tree a better chance of finding features that are discriminative.

Understanding the decision tree structure will help in gaining more insights about how the decision tree makes predictions, which is important for understanding the important features in the data.

Visualize your tree as you are training by using the export function. Use max_depth=3 as an initial tree depth to get a feel for how the tree is fitting to your data, and then increase the depth.

Remember that the number of samples required to populate the tree doubles for each additional level the tree grows to. Use max_depth to control the size of the tree to prevent overfitting.

Use min_samples_split or min_samples_leaf to ensure that multiple samples inform every decision in the tree, by controlling which splits will be considered. A very small number will usually mean the tree will overfit, whereas a large number will prevent the tree from learning the data. Try min_samples_leaf=5 as an initial value. If the sample size varies greatly, a float number can be used as percentage in these two parameters. While min_samples_split can create arbitrarily small leaves, min_samples_leaf guarantees that each leaf has a minimum size, avoiding low-variance, over-fit leaf nodes in regression problems. For classification with few classes, min_samples_leaf=1 is often the best choice.

Note that min_samples_split considers samples directly and independent of sample_weight, if provided (e.g. a node with m weighted samples is still treated as having exactly m samples). Consider min_weight_fraction_leaf or min_impurity_decrease if accounting for sample weights is required at splits.

Balance your dataset before training to prevent the tree from being biased toward the classes that are dominant. Class balancing can be done by sampling an equal number of samples from each class, or preferably by normalizing the sum of the sample weights (sample_weight) for each class to the same value. Also note that weight-based pre-pruning criteria, such as min_weight_fraction_leaf, will then be less biased toward dominant classes than criteria that are not aware of the sample weights, like min_samples_leaf.

If the samples are weighted, it will be easier to optimize the tree structure using weight-based pre-pruning criterion such as min_weight_fraction_leaf, which ensures that leaf nodes contain at least a fraction of the overall sum of the sample weights.

All decision trees use np.float32 arrays internally. If training data is not in this format, a copy of the dataset will be made.

If the input matrix X is very sparse, it is recommended to convert to sparse csc_matrix before calling fit and sparse csr_matrix before calling predict. Training time can be orders of magnitude faster for a sparse matrix input compared to a dense matrix when features have zero values in most of the samples.

What are all the various decision tree algorithms and how do they differ from each other? Which one is implemented in scikit-learn?

ID3 (Iterative Dichotomiser 3) was developed in 1986 by Ross Quinlan. The algorithm creates a multiway tree, finding for each node (i.e. in a greedy manner) the categorical feature that will yield the largest information gain for categorical targets. Trees are grown to their maximum size and then a pruning step is usually applied to improve the ability of the tree to generalize to unseen data.

C4.5 is the successor to ID3 and removed the restriction that features must be categorical by dynamically defining a discrete attribute (based on numerical variables) that partitions the continuous attribute value into a discrete set of intervals. C4.5 converts the trained trees (i.e. the output of the ID3 algorithm) into sets of if-then rules. The accuracy of each rule is then evaluated to determine the order in which they should be applied. Pruning is done by removing a rule’s precondition if the accuracy of the rule improves without it.

C5.0 is Quinlan’s latest version release under a proprietary license. It uses less memory and builds smaller rulesets than C4.5 while being more accurate.

CART (Classification and Regression Trees) is very similar to C4.5, but it differs in that it supports numerical target variables (regression) and does not compute rule sets. CART constructs binary trees using the feature and threshold that yield the largest information gain at each node.

scikit-learn uses an optimized version of the CART algorithm; however, the scikit-learn implementation does not support categorical variables for now.

Given training vectors \(x_i \in R^n\), i=1,…, l and a label vector \(y \in R^l\), a decision tree recursively partitions the feature space such that the samples with the same labels or similar target values are grouped together.

Let the data at node \(m\) be represented by \(Q_m\) with \(n_m\) samples. For each candidate split \(\theta = (j, t_m)\) consisting of a feature \(j\) and threshold \(t_m\), partition the data into \(Q_m^{left}(\theta)\) and \(Q_m^{right}(\theta)\) subsets

The quality of a candidate split of node \(m\) is then computed using an impurity function or loss function \(H()\), the choice of which depends on the task being solved (classification or regression)

Select the parameters that minimises the impurity

The strategy to choose the split at each node is controlled by the splitter parameter:

With the best splitter (default, splitter='best'), \(\theta^*\) is found by performing a greedy exhaustive search over all available features and all possible thresholds \(t_m\) (i.e. midpoints between sorted, distinct feature values), selecting the pair that exactly minimizes \(G(Q_m, \theta)\).

With the random splitter (splitter='random'), \(\theta^*\) is found by sampling a single random candidate threshold for each available feature. This performs a stochastic approximation of the greedy search, effectively reducing computation time (see Complexity).

After choosing the optimal split \(\theta^*\) at node \(m\), the same splitting procedure is then applied recursively to each partition \(Q_m^{left}(\theta^*)\) and \(Q_m^{right}(\theta^*)\) until a stopping condition is reached, such as:

the maximum allowable depth is reached (max_depth);

\(n_m\) is smaller than min_samples_split;

the impurity decrease for this split is smaller than min_impurity_decrease.

See the respective estimator docstring for other stopping conditions.

If a target is a classification outcome taking on values 0,1,…,K-1, for node \(m\), let

be the proportion of class k observations in node \(m\). If \(m\) is a terminal node, predict_proba for this region is set to \(p_{mk}\). Common measures of impurity are the following.

The entropy criterion computes the Shannon entropy of the possible classes. It takes the class frequencies of the training data points that reached a given leaf \(m\) as their probability. Using the Shannon entropy as tree node splitting criterion is equivalent to minimizing the log loss (also known as cross-entropy and multinomial deviance) between the true labels \(y_i\) and the probabilistic predictions \(T_k(x_i)\) of the tree model \(T\) for class \(k\).

To see this, first recall that the log loss of a tree model \(T\) computed on a dataset \(D\) is defined as follows:

where \(D\) is a training dataset of \(n\) pairs \((x_i, y_i)\).

In a classification tree, the predicted class probabilities within leaf nodes are constant, that is: for all \((x_i, y_i) \in Q_m\), one has: \(T_k(x_i) = p_{mk}\) for each class \(k\).

This property makes it possible to rewrite \(\mathrm{LL}(D, T)\) as the sum of the Shannon entropies computed for each leaf of \(T\) weighted by the number of training data points that reached each leaf:

If the target is a continuous value, then for node \(m\), common criteria to minimize as for determining locations for future splits are Mean Squared Error (MSE or L2 error), Poisson deviance as well as Mean Absolute Error (MAE or L1 error). MSE and Poisson deviance both set the predicted value of terminal nodes to the learned mean value \(\bar{y}_m\) of the node whereas the MAE sets the predicted value of terminal nodes to the median \(median(y)_m\).

Mean Poisson deviance:

Setting criterion="poisson" might be a good choice if your target is a count or a frequency (count per some unit). In any case, \(y >= 0\) is a necessary condition to use this criterion. For performance reasons the actual implementation minimizes the half mean poisson deviance, i.e. the mean poisson deviance divided by 2.

Note that it is 3–6× slower to fit than the MSE criterion as of version 1.8.

DecisionTreeClassifier, DecisionTreeRegressor have built-in support for missing values using splitter='best', where the splits are determined in a greedy fashion. ExtraTreeClassifier, and ExtraTreeRegressor have built-in support for missing values for splitter='random', where the splits are determined randomly. For more details on how the splitter differs on non-missing values, see the Forest section.

The criterion supported when there are missing values are 'gini', 'entropy', or 'log_loss', for classification or 'squared_error', 'friedman_mse', or 'poisson' for regression.

First we will describe how DecisionTreeClassifier, DecisionTreeRegressor handle missing-values in the data.

For each potential threshold on the non-missing data, the splitter will evaluate the split with all the missing values going to the left node or the right node.

Decisions are made as follows:

By default when predicting, the samples with missing values are classified with the class used in the split found during training:

If the criterion evaluation is the same for both nodes, then the tie for missing value at predict time is broken by going to the right node. The splitter also checks the split where all the missing values go to one child and non-missing values go to the other:

If no missing values are seen during training for a given feature, then during prediction missing values are mapped to the child with the most samples:

ExtraTreeClassifier, and ExtraTreeRegressor handle missing values in a slightly different way. When splitting a node, a random threshold will be chosen to split the non-missing values on. Then the non-missing values will be sent to the left and right child based on the randomly selected threshold, while the missing values will also be randomly sent to the left or right child. This is repeated for every feature considered at each split. The best split among these is chosen.

During prediction, the treatment of missing-values is the same as that of the decision tree:

By default when predicting, the samples with missing values are classified with the class used in the split found during training.

If no missing values are seen during training for a given feature, then during prediction missing values are mapped to the child with the most samples.

Minimal cost-complexity pruning is an algorithm used to prune a tree to avoid over-fitting, described in Chapter 3 of [BRE]. This algorithm is parameterized by \(\alpha\ge0\) known as the complexity parameter. The complexity parameter is used to define the cost-complexity measure, \(R_\alpha(T)\) of a given tree \(T\):

where \(|\widetilde{T}|\) is the number of terminal nodes in \(T\) and \(R(T)\) is traditionally defined as the total misclassification rate of the terminal nodes. Alternatively, scikit-learn uses the total sample weighted impurity of the terminal nodes for \(R(T)\). As shown above, the impurity of a node depends on the criterion. Minimal cost-complexity pruning finds the subtree of \(T\) that minimizes \(R_\alpha(T)\).

The cost complexity measure of a single node is \(R_\alpha(t)=R(t)+\alpha\). The branch, \(T_t\), is defined to be a tree where node \(t\) is its root. In general, the impurity of a node is greater than the sum of impurities of its terminal nodes, \(R(T_t)<R(t)\). However, the cost complexity measure of a node, \(t\), and its branch, \(T_t\), can be equal depending on \(\alpha\). We define the effective \(\alpha\) of a node to be the value where they are equal, \(R_\alpha(T_t)=R_\alpha(t)\) or \(\alpha_{eff}(t)=\frac{R(t)-R(T_t)}{|T|-1}\). A non-terminal node with the smallest value of \(\alpha_{eff}\) is the weakest link and will be pruned. This process stops when the pruned tree’s minimal \(\alpha_{eff}\) is greater than the ccp_alpha parameter.

Post pruning decision trees with cost complexity pruning

L. Breiman, J. Friedman, R. Olshen, and C. Stone. Classification and Regression Trees. Wadsworth, Belmont, CA, 1984.

https://en.wikipedia.org/wiki/Decision_tree_learning

https://en.wikipedia.org/wiki/Predictive_analytics

J.R. Quinlan. C4. 5: programs for machine learning. Morgan Kaufmann, 1993.

T. Hastie, R. Tibshirani and J. Friedman. Elements of Statistical Learning, Springer, 2009.

**Examples:**

Example 1 (python):
```python
>>> from sklearn import tree
>>> X = [[0, 0], [1, 1]]
>>> Y = [0, 1]
>>> clf = tree.DecisionTreeClassifier()
>>> clf = clf.fit(X, Y)
```

Example 2 (unknown):
```unknown
>>> clf.predict([[2., 2.]])
array([1])
```

Example 3 (unknown):
```unknown
>>> clf.predict_proba([[2., 2.]])
array([[0., 1.]])
```

Example 4 (python):
```python
>>> from sklearn.datasets import load_iris
>>> from sklearn import tree
>>> iris = load_iris()
>>> X, y = iris.data, iris.target
>>> clf = tree.DecisionTreeClassifier()
>>> clf = clf.fit(X, y)
```

---

## homogeneity_score#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.metrics.homogeneity_score.html

**Contents:**
- homogeneity_score#
- Gallery examples#

Homogeneity metric of a cluster labeling given a ground truth.

A clustering result satisfies homogeneity if all of its clusters contain only data points which are members of a single class.

This metric is independent of the absolute values of the labels: a permutation of the class or cluster label values won’t change the score value in any way.

This metric is not symmetric: switching label_true with label_pred will return the completeness_score which will be different in general.

Read more in the User Guide.

Ground truth class labels to be used as a reference.

Cluster labels to evaluate.

Score between 0.0 and 1.0. 1.0 stands for perfectly homogeneous labeling.

Completeness metric of cluster labeling.

V-Measure (NMI with arithmetic mean option).

Andrew Rosenberg and Julia Hirschberg, 2007. V-Measure: A conditional entropy-based external cluster evaluation measure

Perfect labelings are homogeneous:

Non-perfect labelings that further split classes into more clusters can be perfectly homogeneous:

Clusters that include samples from different classes do not make for an homogeneous labeling:

Demo of affinity propagation clustering algorithm

Demo of DBSCAN clustering algorithm

A demo of K-Means clustering on the handwritten digits data

Clustering text documents using k-means

**Examples:**

Example 1 (sql):
```sql
>>> from sklearn.metrics.cluster import homogeneity_score
>>> homogeneity_score([0, 0, 1, 1], [1, 1, 0, 0])
1.0
```

Example 2 (unknown):
```unknown
>>> print("%.6f" % homogeneity_score([0, 0, 1, 1], [0, 0, 1, 2]))
1.000000
>>> print("%.6f" % homogeneity_score([0, 0, 1, 1], [0, 1, 2, 3]))
1.000000
```

Example 3 (unknown):
```unknown
>>> print("%.6f" % homogeneity_score([0, 0, 1, 1], [0, 1, 0, 1]))
0.0...
>>> print("%.6f" % homogeneity_score([0, 0, 1, 1], [0, 0, 0, 0]))
0.0...
```

---

## 3.5. Validation curves: plotting scores to evaluate models#

**URL:** https://scikit-learn.org/stable/modules/learning_curve.html

**Contents:**
- 3.5. Validation curves: plotting scores to evaluate models#
- 3.5.1. Validation curve#
- 3.5.2. Learning curve#

Every estimator has its advantages and drawbacks. Its generalization error can be decomposed in terms of bias, variance and noise. The bias of an estimator is its average error for different training sets. The variance of an estimator indicates how sensitive it is to varying training sets. Noise is a property of the data.

In the following plot, we see a function \(f(x) = \cos (\frac{3}{2} \pi x)\) and some noisy samples from that function. We use three different estimators to fit the function: linear regression with polynomial features of degree 1, 4 and 15. We see that the first estimator can at best provide only a poor fit to the samples and the true function because it is too simple (high bias), the second estimator approximates it almost perfectly and the last estimator approximates the training data perfectly but does not fit the true function very well, i.e. it is very sensitive to varying training data (high variance).

Bias and variance are inherent properties of estimators and we usually have to select learning algorithms and hyperparameters so that both bias and variance are as low as possible (see Bias-variance dilemma). Another way to reduce the variance of a model is to use more training data. However, you should only collect more training data if the true function is too complex to be approximated by an estimator with a lower variance.

In the simple one-dimensional problem that we have seen in the example it is easy to see whether the estimator suffers from bias or variance. However, in high-dimensional spaces, models can become very difficult to visualize. For this reason, it is often helpful to use the tools described below.

Underfitting vs. Overfitting

Effect of model regularization on training and test error

Plotting Learning Curves and Checking Models’ Scalability

To validate a model we need a scoring function (see Metrics and scoring: quantifying the quality of predictions), for example accuracy for classifiers. The proper way of choosing multiple hyperparameters of an estimator is of course grid search or similar methods (see Tuning the hyper-parameters of an estimator) that select the hyperparameter with the maximum score on a validation set or multiple validation sets. Note that if we optimize the hyperparameters based on a validation score the validation score is biased and not a good estimate of the generalization any longer. To get a proper estimate of the generalization we have to compute the score on another test set.

However, it is sometimes helpful to plot the influence of a single hyperparameter on the training score and the validation score to find out whether the estimator is overfitting or underfitting for some hyperparameter values.

The function validation_curve can help in this case:

If you intend to plot the validation curves only, the class ValidationCurveDisplay is more direct than using matplotlib manually on the results of a call to validation_curve. You can use the method from_estimator similarly to validation_curve to generate and plot the validation curve:

If the training score and the validation score are both low, the estimator will be underfitting. If the training score is high and the validation score is low, the estimator is overfitting and otherwise it is working very well. A low training score and a high validation score is usually not possible.

A learning curve shows the validation and training score of an estimator for varying numbers of training samples. It is a tool to find out how much we benefit from adding more training data and whether the estimator suffers more from a variance error or a bias error. Consider the following example where we plot the learning curve of a naive Bayes classifier and an SVM.

For the naive Bayes, both the validation score and the training score converge to a value that is quite low with increasing size of the training set. Thus, we will probably not benefit much from more training data.

In contrast, for small amounts of data, the training score of the SVM is much greater than the validation score. Adding more training samples will most likely increase generalization.

We can use the function learning_curve to generate the values that are required to plot such a learning curve (number of samples that have been used, the average scores on the training sets and the average scores on the validation sets):

If you intend to plot the learning curves only, the class LearningCurveDisplay will be easier to use. You can use the method from_estimator similarly to learning_curve to generate and plot the learning curve:

See Plotting Learning Curves and Checking Models’ Scalability for an example of using learning curves to check the scalability of a predictive model.

**Examples:**

Example 1 (sql):
```sql
>>> import numpy as np
>>> from sklearn.model_selection import validation_curve
>>> from sklearn.datasets import load_iris
>>> from sklearn.svm import SVC

>>> np.random.seed(0)
>>> X, y = load_iris(return_X_y=True)
>>> indices = np.arange(y.shape[0])
>>> np.random.shuffle(indices)
>>> X, y = X[indices], y[indices]

>>> train_scores, valid_scores = validation_curve(
...     SVC(kernel="linear"), X, y, param_name="C", param_range=np.logspace(-7, 3, 3),
... )
>>> train_scores
array([[0.90, 0.94, 0.91, 0.89, 0.92],
       [0.9 , 0.92, 0.93, 0.92, 0.93],
       [0.97, 1   , 0.98, 0.97, 0.99]])
>>> valid_scores
array([[0.9, 0.9 , 0.9 , 0.96, 0.9 ],
       [0.9, 0.83, 0.96, 0.96, 0.93],
       [1. , 0.93, 1   , 1   , 0.9 ]])
```

Example 2 (sql):
```sql
from sklearn.datasets import load_iris
from sklearn.model_selection import ValidationCurveDisplay
from sklearn.svm import SVC
from sklearn.utils import shuffle
X, y = load_iris(return_X_y=True)
X, y = shuffle(X, y, random_state=0)
ValidationCurveDisplay.from_estimator(
   SVC(kernel="linear"), X, y, param_name="C", param_range=np.logspace(-7, 3, 10)
)
```

Example 3 (sql):
```sql
>>> from sklearn.model_selection import learning_curve
>>> from sklearn.svm import SVC

>>> train_sizes, train_scores, valid_scores = learning_curve(
...     SVC(kernel='linear'), X, y, train_sizes=[50, 80, 110], cv=5)
>>> train_sizes
array([ 50, 80, 110])
>>> train_scores
array([[0.98, 0.98 , 0.98, 0.98, 0.98],
       [0.98, 1.   , 0.98, 0.98, 0.98],
       [0.98, 1.   , 0.98, 0.98, 0.99]])
>>> valid_scores
array([[1. ,  0.93,  1. ,  1. ,  0.96],
       [1. ,  0.96,  1. ,  1. ,  0.96],
       [1. ,  0.96,  1. ,  1. ,  0.96]])
```

Example 4 (sql):
```sql
from sklearn.datasets import load_iris
from sklearn.model_selection import LearningCurveDisplay
from sklearn.svm import SVC
from sklearn.utils import shuffle
X, y = load_iris(return_X_y=True)
X, y = shuffle(X, y, random_state=0)
LearningCurveDisplay.from_estimator(
   SVC(kernel="linear"), X, y, train_sizes=[50, 80, 110], cv=5)
```

---

## OneVsOneClassifier#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.multiclass.OneVsOneClassifier.html

**Contents:**
- OneVsOneClassifier#
- Gallery examples#

One-vs-one multiclass strategy.

This strategy consists in fitting one classifier per class pair. At prediction time, the class which received the most votes is selected. Since it requires to fit n_classes * (n_classes - 1) / 2 classifiers, this method is usually slower than one-vs-the-rest, due to its O(n_classes^2) complexity. However, this method may be advantageous for algorithms such as kernel algorithms which don’t scale well with n_samples. This is because each individual learning problem only involves a small subset of the data whereas, with one-vs-the-rest, the complete dataset is used n_classes times.

Read more in the User Guide.

A regressor or a classifier that implements fit. When a classifier is passed, decision_function will be used in priority and it will fallback to predict_proba if it is not available. When a regressor is passed, predict is used.

The number of jobs to use for the computation: the n_classes * ( n_classes - 1) / 2 OVO problems are computed in parallel.

None means 1 unless in a joblib.parallel_backend context. -1 means using all processors. See Glossary for more details.

Estimators used for predictions.

Array containing labels.

Indices of samples used when training the estimators. None when estimator’s pairwise tag is False.

Number of features seen during fit.

Added in version 0.24.

Names of features seen during fit. Defined only when X has feature names that are all strings.

Added in version 1.0.

One-vs-all multiclass strategy.

(Error-Correcting) Output-Code multiclass strategy.

Decision function for the OneVsOneClassifier.

The decision values for the samples are computed by adding the normalized sum of pair-wise classification confidence levels to the votes in order to disambiguate between the decision values when the votes for all the classes are equal leading to a tie.

Result of calling decision_function on the final estimator.

Changed in version 0.19: output shape changed to (n_samples,) to conform to scikit-learn conventions for binary classification.

Fit underlying estimators.

Parameters passed to the estimator.fit method of each sub-estimator.

Added in version 1.4: Only available if enable_metadata_routing=True. See Metadata Routing User Guide for more details.

The fitted underlying estimator.

Get metadata routing of this object.

Please check User Guide on how the routing mechanism works.

Added in version 1.4.

A MetadataRouter encapsulating routing information.

Get parameters for this estimator.

If True, will return the parameters for this estimator and contained subobjects that are estimators.

Parameter names mapped to their values.

Partially fit underlying estimators.

Should be used when memory is inefficient to train all data. Chunks of data can be passed in several iteration, where the first call should have an array of all target variables.

Classes across all calls to partial_fit. Can be obtained via np.unique(y_all), where y_all is the target vector of the entire dataset. This argument is only required in the first call of partial_fit and can be omitted in the subsequent calls.

Parameters passed to the estimator.partial_fit method of each sub-estimator.

Added in version 1.4: Only available if enable_metadata_routing=True. See Metadata Routing User Guide for more details.

The partially fitted underlying estimator.

Estimate the best class label for each sample in X.

This is implemented as argmax(decision_function(X), axis=1) which will return the label of the class with most votes by estimators predicting the outcome of a decision for each possible class pair.

Predicted multi-class targets.

Return accuracy on provided data and labels.

In multi-label classification, this is the subset accuracy which is a harsh metric since you require for each sample that each label set be correctly predicted.

Mean accuracy of self.predict(X) w.r.t. y.

Set the parameters of this estimator.

The method works on simple estimators as well as on nested objects (such as Pipeline). The latter have parameters of the form <component>__<parameter> so that it’s possible to update each component of a nested object.

Estimator parameters.

Configure whether metadata should be requested to be passed to the partial_fit method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to partial_fit if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to partial_fit.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Added in version 1.3.

Metadata routing for classes parameter in partial_fit.

Configure whether metadata should be requested to be passed to the score method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to score if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to score.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Added in version 1.3.

Metadata routing for sample_weight parameter in score.

Overview of multiclass training meta-estimators

**Examples:**

Example 1 (sql):
```sql
>>> from sklearn.datasets import load_iris
>>> from sklearn.model_selection import train_test_split
>>> from sklearn.multiclass import OneVsOneClassifier
>>> from sklearn.svm import LinearSVC
>>> X, y = load_iris(return_X_y=True)
>>> X_train, X_test, y_train, y_test = train_test_split(
...     X, y, test_size=0.33, shuffle=True, random_state=0)
>>> clf = OneVsOneClassifier(
...     LinearSVC(random_state=0)).fit(X_train, y_train)
>>> clf.predict(X_test[:10])
array([2, 1, 0, 2, 0, 2, 0, 1, 1, 1])
```

---

## Sum#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.gaussian_process.kernels.Sum.html

**Contents:**
- Sum#

The Sum kernel takes two kernels \(k_1\) and \(k_2\) and combines them via

Note that the __add__ magic method is overridden, so Sum(RBF(), RBF()) is equivalent to using the + operator with RBF() + RBF().

Read more in the User Guide.

Added in version 0.18.

The first base-kernel of the sum-kernel

The second base-kernel of the sum-kernel

Return the kernel k(X, Y) and optionally its gradient.

Left argument of the returned kernel k(X, Y)

Right argument of the returned kernel k(X, Y). If None, k(X, X) is evaluated instead.

Determines whether the gradient with respect to the log of the kernel hyperparameter is computed.

The gradient of the kernel k(X, X) with respect to the log of the hyperparameter of the kernel. Only returned when eval_gradient is True.

Returns the log-transformed bounds on the theta.

The log-transformed bounds on the kernel’s hyperparameters theta

Returns a clone of self with given hyperparameters theta.

Returns the diagonal of the kernel k(X, X).

The result of this method is identical to np.diag(self(X)); however, it can be evaluated more efficiently since only the diagonal is evaluated.

Argument to the kernel.

Diagonal of kernel k(X, X)

Get parameters of this kernel.

If True, will return the parameters for this estimator and contained subobjects that are estimators.

Parameter names mapped to their values.

Returns a list of all hyperparameter.

Returns whether the kernel is stationary.

Returns the number of non-fixed hyperparameters of the kernel.

Returns whether the kernel is stationary.

Set the parameters of this kernel.

The method works on simple kernels as well as on nested kernels. The latter have parameters of the form <component>__<parameter> so that it’s possible to update each component of a nested object.

Returns the (flattened, log-transformed) non-fixed hyperparameters.

Note that theta are typically the log-transformed values of the kernel’s hyperparameters as this representation of the search space is more amenable for hyperparameter search, as hyperparameters like length-scales naturally live on a log-scale.

The non-fixed, log-transformed hyperparameters of the kernel

**Examples:**

Example 1 (sql):
```sql
>>> from sklearn.datasets import make_friedman2
>>> from sklearn.gaussian_process import GaussianProcessRegressor
>>> from sklearn.gaussian_process.kernels import RBF, Sum, ConstantKernel
>>> X, y = make_friedman2(n_samples=500, noise=0, random_state=0)
>>> kernel = Sum(ConstantKernel(2), RBF())
>>> gpr = GaussianProcessRegressor(kernel=kernel,
...         random_state=0).fit(X, y)
>>> gpr.score(X, y)
1.0
>>> kernel
1.41**2 + RBF(length_scale=1)
```

---

## r_regression#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.r_regression.html

**Contents:**
- r_regression#

Compute Pearson’s r for each features and the target.

Pearson’s r is also known as the Pearson correlation coefficient.

Linear model for testing the individual effect of each of many regressors. This is a scoring function to be used in a feature selection procedure, not a free standing feature selection procedure.

The cross correlation between each regressor and the target is computed as:

For more on usage see the User Guide.

Added in version 1.0.

Whether or not to center the data matrix X and the target vector y. By default, X and y will be centered.

Whether or not to force the Pearson’s R correlation to be finite. In the particular case where some features in X or the target y are constant, the Pearson’s R correlation is not defined. When force_finite=False, a correlation of np.nan is returned to acknowledge this case. When force_finite=True, this value will be forced to a minimal correlation of 0.0.

Added in version 1.1.

Pearson’s R correlation coefficients of features.

Univariate linear regression tests returning f-statistic and p-values.

Mutual information for a continuous target.

ANOVA F-value between label/feature for classification tasks.

Chi-squared stats of non-negative features for classification tasks.

**Examples:**

Example 1 (unknown):
```unknown
E[(X[:, i] - mean(X[:, i])) * (y - mean(y))] / (std(X[:, i]) * std(y))
```

Example 2 (sql):
```sql
>>> from sklearn.datasets import make_regression
>>> from sklearn.feature_selection import r_regression
>>> X, y = make_regression(
...     n_samples=50, n_features=3, n_informative=1, noise=1e-4, random_state=42
... )
>>> r_regression(X, y)
array([-0.157,  1.        , -0.229])
```

---

## 

**URL:** https://scikit-learn.org/stable/_sources/modules/svm.rst.txt

---

## FrozenEstimator#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.frozen.FrozenEstimator.html

**Contents:**
- FrozenEstimator#
- Gallery examples#

Estimator that wraps a fitted estimator to prevent re-fitting.

This meta-estimator takes an estimator and freezes it, in the sense that calling fit on it has no effect. fit_predict and fit_transform are also disabled. All other methods are delegated to the original estimator and original estimator’s attributes are accessible as well.

This is particularly useful when you have a fitted or a pre-trained model as a transformer in a pipeline, and you’d like pipeline.fit to have no effect on this step.

The estimator which is to be kept frozen.

No similar entry in the scikit-learn documentation.

As a frozen estimator, calling fit has no effect.

Additional positional arguments. Ignored, but present for API compatibility with self.estimator.

Additional keyword arguments. Ignored, but present for API compatibility with self.estimator.

Returns the instance itself.

Get metadata routing of this object.

Please check User Guide on how the routing mechanism works.

A MetadataRequest encapsulating routing information.

Get parameters for this estimator.

Returns a {"estimator": estimator} dict. The parameters of the inner estimator are not included.

Parameter names mapped to their values.

Set the parameters of this estimator.

The only valid key here is estimator. You cannot set the parameters of the inner estimator.

Estimator parameters.

Probability Calibration for 3-class classification

Examples of Using FrozenEstimator

Post-tuning the decision threshold for cost-sensitive learning

Release Highlights for scikit-learn 1.6

**Examples:**

Example 1 (sql):
```sql
>>> from sklearn.datasets import make_classification
>>> from sklearn.frozen import FrozenEstimator
>>> from sklearn.linear_model import LogisticRegression
>>> X, y = make_classification(random_state=0)
>>> clf = LogisticRegression(random_state=0).fit(X, y)
>>> frozen_clf = FrozenEstimator(clf)
>>> frozen_clf.fit(X, y)  # No-op
FrozenEstimator(estimator=LogisticRegression(random_state=0))
>>> frozen_clf.predict(X)  # Predictions from `clf.predict`
array(...)
```

---

## 

**URL:** https://scikit-learn.org/stable/_sources/modules/lda_qda.rst.txt

---

## 2.9. Neural network models (unsupervised)#

**URL:** https://scikit-learn.org/stable/modules/neural_networks_unsupervised.html

**Contents:**
- 2.9. Neural network models (unsupervised)#
- 2.9.1. Restricted Boltzmann machines#
  - 2.9.1.1. Graphical model and parametrization#
  - 2.9.1.2. Bernoulli Restricted Boltzmann machines#
  - 2.9.1.3. Stochastic Maximum Likelihood learning#

Restricted Boltzmann machines (RBM) are unsupervised nonlinear feature learners based on a probabilistic model. The features extracted by an RBM or a hierarchy of RBMs often give good results when fed into a linear classifier such as a linear SVM or a perceptron.

The model makes assumptions regarding the distribution of inputs. At the moment, scikit-learn only provides BernoulliRBM, which assumes the inputs are either binary values or values between 0 and 1, each encoding the probability that the specific feature would be turned on.

The RBM tries to maximize the likelihood of the data using a particular graphical model. The parameter learning algorithm used (Stochastic Maximum Likelihood) prevents the representations from straying far from the input data, which makes them capture interesting regularities, but makes the model less useful for small datasets, and usually not useful for density estimation.

The method gained popularity for initializing deep neural networks with the weights of independent RBMs. This method is known as unsupervised pre-training.

Restricted Boltzmann Machine features for digit classification

The graphical model of an RBM is a fully-connected bipartite graph.

The nodes are random variables whose states depend on the state of the other nodes they are connected to. The model is therefore parameterized by the weights of the connections, as well as one intercept (bias) term for each visible and hidden unit, omitted from the image for simplicity.

The energy function measures the quality of a joint assignment:

In the formula above, \(\mathbf{b}\) and \(\mathbf{c}\) are the intercept vectors for the visible and hidden layers, respectively. The joint probability of the model is defined in terms of the energy:

The word restricted refers to the bipartite structure of the model, which prohibits direct interaction between hidden units, or between visible units. This means that the following conditional independencies are assumed:

The bipartite structure allows for the use of efficient block Gibbs sampling for inference.

In the BernoulliRBM, all units are binary stochastic units. This means that the input data should either be binary, or real-valued between 0 and 1 signifying the probability that the visible unit would turn on or off. This is a good model for character recognition, where the interest is on which pixels are active and which aren’t. For images of natural scenes it no longer fits because of background, depth and the tendency of neighbouring pixels to take the same values.

The conditional probability distribution of each unit is given by the logistic sigmoid activation function of the input it receives:

where \(\sigma\) is the logistic sigmoid function:

The training algorithm implemented in BernoulliRBM is known as Stochastic Maximum Likelihood (SML) or Persistent Contrastive Divergence (PCD). Optimizing maximum likelihood directly is infeasible because of the form of the data likelihood:

For simplicity the equation above is written for a single training example. The gradient with respect to the weights is formed of two terms corresponding to the ones above. They are usually known as the positive gradient and the negative gradient, because of their respective signs. In this implementation, the gradients are estimated over mini-batches of samples.

In maximizing the log-likelihood, the positive gradient makes the model prefer hidden states that are compatible with the observed training data. Because of the bipartite structure of RBMs, it can be computed efficiently. The negative gradient, however, is intractable. Its goal is to lower the energy of joint states that the model prefers, therefore making it stay true to the data. It can be approximated by Markov chain Monte Carlo using block Gibbs sampling by iteratively sampling each of \(v\) and \(h\) given the other, until the chain mixes. Samples generated in this way are sometimes referred as fantasy particles. This is inefficient and it is difficult to determine whether the Markov chain mixes.

The Contrastive Divergence method suggests to stop the chain after a small number of iterations, \(k\), usually even 1. This method is fast and has low variance, but the samples are far from the model distribution.

Persistent Contrastive Divergence addresses this. Instead of starting a new chain each time the gradient is needed, and performing only one Gibbs sampling step, in PCD we keep a number of chains (fantasy particles) that are updated \(k\) Gibbs steps after each weight update. This allows the particles to explore the space more thoroughly.

“A fast learning algorithm for deep belief nets”, G. Hinton, S. Osindero, Y.-W. Teh, 2006

“Training Restricted Boltzmann Machines using Approximations to the Likelihood Gradient”, T. Tieleman, 2008

---

## f_classif#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.f_classif.html

**Contents:**
- f_classif#
- Gallery examples#

Compute the ANOVA F-value for the provided sample.

Read more in the User Guide.

The set of regressors that will be tested sequentially.

F-statistic for each feature.

P-values associated with the F-statistic.

Chi-squared stats of non-negative features for classification tasks.

F-value between label/feature for regression tasks.

Univariate Feature Selection

SVM-Anova: SVM with univariate feature selection

**Examples:**

Example 1 (sql):
```sql
>>> from sklearn.datasets import make_classification
>>> from sklearn.feature_selection import f_classif
>>> X, y = make_classification(
...     n_samples=100, n_features=10, n_informative=2, n_clusters_per_class=1,
...     shuffle=False, random_state=42
... )
>>> f_statistic, p_values = f_classif(X, y)
>>> f_statistic
array([2.21e+02, 7.02e-01, 1.70e+00, 9.31e-01,
       5.41e+00, 3.25e-01, 4.71e-02, 5.72e-01,
       7.54e-01, 8.90e-02])
>>> p_values
array([7.14e-27, 4.04e-01, 1.96e-01, 3.37e-01,
       2.21e-02, 5.70e-01, 8.29e-01, 4.51e-01,
       3.87e-01, 7.66e-01])
```

---

## DecisionTreeClassifier#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html

**Contents:**
- DecisionTreeClassifier#
- Gallery examples#

A decision tree classifier.

Read more in the User Guide.

The function to measure the quality of a split. Supported criteria are “gini” for the Gini impurity and “log_loss” and “entropy” both for the Shannon information gain, see Mathematical formulation.

The strategy used to choose the split at each node. Supported strategies are “best” to choose the best split and “random” to choose the best random split.

The maximum depth of the tree. If None, then nodes are expanded until all leaves are pure or until all leaves contain less than min_samples_split samples.

The minimum number of samples required to split an internal node:

If int, then consider min_samples_split as the minimum number.

If float, then min_samples_split is a fraction and ceil(min_samples_split * n_samples) are the minimum number of samples for each split.

Changed in version 0.18: Added float values for fractions.

The minimum number of samples required to be at a leaf node. A split point at any depth will only be considered if it leaves at least min_samples_leaf training samples in each of the left and right branches. This may have the effect of smoothing the model, especially in regression.

If int, then consider min_samples_leaf as the minimum number.

If float, then min_samples_leaf is a fraction and ceil(min_samples_leaf * n_samples) are the minimum number of samples for each node.

Changed in version 0.18: Added float values for fractions.

The minimum weighted fraction of the sum total of weights (of all the input samples) required to be at a leaf node. Samples have equal weight when sample_weight is not provided.

The number of features to consider when looking for the best split:

If int, then consider max_features features at each split.

If float, then max_features is a fraction and max(1, int(max_features * n_features_in_)) features are considered at each split.

If “sqrt”, then max_features=sqrt(n_features).

If “log2”, then max_features=log2(n_features).

If None, then max_features=n_features.

The search for a split does not stop until at least one valid partition of the node samples is found, even if it requires to effectively inspect more than max_features features.

Controls the randomness of the estimator. The features are always randomly permuted at each split, even if splitter is set to "best". When max_features < n_features, the algorithm will select max_features at random at each split before finding the best split among them. But the best found split may vary across different runs, even if max_features=n_features. That is the case, if the improvement of the criterion is identical for several splits and one split has to be selected at random. To obtain a deterministic behaviour during fitting, random_state has to be fixed to an integer. See Glossary for details.

Grow a tree with max_leaf_nodes in best-first fashion. Best nodes are defined as relative reduction in impurity. If None then unlimited number of leaf nodes.

A node will be split if this split induces a decrease of the impurity greater than or equal to this value.

The weighted impurity decrease equation is the following:

where N is the total number of samples, N_t is the number of samples at the current node, N_t_L is the number of samples in the left child, and N_t_R is the number of samples in the right child.

N, N_t, N_t_R and N_t_L all refer to the weighted sum, if sample_weight is passed.

Added in version 0.19.

Weights associated with classes in the form {class_label: weight}. If None, all classes are supposed to have weight one. For multi-output problems, a list of dicts can be provided in the same order as the columns of y.

Note that for multioutput (including multilabel) weights should be defined for each class of every column in its own dict. For example, for four-class multilabel classification weights should be [{0: 1, 1: 1}, {0: 1, 1: 5}, {0: 1, 1: 1}, {0: 1, 1: 1}] instead of [{1:1}, {2:5}, {3:1}, {4:1}].

The “balanced” mode uses the values of y to automatically adjust weights inversely proportional to class frequencies in the input data as n_samples / (n_classes * np.bincount(y))

For multi-output, the weights of each column of y will be multiplied.

Note that these weights will be multiplied with sample_weight (passed through the fit method) if sample_weight is specified.

Complexity parameter used for Minimal Cost-Complexity Pruning. The subtree with the largest cost complexity that is smaller than ccp_alpha will be chosen. By default, no pruning is performed. See Minimal Cost-Complexity Pruning for details. See Post pruning decision trees with cost complexity pruning for an example of such pruning.

Added in version 0.22.

1: monotonic increase

-1: monotonic decrease

If monotonic_cst is None, no constraints are applied.

multiclass classifications (i.e. when n_classes > 2),

multioutput classifications (i.e. when n_outputs_ > 1),

classifications trained on data with missing values.

The constraints hold over the probability of the positive class.

Read more in the User Guide.

Added in version 1.4.

The classes labels (single output problem), or a list of arrays of class labels (multi-output problem).

Return the feature importances.

The inferred value of max_features.

The number of classes (for single output problems), or a list containing the number of classes for each output (for multi-output problems).

Number of features seen during fit.

Added in version 0.24.

Names of features seen during fit. Defined only when X has feature names that are all strings.

Added in version 1.0.

The number of outputs when fit is performed.

The underlying Tree object. Please refer to help(sklearn.tree._tree.Tree) for attributes of Tree object and Understanding the decision tree structure for basic usage of these attributes.

A decision tree regressor.

The default values for the parameters controlling the size of the trees (e.g. max_depth, min_samples_leaf, etc.) lead to fully grown and unpruned trees which can potentially be very large on some data sets. To reduce memory consumption, the complexity and size of the trees should be controlled by setting those parameter values.

The predict method operates using the numpy.argmax function on the outputs of predict_proba. This means that in case the highest predicted probabilities are tied, the classifier will predict the tied class with the lowest index in classes_.

https://en.wikipedia.org/wiki/Decision_tree_learning

L. Breiman, J. Friedman, R. Olshen, and C. Stone, “Classification and Regression Trees”, Wadsworth, Belmont, CA, 1984.

T. Hastie, R. Tibshirani and J. Friedman. “Elements of Statistical Learning”, Springer, 2009.

L. Breiman, and A. Cutler, “Random Forests”, https://www.stat.berkeley.edu/~breiman/RandomForests/cc_home.htm

Return the index of the leaf that each sample is predicted as.

Added in version 0.17.

The input samples. Internally, it will be converted to dtype=np.float32 and if a sparse matrix is provided to a sparse csr_matrix.

Allow to bypass several input checking. Don’t use this parameter unless you know what you’re doing.

For each datapoint x in X, return the index of the leaf x ends up in. Leaves are numbered within [0; self.tree_.node_count), possibly with gaps in the numbering.

Compute the pruning path during Minimal Cost-Complexity Pruning.

See Minimal Cost-Complexity Pruning for details on the pruning process.

The training input samples. Internally, it will be converted to dtype=np.float32 and if a sparse matrix is provided to a sparse csc_matrix.

The target values (class labels) as integers or strings.

Sample weights. If None, then samples are equally weighted. Splits that would create child nodes with net zero or negative weight are ignored while searching for a split in each node. Splits are also ignored if they would result in any single class carrying a negative weight in either child node.

Dictionary-like object, with the following attributes.

Effective alphas of subtree during pruning.

Sum of the impurities of the subtree leaves for the corresponding alpha value in ccp_alphas.

Return the decision path in the tree.

Added in version 0.18.

The input samples. Internally, it will be converted to dtype=np.float32 and if a sparse matrix is provided to a sparse csr_matrix.

Allow to bypass several input checking. Don’t use this parameter unless you know what you’re doing.

Return a node indicator CSR matrix where non zero elements indicates that the samples goes through the nodes.

Build a decision tree classifier from the training set (X, y).

The training input samples. Internally, it will be converted to dtype=np.float32 and if a sparse matrix is provided to a sparse csc_matrix.

The target values (class labels) as integers or strings.

Sample weights. If None, then samples are equally weighted. Splits that would create child nodes with net zero or negative weight are ignored while searching for a split in each node. Splits are also ignored if they would result in any single class carrying a negative weight in either child node.

Allow to bypass several input checking. Don’t use this parameter unless you know what you’re doing.

Return the depth of the decision tree.

The depth of a tree is the maximum distance between the root and any leaf.

The maximum depth of the tree.

Get metadata routing of this object.

Please check User Guide on how the routing mechanism works.

A MetadataRequest encapsulating routing information.

Return the number of leaves of the decision tree.

Get parameters for this estimator.

If True, will return the parameters for this estimator and contained subobjects that are estimators.

Parameter names mapped to their values.

Predict class or regression value for X.

For a classification model, the predicted class for each sample in X is returned. For a regression model, the predicted value based on X is returned.

The input samples. Internally, it will be converted to dtype=np.float32 and if a sparse matrix is provided to a sparse csr_matrix.

Allow to bypass several input checking. Don’t use this parameter unless you know what you’re doing.

The predicted classes, or the predict values.

Predict class log-probabilities of the input samples X.

The input samples. Internally, it will be converted to dtype=np.float32 and if a sparse matrix is provided to a sparse csr_matrix.

The class log-probabilities of the input samples. The order of the classes corresponds to that in the attribute classes_.

Predict class probabilities of the input samples X.

The predicted class probability is the fraction of samples of the same class in a leaf.

The input samples. Internally, it will be converted to dtype=np.float32 and if a sparse matrix is provided to a sparse csr_matrix.

Allow to bypass several input checking. Don’t use this parameter unless you know what you’re doing.

The class probabilities of the input samples. The order of the classes corresponds to that in the attribute classes_.

Return accuracy on provided data and labels.

In multi-label classification, this is the subset accuracy which is a harsh metric since you require for each sample that each label set be correctly predicted.

Mean accuracy of self.predict(X) w.r.t. y.

Configure whether metadata should be requested to be passed to the fit method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to fit if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to fit.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Added in version 1.3.

Metadata routing for sample_weight parameter in fit.

Set the parameters of this estimator.

The method works on simple estimators as well as on nested objects (such as Pipeline). The latter have parameters of the form <component>__<parameter> so that it’s possible to update each component of a nested object.

Estimator parameters.

Configure whether metadata should be requested to be passed to the score method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to score if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to score.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Added in version 1.3.

Metadata routing for sample_weight parameter in score.

Classifier comparison

Multi-class AdaBoosted Decision Trees

Plot the decision surfaces of ensembles of trees on the iris dataset

Demonstration of multi-metric evaluation on cross_val_score and GridSearchCV

Overview of multiclass training meta-estimators

Release Highlights for scikit-learn 1.3

Post pruning decision trees with cost complexity pruning

Plot the decision surface of decision trees trained on the iris dataset

Understanding the decision tree structure

**Examples:**

Example 1 (yaml):
```yaml
N_t / N * (impurity - N_t_R / N_t * right_impurity
                    - N_t_L / N_t * left_impurity)
```

Example 2 (sql):
```sql
>>> from sklearn.datasets import load_iris
>>> from sklearn.model_selection import cross_val_score
>>> from sklearn.tree import DecisionTreeClassifier
>>> clf = DecisionTreeClassifier(random_state=0)
>>> iris = load_iris()
>>> cross_val_score(clf, iris.data, iris.target, cv=10)
...
...
array([ 1.     ,  0.93,  0.86,  0.93,  0.93,
        0.93,  0.93,  1.     ,  0.93,  1.      ])
```

---

## BayesianGaussianMixture#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.mixture.BayesianGaussianMixture.html

**Contents:**
- BayesianGaussianMixture#
- Gallery examples#

Variational Bayesian estimation of a Gaussian mixture.

This class allows to infer an approximate posterior distribution over the parameters of a Gaussian mixture distribution. The effective number of components can be inferred from the data.

This class implements two types of prior for the weights distribution: a finite mixture model with Dirichlet distribution and an infinite mixture model with the Dirichlet Process. In practice Dirichlet Process inference algorithm is approximated and uses a truncated distribution with a fixed maximum number of components (called the Stick-breaking representation). The number of components actually used almost always depends on the data.

Added in version 0.18.

Read more in the User Guide.

The number of mixture components. Depending on the data and the value of the weight_concentration_prior the model can decide to not use all the components by setting some component weights_ to values very close to zero. The number of effective components is therefore smaller than n_components.

String describing the type of covariance parameters to use. Must be one of:

‘full’ (each component has its own general covariance matrix),

‘tied’ (all components share the same general covariance matrix),

‘diag’ (each component has its own diagonal covariance matrix),

‘spherical’ (each component has its own single variance).

The convergence threshold. EM iterations will stop when the lower bound average gain on the likelihood (of the training data with respect to the model) is below this threshold.

Non-negative regularization added to the diagonal of covariance. Allows to assure that the covariance matrices are all positive.

The number of EM iterations to perform.

The number of initializations to perform. The result with the highest lower bound value on the likelihood is kept.

The method used to initialize the weights, the means and the covariances. String must be one of:

‘kmeans’: responsibilities are initialized using kmeans.

‘k-means++’: use the k-means++ method to initialize.

‘random’: responsibilities are initialized randomly.

‘random_from_data’: initial means are randomly selected data points.

Changed in version v1.1: init_params now accepts ‘random_from_data’ and ‘k-means++’ as initialization methods.

String describing the type of the weight concentration prior.

The dirichlet concentration of each component on the weight distribution (Dirichlet). This is commonly called gamma in the literature. The higher concentration puts more mass in the center and will lead to more components being active, while a lower concentration parameter will lead to more mass at the edge of the mixture weights simplex. The value of the parameter must be greater than 0. If it is None, it’s set to 1. / n_components.

The precision prior on the mean distribution (Gaussian). Controls the extent of where means can be placed. Larger values concentrate the cluster means around mean_prior. The value of the parameter must be greater than 0. If it is None, it is set to 1.

The prior on the mean distribution (Gaussian). If it is None, it is set to the mean of X.

The prior of the number of degrees of freedom on the covariance distributions (Wishart). If it is None, it’s set to n_features.

The prior on the covariance distribution (Wishart). If it is None, the emiprical covariance prior is initialized using the covariance of X. The shape depends on covariance_type:

Controls the random seed given to the method chosen to initialize the parameters (see init_params). In addition, it controls the generation of random samples from the fitted distribution (see the method sample). Pass an int for reproducible output across multiple function calls. See Glossary.

If ‘warm_start’ is True, the solution of the last fitting is used as initialization for the next call of fit(). This can speed up convergence when fit is called several times on similar problems. See the Glossary.

Enable verbose output. If 1 then it prints the current initialization and each iteration step. If greater than 1 then it prints also the log probability and the time needed for each step.

Number of iteration done before the next print.

The weights of each mixture components.

The mean of each mixture component.

The covariance of each mixture component. The shape depends on covariance_type:

The precision matrices for each component in the mixture. A precision matrix is the inverse of a covariance matrix. A covariance matrix is symmetric positive definite so the mixture of Gaussian can be equivalently parameterized by the precision matrices. Storing the precision matrices instead of the covariance matrices makes it more efficient to compute the log-likelihood of new samples at test time. The shape depends on covariance_type:

The Cholesky decomposition of the precision matrices of each mixture component. A precision matrix is the inverse of a covariance matrix. A covariance matrix is symmetric positive definite so the mixture of Gaussian can be equivalently parameterized by the precision matrices. Storing the precision matrices instead of the covariance matrices makes it more efficient to compute the log-likelihood of new samples at test time. The shape depends on covariance_type:

True when convergence of the best fit of inference was reached, False otherwise.

Number of step used by the best fit of inference to reach the convergence.

Lower bound value on the model evidence (of the training data) of the best fit of inference.

The list of lower bound values on the model evidence from each iteration of the best fit of inference.

The dirichlet concentration of each component on the weight distribution (Dirichlet). The type depends on weight_concentration_prior_type:

The higher concentration puts more mass in the center and will lead to more components being active, while a lower concentration parameter will lead to more mass at the edge of the simplex.

The dirichlet concentration of each component on the weight distribution (Dirichlet).

The precision prior on the mean distribution (Gaussian). Controls the extent of where means can be placed. Larger values concentrate the cluster means around mean_prior. If mean_precision_prior is set to None, mean_precision_prior_ is set to 1.

The precision of each components on the mean distribution (Gaussian).

The prior on the mean distribution (Gaussian).

The prior of the number of degrees of freedom on the covariance distributions (Wishart).

The number of degrees of freedom of each components in the model.

The prior on the covariance distribution (Wishart). The shape depends on covariance_type:

Number of features seen during fit.

Added in version 0.24.

Names of features seen during fit. Defined only when X has feature names that are all strings.

Added in version 1.0.

Finite Gaussian mixture fit with EM.

Bishop, Christopher M. (2006). “Pattern recognition and machine learning”. Vol. 4 No. 4. New York: Springer.

Hagai Attias. (2000). “A Variational Bayesian Framework for Graphical Models”. In Advances in Neural Information Processing Systems 12.

Blei, David M. and Michael I. Jordan. (2006). “Variational inference for Dirichlet process mixtures”. Bayesian analysis 1.1

Estimate model parameters with the EM algorithm.

The method fits the model n_init times and sets the parameters with which the model has the largest likelihood or lower bound. Within each trial, the method iterates between E-step and M-step for max_iter times until the change of likelihood or lower bound is less than tol, otherwise, a ConvergenceWarning is raised. If warm_start is True, then n_init is ignored and a single initialization is performed upon the first call. Upon consecutive calls, training starts where it left off.

List of n_features-dimensional data points. Each row corresponds to a single data point.

Not used, present for API consistency by convention.

Estimate model parameters using X and predict the labels for X.

The method fits the model n_init times and sets the parameters with which the model has the largest likelihood or lower bound. Within each trial, the method iterates between E-step and M-step for max_iter times until the change of likelihood or lower bound is less than tol, otherwise, a ConvergenceWarning is raised. After fitting, it predicts the most probable label for the input data points.

Added in version 0.20.

List of n_features-dimensional data points. Each row corresponds to a single data point.

Not used, present for API consistency by convention.

Get metadata routing of this object.

Please check User Guide on how the routing mechanism works.

A MetadataRequest encapsulating routing information.

Get parameters for this estimator.

If True, will return the parameters for this estimator and contained subobjects that are estimators.

Parameter names mapped to their values.

Predict the labels for the data samples in X using trained model.

List of n_features-dimensional data points. Each row corresponds to a single data point.

Evaluate the components’ density for each sample.

List of n_features-dimensional data points. Each row corresponds to a single data point.

Density of each Gaussian component for each sample in X.

Generate random samples from the fitted Gaussian distribution.

Number of samples to generate.

Randomly generated sample.

Compute the per-sample average log-likelihood of the given data X.

List of n_features-dimensional data points. Each row corresponds to a single data point.

Not used, present for API consistency by convention.

Log-likelihood of X under the Gaussian mixture model.

Compute the log-likelihood of each sample.

List of n_features-dimensional data points. Each row corresponds to a single data point.

Log-likelihood of each sample in X under the current model.

Set the parameters of this estimator.

The method works on simple estimators as well as on nested objects (such as Pipeline). The latter have parameters of the form <component>__<parameter> so that it’s possible to update each component of a nested object.

Estimator parameters.

Concentration Prior Type Analysis of Variation Bayesian Gaussian Mixture

Gaussian Mixture Model Ellipsoids

Gaussian Mixture Model Sine Curve

**Examples:**

Example 1 (unknown):
```unknown
(n_features, n_features) if 'full',
(n_features, n_features) if 'tied',
(n_features)             if 'diag',
float                    if 'spherical'
```

Example 2 (unknown):
```unknown
(n_components,)                        if 'spherical',
(n_features, n_features)               if 'tied',
(n_components, n_features)             if 'diag',
(n_components, n_features, n_features) if 'full'
```

Example 3 (unknown):
```unknown
(n_components,)                        if 'spherical',
(n_features, n_features)               if 'tied',
(n_components, n_features)             if 'diag',
(n_components, n_features, n_features) if 'full'
```

Example 4 (unknown):
```unknown
(n_components,)                        if 'spherical',
(n_features, n_features)               if 'tied',
(n_components, n_features)             if 'diag',
(n_components, n_features, n_features) if 'full'
```

---

## 7.8. Pairwise metrics, Affinities and Kernels#

**URL:** https://scikit-learn.org/stable/modules/metrics.html

**Contents:**
- 7.8. Pairwise metrics, Affinities and Kernels#
- 7.8.1. Cosine similarity#
- 7.8.2. Linear kernel#
- 7.8.3. Polynomial kernel#
- 7.8.4. Sigmoid kernel#
- 7.8.5. RBF kernel#
- 7.8.6. Laplacian kernel#
- 7.8.7. Chi-squared kernel#

The sklearn.metrics.pairwise submodule implements utilities to evaluate pairwise distances or affinity of sets of samples.

This module contains both distance metrics and kernels. A brief summary is given on the two here.

Distance metrics are functions d(a, b) such that d(a, b) < d(a, c) if objects a and b are considered “more similar” than objects a and c. Two objects exactly alike would have a distance of zero. One of the most popular examples is Euclidean distance. To be a ‘true’ metric, it must obey the following four conditions:

Kernels are measures of similarity, i.e. s(a, b) > s(a, c) if objects a and b are considered “more similar” than objects a and c. A kernel must also be positive semi-definite.

There are a number of ways to convert between a distance metric and a similarity measure, such as a kernel. Let D be the distance, and S be the kernel:

gamma is 1 / num_features

S = 1. / (D / np.max(D))

The distances between the row vectors of X and the row vectors of Y can be evaluated using pairwise_distances. If Y is omitted the pairwise distances of the row vectors of X are calculated. Similarly, pairwise.pairwise_kernels can be used to calculate the kernel between X and Y using different kernel functions. See the API reference for more details.

cosine_similarity computes the L2-normalized dot product of vectors. That is, if \(x\) and \(y\) are row vectors, their cosine similarity \(k\) is defined as:

This is called cosine similarity, because Euclidean (L2) normalization projects the vectors onto the unit sphere, and their dot product is then the cosine of the angle between the points denoted by the vectors.

This kernel is a popular choice for computing the similarity of documents represented as tf-idf vectors. cosine_similarity accepts scipy.sparse matrices. (Note that the tf-idf functionality in sklearn.feature_extraction.text can produce normalized vectors, in which case cosine_similarity is equivalent to linear_kernel, only slower.)

C.D. Manning, P. Raghavan and H. Schütze (2008). Introduction to Information Retrieval. Cambridge University Press. https://nlp.stanford.edu/IR-book/html/htmledition/the-vector-space-model-for-scoring-1.html

The function linear_kernel computes the linear kernel, that is, a special case of polynomial_kernel with degree=1 and coef0=0 (homogeneous). If x and y are column vectors, their linear kernel is:

The function polynomial_kernel computes the degree-d polynomial kernel between two vectors. The polynomial kernel represents the similarity between two vectors. Conceptually, the polynomial kernel considers not only the similarity between vectors under the same dimension, but also across dimensions. When used in machine learning algorithms, this allows to account for feature interaction.

The polynomial kernel is defined as:

x, y are the input vectors

d is the kernel degree

If \(c_0 = 0\) the kernel is said to be homogeneous.

The function sigmoid_kernel computes the sigmoid kernel between two vectors. The sigmoid kernel is also known as hyperbolic tangent, or Multilayer Perceptron (because, in the neural network field, it is often used as neuron activation function). It is defined as:

x, y are the input vectors

\(\gamma\) is known as slope

\(c_0\) is known as intercept

The function rbf_kernel computes the radial basis function (RBF) kernel between two vectors. This kernel is defined as:

where x and y are the input vectors. If \(\gamma = \sigma^{-2}\) the kernel is known as the Gaussian kernel of variance \(\sigma^2\).

The function laplacian_kernel is a variant on the radial basis function kernel defined as:

where x and y are the input vectors and \(\|x-y\|_1\) is the Manhattan distance between the input vectors.

It has proven useful in ML applied to noiseless data. See e.g. Machine learning for quantum mechanics in a nutshell.

The chi-squared kernel is a very popular choice for training non-linear SVMs in computer vision applications. It can be computed using chi2_kernel and then passed to an SVC with kernel="precomputed":

It can also be directly used as the kernel argument:

The chi squared kernel is given by

The data is assumed to be non-negative, and is often normalized to have an L1-norm of one. The normalization is rationalized with the connection to the chi squared distance, which is a distance between discrete probability distributions.

The chi squared kernel is most commonly used on histograms (bags) of visual words.

Zhang, J. and Marszalek, M. and Lazebnik, S. and Schmid, C. Local features and kernels for classification of texture and object categories: A comprehensive study International Journal of Computer Vision 2007 https://hal.archives-ouvertes.fr/hal-00171412/document

**Examples:**

Example 1 (unknown):
```unknown
1. d(a, b) >= 0, for all a and b
2. d(a, b) == 0, if and only if a = b, positive definiteness
3. d(a, b) == d(b, a), symmetry
4. d(a, c) <= d(a, b) + d(b, c), the triangle inequality
```

Example 2 (sql):
```sql
>>> import numpy as np
>>> from sklearn.metrics import pairwise_distances
>>> from sklearn.metrics.pairwise import pairwise_kernels
>>> X = np.array([[2, 3], [3, 5], [5, 8]])
>>> Y = np.array([[1, 0], [2, 1]])
>>> pairwise_distances(X, Y, metric='manhattan')
array([[ 4.,  2.],
       [ 7.,  5.],
       [12., 10.]])
>>> pairwise_distances(X, metric='manhattan')
array([[0., 3., 8.],
       [3., 0., 5.],
       [8., 5., 0.]])
>>> pairwise_kernels(X, Y, metric='linear')
array([[ 2.,  7.],
       [ 3., 11.],
       [ 5., 18.]])
```

Example 3 (sql):
```sql
>>> from sklearn.svm import SVC
>>> from sklearn.metrics.pairwise import chi2_kernel
>>> X = [[0, 1], [1, 0], [.2, .8], [.7, .3]]
>>> y = [0, 1, 0, 1]
>>> K = chi2_kernel(X, gamma=.5)
>>> K
array([[1.        , 0.36787944, 0.89483932, 0.58364548],
       [0.36787944, 1.        , 0.51341712, 0.83822343],
       [0.89483932, 0.51341712, 1.        , 0.7768366 ],
       [0.58364548, 0.83822343, 0.7768366 , 1.        ]])

>>> svm = SVC(kernel='precomputed').fit(K, y)
>>> svm.predict(K)
array([0, 1, 0, 1])
```

Example 4 (unknown):
```unknown
>>> svm = SVC(kernel=chi2_kernel).fit(X, y)
>>> svm.predict(X)
array([0, 1, 0, 1])
```

---

## PolynomialFeatures#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html

**Contents:**
- PolynomialFeatures#
- Gallery examples#

Generate polynomial and interaction features.

Generate a new feature matrix consisting of all polynomial combinations of the features with degree less than or equal to the specified degree. For example, if an input sample is two dimensional and of the form [a, b], the degree-2 polynomial features are [1, a, b, a^2, ab, b^2].

Read more in the User Guide.

If a single int is given, it specifies the maximal degree of the polynomial features. If a tuple (min_degree, max_degree) is passed, then min_degree is the minimum and max_degree is the maximum polynomial degree of the generated features. Note that min_degree=0 and min_degree=1 are equivalent as outputting the degree zero term is determined by include_bias.

If True, only interaction features are produced: features that are products of at most degree distinct input features, i.e. terms with power of 2 or higher of the same input feature are excluded:

included: x[0], x[1], x[0] * x[1], etc.

excluded: x[0] ** 2, x[0] ** 2 * x[1], etc.

If True (default), then include a bias column, the feature in which all polynomial powers are zero (i.e. a column of ones - acts as an intercept term in a linear model).

Order of output array in the dense case. 'F' order is faster to compute, but may slow down subsequent estimators.

Added in version 0.21.

Exponent for each of the inputs in the output.

Number of features seen during fit.

Added in version 0.24.

Names of features seen during fit. Defined only when X has feature names that are all strings.

Added in version 1.0.

The total number of polynomial output features. The number of output features is computed by iterating over all suitably sized combinations of input features.

Transformer that generates univariate B-spline bases for features.

Be aware that the number of features in the output array scales polynomially in the number of features of the input array, and exponentially in the degree. High degrees can cause overfitting.

See examples/linear_model/plot_polynomial_interpolation.py

Compute number of output features.

Not used, present here for API consistency by convention.

Fit to data, then transform it.

Fits transformer to X and y with optional parameters fit_params and returns a transformed version of X.

Target values (None for unsupervised transformations).

Additional fit parameters. Pass only if the estimator accepts additional params in its fit method.

Get output feature names for transformation.

If input_features is None, then feature_names_in_ is used as feature names in. If feature_names_in_ is not defined, then the following input feature names are generated: ["x0", "x1", ..., "x(n_features_in_ - 1)"].

If input_features is an array-like, then input_features must match feature_names_in_ if feature_names_in_ is defined.

Transformed feature names.

Get metadata routing of this object.

Please check User Guide on how the routing mechanism works.

A MetadataRequest encapsulating routing information.

Get parameters for this estimator.

If True, will return the parameters for this estimator and contained subobjects that are estimators.

Parameter names mapped to their values.

Set output container.

See Introducing the set_output API for an example on how to use the API.

Configure output of transform and fit_transform.

"default": Default output format of a transformer

"pandas": DataFrame output

"polars": Polars output

None: Transform configuration is unchanged

Added in version 1.4: "polars" option was added.

Set the parameters of this estimator.

The method works on simple estimators as well as on nested objects (such as Pipeline). The latter have parameters of the form <component>__<parameter> so that it’s possible to update each component of a nested object.

Estimator parameters.

Transform data to polynomial features.

The data to transform, row by row.

Prefer CSR over CSC for sparse input (for speed), but CSC is required if the degree is 4 or higher. If the degree is less than 4 and the input format is CSC, it will be converted to CSR, have its polynomial features generated, then converted back to CSC.

If the degree is 2 or 3, the method described in “Leveraging Sparsity to Speed Up Polynomial Feature Expansions of CSR Matrices Using K-Simplex Numbers” by Andrew Nystrom and John Hughes is used, which is much faster than the method used on CSC input. For this reason, a CSC input will be converted to CSR, and the output will be converted back to CSC prior to being returned, hence the preference of CSR.

The matrix of features, where NP is the number of polynomial features generated from the combination of inputs. If a sparse matrix is provided, it will be converted into a sparse csr_matrix.

Time-related feature engineering

Plot classification probability

Visualizing the probabilistic predictions of a VotingClassifier

Comparing Linear Bayesian Regressors

Poisson regression and non-normal loss

Polynomial and Spline interpolation

Robust linear estimator fitting

Underfitting vs. Overfitting

Release Highlights for scikit-learn 0.24

Plot classification boundaries with different SVM Kernels

**Examples:**

Example 1 (sql):
```sql
>>> import numpy as np
>>> from sklearn.preprocessing import PolynomialFeatures
>>> X = np.arange(6).reshape(3, 2)
>>> X
array([[0, 1],
       [2, 3],
       [4, 5]])
>>> poly = PolynomialFeatures(2)
>>> poly.fit_transform(X)
array([[ 1.,  0.,  1.,  0.,  0.,  1.],
       [ 1.,  2.,  3.,  4.,  6.,  9.],
       [ 1.,  4.,  5., 16., 20., 25.]])
>>> poly = PolynomialFeatures(interaction_only=True)
>>> poly.fit_transform(X)
array([[ 1.,  0.,  1.,  0.],
       [ 1.,  2.,  3.,  6.],
       [ 1.,  4.,  5., 20.]])
```

---

## radius_neighbors_graph#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.radius_neighbors_graph.html

**Contents:**
- radius_neighbors_graph#

Compute the (weighted) graph of Neighbors for points in X.

Neighborhoods are restricted the points at a distance lower than radius.

Read more in the User Guide.

Radius of neighborhoods.

Type of returned matrix: ‘connectivity’ will return the connectivity matrix with ones and zeros, and ‘distance’ will return the distances between neighbors according to the given metric.

Metric to use for distance computation. Default is “minkowski”, which results in the standard Euclidean distance when p = 2. See the documentation of scipy.spatial.distance and the metrics listed in distance_metrics for valid metric values.

Power parameter for the Minkowski metric. When p = 1, this is equivalent to using manhattan_distance (l1), and euclidean_distance (l2) for p = 2. For arbitrary p, minkowski_distance (l_p) is used.

Additional keyword arguments for the metric function.

Whether or not to mark each sample as the first nearest neighbor to itself. If ‘auto’, then True is used for mode=’connectivity’ and False for mode=’distance’.

The number of parallel jobs to run for neighbors search. None means 1 unless in a joblib.parallel_backend context. -1 means using all processors. See Glossary for more details.

Graph where A[i, j] is assigned the weight of edge that connects i to j. The matrix is of CSR format.

Compute the weighted graph of k-neighbors for points in X.

**Examples:**

Example 1 (sql):
```sql
>>> X = [[0], [3], [1]]
>>> from sklearn.neighbors import radius_neighbors_graph
>>> A = radius_neighbors_graph(X, 1.5, mode='connectivity',
...                            include_self=True)
>>> A.toarray()
array([[1., 0., 1.],
       [0., 1., 0.],
       [1., 0., 1.]])
```

---

## VotingClassifier#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.VotingClassifier.html

**Contents:**
- VotingClassifier#
- Gallery examples#

Soft Voting/Majority Rule classifier for unfitted estimators.

Read more in the User Guide.

Added in version 0.17.

Invoking the fit method on the VotingClassifier will fit clones of those original estimators that will be stored in the class attribute self.estimators_. An estimator can be set to 'drop' using set_params.

Changed in version 0.21: 'drop' is accepted. Using None was deprecated in 0.22 and support was removed in 0.24.

If ‘hard’, uses predicted class labels for majority rule voting. Else if ‘soft’, predicts the class label based on the argmax of the sums of the predicted probabilities, which is recommended for an ensemble of well-calibrated classifiers.

Sequence of weights (float or int) to weight the occurrences of predicted class labels (hard voting) or class probabilities before averaging (soft voting). Uses uniform weights if None.

The number of jobs to run in parallel for fit. None means 1 unless in a joblib.parallel_backend context. -1 means using all processors. See Glossary for more details.

Added in version 0.18.

Affects shape of transform output only when voting=’soft’ If voting=’soft’ and flatten_transform=True, transform method returns matrix with shape (n_samples, n_classifiers * n_classes). If flatten_transform=False, it returns (n_classifiers, n_samples, n_classes).

If True, the time elapsed while fitting will be printed as it is completed.

Added in version 0.23.

The collection of fitted sub-estimators as defined in estimators that are not ‘drop’.

Attribute to access any fitted sub-estimators by name.

Added in version 0.20.

Transformer used to encode the labels during fit and decode during prediction.

Number of features seen during fit.

Names of features seen during fit. Only defined if the underlying estimators expose such an attribute when fit.

Added in version 1.0.

Prediction voting regressor.

To drop an estimator, set_params can be used to remove it. Here we dropped one of the estimators, resulting in 2 fitted estimators:

Setting flatten_transform=True with voting='soft' flattens output shape of transform:

Training vectors, where n_samples is the number of samples and n_features is the number of features.

Parameters to pass to the underlying estimators.

Added in version 1.5: Only available if enable_metadata_routing=True, which can be set by using sklearn.set_config(enable_metadata_routing=True). See Metadata Routing User Guide for more details.

Returns the instance itself.

Return class labels or probabilities for each estimator.

Return predictions for X for each estimator.

Target values (None for unsupervised transformations).

Additional fit parameters.

Get output feature names for transformation.

Not used, present here for API consistency by convention.

Transformed feature names.

Get metadata routing of this object.

Please check User Guide on how the routing mechanism works.

Added in version 1.5.

A MetadataRouter encapsulating routing information.

Get the parameters of an estimator from the ensemble.

Returns the parameters given in the constructor as well as the estimators contained within the estimators parameter.

Setting it to True gets the various estimators and the parameters of the estimators as well.

Parameter and estimator names mapped to their values or parameter names mapped to their values.

Dictionary to access any fitted sub-estimators by name.

Predict class labels for X.

Predicted class labels.

Compute probabilities of possible outcomes for samples in X.

Weighted average probability for each class per sample.

Return accuracy on provided data and labels.

In multi-label classification, this is the subset accuracy which is a harsh metric since you require for each sample that each label set be correctly predicted.

Mean accuracy of self.predict(X) w.r.t. y.

Set output container.

See Introducing the set_output API for an example on how to use the API.

Configure output of transform and fit_transform.

"default": Default output format of a transformer

"pandas": DataFrame output

"polars": Polars output

None: Transform configuration is unchanged

Added in version 1.4: "polars" option was added.

Set the parameters of an estimator from the ensemble.

Valid parameter keys can be listed with get_params(). Note that you can directly set the parameters of the estimators contained in estimators.

Specific parameters using e.g. set_params(parameter_name=new_value). In addition, to setting the parameters of the estimator, the individual estimator of the estimators can also be set, or can be removed by setting them to ‘drop’.

Configure whether metadata should be requested to be passed to the score method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to score if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to score.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Added in version 1.3.

Metadata routing for sample_weight parameter in score.

Return class labels or probabilities for X for each estimator.

Training vectors, where n_samples is the number of samples and n_features is the number of features.

returns ndarray of shape (n_samples, n_classifiers * n_classes), being class probabilities calculated by each classifier.

ndarray of shape (n_classifiers, n_samples, n_classes)

ndarray of shape (n_samples, n_classifiers), being class labels predicted by each classifier.

Visualizing the probabilistic predictions of a VotingClassifier

**Examples:**

Example 1 (python):
```python
>>> import numpy as np
>>> from sklearn.linear_model import LogisticRegression
>>> from sklearn.naive_bayes import GaussianNB
>>> from sklearn.ensemble import RandomForestClassifier, VotingClassifier
>>> clf1 = LogisticRegression(random_state=1)
>>> clf2 = RandomForestClassifier(n_estimators=50, random_state=1)
>>> clf3 = GaussianNB()
>>> X = np.array([[-1, -1], [-2, -1], [-3, -2], [1, 1], [2, 1], [3, 2]])
>>> y = np.array([1, 1, 1, 2, 2, 2])
>>> eclf1 = VotingClassifier(estimators=[
...         ('lr', clf1), ('rf', clf2), ('gnb', clf3)], voting='hard')
>>> eclf1 = eclf1.fit(X, y)
>>> print(eclf1.predict(X))
[1 1 1 2 2 2]
>>> np.array_equal(eclf1.named_estimators_.lr.predict(X),
...                eclf1.named_estimators_['lr'].predict(X))
True
>>> eclf2 = VotingClassifier(estimators=[
...         ('lr', clf1), ('rf', clf2), ('gnb', clf3)],
...         voting='soft')
>>> eclf2 = eclf2.fit(X, y)
>>> print(eclf2.predict(X))
[1 1 1 2 2 2]
```

Example 2 (unknown):
```unknown
>>> eclf2 = eclf2.set_params(lr='drop')
>>> eclf2 = eclf2.fit(X, y)
>>> len(eclf2.estimators_)
2
```

Example 3 (csharp):
```csharp
>>> eclf3 = VotingClassifier(estimators=[
...        ('lr', clf1), ('rf', clf2), ('gnb', clf3)],
...        voting='soft', weights=[2,1,1],
...        flatten_transform=True)
>>> eclf3 = eclf3.fit(X, y)
>>> print(eclf3.predict(X))
[1 1 1 2 2 2]
>>> print(eclf3.transform(X).shape)
(6, 6)
```

---

## ClassicalMDS#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.manifold.ClassicalMDS.html

**Contents:**
- ClassicalMDS#
- Gallery examples#

Classical multidimensional scaling (MDS).

This is also known as principal coordinates analysis (PCoA) or Torgerson’s scaling. It is a version of MDS that has exact solution in terms of eigendecomposition. If the input dissimilarity matrix consists of the pairwise Euclidean distances between some vectors, then classical MDS is equivalent to PCA applied to this set of vectors.

Read more in the User Guide.

Number of embedding dimensions.

Metric to use for dissimilarity computation. Default is “euclidean”.

If metric is a string, it must be one of the options allowed by scipy.spatial.distance.pdist for its metric parameter, or a metric listed in sklearn.metrics.pairwise.distance_metrics

If metric is “precomputed”, X is assumed to be a distance matrix and must be square during fit.

If metric is a callable function, it takes two arrays representing 1D vectors as inputs and must return one value indicating the distance between those vectors. This works for Scipy’s metrics, but is less efficient than passing the metric name as a string.

Additional keyword arguments for the dissimilarity computation.

Stores the position of the dataset in the embedding space.

Pairwise dissimilarities between the points.

Eigenvalues of the double-centered dissimilarity matrix, corresponding to each of the selected components. They are equal to the squared 2-norms of the n_components variables in the embedding space.

Number of features seen during fit.

Names of features seen during fit. Defined only when X has feature names that are all strings.

Principal component analysis.

Metric and non-metric MDS.

“Modern Multidimensional Scaling - Theory and Applications” Borg, I.; Groenen P. Springer Series in Statistics (1997)

Compute the embedding positions.

Input data. If metric=='precomputed', the input should be the dissimilarity matrix.

Not used, present for API consistency by convention.

Compute and return the embedding positions.

Input data. If metric=='precomputed', the input should be the dissimilarity matrix.

Not used, present for API consistency by convention.

The embedding coordinates.

Get metadata routing of this object.

Please check User Guide on how the routing mechanism works.

A MetadataRequest encapsulating routing information.

Get parameters for this estimator.

If True, will return the parameters for this estimator and contained subobjects that are estimators.

Parameter names mapped to their values.

Set the parameters of this estimator.

The method works on simple estimators as well as on nested objects (such as Pipeline). The latter have parameters of the form <component>__<parameter> so that it’s possible to update each component of a nested object.

Estimator parameters.

Comparison of Manifold Learning methods

Manifold learning on handwritten digits: Locally Linear Embedding, Isomap…

Manifold Learning methods on a severed sphere

Multi-dimensional scaling

Release Highlights for scikit-learn 1.8

**Examples:**

Example 1 (sql):
```sql
>>> from sklearn.datasets import load_digits
>>> from sklearn.manifold import ClassicalMDS
>>> X, _ = load_digits(return_X_y=True)
>>> X.shape
(1797, 64)
>>> cmds = ClassicalMDS(n_components=2)
>>> X_emb = cmds.fit_transform(X[:100])
>>> X_emb.shape
(100, 2)
```

---

## BaseEstimator#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.base.BaseEstimator.html

**Contents:**
- BaseEstimator#
- Gallery examples#

Base class for all estimators in scikit-learn.

Inheriting from this class provides default implementations of:

setting and getting parameters used by GridSearchCV and friends;

textual and HTML representation displayed in terminals and IDEs;

estimator serialization;

parameters validation;

feature names validation.

Read more in the User Guide.

All estimators should specify all the parameters that can be set at the class level in their __init__ as explicit keyword arguments (no *args or **kwargs).

Get metadata routing of this object.

Please check User Guide on how the routing mechanism works.

A MetadataRequest encapsulating routing information.

Get parameters for this estimator.

If True, will return the parameters for this estimator and contained subobjects that are estimators.

Parameter names mapped to their values.

Set the parameters of this estimator.

The method works on simple estimators as well as on nested objects (such as Pipeline). The latter have parameters of the form <component>__<parameter> so that it’s possible to update each component of a nested object.

Estimator parameters.

__sklearn_is_fitted__ as Developer API

Approximate nearest neighbors in TSNE

**Examples:**

Example 1 (python):
```python
>>> import numpy as np
>>> from sklearn.base import BaseEstimator
>>> class MyEstimator(BaseEstimator):
...     def __init__(self, *, param=1):
...         self.param = param
...     def fit(self, X, y=None):
...         self.is_fitted_ = True
...         return self
...     def predict(self, X):
...         return np.full(shape=X.shape[0], fill_value=self.param)
>>> estimator = MyEstimator(param=2)
>>> estimator.get_params()
{'param': 2}
>>> X = np.array([[1, 2], [2, 3], [3, 4]])
>>> y = np.array([1, 0, 1])
>>> estimator.fit(X, y).predict(X)
array([2, 2, 2])
>>> estimator.set_params(param=3).fit(X, y).predict(X)
array([3, 3, 3])
```

---

## brier_score_loss#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.metrics.brier_score_loss.html

**Contents:**
- brier_score_loss#
- Gallery examples#

Compute the Brier score loss.

The smaller the Brier score loss, the better, hence the naming with “loss”. The Brier score measures the mean squared difference between the predicted probability and the actual outcome. The Brier score is a strictly proper scoring rule.

Read more in the User Guide.

Predicted probabilities. If y_proba.shape = (n_samples,) the probabilities provided are assumed to be that of the positive class. If y_proba.shape = (n_samples, n_classes) the columns in y_proba are assumed to correspond to the labels in alphabetical order, as done by LabelBinarizer.

Label of the positive class when y_proba.shape = (n_samples,). If not provided, pos_label will be inferred in the following manner:

if y_true in {-1, 1} or {0, 1}, pos_label defaults to 1;

else if y_true contains string, an error will be raised and pos_label should be explicitly specified;

otherwise, pos_label defaults to the greater label, i.e. np.unique(y_true)[-1].

Class labels when y_proba.shape = (n_samples, n_classes). If not provided, labels will be inferred from y_true.

Added in version 1.7.

When True, scale the Brier score by 1/2 to lie in the [0, 1] range instead of the [0, 2] range. The default “auto” option implements the rescaling to [0, 1] only for binary classification (as customary) but keeps the original [0, 2] range for multiclass classification.

Added in version 1.7.

For \(N\) observations labeled from \(C\) possible classes, the Brier score is defined as:

where \(y_{ic}\) is 1 if observation i belongs to class c, otherwise 0 and \(\hat{p}_{ic}\) is the predicted probability for observation i to belong to class c. The Brier score then ranges between \([0, 2]\).

In binary classification tasks the Brier score is usually divided by two and then ranges between \([0, 1]\). It can be alternatively written as:

where \(y_{i}\) is the binary target and \(\hat{p}_{i}\) is the predicted probability of the positive class.

Wikipedia entry for the Brier score.

Probability calibration of classifiers

Probability Calibration curves

Probability Calibration for 3-class classification

Examples of Using FrozenEstimator

**Examples:**

Example 1 (sql):
```sql
>>> import numpy as np
>>> from sklearn.metrics import brier_score_loss
>>> y_true = np.array([0, 1, 1, 0])
>>> y_true_categorical = np.array(["spam", "ham", "ham", "spam"])
>>> y_prob = np.array([0.1, 0.9, 0.8, 0.3])
>>> brier_score_loss(y_true, y_prob)
0.0375
>>> brier_score_loss(y_true, 1-y_prob, pos_label=0)
0.0375
>>> brier_score_loss(y_true_categorical, y_prob, pos_label="ham")
0.0375
>>> brier_score_loss(y_true, np.array(y_prob) > 0.5)
0.0
>>> brier_score_loss(y_true, y_prob, scale_by_half=False)
0.075
>>> brier_score_loss(
...    ["eggs", "ham", "spam"],
...    [[0.8, 0.1, 0.1], [0.2, 0.7, 0.1], [0.2, 0.2, 0.6]],
...    labels=["eggs", "ham", "spam"]
... )
0.146
```

---

## RBF#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.gaussian_process.kernels.RBF.html

**Contents:**
- RBF#
- Gallery examples#

Radial basis function kernel (aka squared-exponential kernel).

The RBF kernel is a stationary kernel. It is also known as the “squared exponential” kernel. It is parameterized by a length scale parameter \(l>0\), which can either be a scalar (isotropic variant of the kernel) or a vector with the same number of dimensions as the inputs X (anisotropic variant of the kernel). The kernel is given by:

where \(l\) is the length scale of the kernel and \(d(\cdot,\cdot)\) is the Euclidean distance. For advice on how to set the length scale parameter, see e.g. [1].

This kernel is infinitely differentiable, which implies that GPs with this kernel as covariance function have mean square derivatives of all orders, and are thus very smooth. See [2], Chapter 4, Section 4.2, for further details of the RBF kernel.

Read more in the User Guide.

Added in version 0.18.

The length scale of the kernel. If a float, an isotropic kernel is used. If an array, an anisotropic kernel is used where each dimension of l defines the length-scale of the respective feature dimension.

The lower and upper bound on ‘length_scale’. If set to “fixed”, ‘length_scale’ cannot be changed during hyperparameter tuning.

David Duvenaud (2014). “The Kernel Cookbook: Advice on Covariance functions”.

Carl Edward Rasmussen, Christopher K. I. Williams (2006). “Gaussian Processes for Machine Learning”. The MIT Press.

Return the kernel k(X, Y) and optionally its gradient.

Left argument of the returned kernel k(X, Y)

Right argument of the returned kernel k(X, Y). If None, k(X, X) if evaluated instead.

Determines whether the gradient with respect to the log of the kernel hyperparameter is computed. Only supported when Y is None.

The gradient of the kernel k(X, X) with respect to the log of the hyperparameter of the kernel. Only returned when eval_gradient is True.

Returns the log-transformed bounds on the theta.

The log-transformed bounds on the kernel’s hyperparameters theta

Returns a clone of self with given hyperparameters theta.

Returns the diagonal of the kernel k(X, X).

The result of this method is identical to np.diag(self(X)); however, it can be evaluated more efficiently since only the diagonal is evaluated.

Left argument of the returned kernel k(X, Y)

Diagonal of kernel k(X, X)

Get parameters of this kernel.

If True, will return the parameters for this estimator and contained subobjects that are estimators.

Parameter names mapped to their values.

Returns a list of all hyperparameter specifications.

Returns whether the kernel is stationary.

Returns the number of non-fixed hyperparameters of the kernel.

Returns whether the kernel is defined on fixed-length feature vectors or generic objects. Defaults to True for backward compatibility.

Set the parameters of this kernel.

The method works on simple kernels as well as on nested kernels. The latter have parameters of the form <component>__<parameter> so that it’s possible to update each component of a nested object.

Returns the (flattened, log-transformed) non-fixed hyperparameters.

Note that theta are typically the log-transformed values of the kernel’s hyperparameters as this representation of the search space is more amenable for hyperparameter search, as hyperparameters like length-scales naturally live on a log-scale.

The non-fixed, log-transformed hyperparameters of the kernel

Plot classification probability

Classifier comparison

Comparison of kernel ridge and Gaussian process regression

Probabilistic predictions with Gaussian process classification (GPC)

Gaussian process classification (GPC) on iris dataset

Illustration of Gaussian process classification (GPC) on the XOR dataset

Forecasting of CO2 level on Mona Loa dataset using Gaussian process regression (GPR)

Ability of Gaussian process regression (GPR) to estimate data noise-level

Gaussian Processes regression: basic introductory example

Illustration of prior and posterior Gaussian process for different kernels

**Examples:**

Example 1 (json):
```json
>>> from sklearn.datasets import load_iris
>>> from sklearn.gaussian_process import GaussianProcessClassifier
>>> from sklearn.gaussian_process.kernels import RBF
>>> X, y = load_iris(return_X_y=True)
>>> kernel = 1.0 * RBF(1.0)
>>> gpc = GaussianProcessClassifier(kernel=kernel,
...         random_state=0).fit(X, y)
>>> gpc.score(X, y)
0.9866
>>> gpc.predict_proba(X[:2,:])
array([[0.8354, 0.03228, 0.1322],
       [0.7906, 0.0652, 0.1441]])
```

---

## 

**URL:** https://scikit-learn.org/stable/_sources/modules/naive_bayes.rst.txt

---

## log_loss#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.metrics.log_loss.html

**Contents:**
- log_loss#
- Gallery examples#

Log loss, aka logistic loss or cross-entropy loss.

This is the loss function used in (multinomial) logistic regression and extensions of it such as neural networks, defined as the negative log-likelihood of a logistic model that returns y_pred probabilities for its training data y_true. The log loss is only defined for two or more labels. For a single sample with true label \(y \in \{0,1\}\) and a probability estimate \(p = \operatorname{Pr}(y = 1)\), the log loss is:

Read more in the User Guide.

Ground truth (correct) labels for n_samples samples.

Predicted probabilities, as returned by a classifier’s predict_proba method. If y_pred.shape = (n_samples,) the probabilities provided are assumed to be that of the positive class. The labels in y_pred are assumed to be ordered alphabetically, as done by LabelBinarizer.

y_pred values are clipped to [eps, 1-eps] where eps is the machine precision for y_pred’s dtype.

If true, return the mean loss per sample. Otherwise, return the sum of the per-sample losses.

If not provided, labels will be inferred from y_true. If labels is None and y_pred has shape (n_samples,) the labels are assumed to be binary and are inferred from y_true.

Added in version 0.18.

Log loss, aka logistic loss or cross-entropy loss.

The logarithm used is the natural logarithm (base-e).

C.M. Bishop (2006). Pattern Recognition and Machine Learning. Springer, p. 209.

Probability Calibration curves

Probability Calibration for 3-class classification

Plot classification probability

Gradient Boosting Out-of-Bag estimates

Gradient Boosting regularization

Probabilistic predictions with Gaussian process classification (GPC)

Importance of Feature Scaling

**Examples:**

Example 1 (sql):
```sql
>>> from sklearn.metrics import log_loss
>>> log_loss(["spam", "ham", "ham", "spam"],
...          [[.1, .9], [.9, .1], [.8, .2], [.35, .65]])
0.21616
```

---

## MLPClassifier#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html

**Contents:**
- MLPClassifier#
- Gallery examples#

Multi-layer Perceptron classifier.

This model optimizes the log-loss function using LBFGS or stochastic gradient descent.

Added in version 0.18.

The ith element represents the number of neurons in the ith hidden layer.

Activation function for the hidden layer.

‘identity’, no-op activation, useful to implement linear bottleneck, returns f(x) = x

‘logistic’, the logistic sigmoid function, returns f(x) = 1 / (1 + exp(-x)).

‘tanh’, the hyperbolic tan function, returns f(x) = tanh(x).

‘relu’, the rectified linear unit function, returns f(x) = max(0, x)

The solver for weight optimization.

‘lbfgs’ is an optimizer in the family of quasi-Newton methods.

‘sgd’ refers to stochastic gradient descent.

‘adam’ refers to a stochastic gradient-based optimizer proposed by Kingma, Diederik, and Jimmy Ba

For a comparison between Adam optimizer and SGD, see Compare Stochastic learning strategies for MLPClassifier.

Note: The default solver ‘adam’ works pretty well on relatively large datasets (with thousands of training samples or more) in terms of both training time and validation score. For small datasets, however, ‘lbfgs’ can converge faster and perform better.

Strength of the L2 regularization term. The L2 regularization term is divided by the sample size when added to the loss.

For an example usage and visualization of varying regularization, see Varying regularization in Multi-layer Perceptron.

Size of minibatches for stochastic optimizers. If the solver is ‘lbfgs’, the classifier will not use minibatch. When set to “auto”, batch_size=min(200, n_samples).

Learning rate schedule for weight updates.

‘constant’ is a constant learning rate given by ‘learning_rate_init’.

‘invscaling’ gradually decreases the learning rate at each time step ‘t’ using an inverse scaling exponent of ‘power_t’. effective_learning_rate = learning_rate_init / pow(t, power_t)

‘adaptive’ keeps the learning rate constant to ‘learning_rate_init’ as long as training loss keeps decreasing. Each time two consecutive epochs fail to decrease training loss by at least tol, or fail to increase validation score by at least tol if ‘early_stopping’ is on, the current learning rate is divided by 5.

Only used when solver='sgd'.

The initial learning rate used. It controls the step-size in updating the weights. Only used when solver=’sgd’ or ‘adam’.

The exponent for inverse scaling learning rate. It is used in updating effective learning rate when the learning_rate is set to ‘invscaling’. Only used when solver=’sgd’.

Maximum number of iterations. The solver iterates until convergence (determined by ‘tol’) or this number of iterations. For stochastic solvers (‘sgd’, ‘adam’), note that this determines the number of epochs (how many times each data point will be used), not the number of gradient steps.

Whether to shuffle samples in each iteration. Only used when solver=’sgd’ or ‘adam’.

Determines random number generation for weights and bias initialization, train-test split if early stopping is used, and batch sampling when solver=’sgd’ or ‘adam’. Pass an int for reproducible results across multiple function calls. See Glossary.

Tolerance for the optimization. When the loss or score is not improving by at least tol for n_iter_no_change consecutive iterations, unless learning_rate is set to ‘adaptive’, convergence is considered to be reached and training stops.

Whether to print progress messages to stdout.

When set to True, reuse the solution of the previous call to fit as initialization, otherwise, just erase the previous solution. See the Glossary.

Momentum for gradient descent update. Should be between 0 and 1. Only used when solver=’sgd’.

Whether to use Nesterov’s momentum. Only used when solver=’sgd’ and momentum > 0.

Whether to use early stopping to terminate training when validation score is not improving. If set to True, it will automatically set aside validation_fraction of training data as validation and terminate training when validation score is not improving by at least tol for n_iter_no_change consecutive epochs. The split is stratified, except in a multilabel setting. If early stopping is False, then the training stops when the training loss does not improve by more than tol for n_iter_no_change consecutive passes over the training set. Only effective when solver=’sgd’ or ‘adam’.

The proportion of training data to set aside as validation set for early stopping. Must be between 0 and 1. Only used if early_stopping is True.

Exponential decay rate for estimates of first moment vector in adam, should be in [0, 1). Only used when solver=’adam’.

Exponential decay rate for estimates of second moment vector in adam, should be in [0, 1). Only used when solver=’adam’.

Value for numerical stability in adam. Only used when solver=’adam’.

Maximum number of epochs to not meet tol improvement. Only effective when solver=’sgd’ or ‘adam’.

Added in version 0.20.

Only used when solver=’lbfgs’. Maximum number of loss function calls. The solver iterates until convergence (determined by ‘tol’), number of iterations reaches max_iter, or this number of loss function calls. Note that number of loss function calls will be greater than or equal to the number of iterations for the MLPClassifier.

Added in version 0.22.

Class labels for each output.

The current loss computed with the loss function.

The minimum loss reached by the solver throughout fitting. If early_stopping=True, this attribute is set to None. Refer to the best_validation_score_ fitted attribute instead.

The ith element in the list represents the loss at the ith iteration.

The score at each iteration on a held-out validation set. The score reported is the accuracy score. Only available if early_stopping=True, otherwise the attribute is set to None.

The best validation score (i.e. accuracy score) that triggered the early stopping. Only available if early_stopping=True, otherwise the attribute is set to None.

The number of training samples seen by the solver during fitting.

The ith element in the list represents the weight matrix corresponding to layer i.

The ith element in the list represents the bias vector corresponding to layer i + 1.

Number of features seen during fit.

Added in version 0.24.

Names of features seen during fit. Defined only when X has feature names that are all strings.

Added in version 1.0.

The number of iterations the solver has run.

Name of the output activation function.

Multi-layer Perceptron regressor.

Bernoulli Restricted Boltzmann Machine (RBM).

MLPClassifier trains iteratively since at each time step the partial derivatives of the loss function with respect to the model parameters are computed to update the parameters.

It can also have a regularization term added to the loss function that shrinks model parameters to prevent overfitting.

This implementation works with data represented as dense numpy arrays or sparse scipy arrays of floating point values.

Hinton, Geoffrey E. “Connectionist learning procedures.” Artificial intelligence 40.1 (1989): 185-234.

Glorot, Xavier, and Yoshua Bengio. “Understanding the difficulty of training deep feedforward neural networks.” International Conference on Artificial Intelligence and Statistics. 2010.

He, Kaiming, et al (2015). “Delving deep into rectifiers: Surpassing human-level performance on imagenet classification.”

Kingma, Diederik, and Jimmy Ba (2014) “Adam: A method for stochastic optimization.”

Fit the model to data matrix X and target(s) y.

The target values (class labels in classification, real numbers in regression).

Added in version 1.7.

Returns a trained MLP model.

Get metadata routing of this object.

Please check User Guide on how the routing mechanism works.

A MetadataRequest encapsulating routing information.

Get parameters for this estimator.

If True, will return the parameters for this estimator and contained subobjects that are estimators.

Parameter names mapped to their values.

Update the model with a single iteration over the given data.

Added in version 1.7.

Classes across all calls to partial_fit. Can be obtained via np.unique(y_all), where y_all is the target vector of the entire dataset. This argument is required for the first call to partial_fit and can be omitted in the subsequent calls. Note that y doesn’t need to contain all labels in classes.

Predict using the multi-layer perceptron classifier.

The predicted classes.

Return the log of probability estimates.

The predicted log-probability of the sample for each class in the model, where classes are ordered as they are in self.classes_. Equivalent to log(predict_proba(X)).

Probability estimates.

The predicted probability of the sample for each class in the model, where classes are ordered as they are in self.classes_.

Return accuracy on provided data and labels.

In multi-label classification, this is the subset accuracy which is a harsh metric since you require for each sample that each label set be correctly predicted.

Mean accuracy of self.predict(X) w.r.t. y.

Configure whether metadata should be requested to be passed to the fit method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to fit if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to fit.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Added in version 1.3.

Metadata routing for sample_weight parameter in fit.

Set the parameters of this estimator.

The method works on simple estimators as well as on nested objects (such as Pipeline). The latter have parameters of the form <component>__<parameter> so that it’s possible to update each component of a nested object.

Estimator parameters.

Configure whether metadata should be requested to be passed to the partial_fit method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to partial_fit if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to partial_fit.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Added in version 1.3.

Metadata routing for classes parameter in partial_fit.

Metadata routing for sample_weight parameter in partial_fit.

Configure whether metadata should be requested to be passed to the score method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to score if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to score.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Added in version 1.3.

Metadata routing for sample_weight parameter in score.

Classifier comparison

Varying regularization in Multi-layer Perceptron

Compare Stochastic learning strategies for MLPClassifier

Visualization of MLP weights on MNIST

**Examples:**

Example 1 (sql):
```sql
>>> from sklearn.neural_network import MLPClassifier
>>> from sklearn.datasets import make_classification
>>> from sklearn.model_selection import train_test_split
>>> X, y = make_classification(n_samples=100, random_state=1)
>>> X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y,
...                                                     random_state=1)
>>> clf = MLPClassifier(random_state=1, max_iter=300).fit(X_train, y_train)
>>> clf.predict_proba(X_test[:1])
array([[0.0383, 0.961]])
>>> clf.predict(X_test[:5, :])
array([1, 0, 1, 0, 1])
>>> clf.score(X_test, y_test)
0.8...
```

---

## 7.1. Pipelines and composite estimators#

**URL:** https://scikit-learn.org/stable/modules/compose.html

**Contents:**
- 7.1. Pipelines and composite estimators#
- 7.1.1. Pipeline: chaining estimators#
  - 7.1.1.1. Usage#
    - 7.1.1.1.1. Build a pipeline#
    - 7.1.1.1.2. Access pipeline steps#
    - 7.1.1.1.3. Tracking feature names in a pipeline#
    - 7.1.1.1.4. Access to nested parameters#
  - 7.1.1.2. Caching transformers: avoid repeated computation#
- 7.1.2. Transforming target in regression#
- 7.1.3. FeatureUnion: composite feature spaces#

To build a composite estimator, transformers are usually combined with other transformers or with predictors (such as classifiers or regressors). The most common tool used for composing estimators is a Pipeline. Pipelines require all steps except the last to be a transformer. The last step can be anything, a transformer, a predictor, or a clustering estimator which might have or not have a .predict(...) method. A pipeline exposes all methods provided by the last estimator: if the last step provides a transform method, then the pipeline would have a transform method and behave like a transformer. If the last step provides a predict method, then the pipeline would expose that method, and given a data X, use all steps except the last to transform the data, and then give that transformed data to the predict method of the last step of the pipeline. The class Pipeline is often used in combination with ColumnTransformer or FeatureUnion which concatenate the output of transformers into a composite feature space. TransformedTargetRegressor deals with transforming the target (i.e. log-transform y).

Pipeline can be used to chain multiple estimators into one. This is useful as there is often a fixed sequence of steps in processing the data, for example feature selection, normalization and classification. Pipeline serves multiple purposes here:

You only have to call fit and predict once on your data to fit a whole sequence of estimators.

You can grid search over parameters of all estimators in the pipeline at once.

Pipelines help avoid leaking statistics from your test data into the trained model in cross-validation, by ensuring that the same samples are used to train the transformers and predictors.

All estimators in a pipeline, except the last one, must be transformers (i.e. must have a transform method). The last estimator may be any type (transformer, classifier, etc.).

Calling fit on the pipeline is the same as calling fit on each estimator in turn, transform the input and pass it on to the next step. The pipeline has all the methods that the last estimator in the pipeline has, i.e. if the last estimator is a classifier, the Pipeline can be used as a classifier. If the last estimator is a transformer, again, so is the pipeline.

The Pipeline is built using a list of (key, value) pairs, where the key is a string containing the name you want to give this step and value is an estimator object:

The utility function make_pipeline is a shorthand for constructing pipelines; it takes a variable number of estimators and returns a pipeline, filling in the names automatically:

The estimators of a pipeline are stored as a list in the steps attribute. A sub-pipeline can be extracted using the slicing notation commonly used for Python Sequences such as lists or strings (although only a step of 1 is permitted). This is convenient for performing only some of the transformations (or their inverse):

A specific step can also be accessed by index or name by indexing (with [idx]) the pipeline:

Pipeline’s named_steps attribute allows accessing steps by name with tab completion in interactive environments:

To enable model inspection, Pipeline has a get_feature_names_out() method, just like all transformers. You can use pipeline slicing to get the feature names going into each step:

You can also provide custom feature names for the input data using get_feature_names_out:

It is common to adjust the parameters of an estimator within a pipeline. This parameter is therefore nested because it belongs to a particular sub-step. Parameters of the estimators in the pipeline are accessible using the <estimator>__<parameter> syntax:

This is particularly important for doing grid searches:

Individual steps may also be replaced as parameters, and non-final steps may be ignored by setting them to 'passthrough':

Composite estimators and parameter spaces

Sample pipeline for text feature extraction and evaluation

Pipelining: chaining a PCA and a logistic regression

Explicit feature map approximation for RBF kernels

SVM-Anova: SVM with univariate feature selection

Selecting dimensionality reduction with Pipeline and GridSearchCV

Fitting transformers may be computationally expensive. With its memory parameter set, Pipeline will cache each transformer after calling fit. This feature is used to avoid computing the fit transformers within a pipeline if the parameters and input data are identical. A typical example is the case of a grid search in which the transformers can be fitted only once and reused for each configuration. The last step will never be cached, even if it is a transformer.

The parameter memory is needed in order to cache the transformers. memory can be either a string containing the directory where to cache the transformers or a joblib.Memory object:

Using a Pipeline without cache enabled, it is possible to inspect the original instance such as:

Enabling caching triggers a clone of the transformers before fitting. Therefore, the transformer instance given to the pipeline cannot be inspected directly. In the following example, accessing the PCA instance pca2 will raise an AttributeError since pca2 will be an unfitted transformer. Instead, use the attribute named_steps to inspect estimators within the pipeline:

Selecting dimensionality reduction with Pipeline and GridSearchCV

TransformedTargetRegressor transforms the targets y before fitting a regression model. The predictions are mapped back to the original space via an inverse transform. It takes as an argument the regressor that will be used for prediction, and the transformer that will be applied to the target variable:

For simple transformations, instead of a Transformer object, a pair of functions can be passed, defining the transformation and its inverse mapping:

Subsequently, the object is created as:

By default, the provided functions are checked at each fit to be the inverse of each other. However, it is possible to bypass this checking by setting check_inverse to False:

The transformation can be triggered by setting either transformer or the pair of functions func and inverse_func. However, setting both options will raise an error.

Effect of transforming the targets in regression model

FeatureUnion combines several transformer objects into a new transformer that combines their output. A FeatureUnion takes a list of transformer objects. During fitting, each of these is fit to the data independently. The transformers are applied in parallel, and the feature matrices they output are concatenated side-by-side into a larger matrix.

When you want to apply different transformations to each field of the data, see the related class ColumnTransformer (see user guide).

FeatureUnion serves the same purposes as Pipeline - convenience and joint parameter estimation and validation.

FeatureUnion and Pipeline can be combined to create complex models.

(A FeatureUnion has no way of checking whether two transformers might produce identical features. It only produces a union when the feature sets are disjoint, and making sure they are is the caller’s responsibility.)

A FeatureUnion is built using a list of (key, value) pairs, where the key is the name you want to give to a given transformation (an arbitrary string; it only serves as an identifier) and value is an estimator object:

Like pipelines, feature unions have a shorthand constructor called make_union that does not require explicit naming of the components.

Like Pipeline, individual steps may be replaced using set_params, and ignored by setting to 'drop':

Concatenating multiple feature extraction methods

Many datasets contain features of different types, say text, floats, and dates, where each type of feature requires separate preprocessing or feature extraction steps. Often it is easiest to preprocess data before applying scikit-learn methods, for example using pandas. Processing your data before passing it to scikit-learn might be problematic for one of the following reasons:

Incorporating statistics from test data into the preprocessors makes cross-validation scores unreliable (known as data leakage), for example in the case of scalers or imputing missing values.

You may want to include the parameters of the preprocessors in a parameter search.

The ColumnTransformer helps performing different transformations for different columns of the data, within a Pipeline that is safe from data leakage and that can be parametrized. ColumnTransformer works on arrays, sparse matrices, and pandas DataFrames.

To each column, a different transformation can be applied, such as preprocessing or a specific feature extraction method:

For this data, we might want to encode the 'city' column as a categorical variable using OneHotEncoder but apply a CountVectorizer to the 'title' column. As we might use multiple feature extraction methods on the same column, we give each transformer a unique name, say 'city_category' and 'title_bow'. By default, the remaining rating columns are ignored (remainder='drop'):

In the above example, the CountVectorizer expects a 1D array as input and therefore the columns were specified as a string ('title'). However, OneHotEncoder as most of other transformers expects 2D data, therefore in that case you need to specify the column as a list of strings (['city']).

Apart from a scalar or a single item list, the column selection can be specified as a list of multiple items, an integer array, a slice, a boolean mask, or with a make_column_selector. The make_column_selector is used to select columns based on data type or column name:

Strings can reference columns if the input is a DataFrame, integers are always interpreted as the positional columns.

We can keep the remaining rating columns by setting remainder='passthrough'. The values are appended to the end of the transformation:

The remainder parameter can be set to an estimator to transform the remaining rating columns. The transformed values are appended to the end of the transformation:

The make_column_transformer function is available to more easily create a ColumnTransformer object. Specifically, the names will be given automatically. The equivalent for the above example would be:

If ColumnTransformer is fitted with a dataframe and the dataframe only has string column names, then transforming a dataframe will use the column names to select the columns:

Estimators are displayed with an HTML representation when shown in a jupyter notebook. This is useful to diagnose or visualize a Pipeline with many estimators. This visualization is activated by default:

It can be deactivated by setting the display option in set_config to ‘text’:

An example of the HTML output can be seen in the HTML representation of Pipeline section of Column Transformer with Mixed Types. As an alternative, the HTML can be written to a file using estimator_html_repr:

Column Transformer with Heterogeneous Data Sources

Column Transformer with Mixed Types

**Examples:**

Example 1 (sql):
```sql
>>> from sklearn.pipeline import Pipeline
>>> from sklearn.svm import SVC
>>> from sklearn.decomposition import PCA
>>> estimators = [('reduce_dim', PCA()), ('clf', SVC())]
>>> pipe = Pipeline(estimators)
>>> pipe
Pipeline(steps=[('reduce_dim', PCA()), ('clf', SVC())])
```

Example 2 (sql):
```sql
>>> from sklearn.pipeline import make_pipeline
>>> make_pipeline(PCA(), SVC())
Pipeline(steps=[('pca', PCA()), ('svc', SVC())])
```

Example 3 (json):
```json
>>> pipe[:1]
Pipeline(steps=[('reduce_dim', PCA())])
>>> pipe[-1:]
Pipeline(steps=[('clf', SVC())])
```

Example 4 (unknown):
```unknown
>>> pipe.steps[0]
('reduce_dim', PCA())
>>> pipe[0]
PCA()
>>> pipe['reduce_dim']
PCA()
```

---

## 7.3. Preprocessing data#

**URL:** https://scikit-learn.org/stable/modules/preprocessing.html

**Contents:**
- 7.3. Preprocessing data#
- 7.3.1. Standardization, or mean removal and variance scaling#
  - 7.3.1.1. Scaling features to a range#
  - 7.3.1.2. Scaling sparse data#
  - 7.3.1.3. Scaling data with outliers#
  - 7.3.1.4. Centering kernel matrices#
- 7.3.2. Non-linear transformation#
  - 7.3.2.1. Mapping to a Uniform distribution#
  - 7.3.2.2. Mapping to a Gaussian distribution#
- 7.3.3. Normalization#

The sklearn.preprocessing package provides several common utility functions and transformer classes to change raw feature vectors into a representation that is more suitable for the downstream estimators.

In general, many learning algorithms such as linear models benefit from standardization of the data set (see Importance of Feature Scaling). If some outliers are present in the set, robust scalers or other transformers can be more appropriate. The behaviors of the different scalers, transformers, and normalizers on a dataset containing marginal outliers are highlighted in Compare the effect of different scalers on data with outliers.

Standardization of datasets is a common requirement for many machine learning estimators implemented in scikit-learn; they might behave badly if the individual features do not more or less look like standard normally distributed data: Gaussian with zero mean and unit variance.

In practice we often ignore the shape of the distribution and just transform the data to center it by removing the mean value of each feature, then scale it by dividing non-constant features by their standard deviation.

For instance, many elements used in the objective function of a learning algorithm (such as the RBF kernel of Support Vector Machines or the l1 and l2 regularizers of linear models) may assume that all features are centered around zero or have variance in the same order. If a feature has a variance that is orders of magnitude larger than others, it might dominate the objective function and make the estimator unable to learn from other features correctly as expected.

The preprocessing module provides the StandardScaler utility class, which is a quick and easy way to perform the following operation on an array-like dataset:

Scaled data has zero mean and unit variance:

This class implements the Transformer API to compute the mean and standard deviation on a training set so as to be able to later re-apply the same transformation on the testing set. This class is hence suitable for use in the early steps of a Pipeline:

It is possible to disable either centering or scaling by either passing with_mean=False or with_std=False to the constructor of StandardScaler.

An alternative standardization is scaling features to lie between a given minimum and maximum value, often between zero and one, or so that the maximum absolute value of each feature is scaled to unit size. This can be achieved using MinMaxScaler or MaxAbsScaler, respectively.

The motivation to use this scaling includes robustness to very small standard deviations of features and preserving zero entries in sparse data.

Here is an example to scale a toy data matrix to the [0, 1] range:

The same instance of the transformer can then be applied to some new test data unseen during the fit call: the same scaling and shifting operations will be applied to be consistent with the transformation performed on the train data:

It is possible to introspect the scaler attributes to find about the exact nature of the transformation learned on the training data:

If MinMaxScaler is given an explicit feature_range=(min, max) the full formula is:

MaxAbsScaler works in a very similar fashion, but scales in a way that the training data lies within the range [-1, 1] by dividing through the largest maximum value in each feature. It is meant for data that is already centered at zero or sparse data.

Here is how to use the toy data from the previous example with this scaler:

Centering sparse data would destroy the sparseness structure in the data, and thus rarely is a sensible thing to do. However, it can make sense to scale sparse inputs, especially if features are on different scales.

MaxAbsScaler was specifically designed for scaling sparse data, and is the recommended way to go about this. However, StandardScaler can accept scipy.sparse matrices as input, as long as with_mean=False is explicitly passed to the constructor. Otherwise a ValueError will be raised as silently centering would break the sparsity and would often crash the execution by allocating excessive amounts of memory unintentionally. RobustScaler cannot be fitted to sparse inputs, but you can use the transform method on sparse inputs.

Note that the scalers accept both Compressed Sparse Rows and Compressed Sparse Columns format (see scipy.sparse.csr_matrix and scipy.sparse.csc_matrix). Any other sparse input will be converted to the Compressed Sparse Rows representation. To avoid unnecessary memory copies, it is recommended to choose the CSR or CSC representation upstream.

Finally, if the centered data is expected to be small enough, explicitly converting the input to an array using the toarray method of sparse matrices is another option.

If your data contains many outliers, scaling using the mean and variance of the data is likely to not work very well. In these cases, you can use RobustScaler as a drop-in replacement instead. It uses more robust estimates for the center and range of your data.

Further discussion on the importance of centering and scaling data is available on this FAQ: Should I normalize/standardize/rescale the data?

It is sometimes not enough to center and scale the features independently, since a downstream model can further make some assumption on the linear independence of the features.

To address this issue you can use PCA with whiten=True to further remove the linear correlation across features.

If you have a kernel matrix of a kernel \(K\) that computes a dot product in a feature space (possibly implicitly) defined by a function \(\phi(\cdot)\), a KernelCenterer can transform the kernel matrix so that it contains inner products in the feature space defined by \(\phi\) followed by the removal of the mean in that space. In other words, KernelCenterer computes the centered Gram matrix associated to a positive semidefinite kernel \(K\).

We can have a look at the mathematical formulation now that we have the intuition. Let \(K\) be a kernel matrix of shape (n_samples, n_samples) computed from \(X\), a data matrix of shape (n_samples, n_features), during the fit step. \(K\) is defined by

\(\phi(X)\) is a function mapping of \(X\) to a Hilbert space. A centered kernel \(\tilde{K}\) is defined as:

where \(\tilde{\phi}(X)\) results from centering \(\phi(X)\) in the Hilbert space.

Thus, one could compute \(\tilde{K}\) by mapping \(X\) using the function \(\phi(\cdot)\) and center the data in this new space. However, kernels are often used because they allow some algebra calculations that avoid computing explicitly this mapping using \(\phi(\cdot)\). Indeed, one can implicitly center as shown in Appendix B in [Scholkopf1998]:

\(1_{\text{n}_{samples}}\) is a matrix of (n_samples, n_samples) where all entries are equal to \(\frac{1}{\text{n}_{samples}}\). In the transform step, the kernel becomes \(K_{test}(X, Y)\) defined as:

\(Y\) is the test dataset of shape (n_samples_test, n_features) and thus \(K_{test}\) is of shape (n_samples_test, n_samples). In this case, centering \(K_{test}\) is done as:

\(1'_{\text{n}_{samples}}\) is a matrix of shape (n_samples_test, n_samples) where all entries are equal to \(\frac{1}{\text{n}_{samples}}\).

B. Schölkopf, A. Smola, and K.R. Müller, “Nonlinear component analysis as a kernel eigenvalue problem.” Neural computation 10.5 (1998): 1299-1319.

Two types of transformations are available: quantile transforms and power transforms. Both quantile and power transforms are based on monotonic transformations of the features and thus preserve the rank of the values along each feature.

Quantile transforms put all features into the same desired distribution based on the formula \(G^{-1}(F(X))\) where \(F\) is the cumulative distribution function of the feature and \(G^{-1}\) the quantile function of the desired output distribution \(G\). This formula is using the two following facts: (i) if \(X\) is a random variable with a continuous cumulative distribution function \(F\) then \(F(X)\) is uniformly distributed on \([0,1]\); (ii) if \(U\) is a random variable with uniform distribution on \([0,1]\) then \(G^{-1}(U)\) has distribution \(G\). By performing a rank transformation, a quantile transform smooths out unusual distributions and is less influenced by outliers than scaling methods. It does, however, distort correlations and distances within and across features.

Power transforms are a family of parametric transformations that aim to map data from any distribution to as close to a Gaussian distribution.

QuantileTransformer provides a non-parametric transformation to map the data to a uniform distribution with values between 0 and 1:

This feature corresponds to the sepal length in cm. Once the quantile transformation is applied, those landmarks approach closely the percentiles previously defined:

This can be confirmed on an independent testing set with similar remarks:

In many modeling scenarios, normality of the features in a dataset is desirable. Power transforms are a family of parametric, monotonic transformations that aim to map data from any distribution to as close to a Gaussian distribution as possible in order to stabilize variance and minimize skewness.

PowerTransformer currently provides two such power transformations, the Yeo-Johnson transform and the Box-Cox transform.

Box-Cox can only be applied to strictly positive data. In both methods, the transformation is parameterized by \(\lambda\), which is determined through maximum likelihood estimation. Here is an example of using Box-Cox to map samples drawn from a lognormal distribution to a normal distribution:

While the above example sets the standardize option to False, PowerTransformer will apply zero-mean, unit-variance normalization to the transformed output by default.

Below are examples of Box-Cox and Yeo-Johnson applied to various probability distributions. Note that when applied to certain distributions, the power transforms achieve very Gaussian-like results, but with others, they are ineffective. This highlights the importance of visualizing the data before and after transformation.

It is also possible to map data to a normal distribution using QuantileTransformer by setting output_distribution='normal'. Using the earlier example with the iris dataset:

Thus the median of the input becomes the mean of the output, centered at 0. The normal output is clipped so that the input’s minimum and maximum — corresponding to the 1e-7 and 1 - 1e-7 quantiles respectively — do not become infinite under the transformation.

Normalization is the process of scaling individual samples to have unit norm. This process can be useful if you plan to use a quadratic form such as the dot-product or any other kernel to quantify the similarity of any pair of samples.

This assumption is the base of the Vector Space Model often used in text classification and clustering contexts.

The function normalize provides a quick and easy way to perform this operation on a single array-like dataset, either using the l1, l2, or max norms:

The preprocessing module further provides a utility class Normalizer that implements the same operation using the Transformer API (even though the fit method is useless in this case: the class is stateless as this operation treats samples independently).

This class is hence suitable for use in the early steps of a Pipeline:

The normalizer instance can then be used on sample vectors as any transformer:

Note: L2 normalization is also known as spatial sign preprocessing.

normalize and Normalizer accept both dense array-like and sparse matrices from scipy.sparse as input.

For sparse input the data is converted to the Compressed Sparse Rows representation (see scipy.sparse.csr_matrix) before being fed to efficient Cython routines. To avoid unnecessary memory copies, it is recommended to choose the CSR representation upstream.

Often features are not given as continuous values but categorical. For example a person could have features ["male", "female"], ["from Europe", "from US", "from Asia"], ["uses Firefox", "uses Chrome", "uses Safari", "uses Internet Explorer"]. Such features can be efficiently coded as integers, for instance ["male", "from US", "uses Internet Explorer"] could be expressed as [0, 1, 3] while ["female", "from Asia", "uses Chrome"] would be [1, 2, 1].

To convert categorical features to such integer codes, we can use the OrdinalEncoder. This estimator transforms each categorical feature to one new feature of integers (0 to n_categories - 1):

Such integer representation can, however, not be used directly with all scikit-learn estimators, as these expect continuous input, and would interpret the categories as being ordered, which is often not desired (i.e. the set of browsers was ordered arbitrarily).

By default, OrdinalEncoder will also passthrough missing values that are indicated by np.nan.

OrdinalEncoder provides a parameter encoded_missing_value to encode the missing values without the need to create a pipeline and using SimpleImputer.

The above processing is equivalent to the following pipeline:

Another possibility to convert categorical features to features that can be used with scikit-learn estimators is to use a one-of-K, also known as one-hot or dummy encoding. This type of encoding can be obtained with the OneHotEncoder, which transforms each categorical feature with n_categories possible values into n_categories binary features, with one of them 1, and all others 0.

Continuing the example above:

By default, the values each feature can take is inferred automatically from the dataset and can be found in the categories_ attribute:

It is possible to specify this explicitly using the parameter categories. There are two genders, four possible continents and four web browsers in our dataset:

If there is a possibility that the training data might have missing categorical features, it can often be better to specify handle_unknown='infrequent_if_exist' instead of setting the categories manually as above. When handle_unknown='infrequent_if_exist' is specified and unknown categories are encountered during transform, no error will be raised but the resulting one-hot encoded columns for this feature will be all zeros or considered as an infrequent category if enabled. (handle_unknown='infrequent_if_exist' is only supported for one-hot encoding):

It is also possible to encode each column into n_categories - 1 columns instead of n_categories columns by using the drop parameter. This parameter allows the user to specify a category for each feature to be dropped. This is useful to avoid co-linearity in the input matrix in some classifiers. Such functionality is useful, for example, when using non-regularized regression (LinearRegression), since co-linearity would cause the covariance matrix to be non-invertible:

One might want to drop one of the two columns only for features with 2 categories. In this case, you can set the parameter drop='if_binary'.

In the transformed X, the first column is the encoding of the feature with categories “male”/”female”, while the remaining 6 columns are the encoding of the 2 features with respectively 3 categories each.

When handle_unknown='ignore' and drop is not None, unknown categories will be encoded as all zeros:

All the categories in X_test are unknown during transform and will be mapped to all zeros. This means that unknown categories will have the same mapping as the dropped category. OneHotEncoder.inverse_transform will map all zeros to the dropped category if a category is dropped and None if a category is not dropped:

OneHotEncoder supports categorical features with missing values by considering the missing values as an additional category:

If a feature contains both np.nan and None, they will be considered separate categories:

See Loading features from dicts for categorical features that are represented as a dict, not as scalars.

OneHotEncoder and OrdinalEncoder support aggregating infrequent categories into a single output for each feature. The parameters to enable the gathering of infrequent categories are min_frequency and max_categories.

min_frequency is either an integer greater or equal to 1, or a float in the interval (0.0, 1.0). If min_frequency is an integer, categories with a cardinality smaller than min_frequency will be considered infrequent. If min_frequency is a float, categories with a cardinality smaller than this fraction of the total number of samples will be considered infrequent. The default value is 1, which means every category is encoded separately.

max_categories is either None or any integer greater than 1. This parameter sets an upper limit to the number of output features for each input feature. max_categories includes the feature that combines infrequent categories.

In the following example with OrdinalEncoder, the categories 'dog' and 'snake' are considered infrequent:

OrdinalEncoder’s max_categories do not take into account missing or unknown categories. Setting unknown_value or encoded_missing_value to an integer will increase the number of unique integer codes by one each. This can result in up to max_categories + 2 integer codes. In the following example, “a” and “d” are considered infrequent and grouped together into a single category, “b” and “c” are their own categories, unknown values are encoded as 3 and missing values are encoded as 4.

Similarly, OneHotEncoder can be configured to group together infrequent categories:

By setting handle_unknown to 'infrequent_if_exist', unknown categories will be considered infrequent:

OneHotEncoder.get_feature_names_out uses ‘infrequent’ as the infrequent feature name:

When 'handle_unknown' is set to 'infrequent_if_exist' and an unknown category is encountered in transform:

If infrequent category support was not configured or there was no infrequent category during training, the resulting one-hot encoded columns for this feature will be all zeros. In the inverse transform, an unknown category will be denoted as None.

If there is an infrequent category during training, the unknown category will be considered infrequent. In the inverse transform, ‘infrequent_sklearn’ will be used to represent the infrequent category.

Infrequent categories can also be configured using max_categories. In the following example, we set max_categories=2 to limit the number of features in the output. This will result in all but the 'cat' category to be considered infrequent, leading to two features, one for 'cat' and one for infrequent categories - which are all the others:

If both max_categories and min_frequency are non-default values, then categories are selected based on min_frequency first and max_categories categories are kept. In the following example, min_frequency=4 considers only snake to be infrequent, but max_categories=3, forces dog to also be infrequent:

If there are infrequent categories with the same cardinality at the cutoff of max_categories, then the first max_categories are taken based on lexicon ordering. In the following example, “b”, “c”, and “d”, have the same cardinality and with max_categories=2, “b” and “c” are infrequent because they have a higher lexicon order.

The TargetEncoder uses the target mean conditioned on the categorical feature for encoding unordered categories, i.e. nominal categories [PAR] [MIC]. This encoding scheme is useful with categorical features with high cardinality, where one-hot encoding would inflate the feature space making it more expensive for a downstream model to process. A classical example of high cardinality categories are location based such as zip code or region.

For the binary classification target, the target encoding is given by:

where \(S_i\) is the encoding for category \(i\), \(n_{iY}\) is the number of observations with \(Y=1\) and category \(i\), \(n_i\) is the number of observations with category \(i\), \(n_Y\) is the number of observations with \(Y=1\), \(n\) is the number of observations, and \(\lambda_i\) is a shrinkage factor for category \(i\). The shrinkage factor is given by:

where \(m\) is a smoothing factor, which is controlled with the smooth parameter in TargetEncoder. Large smoothing factors will put more weight on the global mean. When smooth="auto", the smoothing factor is computed as an empirical Bayes estimate: \(m=\sigma_i^2/\tau^2\), where \(\sigma_i^2\) is the variance of y with category \(i\) and \(\tau^2\) is the global variance of y.

For multiclass classification targets, the formulation is similar to binary classification:

where \(S_{ij}\) is the encoding for category \(i\) and class \(j\), \(n_{iY_j}\) is the number of observations with \(Y=j\) and category \(i\), \(n_i\) is the number of observations with category \(i\), \(n_{Y_j}\) is the number of observations with \(Y=j\), \(n\) is the number of observations, and \(\lambda_i\) is a shrinkage factor for category \(i\).

For continuous targets, the formulation is similar to binary classification:

where \(L_i\) is the set of observations with category \(i\) and \(n_i\) is the number of observations with category \(i\).

In TargetEncoder, fit(X, y).transform(X) does not equal fit_transform(X, y).

fit_transform internally relies on a cross fitting scheme to prevent target information from leaking into the train-time representation, especially for non-informative high-cardinality categorical variables (features with many unique categories where each category appears only a few times), and help prevent the downstream model from overfitting spurious correlations. In fit_transform, the training data is split into k folds (determined by the cv parameter) and each fold is encoded using the encodings learnt using the other k-1 folds. For this reason, training data should always be trained and transformed with fit_transform(X_train, y_train).

This diagram shows the cross fitting scheme in fit_transform with the default cv=5:

The fit method does not use any cross fitting schemes and learns one encoding on the entire training set. It is discouraged to use this method because it can introduce data leakage as mentioned above. Use fit_transform instead.

During fit_transform, the encoder learns category encodings from the full training data and stores them in the encodings_ attribute. The intermediate encodings learned for each fold during the cross fitting process are temporary and not saved. The stored encodings can then be used to transform test data with encoder.transform(X_test).

TargetEncoder considers missing values, such as np.nan or None, as another category and encodes them like any other category. Categories that are not seen during fit are encoded with the target mean, i.e. target_mean_.

Comparing Target Encoder with Other Encoders

Target Encoder’s Internal Cross fitting

Micci-Barreca, Daniele. “A preprocessing scheme for high-cardinality categorical attributes in classification and prediction problems” SIGKDD Explor. Newsl. 3, 1 (July 2001), 27-32.

Pargent, F., Pfisterer, F., Thomas, J. et al. “Regularized target encoding outperforms traditional methods in supervised machine learning with high cardinality features” Comput Stat 37, 2671-2692 (2022)

Discretization (otherwise known as quantization or binning) provides a way to partition continuous features into discrete values. Certain datasets with continuous features may benefit from discretization, because discretization can transform the dataset of continuous attributes to one with only nominal attributes.

One-hot encoded discretized features can make a model more expressive, while maintaining interpretability. For instance, pre-processing with a discretizer can introduce nonlinearity to linear models. For more advanced possibilities, in particular smooth ones, see Generating polynomial features further below.

KBinsDiscretizer discretizes features into k bins:

By default the output is one-hot encoded into a sparse matrix (See Encoding categorical features) and this can be configured with the encode parameter. For each feature, the bin edges are computed during fit and together with the number of bins, they will define the intervals. Therefore, for the current example, these intervals are defined as:

feature 1: \({[-\infty, -1), [-1, 2), [2, \infty)}\)

feature 2: \({[-\infty, 5), [5, \infty)}\)

feature 3: \({[-\infty, 14), [14, \infty)}\)

Based on these bin intervals, X is transformed as follows:

The resulting dataset contains ordinal attributes which can be further used in a Pipeline.

Discretization is similar to constructing histograms for continuous data. However, histograms focus on counting features which fall into particular bins, whereas discretization focuses on assigning feature values to these bins.

KBinsDiscretizer implements different binning strategies, which can be selected with the strategy parameter. The ‘uniform’ strategy uses constant-width bins. The ‘quantile’ strategy uses the quantiles values to have equally populated bins in each feature. The ‘kmeans’ strategy defines bins based on a k-means clustering procedure performed on each feature independently.

Be aware that one can specify custom bins by passing a callable defining the discretization strategy to FunctionTransformer. For instance, we can use the Pandas function pandas.cut:

Using KBinsDiscretizer to discretize continuous features

Feature discretization

Demonstrating the different strategies of KBinsDiscretizer

Feature binarization is the process of thresholding numerical features to get boolean values. This can be useful for downstream probabilistic estimators that make assumption that the input data is distributed according to a multi-variate Bernoulli distribution. For instance, this is the case for the BernoulliRBM.

It is also common among the text processing community to use binary feature values (probably to simplify the probabilistic reasoning) even if normalized counts (a.k.a. term frequencies) or TF-IDF valued features often perform slightly better in practice.

As for the Normalizer, the utility class Binarizer is meant to be used in the early stages of Pipeline. The fit method does nothing as each sample is treated independently of others:

It is possible to adjust the threshold of the binarizer:

As for the Normalizer class, the preprocessing module provides a companion function binarize to be used when the transformer API is not necessary.

Note that the Binarizer is similar to the KBinsDiscretizer when k = 2, and when the bin edge is at the value threshold.

binarize and Binarizer accept both dense array-like and sparse matrices from scipy.sparse as input.

For sparse input the data is converted to the Compressed Sparse Rows representation (see scipy.sparse.csr_matrix). To avoid unnecessary memory copies, it is recommended to choose the CSR representation upstream.

Tools for imputing missing values are discussed at Imputation of missing values.

Often it’s useful to add complexity to a model by considering nonlinear features of the input data. We show two possibilities that are both based on polynomials: The first one uses pure polynomials, the second one uses splines, i.e. piecewise polynomials.

A simple and common method to use is polynomial features, which can get features’ high-order and interaction terms. It is implemented in PolynomialFeatures:

The features of X have been transformed from \((X_1, X_2)\) to \((1, X_1, X_2, X_1^2, X_1X_2, X_2^2)\).

In some cases, only interaction terms among features are required, and it can be gotten with the setting interaction_only=True:

The features of X have been transformed from \((X_1, X_2, X_3)\) to \((1, X_1, X_2, X_3, X_1X_2, X_1X_3, X_2X_3, X_1X_2X_3)\).

Note that polynomial features are used implicitly in kernel methods (e.g., SVC, KernelPCA) when using polynomial Kernel functions.

See Polynomial and Spline interpolation for Ridge regression using created polynomial features.

Another way to add nonlinear terms instead of pure polynomials of features is to generate spline basis functions for each feature with the SplineTransformer. Splines are piecewise polynomials, parametrized by their polynomial degree and the positions of the knots. The SplineTransformer implements a B-spline basis, cf. the references below.

The SplineTransformer treats each feature separately, i.e. it won’t give you interaction terms.

Some of the advantages of splines over polynomials are:

B-splines are very flexible and robust if you keep a fixed low degree, usually 3, and parsimoniously adapt the number of knots. Polynomials would need a higher degree, which leads to the next point.

B-splines do not have oscillatory behaviour at the boundaries as have polynomials (the higher the degree, the worse). This is known as Runge’s phenomenon.

B-splines provide good options for extrapolation beyond the boundaries, i.e. beyond the range of fitted values. Have a look at the option extrapolation.

B-splines generate a feature matrix with a banded structure. For a single feature, every row contains only degree + 1 non-zero elements, which occur consecutively and are even positive. This results in a matrix with good numerical properties, e.g. a low condition number, in sharp contrast to a matrix of polynomials, which goes under the name Vandermonde matrix. A low condition number is important for stable algorithms of linear models.

The following code snippet shows splines in action:

As the X is sorted, one can easily see the banded matrix output. Only the three middle diagonals are non-zero for degree=2. The higher the degree, the more overlapping of the splines.

Interestingly, a SplineTransformer of degree=0 is the same as KBinsDiscretizer with encode='onehot-dense' and n_bins = n_knots - 1 if knots = strategy.

Polynomial and Spline interpolation

Time-related feature engineering

Eilers, P., & Marx, B. (1996). Flexible Smoothing with B-splines and Penalties. Statist. Sci. 11 (1996), no. 2, 89–121.

Perperoglou, A., Sauerbrei, W., Abrahamowicz, M. et al. A review of spline function procedures in R. BMC Med Res Methodol 19, 46 (2019).

Often, you will want to convert an existing Python function into a transformer to assist in data cleaning or processing. You can implement a transformer from an arbitrary function with FunctionTransformer. For example, to build a transformer that applies a log transformation in a pipeline, do:

You can ensure that func and inverse_func are the inverse of each other by setting check_inverse=True and calling fit before transform. Please note that a warning is raised and can be turned into an error with a filterwarnings:

For a full code example that demonstrates using a FunctionTransformer to extract features from text data see Column Transformer with Heterogeneous Data Sources and Time-related feature engineering.

**Examples:**

Example 1 (csharp):
```csharp
>>> from sklearn import preprocessing
>>> import numpy as np
>>> X_train = np.array([[ 1., -1.,  2.],
...                     [ 2.,  0.,  0.],
...                     [ 0.,  1., -1.]])
>>> scaler = preprocessing.StandardScaler().fit(X_train)
>>> scaler
StandardScaler()

>>> scaler.mean_
array([1., 0., 0.33])

>>> scaler.scale_
array([0.81, 0.81, 1.24])

>>> X_scaled = scaler.transform(X_train)
>>> X_scaled
array([[ 0.  , -1.22,  1.33 ],
       [ 1.22,  0.  , -0.267],
       [-1.22,  1.22, -1.06 ]])
```

Example 2 (unknown):
```unknown
>>> X_scaled.mean(axis=0)
array([0., 0., 0.])

>>> X_scaled.std(axis=0)
array([1., 1., 1.])
```

Example 3 (sql):
```sql
>>> from sklearn.datasets import make_classification
>>> from sklearn.linear_model import LogisticRegression
>>> from sklearn.model_selection import train_test_split
>>> from sklearn.pipeline import make_pipeline
>>> from sklearn.preprocessing import StandardScaler

>>> X, y = make_classification(random_state=42)
>>> X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)
>>> pipe = make_pipeline(StandardScaler(), LogisticRegression())
>>> pipe.fit(X_train, y_train)  # apply scaling on training data
Pipeline(steps=[('standardscaler', StandardScaler()),
                ('logisticregression', LogisticRegression())])

>>> pipe.score(X_test, y_test)  # apply scaling on testing data, without leaking training data.
0.96
```

Example 4 (json):
```json
>>> X_train = np.array([[ 1., -1.,  2.],
...                     [ 2.,  0.,  0.],
...                     [ 0.,  1., -1.]])
...
>>> min_max_scaler = preprocessing.MinMaxScaler()
>>> X_train_minmax = min_max_scaler.fit_transform(X_train)
>>> X_train_minmax
array([[0.5       , 0.        , 1.        ],
       [1.        , 0.5       , 0.33333333],
       [0.        , 1.        , 0.        ]])
```

---

## CountVectorizer#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html

**Contents:**
- CountVectorizer#
- Gallery examples#

Convert a collection of text documents to a matrix of token counts.

This implementation produces a sparse representation of the counts using scipy.sparse.csr_matrix.

If you do not provide an a-priori dictionary and you do not use an analyzer that does some kind of feature selection then the number of features will be equal to the vocabulary size found by analyzing the data.

For an efficiency comparison of the different feature extractors, see FeatureHasher and DictVectorizer Comparison.

Read more in the User Guide.

If 'filename', the sequence passed as an argument to fit is expected to be a list of filenames that need reading to fetch the raw content to analyze.

If 'file', the sequence items must have a ‘read’ method (file-like object) that is called to fetch the bytes in memory.

If 'content', the input is expected to be a sequence of items that can be of type string or byte.

If bytes or files are given to analyze, this encoding is used to decode.

Instruction on what to do if a byte sequence is given to analyze that contains characters not of the given encoding. By default, it is ‘strict’, meaning that a UnicodeDecodeError will be raised. Other values are ‘ignore’ and ‘replace’.

Remove accents and perform other character normalization during the preprocessing step. ‘ascii’ is a fast method that only works on characters that have a direct ASCII mapping. ‘unicode’ is a slightly slower method that works on any characters. None (default) means no character normalization is performed.

Both ‘ascii’ and ‘unicode’ use NFKD normalization from unicodedata.normalize.

Convert all characters to lowercase before tokenizing.

Override the preprocessing (strip_accents and lowercase) stage while preserving the tokenizing and n-grams generation steps. Only applies if analyzer is not callable.

Override the string tokenization step while preserving the preprocessing and n-grams generation steps. Only applies if analyzer == 'word'.

If ‘english’, a built-in stop word list for English is used. There are several known issues with ‘english’ and you should consider an alternative (see Using stop words).

If a list, that list is assumed to contain stop words, all of which will be removed from the resulting tokens. Only applies if analyzer == 'word'.

If None, no stop words will be used. In this case, setting max_df to a higher value, such as in the range (0.7, 1.0), can automatically detect and filter stop words based on intra corpus document frequency of terms.

Regular expression denoting what constitutes a “token”, only used if analyzer == 'word'. The default regexp select tokens of 2 or more alphanumeric characters (punctuation is completely ignored and always treated as a token separator).

If there is a capturing group in token_pattern then the captured group content, not the entire match, becomes the token. At most one capturing group is permitted.

The lower and upper boundary of the range of n-values for different word n-grams or char n-grams to be extracted. All values of n such such that min_n <= n <= max_n will be used. For example an ngram_range of (1, 1) means only unigrams, (1, 2) means unigrams and bigrams, and (2, 2) means only bigrams. Only applies if analyzer is not callable.

Whether the feature should be made of word n-gram or character n-grams. Option ‘char_wb’ creates character n-grams only from text inside word boundaries; n-grams at the edges of words are padded with space.

If a callable is passed it is used to extract the sequence of features out of the raw, unprocessed input.

Changed in version 0.21.

Since v0.21, if input is filename or file, the data is first read from the file and then passed to the given callable analyzer.

When building the vocabulary ignore terms that have a document frequency strictly higher than the given threshold (corpus-specific stop words). If float, the parameter represents a proportion of documents, integer absolute counts. This parameter is ignored if vocabulary is not None.

When building the vocabulary ignore terms that have a document frequency strictly lower than the given threshold. This value is also called cut-off in the literature. If float, the parameter represents a proportion of documents, integer absolute counts. This parameter is ignored if vocabulary is not None.

If not None, build a vocabulary that only consider the top max_features ordered by term frequency across the corpus. Otherwise, all features are used.

This parameter is ignored if vocabulary is not None.

Either a Mapping (e.g., a dict) where keys are terms and values are indices in the feature matrix, or an iterable over terms. If not given, a vocabulary is determined from the input documents. Indices in the mapping should not be repeated and should not have any gap between 0 and the largest index.

If True, all non zero counts are set to 1. This is useful for discrete probabilistic models that model binary events rather than integer counts.

Type of the matrix returned by fit_transform() or transform().

A mapping of terms to feature indices.

True if a fixed vocabulary of term to indices mapping is provided by the user.

Convert a collection of text documents to a matrix of token counts.

Convert a collection of raw documents to a matrix of TF-IDF features.

Return a callable to process input data.

The callable handles preprocessing, tokenization, and n-grams generation.

A function to handle preprocessing, tokenization and n-grams generation.

Return a function to preprocess the text before tokenization.

A function to preprocess the text before tokenization.

Return a function that splits a string into a sequence of tokens.

A function to split a string into a sequence of tokens.

Decode the input into a string of unicode symbols.

The decoding strategy depends on the vectorizer parameters.

The string to decode.

A string of unicode symbols.

Learn a vocabulary dictionary of all tokens in the raw documents.

An iterable which generates either str, unicode or file objects.

This parameter is ignored.

Learn the vocabulary dictionary and return document-term matrix.

This is equivalent to fit followed by transform, but more efficiently implemented.

An iterable which generates either str, unicode or file objects.

This parameter is ignored.

Document-term matrix.

Get output feature names for transformation.

Not used, present here for API consistency by convention.

Transformed feature names.

Get metadata routing of this object.

Please check User Guide on how the routing mechanism works.

A MetadataRequest encapsulating routing information.

Get parameters for this estimator.

If True, will return the parameters for this estimator and contained subobjects that are estimators.

Parameter names mapped to their values.

Build or fetch the effective stop words list.

A list of stop words.

Return terms per document with nonzero entries in X.

Document-term matrix.

List of arrays of terms.

Set the parameters of this estimator.

The method works on simple estimators as well as on nested objects (such as Pipeline). The latter have parameters of the form <component>__<parameter> so that it’s possible to update each component of a nested object.

Estimator parameters.

Transform documents to document-term matrix.

Extract token counts out of raw text documents using the vocabulary fitted with fit or the one provided to the constructor.

An iterable which generates either str, unicode or file objects.

Document-term matrix.

Topic extraction with Non-negative Matrix Factorization and Latent Dirichlet Allocation

Semi-supervised Classification on a Text Dataset

FeatureHasher and DictVectorizer Comparison

**Examples:**

Example 1 (python):
```python
>>> from sklearn.feature_extraction.text import CountVectorizer
>>> corpus = [
...     'This is the first document.',
...     'This document is the second document.',
...     'And this is the third one.',
...     'Is this the first document?',
... ]
>>> vectorizer = CountVectorizer()
>>> X = vectorizer.fit_transform(corpus)
>>> vectorizer.get_feature_names_out()
array(['and', 'document', 'first', 'is', 'one', 'second', 'the', 'third',
       'this'], ...)
>>> print(X.toarray())
[[0 1 1 1 0 0 1 0 1]
 [0 2 0 1 0 1 1 0 1]
 [1 0 0 1 1 0 1 1 1]
 [0 1 1 1 0 0 1 0 1]]
>>> vectorizer2 = CountVectorizer(analyzer='word', ngram_range=(2, 2))
>>> X2 = vectorizer2.fit_transform(corpus)
>>> vectorizer2.get_feature_names_out()
array(['and this', 'document is', 'first document', 'is the', 'is this',
       'second document', 'the first', 'the second', 'the third', 'third one',
       'this document', 'this is', 'this the'], ...)
 >>> print(X2.toarray())
 [[0 0 1 1 0 0 1 0 0 0 0 1 0]
 [0 1 0 1 0 1 0 1 0 0 1 0 0]
 [1 0 0 1 0 0 0 0 1 1 0 1 0]
 [0 0 1 0 1 0 1 0 0 0 0 0 1]]
```

---

## 

**URL:** https://scikit-learn.org/stable/_sources/modules/gaussian_process.rst.txt

---

## 1.12. Multiclass and multioutput algorithms#

**URL:** https://scikit-learn.org/stable/modules/multiclass.html

**Contents:**
- 1.12. Multiclass and multioutput algorithms#
- 1.12.1. Multiclass classification#
  - 1.12.1.1. Target format#
  - 1.12.1.2. OneVsRestClassifier#
  - 1.12.1.3. OneVsOneClassifier#
  - 1.12.1.4. OutputCodeClassifier#
- 1.12.2. Multilabel classification#
  - 1.12.2.1. Target format#
  - 1.12.2.2. MultiOutputClassifier#
  - 1.12.2.3. ClassifierChain#

This section of the user guide covers functionality related to multi-learning problems, including multiclass, multilabel, and multioutput classification and regression.

The modules in this section implement meta-estimators, which require a base estimator to be provided in their constructor. Meta-estimators extend the functionality of the base estimator to support multi-learning problems, which is accomplished by transforming the multi-learning problem into a set of simpler problems, then fitting one estimator per problem.

This section covers two modules: sklearn.multiclass and sklearn.multioutput. The chart below demonstrates the problem types that each module is responsible for, and the corresponding meta-estimators that each module provides.

The table below provides a quick reference on the differences between problem types. More detailed explanations can be found in subsequent sections of this guide.

Multiclass classification

Multilabel classification

‘multilabel-indicator’

Multiclass-multioutput classification

‘multiclass-multioutput’

Multioutput regression

‘continuous-multioutput’

Below is a summary of scikit-learn estimators that have multi-learning support built-in, grouped by strategy. You don’t need the meta-estimators provided by this section if you’re using one of these estimators. However, meta-estimators can provide additional strategies beyond what is built-in:

Inherently multiclass:

naive_bayes.BernoulliNB

tree.DecisionTreeClassifier

tree.ExtraTreeClassifier

ensemble.ExtraTreesClassifier

naive_bayes.GaussianNB

neighbors.KNeighborsClassifier

semi_supervised.LabelPropagation

semi_supervised.LabelSpreading

discriminant_analysis.LinearDiscriminantAnalysis

svm.LinearSVC (setting multi_class=”crammer_singer”)

linear_model.LogisticRegression (with most solvers)

linear_model.LogisticRegressionCV (with most solvers)

neural_network.MLPClassifier

neighbors.NearestCentroid

discriminant_analysis.QuadraticDiscriminantAnalysis

neighbors.RadiusNeighborsClassifier

ensemble.RandomForestClassifier

linear_model.RidgeClassifier

linear_model.RidgeClassifierCV

Multiclass as One-Vs-One:

gaussian_process.GaussianProcessClassifier (setting multi_class = “one_vs_one”)

Multiclass as One-Vs-The-Rest:

ensemble.GradientBoostingClassifier

gaussian_process.GaussianProcessClassifier (setting multi_class = “one_vs_rest”)

svm.LinearSVC (setting multi_class=”ovr”)

linear_model.LogisticRegression (most solvers)

linear_model.LogisticRegressionCV (most solvers)

linear_model.SGDClassifier

linear_model.Perceptron

tree.DecisionTreeClassifier

tree.ExtraTreeClassifier

ensemble.ExtraTreesClassifier

neighbors.KNeighborsClassifier

neural_network.MLPClassifier

neighbors.RadiusNeighborsClassifier

ensemble.RandomForestClassifier

linear_model.RidgeClassifier

linear_model.RidgeClassifierCV

Support multiclass-multioutput:

tree.DecisionTreeClassifier

tree.ExtraTreeClassifier

ensemble.ExtraTreesClassifier

neighbors.KNeighborsClassifier

neighbors.RadiusNeighborsClassifier

ensemble.RandomForestClassifier

All classifiers in scikit-learn do multiclass classification out-of-the-box. You don’t need to use the sklearn.multiclass module unless you want to experiment with different multiclass strategies.

Multiclass classification is a classification task with more than two classes. Each sample can only be labeled as one class.

For example, classification using features extracted from a set of images of fruit, where each image may either be of an orange, an apple, or a pear. Each image is one sample and is labeled as one of the 3 possible classes. Multiclass classification makes the assumption that each sample is assigned to one and only one label - one sample cannot, for example, be both a pear and an apple.

While all scikit-learn classifiers are capable of multiclass classification, the meta-estimators offered by sklearn.multiclass permit changing the way they handle more than two classes because this may have an effect on classifier performance (either in terms of generalization error or required computational resources).

Valid multiclass representations for type_of_target (y) are:

1d or column vector containing more than two discrete values. An example of a vector y for 4 samples:

Dense or sparse binary matrix of shape (n_samples, n_classes) with a single sample per row, where each column represents one class. An example of both a dense and sparse binary matrix y for 4 samples, where the columns, in order, are apple, orange, and pear:

For more information about LabelBinarizer, refer to Transforming the prediction target (y).

The one-vs-rest strategy, also known as one-vs-all, is implemented in OneVsRestClassifier. The strategy consists in fitting one classifier per class. For each classifier, the class is fitted against all the other classes. In addition to its computational efficiency (only n_classes classifiers are needed), one advantage of this approach is its interpretability. Since each class is represented by one and only one classifier, it is possible to gain knowledge about the class by inspecting its corresponding classifier. This is the most commonly used strategy and is a fair default choice.

Below is an example of multiclass learning using OvR:

OneVsRestClassifier also supports multilabel classification. To use this feature, feed the classifier an indicator matrix, in which cell [i, j] indicates the presence of label j in sample i.

Multilabel classification

Plot classification probability

Decision Boundaries of Multinomial and One-vs-Rest Logistic Regression

OneVsOneClassifier constructs one classifier per pair of classes. At prediction time, the class which received the most votes is selected. In the event of a tie (among two classes with an equal number of votes), it selects the class with the highest aggregate classification confidence by summing over the pair-wise classification confidence levels computed by the underlying binary classifiers.

Since it requires to fit n_classes * (n_classes - 1) / 2 classifiers, this method is usually slower than one-vs-the-rest, due to its O(n_classes^2) complexity. However, this method may be advantageous for algorithms such as kernel algorithms which don’t scale well with n_samples. This is because each individual learning problem only involves a small subset of the data whereas, with one-vs-the-rest, the complete dataset is used n_classes times. The decision function is the result of a monotonic transformation of the one-versus-one classification.

Below is an example of multiclass learning using OvO:

“Pattern Recognition and Machine Learning. Springer”, Christopher M. Bishop, page 183, (First Edition)

Error-Correcting Output Code-based strategies are fairly different from one-vs-the-rest and one-vs-one. With these strategies, each class is represented in a Euclidean space, where each dimension can only be 0 or 1. Another way to put it is that each class is represented by a binary code (an array of 0 and 1). The matrix which keeps track of the location/code of each class is called the code book. The code size is the dimensionality of the aforementioned space. Intuitively, each class should be represented by a code as unique as possible and a good code book should be designed to optimize classification accuracy. In this implementation, we simply use a randomly-generated code book as advocated in [3] although more elaborate methods may be added in the future.

At fitting time, one binary classifier per bit in the code book is fitted. At prediction time, the classifiers are used to project new points in the class space and the class closest to the points is chosen.

In OutputCodeClassifier, the code_size attribute allows the user to control the number of classifiers which will be used. It is a percentage of the total number of classes.

A number between 0 and 1 will require fewer classifiers than one-vs-the-rest. In theory, log2(n_classes) / n_classes is sufficient to represent each class unambiguously. However, in practice, it may not lead to good accuracy since log2(n_classes) is much smaller than n_classes.

A number greater than 1 will require more classifiers than one-vs-the-rest. In this case, some classifiers will in theory correct for the mistakes made by other classifiers, hence the name “error-correcting”. In practice, however, this may not happen as classifier mistakes will typically be correlated. The error-correcting output codes have a similar effect to bagging.

Below is an example of multiclass learning using Output-Codes:

“Solving multiclass learning problems via error-correcting output codes”, Dietterich T., Bakiri G., Journal of Artificial Intelligence Research 2, 1995.

“The error coding method and PICTs”, James G., Hastie T., Journal of Computational and Graphical statistics 7, 1998.

“The Elements of Statistical Learning”, Hastie T., Tibshirani R., Friedman J., page 606 (second-edition), 2008.

Multilabel classification (closely related to multioutput classification) is a classification task labeling each sample with m labels from n_classes possible classes, where m can be 0 to n_classes inclusive. This can be thought of as predicting properties of a sample that are not mutually exclusive. Formally, a binary output is assigned to each class, for every sample. Positive classes are indicated with 1 and negative classes with 0 or -1. It is thus comparable to running n_classes binary classification tasks, for example with MultiOutputClassifier. This approach treats each label independently whereas multilabel classifiers may treat the multiple classes simultaneously, accounting for correlated behavior among them.

For example, prediction of the topics relevant to a text document or video. The document or video may be about one of ‘religion’, ‘politics’, ‘finance’ or ‘education’, several of the topic classes or all of the topic classes.

A valid representation of multilabel y is an either dense or sparse binary matrix of shape (n_samples, n_classes). Each column represents a class. The 1’s in each row denote the positive classes a sample has been labeled with. An example of a dense matrix y for 3 samples:

Dense binary matrices can also be created using MultiLabelBinarizer. For more information, refer to Transforming the prediction target (y).

An example of the same y in sparse matrix form:

Multilabel classification support can be added to any classifier with MultiOutputClassifier. This strategy consists of fitting one classifier per target. This allows multiple target variable classifications. The purpose of this class is to extend estimators to be able to estimate a series of target functions (f1,f2,f3…,fn) that are trained on a single X predictor matrix to predict a series of responses (y1,y2,y3…,yn).

You can find a usage example for MultiOutputClassifier as part of the section on Multiclass-multioutput classification since it is a generalization of multilabel classification to multiclass outputs instead of binary outputs.

Classifier chains (see ClassifierChain) are a way of combining a number of binary classifiers into a single multi-label model that is capable of exploiting correlations among targets.

For a multi-label classification problem with N classes, N binary classifiers are assigned an integer between 0 and N-1. These integers define the order of models in the chain. Each classifier is then fit on the available training data plus the true labels of the classes whose models were assigned a lower number.

When predicting, the true labels will not be available. Instead the predictions of each model are passed on to the subsequent models in the chain to be used as features.

Clearly the order of the chain is important. The first model in the chain has no information about the other labels while the last model in the chain has features indicating the presence of all of the other labels. In general one does not know the optimal ordering of the models in the chain so typically many randomly ordered chains are fit and their predictions are averaged together.

Jesse Read, Bernhard Pfahringer, Geoff Holmes, Eibe Frank, “Classifier Chains for Multi-label Classification”, 2009.

Multiclass-multioutput classification (also known as multitask classification) is a classification task which labels each sample with a set of non-binary properties. Both the number of properties and the number of classes per property is greater than 2. A single estimator thus handles several joint classification tasks. This is both a generalization of the multilabel classification task, which only considers binary attributes, as well as a generalization of the multiclass classification task, where only one property is considered.

For example, classification of the properties “type of fruit” and “colour” for a set of images of fruit. The property “type of fruit” has the possible classes: “apple”, “pear” and “orange”. The property “colour” has the possible classes: “green”, “red”, “yellow” and “orange”. Each sample is an image of a fruit, a label is output for both properties and each label is one of the possible classes of the corresponding property.

Note that all classifiers handling multiclass-multioutput (also known as multitask classification) tasks, support the multilabel classification task as a special case. Multitask classification is similar to the multioutput classification task with different model formulations. For more information, see the relevant estimator documentation.

Below is an example of multiclass-multioutput classification:

At present, no metric in sklearn.metrics supports the multiclass-multioutput classification task.

A valid representation of multioutput y is a dense matrix of shape (n_samples, n_classes) of class labels. A column wise concatenation of 1d multiclass variables. An example of y for 3 samples:

Multioutput regression predicts multiple numerical properties for each sample. Each property is a numerical variable and the number of properties to be predicted for each sample is greater than or equal to 2. Some estimators that support multioutput regression are faster than just running n_output estimators.

For example, prediction of both wind speed and wind direction, in degrees, using data obtained at a certain location. Each sample would be data obtained at one location and both wind speed and direction would be output for each sample.

The following regressors natively support multioutput regression:

cross_decomposition.CCA

tree.DecisionTreeRegressor

linear_model.ElasticNet

tree.ExtraTreeRegressor

ensemble.ExtraTreesRegressor

gaussian_process.GaussianProcessRegressor

neighbors.KNeighborsRegressor

kernel_ridge.KernelRidge

linear_model.LassoLars

linear_model.LinearRegression

multioutput.MultiOutputRegressor

linear_model.MultiTaskElasticNet

linear_model.MultiTaskElasticNetCV

linear_model.MultiTaskLasso

linear_model.MultiTaskLassoCV

linear_model.OrthogonalMatchingPursuit

cross_decomposition.PLSCanonical

cross_decomposition.PLSRegression

linear_model.RANSACRegressor

neighbors.RadiusNeighborsRegressor

ensemble.RandomForestRegressor

multioutput.RegressorChain

compose.TransformedTargetRegressor

A valid representation of multioutput y is a dense matrix of shape (n_samples, n_output) of floats. A column wise concatenation of continuous variables. An example of y for 3 samples:

Multioutput regression support can be added to any regressor with MultiOutputRegressor. This strategy consists of fitting one regressor per target. Since each target is represented by exactly one regressor it is possible to gain knowledge about the target by inspecting its corresponding regressor. As MultiOutputRegressor fits one regressor per target it can not take advantage of correlations between targets.

Below is an example of multioutput regression:

Regressor chains (see RegressorChain) is analogous to ClassifierChain as a way of combining a number of regressions into a single multi-target model that is capable of exploiting correlations among targets.

**Examples:**

Example 1 (python):
```python
>>> import numpy as np
>>> y = np.array(['apple', 'pear', 'apple', 'orange'])
>>> print(y)
['apple' 'pear' 'apple' 'orange']
```

Example 2 (python):
```python
>>> import numpy as np
>>> from sklearn.preprocessing import LabelBinarizer
>>> y = np.array(['apple', 'pear', 'apple', 'orange'])
>>> y_dense = LabelBinarizer().fit_transform(y)
>>> print(y_dense)
[[1 0 0]
 [0 0 1]
 [1 0 0]
 [0 1 0]]
>>> from scipy import sparse
>>> y_sparse = sparse.csr_matrix(y_dense)
>>> print(y_sparse)
<Compressed Sparse Row sparse matrix of dtype 'int64'
  with 4 stored elements and shape (4, 3)>
  Coords Values
  (0, 0) 1
  (1, 2) 1
  (2, 0) 1
  (3, 1) 1
```

Example 3 (python):
```python
>>> from sklearn import datasets
>>> from sklearn.multiclass import OneVsRestClassifier
>>> from sklearn.svm import LinearSVC
>>> X, y = datasets.load_iris(return_X_y=True)
>>> OneVsRestClassifier(LinearSVC(random_state=0)).fit(X, y).predict(X)
array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
       1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1,
       1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 1, 2, 2, 2, 2,
       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])
```

Example 4 (python):
```python
>>> from sklearn import datasets
>>> from sklearn.multiclass import OneVsOneClassifier
>>> from sklearn.svm import LinearSVC
>>> X, y = datasets.load_iris(return_X_y=True)
>>> OneVsOneClassifier(LinearSVC(random_state=0)).fit(X, y).predict(X)
array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
       1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1,
       1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])
```

---

## ExtraTreeClassifier#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.tree.ExtraTreeClassifier.html

**Contents:**
- ExtraTreeClassifier#

An extremely randomized tree classifier.

Extra-trees differ from classic decision trees in the way they are built. When looking for the best split to separate the samples of a node into two groups, random splits are drawn for each of the max_features randomly selected features and the best split among those is chosen. When max_features is set 1, this amounts to building a totally random decision tree.

Warning: Extra-trees should only be used within ensemble methods.

Read more in the User Guide.

The function to measure the quality of a split. Supported criteria are “gini” for the Gini impurity and “log_loss” and “entropy” both for the Shannon information gain, see Mathematical formulation.

The strategy used to choose the split at each node. Supported strategies are “best” to choose the best split and “random” to choose the best random split.

The maximum depth of the tree. If None, then nodes are expanded until all leaves are pure or until all leaves contain less than min_samples_split samples.

The minimum number of samples required to split an internal node:

If int, then consider min_samples_split as the minimum number.

If float, then min_samples_split is a fraction and ceil(min_samples_split * n_samples) are the minimum number of samples for each split.

Changed in version 0.18: Added float values for fractions.

The minimum number of samples required to be at a leaf node. A split point at any depth will only be considered if it leaves at least min_samples_leaf training samples in each of the left and right branches. This may have the effect of smoothing the model, especially in regression.

If int, then consider min_samples_leaf as the minimum number.

If float, then min_samples_leaf is a fraction and ceil(min_samples_leaf * n_samples) are the minimum number of samples for each node.

Changed in version 0.18: Added float values for fractions.

The minimum weighted fraction of the sum total of weights (of all the input samples) required to be at a leaf node. Samples have equal weight when sample_weight is not provided.

The number of features to consider when looking for the best split:

If int, then consider max_features features at each split.

If float, then max_features is a fraction and max(1, int(max_features * n_features_in_)) features are considered at each split.

If “sqrt”, then max_features=sqrt(n_features).

If “log2”, then max_features=log2(n_features).

If None, then max_features=n_features.

Changed in version 1.1: The default of max_features changed from "auto" to "sqrt".

Note: the search for a split does not stop until at least one valid partition of the node samples is found, even if it requires to effectively inspect more than max_features features.

Used to pick randomly the max_features used at each split. See Glossary for details.

Grow a tree with max_leaf_nodes in best-first fashion. Best nodes are defined as relative reduction in impurity. If None then unlimited number of leaf nodes.

A node will be split if this split induces a decrease of the impurity greater than or equal to this value.

The weighted impurity decrease equation is the following:

where N is the total number of samples, N_t is the number of samples at the current node, N_t_L is the number of samples in the left child, and N_t_R is the number of samples in the right child.

N, N_t, N_t_R and N_t_L all refer to the weighted sum, if sample_weight is passed.

Added in version 0.19.

Weights associated with classes in the form {class_label: weight}. If None, all classes are supposed to have weight one. For multi-output problems, a list of dicts can be provided in the same order as the columns of y.

Note that for multioutput (including multilabel) weights should be defined for each class of every column in its own dict. For example, for four-class multilabel classification weights should be [{0: 1, 1: 1}, {0: 1, 1: 5}, {0: 1, 1: 1}, {0: 1, 1: 1}] instead of [{1:1}, {2:5}, {3:1}, {4:1}].

The “balanced” mode uses the values of y to automatically adjust weights inversely proportional to class frequencies in the input data as n_samples / (n_classes * np.bincount(y))

For multi-output, the weights of each column of y will be multiplied.

Note that these weights will be multiplied with sample_weight (passed through the fit method) if sample_weight is specified.

Complexity parameter used for Minimal Cost-Complexity Pruning. The subtree with the largest cost complexity that is smaller than ccp_alpha will be chosen. By default, no pruning is performed. See Minimal Cost-Complexity Pruning for details. See Post pruning decision trees with cost complexity pruning for an example of such pruning.

Added in version 0.22.

1: monotonic increase

-1: monotonic decrease

If monotonic_cst is None, no constraints are applied.

multiclass classifications (i.e. when n_classes > 2),

multioutput classifications (i.e. when n_outputs_ > 1),

classifications trained on data with missing values.

The constraints hold over the probability of the positive class.

Read more in the User Guide.

Added in version 1.4.

The classes labels (single output problem), or a list of arrays of class labels (multi-output problem).

The inferred value of max_features.

The number of classes (for single output problems), or a list containing the number of classes for each output (for multi-output problems).

Return the feature importances.

Number of features seen during fit.

Added in version 0.24.

Names of features seen during fit. Defined only when X has feature names that are all strings.

Added in version 1.0.

The number of outputs when fit is performed.

The underlying Tree object. Please refer to help(sklearn.tree._tree.Tree) for attributes of Tree object and Understanding the decision tree structure for basic usage of these attributes.

An extremely randomized tree regressor.

An extra-trees classifier.

An extra-trees regressor.

A random forest classifier.

A random forest regressor.

An ensemble of totally random trees.

The default values for the parameters controlling the size of the trees (e.g. max_depth, min_samples_leaf, etc.) lead to fully grown and unpruned trees which can potentially be very large on some data sets. To reduce memory consumption, the complexity and size of the trees should be controlled by setting those parameter values.

P. Geurts, D. Ernst., and L. Wehenkel, “Extremely randomized trees”, Machine Learning, 63(1), 3-42, 2006.

Return the index of the leaf that each sample is predicted as.

Added in version 0.17.

The input samples. Internally, it will be converted to dtype=np.float32 and if a sparse matrix is provided to a sparse csr_matrix.

Allow to bypass several input checking. Don’t use this parameter unless you know what you’re doing.

For each datapoint x in X, return the index of the leaf x ends up in. Leaves are numbered within [0; self.tree_.node_count), possibly with gaps in the numbering.

Compute the pruning path during Minimal Cost-Complexity Pruning.

See Minimal Cost-Complexity Pruning for details on the pruning process.

The training input samples. Internally, it will be converted to dtype=np.float32 and if a sparse matrix is provided to a sparse csc_matrix.

The target values (class labels) as integers or strings.

Sample weights. If None, then samples are equally weighted. Splits that would create child nodes with net zero or negative weight are ignored while searching for a split in each node. Splits are also ignored if they would result in any single class carrying a negative weight in either child node.

Dictionary-like object, with the following attributes.

Effective alphas of subtree during pruning.

Sum of the impurities of the subtree leaves for the corresponding alpha value in ccp_alphas.

Return the decision path in the tree.

Added in version 0.18.

The input samples. Internally, it will be converted to dtype=np.float32 and if a sparse matrix is provided to a sparse csr_matrix.

Allow to bypass several input checking. Don’t use this parameter unless you know what you’re doing.

Return a node indicator CSR matrix where non zero elements indicates that the samples goes through the nodes.

Build a decision tree classifier from the training set (X, y).

The training input samples. Internally, it will be converted to dtype=np.float32 and if a sparse matrix is provided to a sparse csc_matrix.

The target values (class labels) as integers or strings.

Sample weights. If None, then samples are equally weighted. Splits that would create child nodes with net zero or negative weight are ignored while searching for a split in each node. Splits are also ignored if they would result in any single class carrying a negative weight in either child node.

Allow to bypass several input checking. Don’t use this parameter unless you know what you’re doing.

Return the depth of the decision tree.

The depth of a tree is the maximum distance between the root and any leaf.

The maximum depth of the tree.

Get metadata routing of this object.

Please check User Guide on how the routing mechanism works.

A MetadataRequest encapsulating routing information.

Return the number of leaves of the decision tree.

Get parameters for this estimator.

If True, will return the parameters for this estimator and contained subobjects that are estimators.

Parameter names mapped to their values.

Predict class or regression value for X.

For a classification model, the predicted class for each sample in X is returned. For a regression model, the predicted value based on X is returned.

The input samples. Internally, it will be converted to dtype=np.float32 and if a sparse matrix is provided to a sparse csr_matrix.

Allow to bypass several input checking. Don’t use this parameter unless you know what you’re doing.

The predicted classes, or the predict values.

Predict class log-probabilities of the input samples X.

The input samples. Internally, it will be converted to dtype=np.float32 and if a sparse matrix is provided to a sparse csr_matrix.

The class log-probabilities of the input samples. The order of the classes corresponds to that in the attribute classes_.

Predict class probabilities of the input samples X.

The predicted class probability is the fraction of samples of the same class in a leaf.

The input samples. Internally, it will be converted to dtype=np.float32 and if a sparse matrix is provided to a sparse csr_matrix.

Allow to bypass several input checking. Don’t use this parameter unless you know what you’re doing.

The class probabilities of the input samples. The order of the classes corresponds to that in the attribute classes_.

Return accuracy on provided data and labels.

In multi-label classification, this is the subset accuracy which is a harsh metric since you require for each sample that each label set be correctly predicted.

Mean accuracy of self.predict(X) w.r.t. y.

Configure whether metadata should be requested to be passed to the fit method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to fit if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to fit.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Added in version 1.3.

Metadata routing for sample_weight parameter in fit.

Set the parameters of this estimator.

The method works on simple estimators as well as on nested objects (such as Pipeline). The latter have parameters of the form <component>__<parameter> so that it’s possible to update each component of a nested object.

Estimator parameters.

Configure whether metadata should be requested to be passed to the score method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to score if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to score.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Added in version 1.3.

Metadata routing for sample_weight parameter in score.

**Examples:**

Example 1 (yaml):
```yaml
N_t / N * (impurity - N_t_R / N_t * right_impurity
                    - N_t_L / N_t * left_impurity)
```

Example 2 (sql):
```sql
>>> from sklearn.datasets import load_iris
>>> from sklearn.model_selection import train_test_split
>>> from sklearn.ensemble import BaggingClassifier
>>> from sklearn.tree import ExtraTreeClassifier
>>> X, y = load_iris(return_X_y=True)
>>> X_train, X_test, y_train, y_test = train_test_split(
...    X, y, random_state=0)
>>> extra_tree = ExtraTreeClassifier(random_state=0)
>>> cls = BaggingClassifier(extra_tree, random_state=0).fit(
...    X_train, y_train)
>>> cls.score(X_test, y_test)
0.8947
```

---

## GenericUnivariateSelect#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.GenericUnivariateSelect.html

**Contents:**
- GenericUnivariateSelect#

Univariate feature selector with configurable strategy.

Read more in the User Guide.

Function taking two arrays X and y, and returning a pair of arrays (scores, pvalues). For modes ‘percentile’ or ‘kbest’ it can return a single array scores.

Feature selection mode. Note that the 'percentile' and 'kbest' modes are supporting unsupervised feature selection (when y is None).

Parameter of the corresponding mode.

p-values of feature scores, None if score_func returned scores only.

Number of features seen during fit.

Added in version 0.24.

Names of features seen during fit. Defined only when X has feature names that are all strings.

Added in version 1.0.

ANOVA F-value between label/feature for classification tasks.

Mutual information for a discrete target.

Chi-squared stats of non-negative features for classification tasks.

F-value between label/feature for regression tasks.

Mutual information for a continuous target.

Select features based on percentile of the highest scores.

Select features based on the k highest scores.

Select features based on a false positive rate test.

Select features based on an estimated false discovery rate.

Select features based on family-wise error rate.

Run score function on (X, y) and get the appropriate features.

The training input samples.

The target values (class labels in classification, real numbers in regression). If the selector is unsupervised then y can be set to None.

Returns the instance itself.

Fit to data, then transform it.

Fits transformer to X and y with optional parameters fit_params and returns a transformed version of X.

Target values (None for unsupervised transformations).

Additional fit parameters. Pass only if the estimator accepts additional params in its fit method.

Mask feature names according to selected features.

If input_features is None, then feature_names_in_ is used as feature names in. If feature_names_in_ is not defined, then the following input feature names are generated: ["x0", "x1", ..., "x(n_features_in_ - 1)"].

If input_features is an array-like, then input_features must match feature_names_in_ if feature_names_in_ is defined.

Transformed feature names.

Get metadata routing of this object.

Please check User Guide on how the routing mechanism works.

A MetadataRequest encapsulating routing information.

Get parameters for this estimator.

If True, will return the parameters for this estimator and contained subobjects that are estimators.

Parameter names mapped to their values.

Get a mask, or integer index, of the features selected.

If True, the return value will be an array of integers, rather than a boolean mask.

An index that selects the retained features from a feature vector. If indices is False, this is a boolean array of shape [# input features], in which an element is True iff its corresponding feature is selected for retention. If indices is True, this is an integer array of shape [# output features] whose values are indices into the input feature vector.

Reverse the transformation operation.

X with columns of zeros inserted where features would have been removed by transform.

Set output container.

See Introducing the set_output API for an example on how to use the API.

Configure output of transform and fit_transform.

"default": Default output format of a transformer

"pandas": DataFrame output

"polars": Polars output

None: Transform configuration is unchanged

Added in version 1.4: "polars" option was added.

Set the parameters of this estimator.

The method works on simple estimators as well as on nested objects (such as Pipeline). The latter have parameters of the form <component>__<parameter> so that it’s possible to update each component of a nested object.

Estimator parameters.

Reduce X to the selected features.

The input samples with only the selected features.

**Examples:**

Example 1 (sql):
```sql
>>> from sklearn.datasets import load_breast_cancer
>>> from sklearn.feature_selection import GenericUnivariateSelect, chi2
>>> X, y = load_breast_cancer(return_X_y=True)
>>> X.shape
(569, 30)
>>> transformer = GenericUnivariateSelect(chi2, mode='k_best', param=20)
>>> X_new = transformer.fit_transform(X, y)
>>> X_new.shape
(569, 20)
```

---

## ExtraTreeRegressor#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.tree.ExtraTreeRegressor.html

**Contents:**
- ExtraTreeRegressor#

An extremely randomized tree regressor.

Extra-trees differ from classic decision trees in the way they are built. When looking for the best split to separate the samples of a node into two groups, random splits are drawn for each of the max_features randomly selected features and the best split among those is chosen. When max_features is set 1, this amounts to building a totally random decision tree.

Warning: Extra-trees should only be used within ensemble methods.

Read more in the User Guide.

The function to measure the quality of a split. Supported criteria are “squared_error” for the mean squared error, which is equal to variance reduction as feature selection criterion and minimizes the L2 loss using the mean of each terminal node, “friedman_mse”, which uses mean squared error with Friedman’s improvement score for potential splits, “absolute_error” for the mean absolute error, which minimizes the L1 loss using the median of each terminal node, and “poisson” which uses reduction in Poisson deviance to find splits.

Added in version 0.18: Mean Absolute Error (MAE) criterion.

Added in version 0.24: Poisson deviance criterion.

The strategy used to choose the split at each node. Supported strategies are “best” to choose the best split and “random” to choose the best random split.

The maximum depth of the tree. If None, then nodes are expanded until all leaves are pure or until all leaves contain less than min_samples_split samples.

The minimum number of samples required to split an internal node:

If int, then consider min_samples_split as the minimum number.

If float, then min_samples_split is a fraction and ceil(min_samples_split * n_samples) are the minimum number of samples for each split.

Changed in version 0.18: Added float values for fractions.

The minimum number of samples required to be at a leaf node. A split point at any depth will only be considered if it leaves at least min_samples_leaf training samples in each of the left and right branches. This may have the effect of smoothing the model, especially in regression.

If int, then consider min_samples_leaf as the minimum number.

If float, then min_samples_leaf is a fraction and ceil(min_samples_leaf * n_samples) are the minimum number of samples for each node.

Changed in version 0.18: Added float values for fractions.

The minimum weighted fraction of the sum total of weights (of all the input samples) required to be at a leaf node. Samples have equal weight when sample_weight is not provided.

The number of features to consider when looking for the best split:

If int, then consider max_features features at each split.

If float, then max_features is a fraction and max(1, int(max_features * n_features_in_)) features are considered at each split.

If “sqrt”, then max_features=sqrt(n_features).

If “log2”, then max_features=log2(n_features).

If None, then max_features=n_features.

Changed in version 1.1: The default of max_features changed from "auto" to 1.0.

Note: the search for a split does not stop until at least one valid partition of the node samples is found, even if it requires to effectively inspect more than max_features features.

Used to pick randomly the max_features used at each split. See Glossary for details.

A node will be split if this split induces a decrease of the impurity greater than or equal to this value.

The weighted impurity decrease equation is the following:

where N is the total number of samples, N_t is the number of samples at the current node, N_t_L is the number of samples in the left child, and N_t_R is the number of samples in the right child.

N, N_t, N_t_R and N_t_L all refer to the weighted sum, if sample_weight is passed.

Added in version 0.19.

Grow a tree with max_leaf_nodes in best-first fashion. Best nodes are defined as relative reduction in impurity. If None then unlimited number of leaf nodes.

Complexity parameter used for Minimal Cost-Complexity Pruning. The subtree with the largest cost complexity that is smaller than ccp_alpha will be chosen. By default, no pruning is performed. See Minimal Cost-Complexity Pruning for details. See Post pruning decision trees with cost complexity pruning for an example of such pruning.

Added in version 0.22.

1: monotonic increase

-1: monotonic decrease

If monotonic_cst is None, no constraints are applied.

multioutput regressions (i.e. when n_outputs_ > 1),

regressions trained on data with missing values.

Read more in the User Guide.

Added in version 1.4.

The inferred value of max_features.

Number of features seen during fit.

Added in version 0.24.

Names of features seen during fit. Defined only when X has feature names that are all strings.

Added in version 1.0.

Return the feature importances.

The number of outputs when fit is performed.

The underlying Tree object. Please refer to help(sklearn.tree._tree.Tree) for attributes of Tree object and Understanding the decision tree structure for basic usage of these attributes.

An extremely randomized tree classifier.

An extra-trees classifier.

An extra-trees regressor.

The default values for the parameters controlling the size of the trees (e.g. max_depth, min_samples_leaf, etc.) lead to fully grown and unpruned trees which can potentially be very large on some data sets. To reduce memory consumption, the complexity and size of the trees should be controlled by setting those parameter values.

P. Geurts, D. Ernst., and L. Wehenkel, “Extremely randomized trees”, Machine Learning, 63(1), 3-42, 2006.

Return the index of the leaf that each sample is predicted as.

Added in version 0.17.

The input samples. Internally, it will be converted to dtype=np.float32 and if a sparse matrix is provided to a sparse csr_matrix.

Allow to bypass several input checking. Don’t use this parameter unless you know what you’re doing.

For each datapoint x in X, return the index of the leaf x ends up in. Leaves are numbered within [0; self.tree_.node_count), possibly with gaps in the numbering.

Compute the pruning path during Minimal Cost-Complexity Pruning.

See Minimal Cost-Complexity Pruning for details on the pruning process.

The training input samples. Internally, it will be converted to dtype=np.float32 and if a sparse matrix is provided to a sparse csc_matrix.

The target values (class labels) as integers or strings.

Sample weights. If None, then samples are equally weighted. Splits that would create child nodes with net zero or negative weight are ignored while searching for a split in each node. Splits are also ignored if they would result in any single class carrying a negative weight in either child node.

Dictionary-like object, with the following attributes.

Effective alphas of subtree during pruning.

Sum of the impurities of the subtree leaves for the corresponding alpha value in ccp_alphas.

Return the decision path in the tree.

Added in version 0.18.

The input samples. Internally, it will be converted to dtype=np.float32 and if a sparse matrix is provided to a sparse csr_matrix.

Allow to bypass several input checking. Don’t use this parameter unless you know what you’re doing.

Return a node indicator CSR matrix where non zero elements indicates that the samples goes through the nodes.

Build a decision tree regressor from the training set (X, y).

The training input samples. Internally, it will be converted to dtype=np.float32 and if a sparse matrix is provided to a sparse csc_matrix.

The target values (real numbers). Use dtype=np.float64 and order='C' for maximum efficiency.

Sample weights. If None, then samples are equally weighted. Splits that would create child nodes with net zero or negative weight are ignored while searching for a split in each node.

Allow to bypass several input checking. Don’t use this parameter unless you know what you’re doing.

Return the depth of the decision tree.

The depth of a tree is the maximum distance between the root and any leaf.

The maximum depth of the tree.

Get metadata routing of this object.

Please check User Guide on how the routing mechanism works.

A MetadataRequest encapsulating routing information.

Return the number of leaves of the decision tree.

Get parameters for this estimator.

If True, will return the parameters for this estimator and contained subobjects that are estimators.

Parameter names mapped to their values.

Predict class or regression value for X.

For a classification model, the predicted class for each sample in X is returned. For a regression model, the predicted value based on X is returned.

The input samples. Internally, it will be converted to dtype=np.float32 and if a sparse matrix is provided to a sparse csr_matrix.

Allow to bypass several input checking. Don’t use this parameter unless you know what you’re doing.

The predicted classes, or the predict values.

Return coefficient of determination on test data.

The coefficient of determination, \(R^2\), is defined as \((1 - \frac{u}{v})\), where \(u\) is the residual sum of squares ((y_true - y_pred)** 2).sum() and \(v\) is the total sum of squares ((y_true - y_true.mean()) ** 2).sum(). The best possible score is 1.0 and it can be negative (because the model can be arbitrarily worse). A constant model that always predicts the expected value of y, disregarding the input features, would get a \(R^2\) score of 0.0.

Test samples. For some estimators this may be a precomputed kernel matrix or a list of generic objects instead with shape (n_samples, n_samples_fitted), where n_samples_fitted is the number of samples used in the fitting for the estimator.

\(R^2\) of self.predict(X) w.r.t. y.

The \(R^2\) score used when calling score on a regressor uses multioutput='uniform_average' from version 0.23 to keep consistent with default value of r2_score. This influences the score method of all the multioutput regressors (except for MultiOutputRegressor).

Configure whether metadata should be requested to be passed to the fit method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to fit if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to fit.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Added in version 1.3.

Metadata routing for sample_weight parameter in fit.

Set the parameters of this estimator.

The method works on simple estimators as well as on nested objects (such as Pipeline). The latter have parameters of the form <component>__<parameter> so that it’s possible to update each component of a nested object.

Estimator parameters.

Configure whether metadata should be requested to be passed to the score method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to score if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to score.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Added in version 1.3.

Metadata routing for sample_weight parameter in score.

**Examples:**

Example 1 (yaml):
```yaml
N_t / N * (impurity - N_t_R / N_t * right_impurity
                    - N_t_L / N_t * left_impurity)
```

Example 2 (sql):
```sql
>>> from sklearn.datasets import load_diabetes
>>> from sklearn.model_selection import train_test_split
>>> from sklearn.ensemble import BaggingRegressor
>>> from sklearn.tree import ExtraTreeRegressor
>>> X, y = load_diabetes(return_X_y=True)
>>> X_train, X_test, y_train, y_test = train_test_split(
...     X, y, random_state=0)
>>> extra_tree = ExtraTreeRegressor(random_state=0)
>>> reg = BaggingRegressor(extra_tree, random_state=0).fit(
...     X_train, y_train)
>>> reg.score(X_test, y_test)
0.33
```

---

## 

**URL:** https://scikit-learn.org/stable/_sources/modules/neural_networks_supervised.rst.txt

---

## PCA#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html

**Contents:**
- PCA#
- Gallery examples#

Principal component analysis (PCA).

Linear dimensionality reduction using Singular Value Decomposition of the data to project it to a lower dimensional space. The input data is centered but not scaled for each feature before applying the SVD.

It uses the LAPACK implementation of the full SVD or a randomized truncated SVD by the method of Halko et al. 2009, depending on the shape of the input data and the number of components to extract.

With sparse inputs, the ARPACK implementation of the truncated SVD can be used (i.e. through scipy.sparse.linalg.svds). Alternatively, one may consider TruncatedSVD where the data are not centered.

Notice that this class only supports sparse inputs for some solvers such as “arpack” and “covariance_eigh”. See TruncatedSVD for an alternative with sparse data.

For a usage example, see Principal Component Analysis (PCA) on Iris Dataset

Read more in the User Guide.

Number of components to keep. if n_components is not set all components are kept:

If n_components == 'mle' and svd_solver == 'full', Minka’s MLE is used to guess the dimension. Use of n_components == 'mle' will interpret svd_solver == 'auto' as svd_solver == 'full'.

If 0 < n_components < 1 and svd_solver == 'full', select the number of components such that the amount of variance that needs to be explained is greater than the percentage specified by n_components.

If svd_solver == 'arpack', the number of components must be strictly less than the minimum of n_features and n_samples.

Hence, the None case results in:

If False, data passed to fit are overwritten and running fit(X).transform(X) will not yield the expected results, use fit_transform(X) instead.

When True (False by default) the components_ vectors are multiplied by the square root of n_samples and then divided by the singular values to ensure uncorrelated outputs with unit component-wise variances.

Whitening will remove some information from the transformed signal (the relative variance scales of the components) but can sometime improve the predictive accuracy of the downstream estimators by making their data respect some hard-wired assumptions.

The solver is selected by a default ‘auto’ policy is based on X.shape and n_components: if the input data has fewer than 1000 features and more than 10 times as many samples, then the “covariance_eigh” solver is used. Otherwise, if the input data is larger than 500x500 and the number of components to extract is lower than 80% of the smallest dimension of the data, then the more efficient “randomized” method is selected. Otherwise the exact “full” SVD is computed and optionally truncated afterwards.

Run exact full SVD calling the standard LAPACK solver via scipy.linalg.svd and select the components by postprocessing

Precompute the covariance matrix (on centered data), run a classical eigenvalue decomposition on the covariance matrix typically using LAPACK and select the components by postprocessing. This solver is very efficient for n_samples >> n_features and small n_features. It is, however, not tractable otherwise for large n_features (large memory footprint required to materialize the covariance matrix). Also note that compared to the “full” solver, this solver effectively doubles the condition number and is therefore less numerical stable (e.g. on input data with a large range of singular values).

Run SVD truncated to n_components calling ARPACK solver via scipy.sparse.linalg.svds. It requires strictly 0 < n_components < min(X.shape)

Run randomized SVD by the method of Halko et al.

Added in version 0.18.0.

Changed in version 1.5: Added the ‘covariance_eigh’ solver.

Tolerance for singular values computed by svd_solver == ‘arpack’. Must be of range [0.0, infinity).

Added in version 0.18.0.

Number of iterations for the power method computed by svd_solver == ‘randomized’. Must be of range [0, infinity).

Added in version 0.18.0.

This parameter is only relevant when svd_solver="randomized". It corresponds to the additional number of random vectors to sample the range of X so as to ensure proper conditioning. See randomized_svd for more details.

Added in version 1.1.

Power iteration normalizer for randomized SVD solver. Not used by ARPACK. See randomized_svd for more details.

Added in version 1.1.

Used when the ‘arpack’ or ‘randomized’ solvers are used. Pass an int for reproducible results across multiple function calls. See Glossary.

Added in version 0.18.0.

Principal axes in feature space, representing the directions of maximum variance in the data. Equivalently, the right singular vectors of the centered input data, parallel to its eigenvectors. The components are sorted by decreasing explained_variance_.

The amount of variance explained by each of the selected components. The variance estimation uses n_samples - 1 degrees of freedom.

Equal to n_components largest eigenvalues of the covariance matrix of X.

Added in version 0.18.

Percentage of variance explained by each of the selected components.

If n_components is not set then all components are stored and the sum of the ratios is equal to 1.0.

The singular values corresponding to each of the selected components. The singular values are equal to the 2-norms of the n_components variables in the lower-dimensional space.

Added in version 0.19.

Per-feature empirical mean, estimated from the training set.

Equal to X.mean(axis=0).

The estimated number of components. When n_components is set to ‘mle’ or a number between 0 and 1 (with svd_solver == ‘full’) this number is estimated from input data. Otherwise it equals the parameter n_components, or the lesser value of n_features and n_samples if n_components is None.

Number of samples in the training data.

The estimated noise covariance following the Probabilistic PCA model from Tipping and Bishop 1999. See “Pattern Recognition and Machine Learning” by C. Bishop, 12.2.1 p. 574 or http://www.miketipping.com/papers/met-mppca.pdf. It is required to compute the estimated data covariance and score samples.

Equal to the average of (min(n_features, n_samples) - n_components) smallest eigenvalues of the covariance matrix of X.

Number of features seen during fit.

Added in version 0.24.

Names of features seen during fit. Defined only when X has feature names that are all strings.

Added in version 1.0.

Kernel Principal Component Analysis.

Sparse Principal Component Analysis.

Dimensionality reduction using truncated SVD.

Incremental Principal Component Analysis.

For n_components == ‘mle’, this class uses the method from: Minka, T. P.. “Automatic choice of dimensionality for PCA”. In NIPS, pp. 598-604

Implements the probabilistic PCA model from: Tipping, M. E., and Bishop, C. M. (1999). “Probabilistic principal component analysis”. Journal of the Royal Statistical Society: Series B (Statistical Methodology), 61(3), 611-622. via the score and score_samples methods.

For svd_solver == ‘arpack’, refer to scipy.sparse.linalg.svds.

For svd_solver == ‘randomized’, see: Halko, N., Martinsson, P. G., and Tropp, J. A. (2011). “Finding structure with randomness: Probabilistic algorithms for constructing approximate matrix decompositions”. SIAM review, 53(2), 217-288. and also Martinsson, P. G., Rokhlin, V., and Tygert, M. (2011). “A randomized algorithm for the decomposition of matrices”. Applied and Computational Harmonic Analysis, 30(1), 47-68.

Fit the model with X.

Training data, where n_samples is the number of samples and n_features is the number of features.

Returns the instance itself.

Fit the model with X and apply the dimensionality reduction on X.

Training data, where n_samples is the number of samples and n_features is the number of features.

This method returns a Fortran-ordered array. To convert it to a C-ordered array, use ‘np.ascontiguousarray’.

Compute data covariance with the generative model.

cov = components_.T * S**2 * components_ + sigma2 * eye(n_features) where S**2 contains the explained variances, and sigma2 contains the noise variances.

Estimated covariance of data.

Get output feature names for transformation.

The feature names out will prefixed by the lowercased class name. For example, if the transformer outputs 3 features, then the feature names out are: ["class_name0", "class_name1", "class_name2"].

Only used to validate feature names with the names seen in fit.

Transformed feature names.

Get metadata routing of this object.

Please check User Guide on how the routing mechanism works.

A MetadataRequest encapsulating routing information.

Get parameters for this estimator.

If True, will return the parameters for this estimator and contained subobjects that are estimators.

Parameter names mapped to their values.

Compute data precision matrix with the generative model.

Equals the inverse of the covariance but computed with the matrix inversion lemma for efficiency.

Estimated precision of data.

Transform data back to its original space.

In other words, return an input X_original whose transform would be X.

New data, where n_samples is the number of samples and n_components is the number of components.

Original data, where n_samples is the number of samples and n_features is the number of features.

If whitening is enabled, inverse_transform will compute the exact inverse operation, which includes reversing whitening.

Return the average log-likelihood of all samples.

See. “Pattern Recognition and Machine Learning” by C. Bishop, 12.2.1 p. 574 or http://www.miketipping.com/papers/met-mppca.pdf

Average log-likelihood of the samples under the current model.

Return the log-likelihood of each sample.

See. “Pattern Recognition and Machine Learning” by C. Bishop, 12.2.1 p. 574 or http://www.miketipping.com/papers/met-mppca.pdf

Log-likelihood of each sample under the current model.

Set output container.

See Introducing the set_output API for an example on how to use the API.

Configure output of transform and fit_transform.

"default": Default output format of a transformer

"pandas": DataFrame output

"polars": Polars output

None: Transform configuration is unchanged

Added in version 1.4: "polars" option was added.

Set the parameters of this estimator.

The method works on simple estimators as well as on nested objects (such as Pipeline). The latter have parameters of the form <component>__<parameter> so that it’s possible to update each component of a nested object.

Estimator parameters.

Apply dimensionality reduction to X.

X is projected on the first principal components previously extracted from a training set.

New data, where n_samples is the number of samples and n_features is the number of features.

Projection of X in the first principal components, where n_samples is the number of samples and n_components is the number of the components.

Image denoising using kernel PCA

Faces recognition example using eigenfaces and SVMs

A demo of K-Means clustering on the handwritten digits data

Column Transformer with Heterogeneous Data Sources

Selecting dimensionality reduction with Pipeline and GridSearchCV

Pipelining: chaining a PCA and a logistic regression

Concatenating multiple feature extraction methods

Principal Component Regression vs Partial Least Squares Regression

Faces dataset decompositions

Blind source separation using FastICA

FastICA on 2D point clouds

Principal Component Analysis (PCA) on Iris Dataset

Model selection with Probabilistic PCA and Factor Analysis (FA)

Comparison of LDA and PCA 2D projection of Iris dataset

Factor Analysis (with rotation) to visualize patterns

Multi-dimensional scaling

Explicit feature map approximation for RBF kernels

Multilabel classification

Balance model complexity and cross-validated score

Kernel Density Estimation

Dimensionality Reduction with Neighborhood Components Analysis

Importance of Feature Scaling

Release Highlights for scikit-learn 1.4

Release Highlights for scikit-learn 1.5

**Examples:**

Example 1 (unknown):
```unknown
n_components == min(n_samples, n_features)
```

Example 2 (unknown):
```unknown
n_components == min(n_samples, n_features) - 1
```

Example 3 (python):
```python
>>> import numpy as np
>>> from sklearn.decomposition import PCA
>>> X = np.array([[-1, -1], [-2, -1], [-3, -2], [1, 1], [2, 1], [3, 2]])
>>> pca = PCA(n_components=2)
>>> pca.fit(X)
PCA(n_components=2)
>>> print(pca.explained_variance_ratio_)
[0.9924 0.0075]
>>> print(pca.singular_values_)
[6.30061 0.54980]
```

Example 4 (json):
```json
>>> pca = PCA(n_components=2, svd_solver='full')
>>> pca.fit(X)
PCA(n_components=2, svd_solver='full')
>>> print(pca.explained_variance_ratio_)
[0.9924 0.00755]
>>> print(pca.singular_values_)
[6.30061 0.54980]
```

---

## GraphicalLassoCV#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.covariance.GraphicalLassoCV.html

**Contents:**
- GraphicalLassoCV#
- Gallery examples#

Sparse inverse covariance w/ cross-validated choice of the l1 penalty.

See glossary entry for cross-validation estimator.

Read more in the User Guide.

Changed in version v0.20: GraphLassoCV has been renamed to GraphicalLassoCV

If an integer is given, it fixes the number of points on the grids of alpha to be used. If a list is given, it gives the grid to be used. See the notes in the class docstring for more details. Range is [1, inf) for an integer. Range is (0, inf] for an array-like of floats.

The number of times the grid is refined. Not used if explicit values of alphas are passed. Range is [1, inf).

Determines the cross-validation splitting strategy. Possible inputs for cv are:

None, to use the default 5-fold cross-validation,

integer, to specify the number of folds.

An iterable yielding (train, test) splits as arrays of indices.

For integer/None inputs KFold is used.

Refer User Guide for the various cross-validation strategies that can be used here.

Changed in version 0.20: cv default value if None changed from 3-fold to 5-fold.

The tolerance to declare convergence: if the dual gap goes below this value, iterations are stopped. Range is (0, inf].

The tolerance for the elastic net solver used to calculate the descent direction. This parameter controls the accuracy of the search direction for a given column update, not of the overall parameter estimate. Only used for mode=’cd’. Range is (0, inf].

Maximum number of iterations.

The Lasso solver to use: coordinate descent or LARS. Use LARS for very sparse underlying graphs, where number of features is greater than number of samples. Elsewhere prefer cd which is more numerically stable.

Number of jobs to run in parallel. None means 1 unless in a joblib.parallel_backend context. -1 means using all processors. See Glossary for more details.

Changed in version v0.20: n_jobs default changed from 1 to None

If verbose is True, the objective function and duality gap are printed at each iteration.

The machine-precision regularization in the computation of the Cholesky diagonal factors. Increase this for very ill-conditioned systems. Default is np.finfo(np.float64).eps.

Added in version 1.3.

If True, data are not centered before computation. Useful when working with data whose mean is almost, but not exactly zero. If False, data are centered before computation.

Estimated location, i.e. the estimated mean.

Estimated covariance matrix.

Estimated precision matrix (inverse covariance).

The list of values of the objective function and the dual gap at each iteration. Returned only if return_costs is True.

Added in version 1.3.

Penalization parameter selected.

All penalization parameters explored.

Log-likelihood score on left-out data across (k)th fold.

Added in version 1.0.

Mean of scores over the folds.

Added in version 1.0.

Standard deviation of scores over the folds.

Added in version 1.0.

Number of iterations run for the optimal alpha.

Number of features seen during fit.

Added in version 0.24.

Names of features seen during fit. Defined only when X has feature names that are all strings.

Added in version 1.0.

L1-penalized covariance estimator.

Sparse inverse covariance estimation with an l1-penalized estimator.

The search for the optimal penalization parameter (alpha) is done on an iteratively refined grid: first the cross-validated scores on a grid are computed, then a new refined grid is centered around the maximum, and so on.

One of the challenges which is faced here is that the solvers can fail to converge to a well-conditioned estimate. The corresponding values of alpha then come out as missing values, but the optimum may be close to these missing values.

In fit, once the best parameter alpha is found through cross-validation, the model is fit again using the entire training set.

For an example comparing sklearn.covariance.GraphicalLassoCV, sklearn.covariance.ledoit_wolf shrinkage and the empirical covariance on high-dimensional gaussian data, see Sparse inverse covariance estimation.

Compute the Mean Squared Error between two covariance estimators.

The covariance to compare with.

The type of norm used to compute the error. Available error types: - ‘frobenius’ (default): sqrt(tr(A^t.A)) - ‘spectral’: sqrt(max(eigenvalues(A^t.A)) where A is the error (comp_cov - self.covariance_).

If True (default), the squared error norm is divided by n_features. If False, the squared error norm is not rescaled.

Whether to compute the squared error norm or the error norm. If True (default), the squared error norm is returned. If False, the error norm is returned.

The Mean Squared Error (in the sense of the Frobenius norm) between self and comp_cov covariance estimators.

Fit the GraphicalLasso covariance model to X.

Data from which to compute the covariance estimate.

Not used, present for API consistency by convention.

Parameters to be passed to the CV splitter and the cross_val_score function.

Added in version 1.5: Only available if enable_metadata_routing=True, which can be set by using sklearn.set_config(enable_metadata_routing=True). See Metadata Routing User Guide for more details.

Returns the instance itself.

Get metadata routing of this object.

Please check User Guide on how the routing mechanism works.

Added in version 1.5.

A MetadataRouter encapsulating routing information.

Get parameters for this estimator.

If True, will return the parameters for this estimator and contained subobjects that are estimators.

Parameter names mapped to their values.

Getter for the precision matrix.

The precision matrix associated to the current covariance object.

Compute the squared Mahalanobis distances of given observations.

For a detailed example of how outliers affects the Mahalanobis distance, see Robust covariance estimation and Mahalanobis distances relevance.

The observations, the Mahalanobis distances of the which we compute. Observations are assumed to be drawn from the same distribution than the data used in fit.

Squared Mahalanobis distances of the observations.

Compute the log-likelihood of X_test under the estimated Gaussian model.

The Gaussian model is defined by its mean and covariance matrix which are represented respectively by self.location_ and self.covariance_.

Test data of which we compute the likelihood, where n_samples is the number of samples and n_features is the number of features. X_test is assumed to be drawn from the same distribution than the data used in fit (including centering).

Not used, present for API consistency by convention.

The log-likelihood of X_test with self.location_ and self.covariance_ as estimators of the Gaussian model mean and covariance matrix respectively.

Set the parameters of this estimator.

The method works on simple estimators as well as on nested objects (such as Pipeline). The latter have parameters of the form <component>__<parameter> so that it’s possible to update each component of a nested object.

Estimator parameters.

Visualizing the stock market structure

Sparse inverse covariance estimation

**Examples:**

Example 1 (sql):
```sql
>>> import numpy as np
>>> from sklearn.covariance import GraphicalLassoCV
>>> true_cov = np.array([[0.8, 0.0, 0.2, 0.0],
...                      [0.0, 0.4, 0.0, 0.0],
...                      [0.2, 0.0, 0.3, 0.1],
...                      [0.0, 0.0, 0.1, 0.7]])
>>> np.random.seed(0)
>>> X = np.random.multivariate_normal(mean=[0, 0, 0, 0],
...                                   cov=true_cov,
...                                   size=200)
>>> cov = GraphicalLassoCV().fit(X)
>>> np.around(cov.covariance_, decimals=3)
array([[0.816, 0.051, 0.22 , 0.017],
       [0.051, 0.364, 0.018, 0.036],
       [0.22 , 0.018, 0.322, 0.094],
       [0.017, 0.036, 0.094, 0.69 ]])
>>> np.around(cov.location_, decimals=3)
array([0.073, 0.04 , 0.038, 0.143])
```

---

## EmpiricalCovariance#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.covariance.EmpiricalCovariance.html

**Contents:**
- EmpiricalCovariance#
- Gallery examples#

Maximum likelihood covariance estimator.

Read more in the User Guide.

Specifies if the estimated precision is stored.

If True, data are not centered before computation. Useful when working with data whose mean is almost, but not exactly zero. If False (default), data are centered before computation.

Estimated location, i.e. the estimated mean.

Estimated covariance matrix.

Estimated pseudo-inverse matrix. (stored only if store_precision is True)

Number of features seen during fit.

Added in version 0.24.

Names of features seen during fit. Defined only when X has feature names that are all strings.

Added in version 1.0.

An object for detecting outliers in a Gaussian distributed dataset.

Sparse inverse covariance estimation with an l1-penalized estimator.

LedoitWolf Estimator.

Minimum Covariance Determinant (robust estimator of covariance).

Oracle Approximating Shrinkage Estimator.

Covariance estimator with shrinkage.

Compute the Mean Squared Error between two covariance estimators.

The covariance to compare with.

The type of norm used to compute the error. Available error types: - ‘frobenius’ (default): sqrt(tr(A^t.A)) - ‘spectral’: sqrt(max(eigenvalues(A^t.A)) where A is the error (comp_cov - self.covariance_).

If True (default), the squared error norm is divided by n_features. If False, the squared error norm is not rescaled.

Whether to compute the squared error norm or the error norm. If True (default), the squared error norm is returned. If False, the error norm is returned.

The Mean Squared Error (in the sense of the Frobenius norm) between self and comp_cov covariance estimators.

Fit the maximum likelihood covariance estimator to X.

Training data, where n_samples is the number of samples and n_features is the number of features.

Not used, present for API consistency by convention.

Returns the instance itself.

Get metadata routing of this object.

Please check User Guide on how the routing mechanism works.

A MetadataRequest encapsulating routing information.

Get parameters for this estimator.

If True, will return the parameters for this estimator and contained subobjects that are estimators.

Parameter names mapped to their values.

Getter for the precision matrix.

The precision matrix associated to the current covariance object.

Compute the squared Mahalanobis distances of given observations.

For a detailed example of how outliers affects the Mahalanobis distance, see Robust covariance estimation and Mahalanobis distances relevance.

The observations, the Mahalanobis distances of the which we compute. Observations are assumed to be drawn from the same distribution than the data used in fit.

Squared Mahalanobis distances of the observations.

Compute the log-likelihood of X_test under the estimated Gaussian model.

The Gaussian model is defined by its mean and covariance matrix which are represented respectively by self.location_ and self.covariance_.

Test data of which we compute the likelihood, where n_samples is the number of samples and n_features is the number of features. X_test is assumed to be drawn from the same distribution than the data used in fit (including centering).

Not used, present for API consistency by convention.

The log-likelihood of X_test with self.location_ and self.covariance_ as estimators of the Gaussian model mean and covariance matrix respectively.

Set the parameters of this estimator.

The method works on simple estimators as well as on nested objects (such as Pipeline). The latter have parameters of the form <component>__<parameter> so that it’s possible to update each component of a nested object.

Estimator parameters.

Shrinkage covariance estimation: LedoitWolf vs OAS and max-likelihood

Robust covariance estimation and Mahalanobis distances relevance

Robust vs Empirical covariance estimate

**Examples:**

Example 1 (sql):
```sql
>>> import numpy as np
>>> from sklearn.covariance import EmpiricalCovariance
>>> from sklearn.datasets import make_gaussian_quantiles
>>> real_cov = np.array([[.8, .3],
...                      [.3, .4]])
>>> rng = np.random.RandomState(0)
>>> X = rng.multivariate_normal(mean=[0, 0],
...                             cov=real_cov,
...                             size=500)
>>> cov = EmpiricalCovariance().fit(X)
>>> cov.covariance_
array([[0.7569, 0.2818],
       [0.2818, 0.3928]])
>>> cov.location_
array([0.0622, 0.0193])
```

---

## 1.17. Neural network models (supervised)#

**URL:** https://scikit-learn.org/stable/modules/neural_networks_supervised.html

**Contents:**
- 1.17. Neural network models (supervised)#
- 1.17.1. Multi-layer Perceptron#
- 1.17.2. Classification#
- 1.17.3. Regression#
- 1.17.4. Regularization#
- 1.17.5. Algorithms#
- 1.17.6. Complexity#
- 1.17.7. Tips on Practical Use#
- 1.17.8. More control with warm_start#

This implementation is not intended for large-scale applications. In particular, scikit-learn offers no GPU support. For much faster, GPU-based implementations, as well as frameworks offering much more flexibility to build deep learning architectures, see Related Projects.

Multi-layer Perceptron (MLP) is a supervised learning algorithm that learns a function \(f: R^m \rightarrow R^o\) by training on a dataset, where \(m\) is the number of dimensions for input and \(o\) is the number of dimensions for output. Given a set of features \(X = \{x_1, x_2, ..., x_m\}\) and a target \(y\), it can learn a non-linear function approximator for either classification or regression. It is different from logistic regression, in that between the input and the output layer, there can be one or more non-linear layers, called hidden layers. Figure 1 shows a one hidden layer MLP with scalar output.

Figure 1 : One hidden layer MLP.#

The leftmost layer, known as the input layer, consists of a set of neurons \(\{x_i | x_1, x_2, ..., x_m\}\) representing the input features. Each neuron in the hidden layer transforms the values from the previous layer with a weighted linear summation \(w_1x_1 + w_2x_2 + ... + w_mx_m\), followed by a non-linear activation function \(g(\cdot):R \rightarrow R\) - like the hyperbolic tan function. The output layer receives the values from the last hidden layer and transforms them into output values.

The module contains the public attributes coefs_ and intercepts_. coefs_ is a list of weight matrices, where weight matrix at index \(i\) represents the weights between layer \(i\) and layer \(i+1\). intercepts_ is a list of bias vectors, where the vector at index \(i\) represents the bias values added to layer \(i+1\).

The advantages of Multi-layer Perceptron are:

Capability to learn non-linear models.

Capability to learn models in real-time (on-line learning) using partial_fit.

The disadvantages of Multi-layer Perceptron (MLP) include:

MLP with hidden layers has a non-convex loss function where there exists more than one local minimum. Therefore, different random weight initializations can lead to different validation accuracy.

MLP requires tuning a number of hyperparameters such as the number of hidden neurons, layers, and iterations.

MLP is sensitive to feature scaling.

Please see Tips on Practical Use section that addresses some of these disadvantages.

Class MLPClassifier implements a multi-layer perceptron (MLP) algorithm that trains using Backpropagation.

MLP trains on two arrays: array X of size (n_samples, n_features), which holds the training samples represented as floating point feature vectors; and array y of size (n_samples,), which holds the target values (class labels) for the training samples:

After fitting (training), the model can predict labels for new samples:

MLP can fit a non-linear model to the training data. clf.coefs_ contains the weight matrices that constitute the model parameters:

Currently, MLPClassifier supports only the Cross-Entropy loss function, which allows probability estimates by running the predict_proba method.

MLP trains using Backpropagation. More precisely, it trains using some form of gradient descent and the gradients are calculated using Backpropagation. For classification, it minimizes the Cross-Entropy loss function, giving a vector of probability estimates \(P(y|x)\) per sample \(x\):

MLPClassifier supports multi-class classification by applying Softmax as the output function.

Further, the model supports multi-label classification in which a sample can belong to more than one class. For each class, the raw output passes through the logistic function. Values larger or equal to 0.5 are rounded to 1, otherwise to 0. For a predicted output of a sample, the indices where the value is 1 represent the assigned classes of that sample:

See the examples below and the docstring of MLPClassifier.fit for further information.

Compare Stochastic learning strategies for MLPClassifier

See Visualization of MLP weights on MNIST for visualized representation of trained weights.

Class MLPRegressor implements a multi-layer perceptron (MLP) that trains using backpropagation with no activation function in the output layer, which can also be seen as using the identity function as activation function. Therefore, it uses the square error as the loss function, and the output is a set of continuous values.

MLPRegressor also supports multi-output regression, in which a sample can have more than one target.

Both MLPRegressor and MLPClassifier use parameter alpha for regularization (L2 regularization) term which helps in avoiding overfitting by penalizing weights with large magnitudes. Following plot displays varying decision function with value of alpha.

See the examples below for further information.

Varying regularization in Multi-layer Perceptron

MLP trains using Stochastic Gradient Descent, Adam, or L-BFGS. Stochastic Gradient Descent (SGD) updates parameters using the gradient of the loss function with respect to a parameter that needs adaptation, i.e.

where \(\eta\) is the learning rate which controls the step-size in the parameter space search. \(Loss\) is the loss function used for the network.

More details can be found in the documentation of SGD

Adam is similar to SGD in a sense that it is a stochastic optimizer, but it can automatically adjust the amount to update parameters based on adaptive estimates of lower-order moments.

With SGD or Adam, training supports online and mini-batch learning.

L-BFGS is a solver that approximates the Hessian matrix which represents the second-order partial derivative of a function. Further it approximates the inverse of the Hessian matrix to perform parameter updates. The implementation uses the Scipy version of L-BFGS.

If the selected solver is ‘L-BFGS’, training does not support online nor mini-batch learning.

Suppose there are \(n\) training samples, \(m\) features, \(k\) hidden layers, each containing \(h\) neurons - for simplicity, and \(o\) output neurons. The time complexity of backpropagation is \(O(i \cdot n \cdot (m \cdot h + (k - 1) \cdot h \cdot h + h \cdot o))\), where \(i\) is the number of iterations. Since backpropagation has a high time complexity, it is advisable to start with smaller number of hidden neurons and few hidden layers for training.

Given a set of training examples \(\{(x_1, y_1), (x_2, y_2), \ldots, (x_n, y_n)\}\) where \(x_i \in \mathbf{R}^n\) and \(y_i \in \{0, 1\}\), a one hidden layer one hidden neuron MLP learns the function \(f(x) = W_2 g(W_1^T x + b_1) + b_2\) where \(W_1 \in \mathbf{R}^m\) and \(W_2, b_1, b_2 \in \mathbf{R}\) are model parameters. \(W_1, W_2\) represent the weights of the input layer and hidden layer, respectively; and \(b_1, b_2\) represent the bias added to the hidden layer and the output layer, respectively. \(g(\cdot) : R \rightarrow R\) is the activation function, set by default as the hyperbolic tan. It is given as,

For binary classification, \(f(x)\) passes through the logistic function \(g(z)=1/(1+e^{-z})\) to obtain output values between zero and one. A threshold, set to 0.5, would assign samples of outputs larger or equal 0.5 to the positive class, and the rest to the negative class.

If there are more than two classes, \(f(x)\) itself would be a vector of size (n_classes,). Instead of passing through logistic function, it passes through the softmax function, which is written as,

where \(z_i\) represents the \(i\) th element of the input to softmax, which corresponds to class \(i\), and \(K\) is the number of classes. The result is a vector containing the probabilities that sample \(x\) belongs to each class. The output is the class with the highest probability.

In regression, the output remains as \(f(x)\); therefore, output activation function is just the identity function.

MLP uses different loss functions depending on the problem type. The loss function for classification is Average Cross-Entropy, which in binary case is given as,

where \(\alpha ||W||_2^2\) is an L2-regularization term (aka penalty) that penalizes complex models; and \(\alpha > 0\) is a non-negative hyperparameter that controls the magnitude of the penalty.

For regression, MLP uses the Mean Square Error loss function; written as,

Starting from initial random weights, multi-layer perceptron (MLP) minimizes the loss function by repeatedly updating these weights. After computing the loss, a backward pass propagates it from the output layer to the previous layers, providing each weight parameter with an update value meant to decrease the loss.

In gradient descent, the gradient \(\nabla Loss_{W}\) of the loss with respect to the weights is computed and deducted from \(W\). More formally, this is expressed as,

where \(i\) is the iteration step, and \(\epsilon\) is the learning rate with a value larger than 0.

The algorithm stops when it reaches a preset maximum number of iterations; or when the improvement in loss is below a certain, small number.

Multi-layer Perceptron is sensitive to feature scaling, so it is highly recommended to scale your data. For example, scale each attribute on the input vector X to [0, 1] or [-1, +1], or standardize it to have mean 0 and variance 1. Note that you must apply the same scaling to the test set for meaningful results. You can use StandardScaler for standardization.

An alternative and recommended approach is to use StandardScaler in a Pipeline

Finding a reasonable regularization parameter \(\alpha\) is best done using GridSearchCV, usually in the range 10.0 ** -np.arange(1, 7).

Empirically, we observed that L-BFGS converges faster and with better solutions on small datasets. For relatively large datasets, however, Adam is very robust. It usually converges quickly and gives pretty good performance. SGD with momentum or nesterov’s momentum, on the other hand, can perform better than those two algorithms if learning rate is correctly tuned.

If you want more control over stopping criteria or learning rate in SGD, or want to do additional monitoring, using warm_start=True and max_iter=1 and iterating yourself can be helpful:

“Learning representations by back-propagating errors.” Rumelhart, David E., Geoffrey E. Hinton, and Ronald J. Williams.

“Stochastic Gradient Descent” L. Bottou - Website, 2010.

“Backpropagation” Andrew Ng, Jiquan Ngiam, Chuan Yu Foo, Yifan Mai, Caroline Suen - Website, 2011.

“Efficient BackProp” Y. LeCun, L. Bottou, G. Orr, K. Müller - In Neural Networks: Tricks of the Trade 1998.

“Adam: A method for stochastic optimization.” Kingma, Diederik, and Jimmy Ba (2014)

**Examples:**

Example 1 (sql):
```sql
>>> from sklearn.neural_network import MLPClassifier
>>> X = [[0., 0.], [1., 1.]]
>>> y = [0, 1]
>>> clf = MLPClassifier(solver='lbfgs', alpha=1e-5,
...                     hidden_layer_sizes=(5, 2), random_state=1)
...
>>> clf.fit(X, y)
MLPClassifier(alpha=1e-05, hidden_layer_sizes=(5, 2), random_state=1,
              solver='lbfgs')
```

Example 2 (unknown):
```unknown
>>> clf.predict([[2., 2.], [-1., -2.]])
array([1, 0])
```

Example 3 (json):
```json
>>> [coef.shape for coef in clf.coefs_]
[(2, 5), (5, 2), (2, 1)]
```

Example 4 (json):
```json
>>> clf.predict_proba([[2., 2.], [1., 2.]])
array([[1.967e-04, 9.998e-01],
       [1.967e-04, 9.998e-01]])
```

---

## 1.4. Support Vector Machines#

**URL:** https://scikit-learn.org/stable/modules/svm.html

**Contents:**
- 1.4. Support Vector Machines#
- 1.4.1. Classification#
  - 1.4.1.1. Multi-class classification#
  - 1.4.1.2. Scores and probabilities#
  - 1.4.1.3. Unbalanced problems#
- 1.4.2. Regression#
- 1.4.3. Density estimation, novelty detection#
- 1.4.4. Complexity#
- 1.4.5. Tips on Practical Use#
- 1.4.6. Kernel functions#

Support vector machines (SVMs) are a set of supervised learning methods used for classification, regression and outliers detection.

The advantages of support vector machines are:

Effective in high dimensional spaces.

Still effective in cases where number of dimensions is greater than the number of samples.

Uses a subset of training points in the decision function (called support vectors), so it is also memory efficient.

Versatile: different Kernel functions can be specified for the decision function. Common kernels are provided, but it is also possible to specify custom kernels.

The disadvantages of support vector machines include:

If the number of features is much greater than the number of samples, avoid over-fitting in choosing Kernel functions and regularization term is crucial.

SVMs do not directly provide probability estimates, these are calculated using an expensive five-fold cross-validation (see Scores and probabilities, below).

The support vector machines in scikit-learn support both dense (numpy.ndarray and convertible to that by numpy.asarray) and sparse (any scipy.sparse) sample vectors as input. However, to use an SVM to make predictions for sparse data, it must have been fit on such data. For optimal performance, use C-ordered numpy.ndarray (dense) or scipy.sparse.csr_matrix (sparse) with dtype=float64.

SVC, NuSVC and LinearSVC are classes capable of performing binary and multi-class classification on a dataset.

SVC and NuSVC are similar methods, but accept slightly different sets of parameters and have different mathematical formulations (see section Mathematical formulation). On the other hand, LinearSVC is another (faster) implementation of Support Vector Classification for the case of a linear kernel. It also lacks some of the attributes of SVC and NuSVC, like support_. LinearSVC uses squared_hinge loss and due to its implementation in liblinear it also regularizes the intercept, if considered. This effect can however be reduced by carefully fine tuning its intercept_scaling parameter, which allows the intercept term to have a different regularization behavior compared to the other features. The classification results and score can therefore differ from the other two classifiers.

As other classifiers, SVC, NuSVC and LinearSVC take as input two arrays: an array X of shape (n_samples, n_features) holding the training samples, and an array y of class labels (strings or integers), of shape (n_samples):

After being fitted, the model can then be used to predict new values:

SVMs decision function (detailed in the Mathematical formulation) depends on some subset of the training data, called the support vectors. Some properties of these support vectors can be found in attributes support_vectors_, support_ and n_support_:

SVM: Maximum margin separating hyperplane

SVM-Anova: SVM with univariate feature selection

Plot classification probability

SVC and NuSVC implement the “one-versus-one” (“ovo”) approach for multi-class classification, which constructs n_classes * (n_classes - 1) / 2 classifiers, each trained on data from two classes. Internally, the solver always uses this “ovo” strategy to train the models. However, by default, the decision_function_shape parameter is set to "ovr" (“one-vs-rest”), to have a consistent interface with other classifiers by monotonically transforming the “ovo” decision function into an “ovr” decision function of shape (n_samples, n_classes).

On the other hand, LinearSVC implements a “one-vs-rest” (“ovr”) multi-class strategy, thus training n_classes models.

See Mathematical formulation for a complete description of the decision function.

Note that the LinearSVC also implements an alternative multi-class strategy, the so-called multi-class SVM formulated by Crammer and Singer [16], by using the option multi_class='crammer_singer'. In practice, one-vs-rest classification is usually preferred, since the results are mostly similar, but the runtime is significantly less.

For “one-vs-rest” LinearSVC the attributes coef_ and intercept_ have the shape (n_classes, n_features) and (n_classes,) respectively. Each row of the coefficients corresponds to one of the n_classes “one-vs-rest” classifiers and similar for the intercepts, in the order of the “one” class.

In the case of “one-vs-one” SVC and NuSVC, the layout of the attributes is a little more involved. In the case of a linear kernel, the attributes coef_ and intercept_ have the shape (n_classes * (n_classes - 1) / 2, n_features) and (n_classes * (n_classes - 1) / 2) respectively. This is similar to the layout for LinearSVC described above, with each row now corresponding to a binary classifier. The order for classes 0 to n is “0 vs 1”, “0 vs 2” , … “0 vs n”, “1 vs 2”, “1 vs 3”, “1 vs n”, . . . “n-1 vs n”.

The shape of dual_coef_ is (n_classes-1, n_SV) with a somewhat hard to grasp layout. The columns correspond to the support vectors involved in any of the n_classes * (n_classes - 1) / 2 “one-vs-one” classifiers. Each support vector v has a dual coefficient in each of the n_classes - 1 classifiers comparing the class of v against another class. Note that some, but not all, of these dual coefficients, may be zero. The n_classes - 1 entries in each column are these dual coefficients, ordered by the opposing class.

This might be clearer with an example: consider a three class problem with class 0 having three support vectors \(v^{0}_0, v^{1}_0, v^{2}_0\) and class 1 and 2 having two support vectors \(v^{0}_1, v^{1}_1\) and \(v^{0}_2, v^{1}_2\) respectively. For each support vector \(v^{j}_i\), there are two dual coefficients. Let’s call the coefficient of support vector \(v^{j}_i\) in the classifier between classes \(i\) and \(k\) \(\alpha^{j}_{i,k}\). Then dual_coef_ looks like this:

Coefficients for SVs of class 0

Coefficients for SVs of class 1

Coefficients for SVs of class 2

Plot different SVM classifiers in the iris dataset

The decision_function method of SVC and NuSVC gives per-class scores for each sample (or a single score per sample in the binary case). When the constructor option probability is set to True, class membership probability estimates (from the methods predict_proba and predict_log_proba) are enabled. In the binary case, the probabilities are calibrated using Platt scaling [9]: logistic regression on the SVM’s scores, fit by an additional cross-validation on the training data. In the multiclass case, this is extended as per [10].

The same probability calibration procedure is available for all estimators via the CalibratedClassifierCV (see Probability calibration). In the case of SVC and NuSVC, this procedure is builtin to libsvm which is used under the hood, so it does not rely on scikit-learn’s CalibratedClassifierCV.

The cross-validation involved in Platt scaling is an expensive operation for large datasets. In addition, the probability estimates may be inconsistent with the scores:

the “argmax” of the scores may not be the argmax of the probabilities

in binary classification, a sample may be labeled by predict as belonging to the positive class even if the output of predict_proba is less than 0.5; and similarly, it could be labeled as negative even if the output of predict_proba is more than 0.5.

Platt’s method is also known to have theoretical issues. If confidence scores are required, but these do not have to be probabilities, then it is advisable to set probability=False and use decision_function instead of predict_proba.

Please note that when decision_function_shape='ovr' and n_classes > 2, unlike decision_function, the predict method does not try to break ties by default. You can set break_ties=True for the output of predict to be the same as np.argmax(clf.decision_function(...), axis=1), otherwise the first class among the tied classes will always be returned; but have in mind that it comes with a computational cost. See SVM Tie Breaking Example for an example on tie breaking.

In problems where it is desired to give more importance to certain classes or certain individual samples, the parameters class_weight and sample_weight can be used.

SVC (but not NuSVC) implements the parameter class_weight in the fit method. It’s a dictionary of the form {class_label : value}, where value is a floating point number > 0 that sets the parameter C of class class_label to C * value. The figure below illustrates the decision boundary of an unbalanced problem, with and without weight correction.

SVC, NuSVC, SVR, NuSVR, LinearSVC, LinearSVR and OneClassSVM implement also weights for individual samples in the fit method through the sample_weight parameter. Similar to class_weight, this sets the parameter C for the i-th example to C * sample_weight[i], which will encourage the classifier to get these samples right. The figure below illustrates the effect of sample weighting on the decision boundary. The size of the circles is proportional to the sample weights:

SVM: Separating hyperplane for unbalanced classes

SVM: Weighted samples

The method of Support Vector Classification can be extended to solve regression problems. This method is called Support Vector Regression.

The model produced by support vector classification (as described above) depends only on a subset of the training data, because the cost function for building the model does not care about training points that lie beyond the margin. Analogously, the model produced by Support Vector Regression depends only on a subset of the training data, because the cost function ignores samples whose prediction is close to their target.

There are three different implementations of Support Vector Regression: SVR, NuSVR and LinearSVR. LinearSVR provides a faster implementation than SVR but only considers the linear kernel, while NuSVR implements a slightly different formulation than SVR and LinearSVR. Due to its implementation in liblinear LinearSVR also regularizes the intercept, if considered. This effect can however be reduced by carefully fine tuning its intercept_scaling parameter, which allows the intercept term to have a different regularization behavior compared to the other features. The classification results and score can therefore differ from the other two classifiers. See Implementation details for further details.

As with classification classes, the fit method will take as argument vectors X, y, only that in this case y is expected to have floating point values instead of integer values:

Support Vector Regression (SVR) using linear and non-linear kernels

The class OneClassSVM implements a One-Class SVM which is used in outlier detection.

See Novelty and Outlier Detection for the description and usage of OneClassSVM.

Support Vector Machines are powerful tools, but their compute and storage requirements increase rapidly with the number of training vectors. The core of an SVM is a quadratic programming problem (QP), separating support vectors from the rest of the training data. The QP solver used by the libsvm-based implementation scales between \(O(n_{features} \times n_{samples}^2)\) and \(O(n_{features} \times n_{samples}^3)\) depending on how efficiently the libsvm cache is used in practice (dataset dependent). If the data is very sparse \(n_{features}\) should be replaced by the average number of non-zero features in a sample vector.

For the linear case, the algorithm used in LinearSVC by the liblinear implementation is much more efficient than its libsvm-based SVC counterpart and can scale almost linearly to millions of samples and/or features.

Avoiding data copy: For SVC, SVR, NuSVC and NuSVR, if the data passed to certain methods is not C-ordered contiguous and double precision, it will be copied before calling the underlying C implementation. You can check whether a given numpy array is C-contiguous by inspecting its flags attribute.

For LinearSVC (and LogisticRegression) any input passed as a numpy array will be copied and converted to the liblinear internal sparse data representation (double precision floats and int32 indices of non-zero components). If you want to fit a large-scale linear classifier without copying a dense numpy C-contiguous double precision array as input, we suggest to use the SGDClassifier class instead. The objective function can be configured to be almost the same as the LinearSVC model.

Kernel cache size: For SVC, SVR, NuSVC and NuSVR, the size of the kernel cache has a strong impact on run times for larger problems. If you have enough RAM available, it is recommended to set cache_size to a higher value than the default of 200(MB), such as 500(MB) or 1000(MB).

Setting C: C is 1 by default and it’s a reasonable default choice. If you have a lot of noisy observations you should decrease it: decreasing C corresponds to more regularization.

LinearSVC and LinearSVR are less sensitive to C when it becomes large, and prediction results stop improving after a certain threshold. Meanwhile, larger C values will take more time to train, sometimes up to 10 times longer, as shown in [11].

Support Vector Machine algorithms are not scale invariant, so it is highly recommended to scale your data. For example, scale each attribute on the input vector X to [0,1] or [-1,+1], or standardize it to have mean 0 and variance 1. Note that the same scaling must be applied to the test vector to obtain meaningful results. This can be done easily by using a Pipeline:

See section Preprocessing data for more details on scaling and normalization.

Regarding the shrinking parameter, quoting [12]: We found that if the number of iterations is large, then shrinking can shorten the training time. However, if we loosely solve the optimization problem (e.g., by using a large stopping tolerance), the code without using shrinking may be much faster

Parameter nu in NuSVC/OneClassSVM/NuSVR approximates the fraction of training errors and support vectors.

In SVC, if the data is unbalanced (e.g. many positive and few negative), set class_weight='balanced' and/or try different penalty parameters C.

Randomness of the underlying implementations: The underlying implementations of SVC and NuSVC use a random number generator only to shuffle the data for probability estimation (when probability is set to True). This randomness can be controlled with the random_state parameter. If probability is set to False these estimators are not random and random_state has no effect on the results. The underlying OneClassSVM implementation is similar to the ones of SVC and NuSVC. As no probability estimation is provided for OneClassSVM, it is not random.

The underlying LinearSVC implementation uses a random number generator to select features when fitting the model with a dual coordinate descent (i.e. when dual is set to True). It is thus not uncommon to have slightly different results for the same input data. If that happens, try with a smaller tol parameter. This randomness can also be controlled with the random_state parameter. When dual is set to False the underlying implementation of LinearSVC is not random and random_state has no effect on the results.

Using L1 penalization as provided by LinearSVC(penalty='l1', dual=False) yields a sparse solution, i.e. only a subset of feature weights is different from zero and contribute to the decision function. Increasing C yields a more complex model (more features are selected). The C value that yields a “null” model (all weights equal to zero) can be calculated using l1_min_c.

The kernel function can be any of the following:

linear: \(\langle x, x'\rangle\).

polynomial: \((\gamma \langle x, x'\rangle + r)^d\), where \(d\) is specified by parameter degree, \(r\) by coef0.

rbf: \(\exp(-\gamma \|x-x'\|^2)\), where \(\gamma\) is specified by parameter gamma, must be greater than 0.

sigmoid \(\tanh(\gamma \langle x,x'\rangle + r)\), where \(r\) is specified by coef0.

Different kernels are specified by the kernel parameter:

See also Kernel Approximation for a solution to use RBF kernels that is much faster and more scalable.

When training an SVM with the Radial Basis Function (RBF) kernel, two parameters must be considered: C and gamma. The parameter C, common to all SVM kernels, trades off misclassification of training examples against simplicity of the decision surface. A low C makes the decision surface smooth, while a high C aims at classifying all training examples correctly. gamma defines how much influence a single training example has. The larger gamma is, the closer other examples must be to be affected.

Proper choice of C and gamma is critical to the SVM’s performance. One is advised to use GridSearchCV with C and gamma spaced exponentially far apart to choose good values.

Scaling the regularization parameter for SVCs

You can define your own kernels by either giving the kernel as a python function or by precomputing the Gram matrix.

Classifiers with custom kernels behave the same way as any other classifiers, except that:

Field support_vectors_ is now empty, only indices of support vectors are stored in support_

A reference (and not a copy) of the first argument in the fit() method is stored for future reference. If that array changes between the use of fit() and predict() you will have unexpected results.

You can use your own defined kernels by passing a function to the kernel parameter.

Your kernel must take as arguments two matrices of shape (n_samples_1, n_features), (n_samples_2, n_features) and return a kernel matrix of shape (n_samples_1, n_samples_2).

The following code defines a linear kernel and creates a classifier instance that will use that kernel:

You can pass pre-computed kernels by using the kernel='precomputed' option. You should then pass Gram matrix instead of X to the fit and predict methods. The kernel values between all training vectors and the test vectors must be provided:

SVM with custom kernel

A support vector machine constructs a hyper-plane or set of hyper-planes in a high or infinite dimensional space, which can be used for classification, regression or other tasks. Intuitively, a good separation is achieved by the hyper-plane that has the largest distance to the nearest training data points of any class (so-called functional margin), since in general the larger the margin the lower the generalization error of the classifier. The figure below shows the decision function for a linearly separable problem, with three samples on the margin boundaries, called “support vectors”:

In general, when the problem isn’t linearly separable, the support vectors are the samples within the margin boundaries.

We recommend [13] and [14] as good references for the theory and practicalities of SVMs.

Given training vectors \(x_i \in \mathbb{R}^p\), i=1,…, n, in two classes, and a vector \(y \in \{1, -1\}^n\), our goal is to find \(w \in \mathbb{R}^p\) and \(b \in \mathbb{R}\) such that the prediction given by \(\text{sign} (w^T\phi(x) + b)\) is correct for most samples.

SVC solves the following primal problem:

Intuitively, we’re trying to maximize the margin (by minimizing \(||w||^2 = w^Tw\)), while incurring a penalty when a sample is misclassified or within the margin boundary. Ideally, the value \(y_i (w^T \phi (x_i) + b)\) would be \(\geq 1\) for all samples, which indicates a perfect prediction. But problems are usually not always perfectly separable with a hyperplane, so we allow some samples to be at a distance \(\zeta_i\) from their correct margin boundary. The penalty term C controls the strength of this penalty, and as a result, acts as an inverse regularization parameter (see note below).

The dual problem to the primal is

where \(e\) is the vector of all ones, and \(Q\) is an \(n\) by \(n\) positive semidefinite matrix, \(Q_{ij} \equiv y_i y_j K(x_i, x_j)\), where \(K(x_i, x_j) = \phi (x_i)^T \phi (x_j)\) is the kernel. The terms \(\alpha_i\) are called the dual coefficients, and they are upper-bounded by \(C\). This dual representation highlights the fact that training vectors are implicitly mapped into a higher (maybe infinite) dimensional space by the function \(\phi\): see kernel trick.

Once the optimization problem is solved, the output of decision_function for a given sample \(x\) becomes:

and the predicted class corresponds to its sign. We only need to sum over the support vectors (i.e. the samples that lie within the margin) because the dual coefficients \(\alpha_i\) are zero for the other samples.

These parameters can be accessed through the attributes dual_coef_ which holds the product \(y_i \alpha_i\), support_vectors_ which holds the support vectors, and intercept_ which holds the independent term \(b\).

While SVM models derived from libsvm and liblinear use C as regularization parameter, most other estimators use alpha. The exact equivalence between the amount of regularization of two models depends on the exact objective function optimized by the model. For example, when the estimator used is Ridge regression, the relation between them is given as \(C = \frac{1}{\alpha}\).

The primal problem can be equivalently formulated as

where we make use of the hinge loss. This is the form that is directly optimized by LinearSVC, but unlike the dual form, this one does not involve inner products between samples, so the famous kernel trick cannot be applied. This is why only the linear kernel is supported by LinearSVC (\(\phi\) is the identity function).

The \(\nu\)-SVC formulation [15] is a reparameterization of the \(C\)-SVC and therefore mathematically equivalent.

We introduce a new parameter \(\nu\) (instead of \(C\)) which controls the number of support vectors and margin errors: \(\nu \in (0, 1]\) is an upper bound on the fraction of margin errors and a lower bound of the fraction of support vectors. A margin error corresponds to a sample that lies on the wrong side of its margin boundary: it is either misclassified, or it is correctly classified but does not lie beyond the margin.

Given training vectors \(x_i \in \mathbb{R}^p\), i=1,…, n, and a vector \(y \in \mathbb{R}^n\) \(\varepsilon\)-SVR solves the following primal problem:

Here, we are penalizing samples whose prediction is at least \(\varepsilon\) away from their true target. These samples penalize the objective by \(\zeta_i\) or \(\zeta_i^*\), depending on whether their predictions lie above or below the \(\varepsilon\) tube.

where \(e\) is the vector of all ones, \(Q\) is an \(n\) by \(n\) positive semidefinite matrix, \(Q_{ij} \equiv K(x_i, x_j) = \phi (x_i)^T \phi (x_j)\) is the kernel. Here training vectors are implicitly mapped into a higher (maybe infinite) dimensional space by the function \(\phi\).

These parameters can be accessed through the attributes dual_coef_ which holds the difference \(\alpha_i - \alpha_i^*\), support_vectors_ which holds the support vectors, and intercept_ which holds the independent term \(b\)

The primal problem can be equivalently formulated as

where we make use of the epsilon-insensitive loss, i.e. errors of less than \(\varepsilon\) are ignored. This is the form that is directly optimized by LinearSVR.

Internally, we use libsvm [12] and liblinear [11] to handle all computations. These libraries are wrapped using C and Cython. For a description of the implementation and details of the algorithms used, please refer to their respective papers.

Platt “Probabilistic outputs for SVMs and comparisons to regularized likelihood methods”.

Wu, Lin and Weng, “Probability estimates for multi-class classification by pairwise coupling”, JMLR 5:975-1005, 2004.

Fan, Rong-En, et al., “LIBLINEAR: A library for large linear classification.”, Journal of machine learning research 9.Aug (2008): 1871-1874.

Chang and Lin, LIBSVM: A Library for Support Vector Machines.

Bishop, Pattern recognition and machine learning, chapter 7 Sparse Kernel Machines.

“A Tutorial on Support Vector Regression” Alex J. Smola, Bernhard Schölkopf - Statistics and Computing archive Volume 14 Issue 3, August 2004, p. 199-222.

Schölkopf et. al New Support Vector Algorithms, Neural Computation 12, 1207-1245 (2000).

Crammer and Singer On the Algorithmic Implementation of Multiclass Kernel-based Vector Machines, JMLR 2001.

**Examples:**

Example 1 (python):
```python
>>> from sklearn import svm
>>> X = [[0, 0], [1, 1]]
>>> y = [0, 1]
>>> clf = svm.SVC()
>>> clf.fit(X, y)
SVC()
```

Example 2 (unknown):
```unknown
>>> clf.predict([[2., 2.]])
array([1])
```

Example 3 (json):
```json
>>> # get support vectors
>>> clf.support_vectors_
array([[0., 0.],
       [1., 1.]])
>>> # get indices of support vectors
>>> clf.support_
array([0, 1]...)
>>> # get number of support vectors for each class
>>> clf.n_support_
array([1, 1]...)
```

Example 4 (json):
```json
>>> X = [[0], [1], [2], [3]]
>>> Y = [0, 1, 2, 3]
>>> clf = svm.SVC(decision_function_shape='ovo')
>>> clf.fit(X, Y)
SVC(decision_function_shape='ovo')
>>> dec = clf.decision_function([[1]])
>>> dec.shape[1] # 6 classes: 4*3/2 = 6
6
>>> clf.decision_function_shape = "ovr"
>>> dec = clf.decision_function([[1]])
>>> dec.shape[1] # 4 classes
4
```

---

## 

**URL:** https://scikit-learn.org/stable/_sources/modules/manifold.rst.txt

---

## 1.15. Isotonic regression#

**URL:** https://scikit-learn.org/stable/modules/isotonic.html

**Contents:**
- 1.15. Isotonic regression#

The class IsotonicRegression fits a non-decreasing real function to 1-dimensional data. It solves the following problem:

subject to \(\hat{y}_i \le \hat{y}_j\) whenever \(X_i \le X_j\), where the weights \(w_i\) are strictly positive, and both X and y are arbitrary real quantities.

The increasing parameter changes the constraint to \(\hat{y}_i \ge \hat{y}_j\) whenever \(X_i \le X_j\). Setting it to ‘auto’ will automatically choose the constraint based on Spearman’s rank correlation coefficient.

IsotonicRegression produces a series of predictions \(\hat{y}_i\) for the training data which are the closest to the targets \(y\) in terms of mean squared error. These predictions are interpolated for predicting to unseen data. The predictions of IsotonicRegression thus form a function that is piecewise linear:

---

## RadiusNeighborsRegressor#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.RadiusNeighborsRegressor.html

**Contents:**
- RadiusNeighborsRegressor#

Regression based on neighbors within a fixed radius.

The target is predicted by local interpolation of the targets associated of the nearest neighbors in the training set.

Read more in the User Guide.

Added in version 0.9.

Range of parameter space to use by default for radius_neighbors queries.

Weight function used in prediction. Possible values:

‘uniform’ : uniform weights. All points in each neighborhood are weighted equally.

‘distance’ : weight points by the inverse of their distance. in this case, closer neighbors of a query point will have a greater influence than neighbors which are further away.

[callable] : a user-defined function which accepts an array of distances, and returns an array of the same shape containing the weights.

Uniform weights are used by default.

Algorithm used to compute the nearest neighbors:

‘ball_tree’ will use BallTree

‘kd_tree’ will use KDTree

‘brute’ will use a brute-force search.

‘auto’ will attempt to decide the most appropriate algorithm based on the values passed to fit method.

Note: fitting on sparse input will override the setting of this parameter, using brute force.

Leaf size passed to BallTree or KDTree. This can affect the speed of the construction and query, as well as the memory required to store the tree. The optimal value depends on the nature of the problem.

Power parameter for the Minkowski metric. When p = 1, this is equivalent to using manhattan_distance (l1), and euclidean_distance (l2) for p = 2. For arbitrary p, minkowski_distance (l_p) is used.

Metric to use for distance computation. Default is “minkowski”, which results in the standard Euclidean distance when p = 2. See the documentation of scipy.spatial.distance and the metrics listed in distance_metrics for valid metric values.

If metric is “precomputed”, X is assumed to be a distance matrix and must be square during fit. X may be a sparse graph, in which case only “nonzero” elements may be considered neighbors.

If metric is a callable function, it takes two arrays representing 1D vectors as inputs and must return one value indicating the distance between those vectors. This works for Scipy’s metrics, but is less efficient than passing the metric name as a string.

Additional keyword arguments for the metric function.

The number of parallel jobs to run for neighbors search. None means 1 unless in a joblib.parallel_backend context. -1 means using all processors. See Glossary for more details.

The distance metric to use. It will be same as the metric parameter or a synonym of it, e.g. ‘euclidean’ if the metric parameter set to ‘minkowski’ and p parameter set to 2.

Additional keyword arguments for the metric function. For most metrics will be same with metric_params parameter, but may also contain the p parameter value if the effective_metric_ attribute is set to ‘minkowski’.

Number of features seen during fit.

Added in version 0.24.

Names of features seen during fit. Defined only when X has feature names that are all strings.

Added in version 1.0.

Number of samples in the fitted data.

Unsupervised learner for implementing neighbor searches.

Regression based on k-nearest neighbors.

Classifier based on the k-nearest neighbors.

Classifier based on neighbors within a given radius.

See Nearest Neighbors in the online documentation for a discussion of the choice of algorithm and leaf_size.

https://en.wikipedia.org/wiki/K-nearest_neighbor_algorithm

Fit the radius neighbors regressor from the training dataset.

The fitted radius neighbors regressor.

Get metadata routing of this object.

Please check User Guide on how the routing mechanism works.

A MetadataRequest encapsulating routing information.

Get parameters for this estimator.

If True, will return the parameters for this estimator and contained subobjects that are estimators.

Parameter names mapped to their values.

Predict the target for the provided data.

Test samples. If None, predictions for all indexed points are returned; in this case, points are not considered their own neighbors.

Find the neighbors within a given radius of a point or points.

Return the indices and distances of each point from the dataset lying in a ball with size radius around the points of the query array. Points lying on the boundary are included in the results.

The result points are not necessarily sorted by distance to their query point.

The query point or points. If not provided, neighbors of each indexed point are returned. In this case, the query point is not considered its own neighbor.

Limiting distance of neighbors to return. The default is the value passed to the constructor.

Whether or not to return the distances.

If True, the distances and indices will be sorted by increasing distances before being returned. If False, the results may not be sorted. If return_distance=False, setting sort_results=True will result in an error.

Added in version 0.22.

Array representing the distances to each point, only present if return_distance=True. The distance values are computed according to the metric constructor parameter.

An array of arrays of indices of the approximate nearest points from the population matrix that lie within a ball of size radius around the query points.

Because the number of neighbors of each point is not necessarily equal, the results for multiple query points cannot be fit in a standard data array. For efficiency, radius_neighbors returns arrays of objects, where each object is a 1D array of indices or distances.

In the following example, we construct a NeighborsClassifier class from an array representing our data set and ask who’s the closest point to [1, 1, 1]:

The first array returned contains the distances to all points which are closer than 1.6, while the second array returned contains their indices. In general, multiple points can be queried at the same time.

Compute the (weighted) graph of Neighbors for points in X.

Neighborhoods are restricted the points at a distance lower than radius.

The query point or points. If not provided, neighbors of each indexed point are returned. In this case, the query point is not considered its own neighbor.

Radius of neighborhoods. The default is the value passed to the constructor.

Type of returned matrix: ‘connectivity’ will return the connectivity matrix with ones and zeros, in ‘distance’ the edges are distances between points, type of distance depends on the selected metric parameter in NearestNeighbors class.

If True, in each row of the result, the non-zero entries will be sorted by increasing distances. If False, the non-zero entries may not be sorted. Only used with mode=’distance’.

Added in version 0.22.

n_samples_fit is the number of samples in the fitted data. A[i, j] gives the weight of the edge connecting i to j. The matrix is of CSR format.

Compute the (weighted) graph of k-Neighbors for points in X.

Return coefficient of determination on test data.

The coefficient of determination, \(R^2\), is defined as \((1 - \frac{u}{v})\), where \(u\) is the residual sum of squares ((y_true - y_pred)** 2).sum() and \(v\) is the total sum of squares ((y_true - y_true.mean()) ** 2).sum(). The best possible score is 1.0 and it can be negative (because the model can be arbitrarily worse). A constant model that always predicts the expected value of y, disregarding the input features, would get a \(R^2\) score of 0.0.

Test samples. For some estimators this may be a precomputed kernel matrix or a list of generic objects instead with shape (n_samples, n_samples_fitted), where n_samples_fitted is the number of samples used in the fitting for the estimator.

\(R^2\) of self.predict(X) w.r.t. y.

The \(R^2\) score used when calling score on a regressor uses multioutput='uniform_average' from version 0.23 to keep consistent with default value of r2_score. This influences the score method of all the multioutput regressors (except for MultiOutputRegressor).

Set the parameters of this estimator.

The method works on simple estimators as well as on nested objects (such as Pipeline). The latter have parameters of the form <component>__<parameter> so that it’s possible to update each component of a nested object.

Estimator parameters.

Configure whether metadata should be requested to be passed to the score method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to score if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to score.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Added in version 1.3.

Metadata routing for sample_weight parameter in score.

**Examples:**

Example 1 (python):
```python
>>> X = [[0], [1], [2], [3]]
>>> y = [0, 0, 1, 1]
>>> from sklearn.neighbors import RadiusNeighborsRegressor
>>> neigh = RadiusNeighborsRegressor(radius=1.0)
>>> neigh.fit(X, y)
RadiusNeighborsRegressor(...)
>>> print(neigh.predict([[1.5]]))
[0.5]
```

Example 2 (python):
```python
>>> import numpy as np
>>> samples = [[0., 0., 0.], [0., .5, 0.], [1., 1., .5]]
>>> from sklearn.neighbors import NearestNeighbors
>>> neigh = NearestNeighbors(radius=1.6)
>>> neigh.fit(samples)
NearestNeighbors(radius=1.6)
>>> rng = neigh.radius_neighbors([[1., 1., 1.]])
>>> print(np.asarray(rng[0][0]))
[1.5 0.5]
>>> print(np.asarray(rng[1][0]))
[1 2]
```

Example 3 (sql):
```sql
>>> X = [[0], [3], [1]]
>>> from sklearn.neighbors import NearestNeighbors
>>> neigh = NearestNeighbors(radius=1.5)
>>> neigh.fit(X)
NearestNeighbors(radius=1.5)
>>> A = neigh.radius_neighbors_graph(X)
>>> A.toarray()
array([[1., 0., 1.],
       [0., 1., 0.],
       [1., 0., 1.]])
```

---

## lasso_path#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.lasso_path.html

**Contents:**
- lasso_path#
- Gallery examples#

Compute Lasso path with coordinate descent.

The Lasso optimization function varies for mono and multi-outputs.

For mono-output tasks it is:

For multi-output tasks it is:

i.e. the sum of norm of each row.

Read more in the User Guide.

Training data. Pass directly as Fortran-contiguous data to avoid unnecessary memory duplication. If y is mono-output then X can be sparse.

Length of the path. eps=1e-3 means that alpha_min / alpha_max = 1e-3.

Number of alphas along the regularization path.

List of alphas where to compute the models. If None alphas are set automatically.

Whether to use a precomputed Gram matrix to speed up calculations. If set to 'auto' let us decide. The Gram matrix can also be passed as argument.

Xy = np.dot(X.T, y) that can be precomputed. It is useful only when the Gram matrix is precomputed.

If True, X will be copied; else, it may be overwritten.

The initial values of the coefficients.

Whether to return the number of iterations or not.

If set to True, forces coefficients to be positive. (Only allowed when y.ndim == 1).

Keyword arguments passed to the coordinate descent solver.

The alphas along the path where models are computed.

Coefficients along the path.

The dual gaps at the end of the optimization for each alpha.

The number of iterations taken by the coordinate descent optimizer to reach the specified tolerance for each alpha.

Compute Least Angle Regression or Lasso path using LARS algorithm.

The Lasso is a linear model that estimates sparse coefficients.

Lasso model fit with Least Angle Regression a.k.a. Lars.

Lasso linear model with iterative fitting along a regularization path.

Cross-validated Lasso using the LARS algorithm.

Estimator that can be used to transform signals into sparse linear combination of atoms from a fixed.

For an example, see examples/linear_model/plot_lasso_lasso_lars_elasticnet_path.py.

To avoid unnecessary memory duplication the X argument of the fit method should be directly passed as a Fortran-contiguous numpy array.

Note that in certain cases, the Lars solver may be significantly faster to implement this functionality. In particular, linear interpolation can be used to retrieve model coefficients between the values output by lars_path.

The underlying coordinate descent solver uses gap safe screening rules to speedup fitting time, see User Guide on coordinate descent.

Comparing lasso_path and lars_path with interpolation:

Lasso, Lasso-LARS, and Elastic Net paths

**Examples:**

Example 1 (unknown):
```unknown
(1 / (2 * n_samples)) * ||y - Xw||^2_2 + alpha * ||w||_1
```

Example 2 (unknown):
```unknown
(1 / (2 * n_samples)) * ||Y - XW||^2_Fro + alpha * ||W||_21
```

Example 3 (unknown):
```unknown
||W||_21 = \sum_i \sqrt{\sum_j w_{ij}^2}
```

Example 4 (python):
```python
>>> import numpy as np
>>> from sklearn.linear_model import lasso_path
>>> X = np.array([[1, 2, 3.1], [2.3, 5.4, 4.3]]).T
>>> y = np.array([1, 2, 3.1])
>>> # Use lasso_path to compute a coefficient path
>>> _, coef_path, _ = lasso_path(X, y, alphas=[5., 1., .5])
>>> print(coef_path)
[[0.         0.         0.46874778]
 [0.2159048  0.4425765  0.23689075]]
```

---

## Birch#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.cluster.Birch.html

**Contents:**
- Birch#
- Gallery examples#

Implements the BIRCH clustering algorithm.

It is a memory-efficient, online-learning algorithm provided as an alternative to MiniBatchKMeans. It constructs a tree data structure with the cluster centroids being read off the leaf. These can be either the final cluster centroids or can be provided as input to another clustering algorithm such as AgglomerativeClustering.

Read more in the User Guide.

Added in version 0.16.

The radius of the subcluster obtained by merging a new sample and the closest subcluster should be lesser than the threshold. Otherwise a new subcluster is started. Setting this value to be very low promotes splitting and vice-versa.

Maximum number of CF subclusters in each node. If a new samples enters such that the number of subclusters exceed the branching_factor then that node is split into two nodes with the subclusters redistributed in each. The parent subcluster of that node is removed and two new subclusters are added as parents of the 2 split nodes.

Number of clusters after the final clustering step, which treats the subclusters from the leaves as new samples.

None : the final clustering step is not performed and the subclusters are returned as they are.

sklearn.cluster Estimator : If a model is provided, the model is fit treating the subclusters as new samples and the initial data is mapped to the label of the closest subcluster.

int : the model fit is AgglomerativeClustering with n_clusters set to be equal to the int.

Whether or not to compute labels for each fit.

Start pointer to all the leaves.

Centroids of all subclusters read directly from the leaves.

Labels assigned to the centroids of the subclusters after they are clustered globally.

Array of labels assigned to the input data. if partial_fit is used instead of fit, they are assigned to the last batch of data.

Number of features seen during fit.

Added in version 0.24.

Names of features seen during fit. Defined only when X has feature names that are all strings.

Added in version 1.0.

Alternative implementation that does incremental updates of the centers’ positions using mini-batches.

The tree data structure consists of nodes with each node consisting of a number of subclusters. The maximum number of subclusters in a node is determined by the branching factor. Each subcluster maintains a linear sum, squared sum and the number of samples in that subcluster. In addition, each subcluster can also have a node as its child, if the subcluster is not a member of a leaf node.

For a new point entering the root, it is merged with the subcluster closest to it and the linear sum, squared sum and the number of samples of that subcluster are updated. This is done recursively till the properties of the leaf node are updated.

See Compare BIRCH and MiniBatchKMeans for a comparison with MiniBatchKMeans.

Tian Zhang, Raghu Ramakrishnan, Maron Livny BIRCH: An efficient data clustering method for large databases. https://www.cs.sfu.ca/CourseCentral/459/han/papers/zhang96.pdf

Roberto Perdisci JBirch - Java implementation of BIRCH clustering algorithm https://code.google.com/archive/p/jbirch

For a comparison of the BIRCH clustering algorithm with other clustering algorithms, see Comparing different clustering algorithms on toy datasets

Build a CF Tree for the input data.

Not used, present here for API consistency by convention.

Perform clustering on X and returns cluster labels.

Not used, present for API consistency by convention.

Arguments to be passed to fit.

Added in version 1.4.

Fit to data, then transform it.

Fits transformer to X and y with optional parameters fit_params and returns a transformed version of X.

Target values (None for unsupervised transformations).

Additional fit parameters. Pass only if the estimator accepts additional params in its fit method.

Get output feature names for transformation.

The feature names out will prefixed by the lowercased class name. For example, if the transformer outputs 3 features, then the feature names out are: ["class_name0", "class_name1", "class_name2"].

Only used to validate feature names with the names seen in fit.

Transformed feature names.

Get metadata routing of this object.

Please check User Guide on how the routing mechanism works.

A MetadataRequest encapsulating routing information.

Get parameters for this estimator.

If True, will return the parameters for this estimator and contained subobjects that are estimators.

Parameter names mapped to their values.

Online learning. Prevents rebuilding of CFTree from scratch.

Input data. If X is not provided, only the global clustering step is done.

Not used, present here for API consistency by convention.

Predict data using the centroids_ of subclusters.

Avoid computation of the row norms of X.

Set output container.

See Introducing the set_output API for an example on how to use the API.

Configure output of transform and fit_transform.

"default": Default output format of a transformer

"pandas": DataFrame output

"polars": Polars output

None: Transform configuration is unchanged

Added in version 1.4: "polars" option was added.

Set the parameters of this estimator.

The method works on simple estimators as well as on nested objects (such as Pipeline). The latter have parameters of the form <component>__<parameter> so that it’s possible to update each component of a nested object.

Estimator parameters.

Transform X into subcluster centroids dimension.

Each dimension represents the distance from the sample point to each cluster centroid.

Compare BIRCH and MiniBatchKMeans

Comparing different clustering algorithms on toy datasets

**Examples:**

Example 1 (sql):
```sql
>>> from sklearn.cluster import Birch
>>> X = [[0, 1], [0.3, 1], [-0.3, 1], [0, -1], [0.3, -1], [-0.3, -1]]
>>> brc = Birch(n_clusters=None)
>>> brc.fit(X)
Birch(n_clusters=None)
>>> brc.predict(X)
array([0, 0, 0, 1, 1, 1])
```

---

## ElasticNet#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.ElasticNet.html

**Contents:**
- ElasticNet#
- Gallery examples#

Linear regression with combined L1 and L2 priors as regularizer.

Minimizes the objective function:

If you are interested in controlling the L1 and L2 penalty separately, keep in mind that this is equivalent to:

The parameter l1_ratio corresponds to alpha in the glmnet R package while alpha corresponds to the lambda parameter in glmnet. Specifically, l1_ratio = 1 is the lasso penalty. Currently, l1_ratio <= 0.01 is not reliable, unless you supply your own sequence of alpha.

Read more in the User Guide.

Constant that multiplies the penalty terms. Defaults to 1.0. See the notes for the exact mathematical meaning of this parameter. alpha = 0 is equivalent to an ordinary least square, solved by the LinearRegression object. For numerical reasons, using alpha = 0 with the Lasso object is not advised. Given this, you should use the LinearRegression object.

The ElasticNet mixing parameter, with 0 <= l1_ratio <= 1. For l1_ratio = 0 the penalty is an L2 penalty. For l1_ratio = 1 it is an L1 penalty. For 0 < l1_ratio < 1, the penalty is a combination of L1 and L2.

Whether the intercept should be estimated or not. If False, the data is assumed to be already centered.

Whether to use a precomputed Gram matrix to speed up calculations. The Gram matrix can also be passed as argument. For sparse input this option is always False to preserve sparsity. Check an example on how to use a precomputed Gram Matrix in ElasticNet for details.

The maximum number of iterations.

If True, X will be copied; else, it may be overwritten.

The tolerance for the optimization: if the updates are smaller or equal to tol, the optimization code checks the dual gap for optimality and continues until it is smaller or equal to tol, see Notes below.

When set to True, reuse the solution of the previous call to fit as initialization, otherwise, just erase the previous solution. See the Glossary.

When set to True, forces the coefficients to be positive.

The seed of the pseudo random number generator that selects a random feature to update. Used when selection == ‘random’. Pass an int for reproducible output across multiple function calls. See Glossary.

If set to ‘random’, a random coefficient is updated every iteration rather than looping over features sequentially by default. This (setting to ‘random’) often leads to significantly faster convergence especially when tol is higher than 1e-4.

Parameter vector (w in the cost function formula).

Sparse representation of the fitted coef_.

Independent term in decision function.

Number of iterations run by the coordinate descent solver to reach the specified tolerance.

Given param alpha, the dual gaps at the end of the optimization, same shape as each observation of y.

Number of features seen during fit.

Added in version 0.24.

Names of features seen during fit. Defined only when X has feature names that are all strings.

Added in version 1.0.

Elastic net model with best model selection by cross-validation.

Implements elastic net regression with incremental training.

Implements logistic regression with elastic net penalty (SGDClassifier(loss="log_loss", penalty="elasticnet")).

To avoid unnecessary memory duplication the X argument of the fit method should be directly passed as a Fortran-contiguous numpy array.

The precise stopping criteria based on tol are the following: First, check that that maximum coordinate update, i.e. \(\max_j |w_j^{new} - w_j^{old}|\) is smaller or equal to tol times the maximum absolute coefficient, \(\max_j |w_j|\). If so, then additionally check whether the dual gap is smaller or equal to tol times \(||y||_2^2 / n_{\text{samples}}\).

The underlying coordinate descent solver uses gap safe screening rules to speedup fitting time, see User Guide on coordinate descent.

L1-based models for Sparse Signals showcases ElasticNet alongside Lasso and ARD Regression for sparse signal recovery in the presence of noise and feature correlation.

Fit model with coordinate descent.

Note that large sparse matrices and arrays requiring int64 indices are not accepted.

Target. Will be cast to X’s dtype if necessary.

Sample weights. Internally, the sample_weight vector will be rescaled to sum to n_samples.

Added in version 0.23.

Allow to bypass several input checking. Don’t use this parameter unless you know what you do.

Coordinate descent is an algorithm that considers each column of data at a time hence it will automatically convert the X input as a Fortran-contiguous numpy array if necessary.

To avoid memory re-allocation it is advised to allocate the initial data in memory directly using that format.

Get metadata routing of this object.

Please check User Guide on how the routing mechanism works.

A MetadataRequest encapsulating routing information.

Get parameters for this estimator.

If True, will return the parameters for this estimator and contained subobjects that are estimators.

Parameter names mapped to their values.

Compute elastic net path with coordinate descent.

The elastic net optimization function varies for mono and multi-outputs.

For mono-output tasks it is:

For multi-output tasks it is:

i.e. the sum of norm of each row.

Read more in the User Guide.

Training data. Pass directly as Fortran-contiguous data to avoid unnecessary memory duplication. If y is mono-output then X can be sparse.

Number between 0 and 1 passed to elastic net (scaling between l1 and l2 penalties). l1_ratio=1 corresponds to the Lasso.

Length of the path. eps=1e-3 means that alpha_min / alpha_max = 1e-3.

Number of alphas along the regularization path.

List of alphas where to compute the models. If None alphas are set automatically.

Whether to use a precomputed Gram matrix to speed up calculations. If set to 'auto' let us decide. The Gram matrix can also be passed as argument.

Xy = np.dot(X.T, y) that can be precomputed. It is useful only when the Gram matrix is precomputed.

If True, X will be copied; else, it may be overwritten.

The initial values of the coefficients.

Whether to return the number of iterations or not.

If set to True, forces coefficients to be positive. (Only allowed when y.ndim == 1).

If set to False, the input validation checks are skipped (including the Gram matrix when provided). It is assumed that they are handled by the caller.

Keyword arguments passed to the coordinate descent solver.

The alphas along the path where models are computed.

Coefficients along the path.

The dual gaps at the end of the optimization for each alpha.

The number of iterations taken by the coordinate descent optimizer to reach the specified tolerance for each alpha. (Is returned when return_n_iter is set to True).

Multi-task ElasticNet model trained with L1/L2 mixed-norm as regularizer.

Multi-task L1/L2 ElasticNet with built-in cross-validation.

Linear regression with combined L1 and L2 priors as regularizer.

Elastic Net model with iterative fitting along a regularization path.

For an example, see examples/linear_model/plot_lasso_lasso_lars_elasticnet_path.py.

The underlying coordinate descent solver uses gap safe screening rules to speedup fitting time, see User Guide on coordinate descent.

Predict using the linear model.

Returns predicted values.

Return coefficient of determination on test data.

The coefficient of determination, \(R^2\), is defined as \((1 - \frac{u}{v})\), where \(u\) is the residual sum of squares ((y_true - y_pred)** 2).sum() and \(v\) is the total sum of squares ((y_true - y_true.mean()) ** 2).sum(). The best possible score is 1.0 and it can be negative (because the model can be arbitrarily worse). A constant model that always predicts the expected value of y, disregarding the input features, would get a \(R^2\) score of 0.0.

Test samples. For some estimators this may be a precomputed kernel matrix or a list of generic objects instead with shape (n_samples, n_samples_fitted), where n_samples_fitted is the number of samples used in the fitting for the estimator.

\(R^2\) of self.predict(X) w.r.t. y.

The \(R^2\) score used when calling score on a regressor uses multioutput='uniform_average' from version 0.23 to keep consistent with default value of r2_score. This influences the score method of all the multioutput regressors (except for MultiOutputRegressor).

Configure whether metadata should be requested to be passed to the fit method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to fit if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to fit.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Added in version 1.3.

Metadata routing for sample_weight parameter in fit.

Set the parameters of this estimator.

The method works on simple estimators as well as on nested objects (such as Pipeline). The latter have parameters of the form <component>__<parameter> so that it’s possible to update each component of a nested object.

Estimator parameters.

Configure whether metadata should be requested to be passed to the score method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to score if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to score.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Added in version 1.3.

Metadata routing for sample_weight parameter in score.

Fitting an Elastic Net with a precomputed Gram Matrix and Weighted Samples

L1-based models for Sparse Signals

Effect of model regularization on training and test error

Release Highlights for scikit-learn 0.23

**Examples:**

Example 1 (sql):
```sql
>>> from sklearn.linear_model import ElasticNet
>>> from sklearn.datasets import make_regression
```

Example 2 (json):
```json
>>> X, y = make_regression(n_features=2, random_state=0)
>>> regr = ElasticNet(random_state=0)
>>> regr.fit(X, y)
ElasticNet(random_state=0)
>>> print(regr.coef_)
[18.83816048 64.55968825]
>>> print(regr.intercept_)
1.451
>>> print(regr.predict([[0, 0]]))
[1.451]
```

Example 3 (unknown):
```unknown
1 / (2 * n_samples) * ||y - Xw||^2_2
+ alpha * l1_ratio * ||w||_1
+ 0.5 * alpha * (1 - l1_ratio) * ||w||^2_2
```

Example 4 (unknown):
```unknown
(1 / (2 * n_samples)) * ||Y - XW||_Fro^2
+ alpha * l1_ratio * ||W||_21
+ 0.5 * alpha * (1 - l1_ratio) * ||W||_Fro^2
```

---

## MLPRegressor#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPRegressor.html

**Contents:**
- MLPRegressor#
- Gallery examples#

Multi-layer Perceptron regressor.

This model optimizes the squared error using LBFGS or stochastic gradient descent.

Added in version 0.18.

The loss function to use when training the weights. Note that the “squared error” and “poisson” losses actually implement “half squares error” and “half poisson deviance” to simplify the computation of the gradient. Furthermore, the “poisson” loss internally uses a log-link (exponential as the output activation function) and requires y >= 0.

Changed in version 1.7: Added parameter loss and option ‘poisson’.

The ith element represents the number of neurons in the ith hidden layer.

Activation function for the hidden layer.

‘identity’, no-op activation, useful to implement linear bottleneck, returns f(x) = x

‘logistic’, the logistic sigmoid function, returns f(x) = 1 / (1 + exp(-x)).

‘tanh’, the hyperbolic tan function, returns f(x) = tanh(x).

‘relu’, the rectified linear unit function, returns f(x) = max(0, x)

The solver for weight optimization.

‘lbfgs’ is an optimizer in the family of quasi-Newton methods.

‘sgd’ refers to stochastic gradient descent.

‘adam’ refers to a stochastic gradient-based optimizer proposed by Kingma, Diederik, and Jimmy Ba

For a comparison between Adam optimizer and SGD, see Compare Stochastic learning strategies for MLPClassifier.

Note: The default solver ‘adam’ works pretty well on relatively large datasets (with thousands of training samples or more) in terms of both training time and validation score. For small datasets, however, ‘lbfgs’ can converge faster and perform better.

Strength of the L2 regularization term. The L2 regularization term is divided by the sample size when added to the loss.

Size of minibatches for stochastic optimizers. If the solver is ‘lbfgs’, the regressor will not use minibatch. When set to “auto”, batch_size=min(200, n_samples).

Learning rate schedule for weight updates.

‘constant’ is a constant learning rate given by ‘learning_rate_init’.

‘invscaling’ gradually decreases the learning rate learning_rate_ at each time step ‘t’ using an inverse scaling exponent of ‘power_t’. effective_learning_rate = learning_rate_init / pow(t, power_t)

‘adaptive’ keeps the learning rate constant to ‘learning_rate_init’ as long as training loss keeps decreasing. Each time two consecutive epochs fail to decrease training loss by at least tol, or fail to increase validation score by at least tol if ‘early_stopping’ is on, the current learning rate is divided by 5.

Only used when solver=’sgd’.

The initial learning rate used. It controls the step-size in updating the weights. Only used when solver=’sgd’ or ‘adam’.

The exponent for inverse scaling learning rate. It is used in updating effective learning rate when the learning_rate is set to ‘invscaling’. Only used when solver=’sgd’.

Maximum number of iterations. The solver iterates until convergence (determined by ‘tol’) or this number of iterations. For stochastic solvers (‘sgd’, ‘adam’), note that this determines the number of epochs (how many times each data point will be used), not the number of gradient steps.

Whether to shuffle samples in each iteration. Only used when solver=’sgd’ or ‘adam’.

Determines random number generation for weights and bias initialization, train-test split if early stopping is used, and batch sampling when solver=’sgd’ or ‘adam’. Pass an int for reproducible results across multiple function calls. See Glossary.

Tolerance for the optimization. When the loss or score is not improving by at least tol for n_iter_no_change consecutive iterations, unless learning_rate is set to ‘adaptive’, convergence is considered to be reached and training stops.

Whether to print progress messages to stdout.

When set to True, reuse the solution of the previous call to fit as initialization, otherwise, just erase the previous solution. See the Glossary.

Momentum for gradient descent update. Should be between 0 and 1. Only used when solver=’sgd’.

Whether to use Nesterov’s momentum. Only used when solver=’sgd’ and momentum > 0.

Whether to use early stopping to terminate training when validation score is not improving. If set to True, it will automatically set aside validation_fraction of training data as validation and terminate training when validation score is not improving by at least tol for n_iter_no_change consecutive epochs. Only effective when solver=’sgd’ or ‘adam’.

The proportion of training data to set aside as validation set for early stopping. Must be between 0 and 1. Only used if early_stopping is True.

Exponential decay rate for estimates of first moment vector in adam, should be in [0, 1). Only used when solver=’adam’.

Exponential decay rate for estimates of second moment vector in adam, should be in [0, 1). Only used when solver=’adam’.

Value for numerical stability in adam. Only used when solver=’adam’.

Maximum number of epochs to not meet tol improvement. Only effective when solver=’sgd’ or ‘adam’.

Added in version 0.20.

Only used when solver=’lbfgs’. Maximum number of function calls. The solver iterates until convergence (determined by tol), number of iterations reaches max_iter, or this number of function calls. Note that number of function calls will be greater than or equal to the number of iterations for the MLPRegressor.

Added in version 0.22.

The current loss computed with the loss function.

The minimum loss reached by the solver throughout fitting. If early_stopping=True, this attribute is set to None. Refer to the best_validation_score_ fitted attribute instead. Only accessible when solver=’sgd’ or ‘adam’.

Loss value evaluated at the end of each training step. The ith element in the list represents the loss at the ith iteration. Only accessible when solver=’sgd’ or ‘adam’.

The score at each iteration on a held-out validation set. The score reported is the R2 score. Only available if early_stopping=True, otherwise the attribute is set to None. Only accessible when solver=’sgd’ or ‘adam’.

The best validation score (i.e. R2 score) that triggered the early stopping. Only available if early_stopping=True, otherwise the attribute is set to None. Only accessible when solver=’sgd’ or ‘adam’.

The number of training samples seen by the solver during fitting. Mathematically equals n_iters * X.shape[0], it means time_step and it is used by optimizer’s learning rate scheduler.

The ith element in the list represents the weight matrix corresponding to layer i.

The ith element in the list represents the bias vector corresponding to layer i + 1.

Number of features seen during fit.

Added in version 0.24.

Names of features seen during fit. Defined only when X has feature names that are all strings.

Added in version 1.0.

The number of iterations the solver has run.

Name of the output activation function.

Bernoulli Restricted Boltzmann Machine (RBM).

Multi-layer Perceptron classifier.

Linear model fitted by minimizing a regularized empirical loss with SGD.

MLPRegressor trains iteratively since at each time step the partial derivatives of the loss function with respect to the model parameters are computed to update the parameters.

It can also have a regularization term added to the loss function that shrinks model parameters to prevent overfitting.

This implementation works with data represented as dense and sparse numpy arrays of floating point values.

Hinton, Geoffrey E. “Connectionist learning procedures.” Artificial intelligence 40.1 (1989): 185-234.

Glorot, Xavier, and Yoshua Bengio. “Understanding the difficulty of training deep feedforward neural networks.” International Conference on Artificial Intelligence and Statistics. 2010.

He, Kaiming, et al (2015). “Delving deep into rectifiers: Surpassing human-level performance on imagenet classification.”

Kingma, Diederik, and Jimmy Ba (2014) “Adam: A method for stochastic optimization.”

Fit the model to data matrix X and target(s) y.

The target values (class labels in classification, real numbers in regression).

Added in version 1.7.

Returns a trained MLP model.

Get metadata routing of this object.

Please check User Guide on how the routing mechanism works.

A MetadataRequest encapsulating routing information.

Get parameters for this estimator.

If True, will return the parameters for this estimator and contained subobjects that are estimators.

Parameter names mapped to their values.

Update the model with a single iteration over the given data.

Added in version 1.6.

Predict using the multi-layer perceptron model.

The predicted values.

Return coefficient of determination on test data.

The coefficient of determination, \(R^2\), is defined as \((1 - \frac{u}{v})\), where \(u\) is the residual sum of squares ((y_true - y_pred)** 2).sum() and \(v\) is the total sum of squares ((y_true - y_true.mean()) ** 2).sum(). The best possible score is 1.0 and it can be negative (because the model can be arbitrarily worse). A constant model that always predicts the expected value of y, disregarding the input features, would get a \(R^2\) score of 0.0.

Test samples. For some estimators this may be a precomputed kernel matrix or a list of generic objects instead with shape (n_samples, n_samples_fitted), where n_samples_fitted is the number of samples used in the fitting for the estimator.

\(R^2\) of self.predict(X) w.r.t. y.

The \(R^2\) score used when calling score on a regressor uses multioutput='uniform_average' from version 0.23 to keep consistent with default value of r2_score. This influences the score method of all the multioutput regressors (except for MultiOutputRegressor).

Configure whether metadata should be requested to be passed to the fit method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to fit if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to fit.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Added in version 1.3.

Metadata routing for sample_weight parameter in fit.

Set the parameters of this estimator.

The method works on simple estimators as well as on nested objects (such as Pipeline). The latter have parameters of the form <component>__<parameter> so that it’s possible to update each component of a nested object.

Estimator parameters.

Configure whether metadata should be requested to be passed to the partial_fit method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to partial_fit if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to partial_fit.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Added in version 1.3.

Metadata routing for sample_weight parameter in partial_fit.

Configure whether metadata should be requested to be passed to the score method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to score if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to score.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Added in version 1.3.

Metadata routing for sample_weight parameter in score.

Time-related feature engineering

Partial Dependence and Individual Conditional Expectation Plots

Advanced Plotting With Partial Dependence

**Examples:**

Example 1 (sql):
```sql
>>> from sklearn.neural_network import MLPRegressor
>>> from sklearn.datasets import make_regression
>>> from sklearn.model_selection import train_test_split
>>> X, y = make_regression(n_samples=200, n_features=20, random_state=1)
>>> X_train, X_test, y_train, y_test = train_test_split(X, y,
...                                                     random_state=1)
>>> regr = MLPRegressor(random_state=1, max_iter=2000, tol=0.1)
>>> regr.fit(X_train, y_train)
MLPRegressor(max_iter=2000, random_state=1, tol=0.1)
>>> regr.predict(X_test[:2])
array([  28.98, -291])
>>> regr.score(X_test, y_test)
0.98
```

---

## ExtraTreesClassifier#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.ExtraTreesClassifier.html

**Contents:**
- ExtraTreesClassifier#
- Gallery examples#

An extra-trees classifier.

This class implements a meta estimator that fits a number of randomized decision trees (a.k.a. extra-trees) on various sub-samples of the dataset and uses averaging to improve the predictive accuracy and control over-fitting.

This estimator has native support for missing values (NaNs) for random splits. During training, a random threshold will be chosen to split the non-missing values on. Then the non-missing values will be sent to the left and right child based on the randomly selected threshold, while the missing values will also be randomly sent to the left or right child. This is repeated for every feature considered at each split. The best split among these is chosen.

Read more in the User Guide.

The number of trees in the forest.

Changed in version 0.22: The default value of n_estimators changed from 10 to 100 in 0.22.

The function to measure the quality of a split. Supported criteria are “gini” for the Gini impurity and “log_loss” and “entropy” both for the Shannon information gain, see Mathematical formulation. Note: This parameter is tree-specific.

The maximum depth of the tree. If None, then nodes are expanded until all leaves are pure or until all leaves contain less than min_samples_split samples.

The minimum number of samples required to split an internal node:

If int, then consider min_samples_split as the minimum number.

If float, then min_samples_split is a fraction and ceil(min_samples_split * n_samples) are the minimum number of samples for each split.

Changed in version 0.18: Added float values for fractions.

The minimum number of samples required to be at a leaf node. A split point at any depth will only be considered if it leaves at least min_samples_leaf training samples in each of the left and right branches. This may have the effect of smoothing the model, especially in regression.

If int, then consider min_samples_leaf as the minimum number.

If float, then min_samples_leaf is a fraction and ceil(min_samples_leaf * n_samples) are the minimum number of samples for each node.

Changed in version 0.18: Added float values for fractions.

The minimum weighted fraction of the sum total of weights (of all the input samples) required to be at a leaf node. Samples have equal weight when sample_weight is not provided.

The number of features to consider when looking for the best split:

If int, then consider max_features features at each split.

If float, then max_features is a fraction and max(1, int(max_features * n_features_in_)) features are considered at each split.

If “sqrt”, then max_features=sqrt(n_features).

If “log2”, then max_features=log2(n_features).

If None, then max_features=n_features.

Changed in version 1.1: The default of max_features changed from "auto" to "sqrt".

Note: the search for a split does not stop until at least one valid partition of the node samples is found, even if it requires to effectively inspect more than max_features features.

Grow trees with max_leaf_nodes in best-first fashion. Best nodes are defined as relative reduction in impurity. If None then unlimited number of leaf nodes.

A node will be split if this split induces a decrease of the impurity greater than or equal to this value.

The weighted impurity decrease equation is the following:

where N is the total number of samples, N_t is the number of samples at the current node, N_t_L is the number of samples in the left child, and N_t_R is the number of samples in the right child.

N, N_t, N_t_R and N_t_L all refer to the weighted sum, if sample_weight is passed.

Added in version 0.19.

Whether bootstrap samples are used when building trees. If False, the whole dataset is used to build each tree.

Whether to use out-of-bag samples to estimate the generalization score. By default, accuracy_score is used. Provide a callable with signature metric(y_true, y_pred) to use a custom metric. Only available if bootstrap=True.

For an illustration of out-of-bag (OOB) error estimation, see the example OOB Errors for Random Forests.

The number of jobs to run in parallel. fit, predict, decision_path and apply are all parallelized over the trees. None means 1 unless in a joblib.parallel_backend context. -1 means using all processors. See Glossary for more details.

Controls 3 sources of randomness:

the bootstrapping of the samples used when building trees (if bootstrap=True)

the sampling of the features to consider when looking for the best split at each node (if max_features < n_features)

the draw of the splits for each of the max_features

See Glossary for details.

Controls the verbosity when fitting and predicting.

When set to True, reuse the solution of the previous call to fit and add more estimators to the ensemble, otherwise, just fit a whole new forest. See Glossary and Fitting additional trees for details.

Weights associated with classes in the form {class_label: weight}. If not given, all classes are supposed to have weight one. For multi-output problems, a list of dicts can be provided in the same order as the columns of y.

Note that for multioutput (including multilabel) weights should be defined for each class of every column in its own dict. For example, for four-class multilabel classification weights should be [{0: 1, 1: 1}, {0: 1, 1: 5}, {0: 1, 1: 1}, {0: 1, 1: 1}] instead of [{1:1}, {2:5}, {3:1}, {4:1}].

The “balanced” mode uses the values of y to automatically adjust weights inversely proportional to class frequencies in the input data as n_samples / (n_classes * np.bincount(y))

The “balanced_subsample” mode is the same as “balanced” except that weights are computed based on the bootstrap sample for every tree grown.

For multi-output, the weights of each column of y will be multiplied.

Note that these weights will be multiplied with sample_weight (passed through the fit method) if sample_weight is specified.

Complexity parameter used for Minimal Cost-Complexity Pruning. The subtree with the largest cost complexity that is smaller than ccp_alpha will be chosen. By default, no pruning is performed. See Minimal Cost-Complexity Pruning for details. See Post pruning decision trees with cost complexity pruning for an example of such pruning.

Added in version 0.22.

If bootstrap is True, the number of samples to draw from X to train each base estimator.

If None (default), then draw X.shape[0] samples.

If int, then draw max_samples samples.

If float, then draw max_samples * X.shape[0] samples. Thus, max_samples should be in the interval (0.0, 1.0].

Added in version 0.22.

1: monotonically increasing

-1: monotonically decreasing

If monotonic_cst is None, no constraints are applied.

multiclass classifications (i.e. when n_classes > 2),

multioutput classifications (i.e. when n_outputs_ > 1),

classifications trained on data with missing values.

The constraints hold over the probability of the positive class.

Read more in the User Guide.

Added in version 1.4.

The child estimator template used to create the collection of fitted sub-estimators.

Added in version 1.2: base_estimator_ was renamed to estimator_.

The collection of fitted sub-estimators.

The classes labels (single output problem), or a list of arrays of class labels (multi-output problem).

The number of classes (single output problem), or a list containing the number of classes for each output (multi-output problem).

The impurity-based feature importances.

Number of features seen during fit.

Added in version 0.24.

Names of features seen during fit. Defined only when X has feature names that are all strings.

Added in version 1.0.

The number of outputs when fit is performed.

Score of the training dataset obtained using an out-of-bag estimate. This attribute exists only when oob_score is True.

Decision function computed with out-of-bag estimate on the training set. If n_estimators is small it might be possible that a data point was never left out during the bootstrap. In this case, oob_decision_function_ might contain NaN. This attribute exists only when oob_score is True.

The subset of drawn samples for each base estimator.

An extra-trees regressor with random splits.

A random forest classifier with optimal splits.

Ensemble regressor using trees with optimal splits.

The default values for the parameters controlling the size of the trees (e.g. max_depth, min_samples_leaf, etc.) lead to fully grown and unpruned trees which can potentially be very large on some data sets. To reduce memory consumption, the complexity and size of the trees should be controlled by setting those parameter values.

P. Geurts, D. Ernst., and L. Wehenkel, “Extremely randomized trees”, Machine Learning, 63(1), 3-42, 2006.

Apply trees in the forest to X, return leaf indices.

The input samples. Internally, its dtype will be converted to dtype=np.float32. If a sparse matrix is provided, it will be converted into a sparse csr_matrix.

For each datapoint x in X and for each tree in the forest, return the index of the leaf x ends up in.

Return the decision path in the forest.

Added in version 0.18.

The input samples. Internally, its dtype will be converted to dtype=np.float32. If a sparse matrix is provided, it will be converted into a sparse csr_matrix.

Return a node indicator matrix where non zero elements indicates that the samples goes through the nodes. The matrix is of CSR format.

The columns from indicator[n_nodes_ptr[i]:n_nodes_ptr[i+1]] gives the indicator value for the i-th estimator.

Build a forest of trees from the training set (X, y).

The training input samples. Internally, its dtype will be converted to dtype=np.float32. If a sparse matrix is provided, it will be converted into a sparse csc_matrix.

The target values (class labels in classification, real numbers in regression).

Sample weights. If None, then samples are equally weighted. Splits that would create child nodes with net zero or negative weight are ignored while searching for a split in each node. In the case of classification, splits are also ignored if they would result in any single class carrying a negative weight in either child node.

Get metadata routing of this object.

Please check User Guide on how the routing mechanism works.

A MetadataRequest encapsulating routing information.

Get parameters for this estimator.

If True, will return the parameters for this estimator and contained subobjects that are estimators.

Parameter names mapped to their values.

The predicted class of an input sample is a vote by the trees in the forest, weighted by their probability estimates. That is, the predicted class is the one with highest mean probability estimate across the trees.

The input samples. Internally, its dtype will be converted to dtype=np.float32. If a sparse matrix is provided, it will be converted into a sparse csr_matrix.

The predicted classes.

Predict class log-probabilities for X.

The predicted class log-probabilities of an input sample is computed as the log of the mean predicted class probabilities of the trees in the forest.

The input samples. Internally, its dtype will be converted to dtype=np.float32. If a sparse matrix is provided, it will be converted into a sparse csr_matrix.

The class probabilities of the input samples. The order of the classes corresponds to that in the attribute classes_.

Predict class probabilities for X.

The predicted class probabilities of an input sample are computed as the mean predicted class probabilities of the trees in the forest. The class probability of a single tree is the fraction of samples of the same class in a leaf.

The input samples. Internally, its dtype will be converted to dtype=np.float32. If a sparse matrix is provided, it will be converted into a sparse csr_matrix.

The class probabilities of the input samples. The order of the classes corresponds to that in the attribute classes_.

Return accuracy on provided data and labels.

In multi-label classification, this is the subset accuracy which is a harsh metric since you require for each sample that each label set be correctly predicted.

Mean accuracy of self.predict(X) w.r.t. y.

Configure whether metadata should be requested to be passed to the fit method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to fit if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to fit.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Added in version 1.3.

Metadata routing for sample_weight parameter in fit.

Set the parameters of this estimator.

The method works on simple estimators as well as on nested objects (such as Pipeline). The latter have parameters of the form <component>__<parameter> so that it’s possible to update each component of a nested object.

Estimator parameters.

Configure whether metadata should be requested to be passed to the score method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to score if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to score.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Added in version 1.3.

Metadata routing for sample_weight parameter in score.

Plot the decision surfaces of ensembles of trees on the iris dataset

Hashing feature transformation using Totally Random Trees

Release Highlights for scikit-learn 1.6

**Examples:**

Example 1 (yaml):
```yaml
N_t / N * (impurity - N_t_R / N_t * right_impurity
                    - N_t_L / N_t * left_impurity)
```

Example 2 (sql):
```sql
>>> from sklearn.ensemble import ExtraTreesClassifier
>>> from sklearn.datasets import make_classification
>>> X, y = make_classification(n_features=4, random_state=0)
>>> clf = ExtraTreesClassifier(n_estimators=100, random_state=0)
>>> clf.fit(X, y)
ExtraTreesClassifier(random_state=0)
>>> clf.predict([[0, 0, 0, 0]])
array([1])
```

---

## BaggingRegressor#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.BaggingRegressor.html

**Contents:**
- BaggingRegressor#
- Gallery examples#

A Bagging regressor is an ensemble meta-estimator that fits base regressors each on random subsets of the original dataset and then aggregate their individual predictions (either by voting or by averaging) to form a final prediction. Such a meta-estimator can typically be used as a way to reduce the variance of a black-box estimator (e.g., a decision tree), by introducing randomization into its construction procedure and then making an ensemble out of it.

This algorithm encompasses several works from the literature. When random subsets of the dataset are drawn as random subsets of the samples, then this algorithm is known as Pasting [1]. If samples are drawn with replacement, then the method is known as Bagging [2]. When random subsets of the dataset are drawn as random subsets of the features, then the method is known as Random Subspaces [3]. Finally, when base estimators are built on subsets of both samples and features, then the method is known as Random Patches [4].

Read more in the User Guide.

Added in version 0.15.

The base estimator to fit on random subsets of the dataset. If None, then the base estimator is a DecisionTreeRegressor.

Added in version 1.2: base_estimator was renamed to estimator.

The number of base estimators in the ensemble.

The number of samples to draw from X to train each base estimator (with replacement by default, see bootstrap for more details).

If None, then draw X.shape[0] samples irrespective of sample_weight.

If int, then draw max_samples samples.

If float, then draw max_samples * X.shape[0] unweighted samples or max_samples * sample_weight.sum() weighted samples.

The number of features to draw from X to train each base estimator ( without replacement by default, see bootstrap_features for more details).

If int, then draw max_features features.

If float, then draw max(1, int(max_features * n_features_in_)) features.

Whether samples are drawn with replacement. If False, sampling without replacement is performed. If fitting with sample_weight, it is strongly recommended to choose True, as only drawing with replacement will ensure the expected frequency semantics of sample_weight.

Whether features are drawn with replacement.

Whether to use out-of-bag samples to estimate the generalization error. Only available if bootstrap=True.

When set to True, reuse the solution of the previous call to fit and add more estimators to the ensemble, otherwise, just fit a whole new ensemble. See the Glossary.

The number of jobs to run in parallel for both fit and predict. None means 1 unless in a joblib.parallel_backend context. -1 means using all processors. See Glossary for more details.

Controls the random resampling of the original dataset (sample wise and feature wise). If the base estimator accepts a random_state attribute, a different seed is generated for each instance in the ensemble. Pass an int for reproducible output across multiple function calls. See Glossary.

Controls the verbosity when fitting and predicting.

The base estimator from which the ensemble is grown.

Added in version 1.2: base_estimator_ was renamed to estimator_.

Number of features seen during fit.

Added in version 0.24.

Names of features seen during fit. Defined only when X has feature names that are all strings.

Added in version 1.0.

The collection of fitted sub-estimators.

The subset of drawn samples for each base estimator.

The subset of drawn features for each base estimator.

Score of the training dataset obtained using an out-of-bag estimate. This attribute exists only when oob_score is True.

Prediction computed with out-of-bag estimate on the training set. If n_estimators is small it might be possible that a data point was never left out during the bootstrap. In this case, oob_prediction_ might contain NaN. This attribute exists only when oob_score is True.

A Bagging classifier.

L. Breiman, “Pasting small votes for classification in large databases and on-line”, Machine Learning, 36(1), 85-103, 1999.

L. Breiman, “Bagging predictors”, Machine Learning, 24(2), 123-140, 1996.

T. Ho, “The random subspace method for constructing decision forests”, Pattern Analysis and Machine Intelligence, 20(8), 832-844, 1998.

G. Louppe and P. Geurts, “Ensembles on Random Patches”, Machine Learning and Knowledge Discovery in Databases, 346-361, 2012.

Build a Bagging ensemble of estimators from the training set (X, y).

The training input samples. Sparse matrices are accepted only if they are supported by the base estimator.

The target values (class labels in classification, real numbers in regression).

Sample weights. If None, then samples are equally weighted. Used as probabilities to sample the training set. Note that the expected frequency semantics for the sample_weight parameter are only fulfilled when sampling with replacement bootstrap=True and using a float or integer max_samples (instead of the default max_samples=None).

Parameters to pass to the underlying estimators.

Added in version 1.5: Only available if enable_metadata_routing=True, which can be set by using sklearn.set_config(enable_metadata_routing=True). See Metadata Routing User Guide for more details.

Get metadata routing of this object.

Please check User Guide on how the routing mechanism works.

Added in version 1.5.

A MetadataRouter encapsulating routing information.

Get parameters for this estimator.

If True, will return the parameters for this estimator and contained subobjects that are estimators.

Parameter names mapped to their values.

Predict regression target for X.

The predicted regression target of an input sample is computed as the mean predicted regression targets of the estimators in the ensemble.

The training input samples. Sparse matrices are accepted only if they are supported by the base estimator.

Parameters routed to the predict method of the sub-estimators via the metadata routing API.

Added in version 1.7: Only available if sklearn.set_config(enable_metadata_routing=True) is set. See Metadata Routing User Guide for more details.

The predicted values.

Return coefficient of determination on test data.

The coefficient of determination, \(R^2\), is defined as \((1 - \frac{u}{v})\), where \(u\) is the residual sum of squares ((y_true - y_pred)** 2).sum() and \(v\) is the total sum of squares ((y_true - y_true.mean()) ** 2).sum(). The best possible score is 1.0 and it can be negative (because the model can be arbitrarily worse). A constant model that always predicts the expected value of y, disregarding the input features, would get a \(R^2\) score of 0.0.

Test samples. For some estimators this may be a precomputed kernel matrix or a list of generic objects instead with shape (n_samples, n_samples_fitted), where n_samples_fitted is the number of samples used in the fitting for the estimator.

\(R^2\) of self.predict(X) w.r.t. y.

The \(R^2\) score used when calling score on a regressor uses multioutput='uniform_average' from version 0.23 to keep consistent with default value of r2_score. This influences the score method of all the multioutput regressors (except for MultiOutputRegressor).

Configure whether metadata should be requested to be passed to the fit method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to fit if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to fit.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Added in version 1.3.

Metadata routing for sample_weight parameter in fit.

Set the parameters of this estimator.

The method works on simple estimators as well as on nested objects (such as Pipeline). The latter have parameters of the form <component>__<parameter> so that it’s possible to update each component of a nested object.

Estimator parameters.

Configure whether metadata should be requested to be passed to the score method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to score if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to score.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Added in version 1.3.

Metadata routing for sample_weight parameter in score.

Single estimator versus bagging: bias-variance decomposition

**Examples:**

Example 1 (sql):
```sql
>>> from sklearn.svm import SVR
>>> from sklearn.ensemble import BaggingRegressor
>>> from sklearn.datasets import make_regression
>>> X, y = make_regression(n_samples=100, n_features=4,
...                        n_informative=2, n_targets=1,
...                        random_state=0, shuffle=False)
>>> regr = BaggingRegressor(estimator=SVR(),
...                         n_estimators=10, random_state=0).fit(X, y)
>>> regr.predict([[0, 0, 0, 0]])
array([-2.8720])
```

---

## 1.2. Linear and Quadratic Discriminant Analysis#

**URL:** https://scikit-learn.org/stable/modules/lda_qda.html

**Contents:**
- 1.2. Linear and Quadratic Discriminant Analysis#
- 1.2.1. Dimensionality reduction using Linear Discriminant Analysis#
- 1.2.2. Mathematical formulation of the LDA and QDA classifiers#
  - 1.2.2.1. QDA#
  - 1.2.2.2. LDA#
- 1.2.3. Mathematical formulation of LDA dimensionality reduction#
- 1.2.4. Shrinkage and Covariance Estimator#
- 1.2.5. Estimation algorithms#

Linear Discriminant Analysis (LinearDiscriminantAnalysis) and Quadratic Discriminant Analysis (QuadraticDiscriminantAnalysis) are two classic classifiers, with, as their names suggest, a linear and a quadratic decision surface, respectively.

These classifiers are attractive because they have closed-form solutions that can be easily computed, are inherently multiclass, have proven to work well in practice, and have no hyperparameters to tune.

The plot shows decision boundaries for Linear Discriminant Analysis and Quadratic Discriminant Analysis. The bottom row demonstrates that Linear Discriminant Analysis can only learn linear boundaries, while Quadratic Discriminant Analysis can learn quadratic boundaries and is therefore more flexible.

Linear and Quadratic Discriminant Analysis with covariance ellipsoid: Comparison of LDA and QDA on synthetic data.

LinearDiscriminantAnalysis can be used to perform supervised dimensionality reduction, by projecting the input data to a linear subspace consisting of the directions which maximize the separation between classes (in a precise sense discussed in the mathematics section below). The dimension of the output is necessarily less than the number of classes, so this is in general a rather strong dimensionality reduction, and only makes sense in a multiclass setting.

This is implemented in the transform method. The desired dimensionality can be set using the n_components parameter. This parameter has no influence on the fit and predict methods.

Comparison of LDA and PCA 2D projection of Iris dataset: Comparison of LDA and PCA for dimensionality reduction of the Iris dataset

Both LDA and QDA can be derived from simple probabilistic models which model the class conditional distribution of the data \(P(X|y=k)\) for each class \(k\). Predictions can then be obtained by using Bayes’ rule, for each training sample \(x \in \mathbb{R}^d\):

and we select the class \(k\) which maximizes this posterior probability.

More specifically, for linear and quadratic discriminant analysis, \(P(x|y)\) is modeled as a multivariate Gaussian distribution with density:

where \(d\) is the number of features.

According to the model above, the log of the posterior is:

where the constant term \(Cst\) corresponds to the denominator \(P(x)\), in addition to other constant terms from the Gaussian. The predicted class is the one that maximises this log-posterior.

Relation with Gaussian Naive Bayes

If in the QDA model one assumes that the covariance matrices are diagonal, then the inputs are assumed to be conditionally independent in each class, and the resulting classifier is equivalent to the Gaussian Naive Bayes classifier naive_bayes.GaussianNB.

LDA is a special case of QDA, where the Gaussians for each class are assumed to share the same covariance matrix: \(\Sigma_k = \Sigma\) for all \(k\). This reduces the log posterior to:

The term \((x-\mu_k)^T \Sigma^{-1} (x-\mu_k)\) corresponds to the Mahalanobis Distance between the sample \(x\) and the mean \(\mu_k\). The Mahalanobis distance tells how close \(x\) is from \(\mu_k\), while also accounting for the variance of each feature. We can thus interpret LDA as assigning \(x\) to the class whose mean is the closest in terms of Mahalanobis distance, while also accounting for the class prior probabilities.

The log-posterior of LDA can also be written [3] as:

where \(\omega_k = \Sigma^{-1} \mu_k\) and \(\omega_{k0} = -\frac{1}{2} \mu_k^T\Sigma^{-1}\mu_k + \log P (y = k)\). These quantities correspond to the coef_ and intercept_ attributes, respectively.

From the above formula, it is clear that LDA has a linear decision surface. In the case of QDA, there are no assumptions on the covariance matrices \(\Sigma_k\) of the Gaussians, leading to quadratic decision surfaces. See [1] for more details.

First note that the K means \(\mu_k\) are vectors in \(\mathbb{R}^d\), and they lie in an affine subspace \(H\) of dimension at most \(K - 1\) (2 points lie on a line, 3 points lie on a plane, etc.).

As mentioned above, we can interpret LDA as assigning \(x\) to the class whose mean \(\mu_k\) is the closest in terms of Mahalanobis distance, while also accounting for the class prior probabilities. Alternatively, LDA is equivalent to first sphering the data so that the covariance matrix is the identity, and then assigning \(x\) to the closest mean in terms of Euclidean distance (still accounting for the class priors).

Computing Euclidean distances in this d-dimensional space is equivalent to first projecting the data points into \(H\), and computing the distances there (since the other dimensions will contribute equally to each class in terms of distance). In other words, if \(x\) is closest to \(\mu_k\) in the original space, it will also be the case in \(H\). This shows that, implicit in the LDA classifier, there is a dimensionality reduction by linear projection onto a \(K-1\) dimensional space.

We can reduce the dimension even more, to a chosen \(L\), by projecting onto the linear subspace \(H_L\) which maximizes the variance of the \(\mu^*_k\) after projection (in effect, we are doing a form of PCA for the transformed class means \(\mu^*_k\)). This \(L\) corresponds to the n_components parameter used in the transform method. See [1] for more details.

Shrinkage is a form of regularization used to improve the estimation of covariance matrices in situations where the number of training samples is small compared to the number of features. In this scenario, the empirical sample covariance is a poor estimator, and shrinkage helps improving the generalization performance of the classifier. Shrinkage can be used with LDA (or QDA) by setting the shrinkage parameter of the LinearDiscriminantAnalysis class (or QuadraticDiscriminantAnalysis) to 'auto'. This automatically determines the optimal shrinkage parameter in an analytic way following the lemma introduced by Ledoit and Wolf [2]. Note that currently shrinkage only works when setting the solver parameter to 'lsqr' or 'eigen' (only 'eigen' is implemented for QDA).

The shrinkage parameter can also be manually set between 0 and 1. In particular, a value of 0 corresponds to no shrinkage (which means the empirical covariance matrix will be used) and a value of 1 corresponds to complete shrinkage (which means that the diagonal matrix of variances will be used as an estimate for the covariance matrix). Setting this parameter to a value between these two extrema will estimate a shrunk version of the covariance matrix.

The shrunk Ledoit and Wolf estimator of covariance may not always be the best choice. For example if the distribution of the data is normally distributed, the Oracle Approximating Shrinkage estimator sklearn.covariance.OAS yields a smaller Mean Squared Error than the one given by Ledoit and Wolf’s formula used with shrinkage="auto". In LDA and QDA, the data are assumed to be gaussian conditionally to the class. If these assumptions hold, using LDA and QDA with the OAS estimator of covariance will yield a better classification accuracy than if Ledoit and Wolf or the empirical covariance estimator is used.

The covariance estimator can be chosen using the covariance_estimator parameter of the discriminant_analysis.LinearDiscriminantAnalysis and discriminant_analysis.QuadraticDiscriminantAnalysis classes. A covariance estimator should have a fit method and a covariance_ attribute like all covariance estimators in the sklearn.covariance module.

Normal, Ledoit-Wolf and OAS Linear Discriminant Analysis for classification: Comparison of LDA classifiers with Empirical, Ledoit Wolf and OAS covariance estimator.

Using LDA and QDA requires computing the log-posterior which depends on the class priors \(P(y=k)\), the class means \(\mu_k\), and the covariance matrices.

The ‘svd’ solver is the default solver used for LinearDiscriminantAnalysis and QuadraticDiscriminantAnalysis. It can perform both classification and transform (for LDA). As it does not rely on the calculation of the covariance matrix, the ‘svd’ solver may be preferable in situations where the number of features is large. The ‘svd’ solver cannot be used with shrinkage. For QDA, the use of the SVD solver relies on the fact that the covariance matrix \(\Sigma_k\) is, by definition, equal to \(\frac{1}{n - 1} X_k^TX_k = \frac{1}{n - 1} V S^2 V^T\) where \(V\) comes from the SVD of the (centered) matrix: \(X_k = U S V^T\). It turns out that we can compute the log-posterior above without having to explicitly compute \(\Sigma\): computing \(S\) and \(V\) via the SVD of \(X\) is enough. For LDA, two SVDs are computed: the SVD of the centered input matrix \(X\) and the SVD of the class-wise mean vectors.

The 'lsqr' solver is an efficient algorithm that only works for classification. It needs to explicitly compute the covariance matrix \(\Sigma\), and supports shrinkage and custom covariance estimators. This solver computes the coefficients \(\omega_k = \Sigma^{-1}\mu_k\) by solving for \(\Sigma \omega = \mu_k\), thus avoiding the explicit computation of the inverse \(\Sigma^{-1}\).

The 'eigen' solver for LinearDiscriminantAnalysis is based on the optimization of the between class scatter to within class scatter ratio. It can be used for both classification and transform, and it supports shrinkage. For QuadraticDiscriminantAnalysis, the 'eigen' solver is based on computing the eigenvalues and eigenvectors of each class covariance matrix. It allows using shrinkage for classification. However, the 'eigen' solver needs to compute the covariance matrix, so it might not be suitable for situations with a high number of features.

“The Elements of Statistical Learning”, Hastie T., Tibshirani R., Friedman J., Section 4.3, p.106-119, 2008.

Ledoit O, Wolf M. Honey, I Shrunk the Sample Covariance Matrix. The Journal of Portfolio Management 30(4), 110-119, 2004.

R. O. Duda, P. E. Hart, D. G. Stork. Pattern Classification (Second Edition), section 2.6.2.

---

## 1.5. Stochastic Gradient Descent#

**URL:** https://scikit-learn.org/stable/modules/sgd.html

**Contents:**
- 1.5. Stochastic Gradient Descent#
- 1.5.1. Classification#
- 1.5.2. Regression#
- 1.5.3. Online One-Class SVM#
- 1.5.4. Stochastic Gradient Descent for sparse data#
- 1.5.5. Complexity#
- 1.5.6. Stopping criterion#
- 1.5.7. Tips on Practical Use#
- 1.5.8. Mathematical formulation#
  - 1.5.8.1. SGD#

Stochastic Gradient Descent (SGD) is a simple yet very efficient approach to fitting linear classifiers and regressors under convex loss functions such as (linear) Support Vector Machines and Logistic Regression. Even though SGD has been around in the machine learning community for a long time, it has received a considerable amount of attention just recently in the context of large-scale learning.

SGD has been successfully applied to large-scale and sparse machine learning problems often encountered in text classification and natural language processing. Given that the data is sparse, the classifiers in this module easily scale to problems with more than \(10^5\) training examples and more than \(10^5\) features.

Strictly speaking, SGD is merely an optimization technique and does not correspond to a specific family of machine learning models. It is only a way to train a model. Often, an instance of SGDClassifier or SGDRegressor will have an equivalent estimator in the scikit-learn API, potentially using a different optimization technique. For example, using SGDClassifier(loss='log_loss') results in logistic regression, i.e. a model equivalent to LogisticRegression which is fitted via SGD instead of being fitted by one of the other solvers in LogisticRegression. Similarly, SGDRegressor(loss='squared_error', penalty='l2') and Ridge solve the same optimization problem, via different means.

The advantages of Stochastic Gradient Descent are:

Ease of implementation (lots of opportunities for code tuning).

The disadvantages of Stochastic Gradient Descent include:

SGD requires a number of hyperparameters such as the regularization parameter and the number of iterations.

SGD is sensitive to feature scaling.

Make sure you permute (shuffle) your training data before fitting the model or use shuffle=True to shuffle after each iteration (used by default). Also, ideally, features should be standardized using e.g. make_pipeline(StandardScaler(), SGDClassifier()) (see Pipelines).

The class SGDClassifier implements a plain stochastic gradient descent learning routine which supports different loss functions and penalties for classification. Below is the decision boundary of a SGDClassifier trained with the hinge loss, equivalent to a linear SVM.

As other classifiers, SGD has to be fitted with two arrays: an array X of shape (n_samples, n_features) holding the training samples, and an array y of shape (n_samples,) holding the target values (class labels) for the training samples:

After being fitted, the model can then be used to predict new values:

SGD fits a linear model to the training data. The coef_ attribute holds the model parameters:

The intercept_ attribute holds the intercept (aka offset or bias):

Whether or not the model should use an intercept, i.e. a biased hyperplane, is controlled by the parameter fit_intercept.

The signed distance to the hyperplane (computed as the dot product between the coefficients and the input sample, plus the intercept) is given by SGDClassifier.decision_function:

The concrete loss function can be set via the loss parameter. SGDClassifier supports the following loss functions:

loss="hinge": (soft-margin) linear Support Vector Machine,

loss="modified_huber": smoothed hinge loss,

loss="log_loss": logistic regression,

and all regression losses below. In this case the target is encoded as \(-1\) or \(1\), and the problem is treated as a regression problem. The predicted class then corresponds to the sign of the predicted target.

Please refer to the mathematical section below for formulas. The first two loss functions are lazy, they only update the model parameters if an example violates the margin constraint, which makes training very efficient and may result in sparser models (i.e. with more zero coefficients), even when \(L_2\) penalty is used.

Using loss="log_loss" or loss="modified_huber" enables the predict_proba method, which gives a vector of probability estimates \(P(y|x)\) per sample \(x\):

The concrete penalty can be set via the penalty parameter. SGD supports the following penalties:

penalty="l2": \(L_2\) norm penalty on coef_.

penalty="l1": \(L_1\) norm penalty on coef_.

penalty="elasticnet": Convex combination of \(L_2\) and \(L_1\); (1 - l1_ratio) * L2 + l1_ratio * L1.

The default setting is penalty="l2". The \(L_1\) penalty leads to sparse solutions, driving most coefficients to zero. The Elastic Net [11] solves some deficiencies of the \(L_1\) penalty in the presence of highly correlated attributes. The parameter l1_ratio controls the convex combination of \(L_1\) and \(L_2\) penalty.

SGDClassifier supports multi-class classification by combining multiple binary classifiers in a “one versus all” (OVA) scheme. For each of the \(K\) classes, a binary classifier is learned that discriminates between that and all other \(K-1\) classes. At testing time, we compute the confidence score (i.e. the signed distances to the hyperplane) for each classifier and choose the class with the highest confidence. The Figure below illustrates the OVA approach on the iris dataset. The dashed lines represent the three OVA classifiers; the background colors show the decision surface induced by the three classifiers.

In the case of multi-class classification coef_ is a two-dimensional array of shape (n_classes, n_features) and intercept_ is a one-dimensional array of shape (n_classes,). The \(i\)-th row of coef_ holds the weight vector of the OVA classifier for the \(i\)-th class; classes are indexed in ascending order (see attribute classes_). Note that, in principle, since they allow to create a probability model, loss="log_loss" and loss="modified_huber" are more suitable for one-vs-all classification.

SGDClassifier supports both weighted classes and weighted instances via the fit parameters class_weight and sample_weight. See the examples below and the docstring of SGDClassifier.fit for further information.

SGDClassifier supports averaged SGD (ASGD) [10]. Averaging can be enabled by setting average=True. ASGD performs the same updates as the regular SGD (see Mathematical formulation), but instead of using the last value of the coefficients as the coef_ attribute (i.e. the values of the last update), coef_ is set instead to the average value of the coefficients across all updates. The same is done for the intercept_ attribute. When using ASGD the learning rate can be larger and even constant, leading on some datasets to a speed up in training time.

For classification with a logistic loss, another variant of SGD with an averaging strategy is available with Stochastic Average Gradient (SAG) algorithm, available as a solver in LogisticRegression.

SGD: Maximum margin separating hyperplane

Plot multi-class SGD on the iris dataset

SGD: Weighted samples

SVM: Separating hyperplane for unbalanced classes (See the Note in the example)

The class SGDRegressor implements a plain stochastic gradient descent learning routine which supports different loss functions and penalties to fit linear regression models. SGDRegressor is well suited for regression problems with a large number of training samples (> 10.000), for other problems we recommend Ridge, Lasso, or ElasticNet.

The concrete loss function can be set via the loss parameter. SGDRegressor supports the following loss functions:

loss="squared_error": Ordinary least squares,

loss="huber": Huber loss for robust regression,

loss="epsilon_insensitive": linear Support Vector Regression.

Please refer to the mathematical section below for formulas. The Huber and epsilon-insensitive loss functions can be used for robust regression. The width of the insensitive region has to be specified via the parameter epsilon. This parameter depends on the scale of the target variables.

The penalty parameter determines the regularization to be used (see description above in the classification section).

SGDRegressor also supports averaged SGD [10] (here again, see description above in the classification section).

For regression with a squared loss and a \(L_2\) penalty, another variant of SGD with an averaging strategy is available with Stochastic Average Gradient (SAG) algorithm, available as a solver in Ridge.

The class sklearn.linear_model.SGDOneClassSVM implements an online linear version of the One-Class SVM using a stochastic gradient descent. Combined with kernel approximation techniques, sklearn.linear_model.SGDOneClassSVM can be used to approximate the solution of a kernelized One-Class SVM, implemented in sklearn.svm.OneClassSVM, with a linear complexity in the number of samples. Note that the complexity of a kernelized One-Class SVM is at best quadratic in the number of samples. sklearn.linear_model.SGDOneClassSVM is thus well suited for datasets with a large number of training samples (over 10,000) for which the SGD variant can be several orders of magnitude faster.

Its implementation is based on the implementation of the stochastic gradient descent. Indeed, the original optimization problem of the One-Class SVM is given by

where \(\nu \in (0, 1]\) is the user-specified parameter controlling the proportion of outliers and the proportion of support vectors. Getting rid of the slack variables \(\xi_i\) this problem is equivalent to

Multiplying by the constant \(\nu\) and introducing the intercept \(b = 1 - \rho\) we obtain the following equivalent optimization problem

This is similar to the optimization problems studied in section Mathematical formulation with \(y_i = 1, 1 \leq i \leq n\) and \(\alpha = \nu/2\), \(L\) being the hinge loss function and \(R\) being the \(L_2\) norm. We just need to add the term \(b\nu\) in the optimization loop.

As SGDClassifier and SGDRegressor, SGDOneClassSVM supports averaged SGD. Averaging can be enabled by setting average=True.

One-Class SVM versus One-Class SVM using Stochastic Gradient Descent

The sparse implementation produces slightly different results from the dense implementation, due to a shrunk learning rate for the intercept. See Implementation details.

There is built-in support for sparse data given in any matrix in a format supported by scipy.sparse. For maximum efficiency, however, use the CSR matrix format as defined in scipy.sparse.csr_matrix.

Classification of text documents using sparse features

The major advantage of SGD is its efficiency, which is basically linear in the number of training examples. If \(X\) is a matrix of size \(n \times p\) (with \(n\) samples and \(p\) features), training has a cost of \(O(k n \bar p)\), where \(k\) is the number of iterations (epochs) and \(\bar p\) is the average number of non-zero attributes per sample.

Recent theoretical results, however, show that the runtime to get some desired optimization accuracy does not increase as the training set size increases.

The classes SGDClassifier and SGDRegressor provide two criteria to stop the algorithm when a given level of convergence is reached:

With early_stopping=True, the input data is split into a training set and a validation set. The model is then fitted on the training set, and the stopping criterion is based on the prediction score (using the score method) computed on the validation set. The size of the validation set can be changed with the parameter validation_fraction.

With early_stopping=False, the model is fitted on the entire input data and the stopping criterion is based on the objective function computed on the training data.

In both cases, the criterion is evaluated once by epoch, and the algorithm stops when the criterion does not improve n_iter_no_change times in a row. The improvement is evaluated with absolute tolerance tol, and the algorithm stops in any case after a maximum number of iterations max_iter.

See Early stopping of Stochastic Gradient Descent for an example of the effects of early stopping.

Stochastic Gradient Descent is sensitive to feature scaling, so it is highly recommended to scale your data. For example, scale each attribute on the input vector \(X\) to \([0,1]\) or \([-1,1]\), or standardize it to have mean \(0\) and variance \(1\). Note that the same scaling must be applied to the test vector to obtain meaningful results. This can be easily done using StandardScaler:

If your attributes have an intrinsic scale (e.g. word frequencies or indicator features) scaling is not needed.

Finding a reasonable regularization term \(\alpha\) is best done using automatic hyper-parameter search, e.g. GridSearchCV or RandomizedSearchCV, usually in the range 10.0**-np.arange(1,7).

Empirically, we found that SGD converges after observing approximately \(10^6\) training samples. Thus, a reasonable first guess for the number of iterations is max_iter = np.ceil(10**6 / n), where n is the size of the training set.

If you apply SGD to features extracted using PCA we found that it is often wise to scale the feature values by some constant c such that the average \(L_2\) norm of the training data equals one.

We found that Averaged SGD works best with a larger number of features and a higher eta0.

“Efficient BackProp” Y. LeCun, L. Bottou, G. Orr, K. Müller - In Neural Networks: Tricks of the Trade 1998.

We describe here the mathematical details of the SGD procedure. A good overview with convergence rates can be found in [12].

Given a set of training examples \(\{(x_1, y_1), \ldots, (x_n, y_n)\}\) where \(x_i \in \mathbf{R}^m\) and \(y_i \in \mathbf{R}\) (\(y_i \in \{-1, 1\}\) for classification), our goal is to learn a linear scoring function \(f(x) = w^T x + b\) with model parameters \(w \in \mathbf{R}^m\) and intercept \(b \in \mathbf{R}\). In order to make predictions for binary classification, we simply look at the sign of \(f(x)\). To find the model parameters, we minimize the regularized training error given by

where \(L\) is a loss function that measures model (mis)fit and \(R\) is a regularization term (aka penalty) that penalizes model complexity; \(\alpha > 0\) is a non-negative hyperparameter that controls the regularization strength.

Different choices for \(L\) entail different classifiers or regressors:

Hinge (soft-margin): equivalent to Support Vector Classification. \(L(y_i, f(x_i)) = \max(0, 1 - y_i f(x_i))\).

Perceptron: \(L(y_i, f(x_i)) = \max(0, - y_i f(x_i))\).

Modified Huber: \(L(y_i, f(x_i)) = \max(0, 1 - y_i f(x_i))^2\) if \(y_i f(x_i) > -1\), and \(L(y_i, f(x_i)) = -4 y_i f(x_i)\) otherwise.

Log Loss: equivalent to Logistic Regression. \(L(y_i, f(x_i)) = \log(1 + \exp (-y_i f(x_i)))\).

Squared Error: Linear regression (Ridge or Lasso depending on \(R\)). \(L(y_i, f(x_i)) = \frac{1}{2}(y_i - f(x_i))^2\).

Huber: less sensitive to outliers than least-squares. It is equivalent to least squares when \(|y_i - f(x_i)| \leq \varepsilon\), and \(L(y_i, f(x_i)) = \varepsilon |y_i - f(x_i)| - \frac{1}{2} \varepsilon^2\) otherwise.

Epsilon-Insensitive: (soft-margin) equivalent to Support Vector Regression. \(L(y_i, f(x_i)) = \max(0, |y_i - f(x_i)| - \varepsilon)\).

All of the above loss functions can be regarded as an upper bound on the misclassification error (Zero-one loss) as shown in the Figure below.

Popular choices for the regularization term \(R\) (the penalty parameter) include:

\(L_2\) norm: \(R(w) := \frac{1}{2} \sum_{j=1}^{m} w_j^2 = ||w||_2^2\),

\(L_1\) norm: \(R(w) := \sum_{j=1}^{m} |w_j|\), which leads to sparse solutions.

Elastic Net: \(R(w) := \frac{\rho}{2} \sum_{j=1}^{n} w_j^2 + (1-\rho) \sum_{j=1}^{m} |w_j|\), a convex combination of \(L_2\) and \(L_1\), where \(\rho\) is given by 1 - l1_ratio.

The Figure below shows the contours of the different regularization terms in a 2-dimensional parameter space (\(m=2\)) when \(R(w) = 1\).

Stochastic gradient descent is an optimization method for unconstrained optimization problems. In contrast to (batch) gradient descent, SGD approximates the true gradient of \(E(w,b)\) by considering a single training example at a time.

The class SGDClassifier implements a first-order SGD learning routine. The algorithm iterates over the training examples and for each example updates the model parameters according to the update rule given by

where \(\eta\) is the learning rate which controls the step-size in the parameter space. The intercept \(b\) is updated similarly but without regularization (and with additional decay for sparse matrices, as detailed in Implementation details).

The learning rate \(\eta\) can be either constant or gradually decaying. For classification, the default learning rate schedule (learning_rate='optimal') is given by

where \(t\) is the time step (there are a total of n_samples * n_iter time steps), \(t_0\) is determined based on a heuristic proposed by Léon Bottou such that the expected initial updates are comparable with the expected size of the weights (this assumes that the norm of the training samples is approximately 1). The exact definition can be found in _init_t in BaseSGD.

For regression the default learning rate schedule is inverse scaling (learning_rate='invscaling'), given by

where \(\eta_0\) and \(power\_t\) are hyperparameters chosen by the user via eta0 and power_t, respectively.

For a constant learning rate use learning_rate='constant' and use eta0 to specify the learning rate.

For an adaptively decreasing learning rate, use learning_rate='adaptive' and use eta0 to specify the starting learning rate. When the stopping criterion is reached, the learning rate is divided by 5, and the algorithm does not stop. The algorithm stops when the learning rate goes below 1e-6.

The model parameters can be accessed through the coef_ and intercept_ attributes: coef_ holds the weights \(w\) and intercept_ holds \(b\).

When using Averaged SGD (with the average parameter), coef_ is set to the average weight across all updates: coef_ \(= \frac{1}{T} \sum_{t=0}^{T-1} w^{(t)}\), where \(T\) is the total number of updates, found in the t_ attribute.

The implementation of SGD is influenced by the Stochastic Gradient SVM of [7]. Similar to SvmSGD, the weight vector is represented as the product of a scalar and a vector which allows an efficient weight update in the case of \(L_2\) regularization. In the case of sparse input X, the intercept is updated with a smaller learning rate (multiplied by 0.01) to account for the fact that it is updated more frequently. Training examples are picked up sequentially and the learning rate is lowered after each observed example. We adopted the learning rate schedule from [8]. For multi-class classification, a “one versus all” approach is used. We use the truncated gradient algorithm proposed in [9] for \(L_1\) regularization (and the Elastic Net). The code is written in Cython.

“Stochastic Gradient Descent” L. Bottou - Website, 2010.

“Pegasos: Primal estimated sub-gradient solver for svm” S. Shalev-Shwartz, Y. Singer, N. Srebro - In Proceedings of ICML ‘07.

“Stochastic gradient descent training for l1-regularized log-linear models with cumulative penalty” Y. Tsuruoka, J. Tsujii, S. Ananiadou - In Proceedings of the AFNLP/ACL’09.

“Towards Optimal One Pass Large Scale Learning with Averaged Stochastic Gradient Descent”. Xu, Wei (2011)

“Regularization and variable selection via the elastic net” H. Zou, T. Hastie - Journal of the Royal Statistical Society Series B, 67 (2), 301-320.

“Solving large scale linear prediction problems using stochastic gradient descent algorithms” T. Zhang - In Proceedings of ICML ‘04.

**Examples:**

Example 1 (sql):
```sql
>>> from sklearn.linear_model import SGDClassifier
>>> X = [[0., 0.], [1., 1.]]
>>> y = [0, 1]
>>> clf = SGDClassifier(loss="hinge", penalty="l2", max_iter=5)
>>> clf.fit(X, y)
SGDClassifier(max_iter=5)
```

Example 2 (unknown):
```unknown
>>> clf.predict([[2., 2.]])
array([1])
```

Example 3 (unknown):
```unknown
>>> clf.coef_
array([[9.9, 9.9]])
```

Example 4 (unknown):
```unknown
>>> clf.intercept_
array([-9.9])
```

---

## 1.7. Gaussian Processes#

**URL:** https://scikit-learn.org/stable/modules/gaussian_process.html

**Contents:**
- 1.7. Gaussian Processes#
- 1.7.1. Gaussian Process Regression (GPR)#
- 1.7.2. Gaussian Process Classification (GPC)#
- 1.7.3. GPC examples#
  - 1.7.3.1. Probabilistic predictions with GPC#
  - 1.7.3.2. Illustration of GPC on the XOR dataset#
  - 1.7.3.3. Gaussian process classification (GPC) on iris dataset#
- 1.7.4. Kernels for Gaussian Processes#
  - 1.7.4.1. Basic kernels#
  - 1.7.4.2. Kernel operators#

Gaussian Processes (GP) are a nonparametric supervised learning method used to solve regression and probabilistic classification problems.

The advantages of Gaussian processes are:

The prediction interpolates the observations (at least for regular kernels).

The prediction is probabilistic (Gaussian) so that one can compute empirical confidence intervals and decide based on those if one should refit (online fitting, adaptive fitting) the prediction in some region of interest.

Versatile: different kernels can be specified. Common kernels are provided, but it is also possible to specify custom kernels.

The disadvantages of Gaussian processes include:

Our implementation is not sparse, i.e., they use the whole samples/features information to perform the prediction.

They lose efficiency in high dimensional spaces – namely when the number of features exceeds a few dozens.

The GaussianProcessRegressor implements Gaussian processes (GP) for regression purposes. For this, the prior of the GP needs to be specified. GP will combine this prior and the likelihood function based on training samples. It allows to give a probabilistic approach to prediction by giving the mean and standard deviation as output when predicting.

The prior mean is assumed to be constant and zero (for normalize_y=False) or the training data’s mean (for normalize_y=True). The prior’s covariance is specified by passing a kernel object. The hyperparameters of the kernel are optimized when fitting the GaussianProcessRegressor by maximizing the log-marginal-likelihood (LML) based on the passed optimizer. As the LML may have multiple local optima, the optimizer can be started repeatedly by specifying n_restarts_optimizer. The first run is always conducted starting from the initial hyperparameter values of the kernel; subsequent runs are conducted from hyperparameter values that have been chosen randomly from the range of allowed values. If the initial hyperparameters should be kept fixed, None can be passed as optimizer.

The noise level in the targets can be specified by passing it via the parameter alpha, either globally as a scalar or per datapoint. Note that a moderate noise level can also be helpful for dealing with numeric instabilities during fitting as it is effectively implemented as Tikhonov regularization, i.e., by adding it to the diagonal of the kernel matrix. An alternative to specifying the noise level explicitly is to include a WhiteKernel component into the kernel, which can estimate the global noise level from the data (see example below). The figure below shows the effect of noisy target handled by setting the parameter alpha.

The implementation is based on Algorithm 2.1 of [RW2006]. In addition to the API of standard scikit-learn estimators, GaussianProcessRegressor:

allows prediction without prior fitting (based on the GP prior)

provides an additional method sample_y(X), which evaluates samples drawn from the GPR (prior or posterior) at given inputs

exposes a method log_marginal_likelihood(theta), which can be used externally for other ways of selecting hyperparameters, e.g., via Markov chain Monte Carlo.

Gaussian Processes regression: basic introductory example

Ability of Gaussian process regression (GPR) to estimate data noise-level

Comparison of kernel ridge and Gaussian process regression

Forecasting of CO2 level on Mona Loa dataset using Gaussian process regression (GPR)

The GaussianProcessClassifier implements Gaussian processes (GP) for classification purposes, more specifically for probabilistic classification, where test predictions take the form of class probabilities. GaussianProcessClassifier places a GP prior on a latent function \(f\), which is then squashed through a link function \(\pi\) to obtain the probabilistic classification. The latent function \(f\) is a so-called nuisance function, whose values are not observed and are not relevant by themselves. Its purpose is to allow a convenient formulation of the model, and \(f\) is removed (integrated out) during prediction. GaussianProcessClassifier implements the logistic link function, for which the integral cannot be computed analytically but is easily approximated in the binary case.

In contrast to the regression setting, the posterior of the latent function \(f\) is not Gaussian even for a GP prior since a Gaussian likelihood is inappropriate for discrete class labels. Rather, a non-Gaussian likelihood corresponding to the logistic link function (logit) is used. GaussianProcessClassifier approximates the non-Gaussian posterior with a Gaussian based on the Laplace approximation. More details can be found in Chapter 3 of [RW2006].

The GP prior mean is assumed to be zero. The prior’s covariance is specified by passing a kernel object. The hyperparameters of the kernel are optimized during fitting of GaussianProcessRegressor by maximizing the log-marginal-likelihood (LML) based on the passed optimizer. As the LML may have multiple local optima, the optimizer can be started repeatedly by specifying n_restarts_optimizer. The first run is always conducted starting from the initial hyperparameter values of the kernel; subsequent runs are conducted from hyperparameter values that have been chosen randomly from the range of allowed values. If the initial hyperparameters should be kept fixed, None can be passed as optimizer.

In some scenarios, information about the latent function \(f\) is desired (i.e. the mean \(\bar{f_*}\) and the variance \(\text{Var}[f_*]\) described in Eqs. (3.21) and (3.24) of [RW2006]). The GaussianProcessClassifier provides access to these quantities via the latent_mean_and_variance method.

GaussianProcessClassifier supports multi-class classification by performing either one-versus-rest or one-versus-one based training and prediction. In one-versus-rest, one binary Gaussian process classifier is fitted for each class, which is trained to separate this class from the rest. In “one_vs_one”, one binary Gaussian process classifier is fitted for each pair of classes, which is trained to separate these two classes. The predictions of these binary predictors are combined into multi-class predictions. See the section on multi-class classification for more details.

In the case of Gaussian process classification, “one_vs_one” might be computationally cheaper since it has to solve many problems involving only a subset of the whole training set rather than fewer problems on the whole dataset. Since Gaussian process classification scales cubically with the size of the dataset, this might be considerably faster. However, note that “one_vs_one” does not support predicting probability estimates but only plain predictions. Moreover, note that GaussianProcessClassifier does not (yet) implement a true multi-class Laplace approximation internally, but as discussed above is based on solving several binary classification tasks internally, which are combined using one-versus-rest or one-versus-one.

This example illustrates the predicted probability of GPC for an RBF kernel with different choices of the hyperparameters. The first figure shows the predicted probability of GPC with arbitrarily chosen hyperparameters and with the hyperparameters corresponding to the maximum log-marginal-likelihood (LML).

While the hyperparameters chosen by optimizing LML have a considerably larger LML, they perform slightly worse according to the log-loss on test data. The figure shows that this is because they exhibit a steep change of the class probabilities at the class boundaries (which is good) but have predicted probabilities close to 0.5 far away from the class boundaries (which is bad). This undesirable effect is caused by the Laplace approximation used internally by GPC.

The second figure shows the log-marginal-likelihood for different choices of the kernel’s hyperparameters, highlighting the two choices of the hyperparameters used in the first figure by black dots.

This example illustrates GPC on XOR data. Compared are a stationary, isotropic kernel (RBF) and a non-stationary kernel (DotProduct). On this particular dataset, the DotProduct kernel obtains considerably better results because the class-boundaries are linear and coincide with the coordinate axes. In practice, however, stationary kernels such as RBF often obtain better results.

This example illustrates the predicted probability of GPC for an isotropic and anisotropic RBF kernel on a two-dimensional version for the iris dataset. This illustrates the applicability of GPC to non-binary classification. The anisotropic RBF kernel obtains slightly higher log-marginal-likelihood by assigning different length-scales to the two feature dimensions.

Kernels (also called “covariance functions” in the context of GPs) are a crucial ingredient of GPs which determine the shape of prior and posterior of the GP. They encode the assumptions on the function being learned by defining the “similarity” of two datapoints combined with the assumption that similar datapoints should have similar target values. Two categories of kernels can be distinguished: stationary kernels depend only on the distance of two datapoints and not on their absolute values \(k(x_i, x_j)= k(d(x_i, x_j))\) and are thus invariant to translations in the input space, while non-stationary kernels depend also on the specific values of the datapoints. Stationary kernels can further be subdivided into isotropic and anisotropic kernels, where isotropic kernels are also invariant to rotations in the input space. For more details, we refer to Chapter 4 of [RW2006]. This example shows how to define a custom kernel over discrete data. For guidance on how to best combine different kernels, we refer to [Duv2014].

The main usage of a Kernel is to compute the GP’s covariance between datapoints. For this, the method __call__ of the kernel can be called. This method can either be used to compute the “auto-covariance” of all pairs of datapoints in a 2d array X, or the “cross-covariance” of all combinations of datapoints of a 2d array X with datapoints in a 2d array Y. The following identity holds true for all kernels k (except for the WhiteKernel): k(X) == K(X, Y=X)

If only the diagonal of the auto-covariance is being used, the method diag() of a kernel can be called, which is more computationally efficient than the equivalent call to __call__: np.diag(k(X, X)) == k.diag(X)

Kernels are parameterized by a vector \(\theta\) of hyperparameters. These hyperparameters can for instance control length-scales or periodicity of a kernel (see below). All kernels support computing analytic gradients of the kernel’s auto-covariance with respect to \(log(\theta)\) via setting eval_gradient=True in the __call__ method. That is, a (len(X), len(X), len(theta)) array is returned where the entry [i, j, l] contains \(\frac{\partial k_\theta(x_i, x_j)}{\partial log(\theta_l)}\). This gradient is used by the Gaussian process (both regressor and classifier) in computing the gradient of the log-marginal-likelihood, which in turn is used to determine the value of \(\theta\), which maximizes the log-marginal-likelihood, via gradient ascent. For each hyperparameter, the initial value and the bounds need to be specified when creating an instance of the kernel. The current value of \(\theta\) can be get and set via the property theta of the kernel object. Moreover, the bounds of the hyperparameters can be accessed by the property bounds of the kernel. Note that both properties (theta and bounds) return log-transformed values of the internally used values since those are typically more amenable to gradient-based optimization. The specification of each hyperparameter is stored in the form of an instance of Hyperparameter in the respective kernel. Note that a kernel using a hyperparameter with name “x” must have the attributes self.x and self.x_bounds.

The abstract base class for all kernels is Kernel. Kernel implements a similar interface as BaseEstimator, providing the methods get_params(), set_params(), and clone(). This allows setting kernel values also via meta-estimators such as Pipeline or GridSearchCV. Note that due to the nested structure of kernels (by applying kernel operators, see below), the names of kernel parameters might become relatively complicated. In general, for a binary kernel operator, parameters of the left operand are prefixed with k1__ and parameters of the right operand with k2__. An additional convenience method is clone_with_theta(theta), which returns a cloned version of the kernel but with the hyperparameters set to theta. An illustrative example:

All Gaussian process kernels are interoperable with sklearn.metrics.pairwise and vice versa: instances of subclasses of Kernel can be passed as metric to pairwise_kernels from sklearn.metrics.pairwise. Moreover, kernel functions from pairwise can be used as GP kernels by using the wrapper class PairwiseKernel. The only caveat is that the gradient of the hyperparameters is not analytic but numeric and all those kernels support only isotropic distances. The parameter gamma is considered to be a hyperparameter and may be optimized. The other kernel parameters are set directly at initialization and are kept fixed.

The ConstantKernel kernel can be used as part of a Product kernel where it scales the magnitude of the other factor (kernel) or as part of a Sum kernel, where it modifies the mean of the Gaussian process. It depends on a parameter \(constant\_value\). It is defined as:

The main use-case of the WhiteKernel kernel is as part of a sum-kernel where it explains the noise-component of the signal. Tuning its parameter \(noise\_level\) corresponds to estimating the noise-level. It is defined as:

Kernel operators take one or two base kernels and combine them into a new kernel. The Sum kernel takes two kernels \(k_1\) and \(k_2\) and combines them via \(k_{sum}(X, Y) = k_1(X, Y) + k_2(X, Y)\). The Product kernel takes two kernels \(k_1\) and \(k_2\) and combines them via \(k_{product}(X, Y) = k_1(X, Y) * k_2(X, Y)\). The Exponentiation kernel takes one base kernel and a scalar parameter \(p\) and combines them via \(k_{exp}(X, Y) = k(X, Y)^p\). Note that magic methods __add__, __mul___ and __pow__ are overridden on the Kernel objects, so one can use e.g. RBF() + RBF() as a shortcut for Sum(RBF(), RBF()).

The RBF kernel is a stationary kernel. It is also known as the “squared exponential” kernel. It is parameterized by a length-scale parameter \(l>0\), which can either be a scalar (isotropic variant of the kernel) or a vector with the same number of dimensions as the inputs \(x\) (anisotropic variant of the kernel). The kernel is given by:

where \(d(\cdot, \cdot)\) is the Euclidean distance. This kernel is infinitely differentiable, which implies that GPs with this kernel as covariance function have mean square derivatives of all orders, and are thus very smooth. The prior and posterior of a GP resulting from an RBF kernel are shown in the following figure:

The Matern kernel is a stationary kernel and a generalization of the RBF kernel. It has an additional parameter \(\nu\) which controls the smoothness of the resulting function. It is parameterized by a length-scale parameter \(l>0\), which can either be a scalar (isotropic variant of the kernel) or a vector with the same number of dimensions as the inputs \(x\) (anisotropic variant of the kernel).

The kernel is given by:

where \(d(\cdot,\cdot)\) is the Euclidean distance, \(K_\nu(\cdot)\) is a modified Bessel function and \(\Gamma(\cdot)\) is the gamma function. As \(\nu\rightarrow\infty\), the Matérn kernel converges to the RBF kernel. When \(\nu = 1/2\), the Matérn kernel becomes identical to the absolute exponential kernel, i.e.,

In particular, \(\nu = 3/2\):

are popular choices for learning functions that are not infinitely differentiable (as assumed by the RBF kernel) but at least once (\(\nu = 3/2\)) or twice differentiable (\(\nu = 5/2\)).

The flexibility of controlling the smoothness of the learned function via \(\nu\) allows adapting to the properties of the true underlying functional relation.

The prior and posterior of a GP resulting from a Matérn kernel are shown in the following figure:

See [RW2006], pp84 for further details regarding the different variants of the Matérn kernel.

The RationalQuadratic kernel can be seen as a scale mixture (an infinite sum) of RBF kernels with different characteristic length-scales. It is parameterized by a length-scale parameter \(l>0\) and a scale mixture parameter \(\alpha>0\) Only the isotropic variant where \(l\) is a scalar is supported at the moment. The kernel is given by:

The prior and posterior of a GP resulting from a RationalQuadratic kernel are shown in the following figure:

The ExpSineSquared kernel allows modeling periodic functions. It is parameterized by a length-scale parameter \(l>0\) and a periodicity parameter \(p>0\). Only the isotropic variant where \(l\) is a scalar is supported at the moment. The kernel is given by:

The prior and posterior of a GP resulting from an ExpSineSquared kernel are shown in the following figure:

The DotProduct kernel is non-stationary and can be obtained from linear regression by putting \(N(0, 1)\) priors on the coefficients of \(x_d (d = 1, . . . , D)\) and a prior of \(N(0, \sigma_0^2)\) on the bias. The DotProduct kernel is invariant to a rotation of the coordinates about the origin, but not translations. It is parameterized by a parameter \(\sigma_0^2\). For \(\sigma_0^2 = 0\), the kernel is called the homogeneous linear kernel, otherwise it is inhomogeneous. The kernel is given by

The DotProduct kernel is commonly combined with exponentiation. An example with exponent 2 is shown in the following figure:

Carl E. Rasmussen and Christopher K.I. Williams, “Gaussian Processes for Machine Learning”, MIT Press 2006

David Duvenaud, “The Kernel Cookbook: Advice on Covariance functions”, 2014

**Examples:**

Example 1 (json):
```json
>>> from sklearn.gaussian_process.kernels import ConstantKernel, RBF
>>> kernel = ConstantKernel(constant_value=1.0, constant_value_bounds=(0.0, 10.0)) * RBF(length_scale=0.5, length_scale_bounds=(0.0, 10.0)) + RBF(length_scale=2.0, length_scale_bounds=(0.0, 10.0))
>>> for hyperparameter in kernel.hyperparameters: print(hyperparameter)
Hyperparameter(name='k1__k1__constant_value', value_type='numeric', bounds=array([[ 0., 10.]]), n_elements=1, fixed=False)
Hyperparameter(name='k1__k2__length_scale', value_type='numeric', bounds=array([[ 0., 10.]]), n_elements=1, fixed=False)
Hyperparameter(name='k2__length_scale', value_type='numeric', bounds=array([[ 0., 10.]]), n_elements=1, fixed=False)
>>> params = kernel.get_params()
>>> for key in sorted(params): print("%s : %s" % (key, params[key]))
k1 : 1**2 * RBF(length_scale=0.5)
k1__k1 : 1**2
k1__k1__constant_value : 1.0
k1__k1__constant_value_bounds : (0.0, 10.0)
k1__k2 : RBF(length_scale=0.5)
k1__k2__length_scale : 0.5
k1__k2__length_scale_bounds : (0.0, 10.0)
k2 : RBF(length_scale=2)
k2__length_scale : 2.0
k2__length_scale_bounds : (0.0, 10.0)
>>> print(kernel.theta)  # Note: log-transformed
[ 0.         -0.69314718  0.69314718]
>>> print(kernel.bounds)  # Note: log-transformed
[[      -inf 2.30258509]
[      -inf 2.30258509]
[      -inf 2.30258509]]
```

---

## 1.6. Nearest Neighbors#

**URL:** https://scikit-learn.org/stable/modules/neighbors.html

**Contents:**
- 1.6. Nearest Neighbors#
- 1.6.1. Unsupervised Nearest Neighbors#
  - 1.6.1.1. Finding the Nearest Neighbors#
  - 1.6.1.2. KDTree and BallTree Classes#
- 1.6.2. Nearest Neighbors Classification#
- 1.6.3. Nearest Neighbors Regression#
- 1.6.4. Nearest Neighbor Algorithms#
  - 1.6.4.1. Brute Force#
  - 1.6.4.2. K-D Tree#
  - 1.6.4.3. Ball Tree#

sklearn.neighbors provides functionality for unsupervised and supervised neighbors-based learning methods. Unsupervised nearest neighbors is the foundation of many other learning methods, notably manifold learning and spectral clustering. Supervised neighbors-based learning comes in two flavors: classification for data with discrete labels, and regression for data with continuous labels.

The principle behind nearest neighbor methods is to find a predefined number of training samples closest in distance to the new point, and predict the label from these. The number of samples can be a user-defined constant (k-nearest neighbor learning), or vary based on the local density of points (radius-based neighbor learning). The distance can, in general, be any metric measure: standard Euclidean distance is the most common choice. Neighbors-based methods are known as non-generalizing machine learning methods, since they simply “remember” all of its training data (possibly transformed into a fast indexing structure such as a Ball Tree or KD Tree).

Despite its simplicity, nearest neighbors has been successful in a large number of classification and regression problems, including handwritten digits and satellite image scenes. Being a non-parametric method, it is often successful in classification situations where the decision boundary is very irregular.

The classes in sklearn.neighbors can handle either NumPy arrays or scipy.sparse matrices as input. For dense matrices, a large number of possible distance metrics are supported. For sparse matrices, arbitrary Minkowski metrics are supported for searches.

There are many learning routines which rely on nearest neighbors at their core. One example is kernel density estimation, discussed in the density estimation section.

NearestNeighbors implements unsupervised nearest neighbors learning. It acts as a uniform interface to three different nearest neighbors algorithms: BallTree, KDTree, and a brute-force algorithm based on routines in sklearn.metrics.pairwise. The choice of neighbors search algorithm is controlled through the keyword 'algorithm', which must be one of ['auto', 'ball_tree', 'kd_tree', 'brute']. When the default value 'auto' is passed, the algorithm attempts to determine the best approach from the training data. For a discussion of the strengths and weaknesses of each option, see Nearest Neighbor Algorithms.

Regarding the Nearest Neighbors algorithms, if two neighbors \(k+1\) and \(k\) have identical distances but different labels, the result will depend on the ordering of the training data.

For the simple task of finding the nearest neighbors between two sets of data, the unsupervised algorithms within sklearn.neighbors can be used:

Because the query set matches the training set, the nearest neighbor of each point is the point itself, at a distance of zero.

It is also possible to efficiently produce a sparse graph showing the connections between neighboring points:

The dataset is structured such that points nearby in index order are nearby in parameter space, leading to an approximately block-diagonal matrix of K-nearest neighbors. Such a sparse graph is useful in a variety of circumstances which make use of spatial relationships between points for unsupervised learning: in particular, see Isomap, LocallyLinearEmbedding, and SpectralClustering.

Alternatively, one can use the KDTree or BallTree classes directly to find nearest neighbors. This is the functionality wrapped by the NearestNeighbors class used above. The Ball Tree and KD Tree have the same interface; we’ll show an example of using the KD Tree here:

Refer to the KDTree and BallTree class documentation for more information on the options available for nearest neighbors searches, including specification of query strategies, distance metrics, etc. For a list of valid metrics use KDTree.valid_metrics and BallTree.valid_metrics:

Neighbors-based classification is a type of instance-based learning or non-generalizing learning: it does not attempt to construct a general internal model, but simply stores instances of the training data. Classification is computed from a simple majority vote of the nearest neighbors of each point: a query point is assigned the data class which has the most representatives within the nearest neighbors of the point.

scikit-learn implements two different nearest neighbors classifiers: KNeighborsClassifier implements learning based on the \(k\) nearest neighbors of each query point, where \(k\) is an integer value specified by the user. RadiusNeighborsClassifier implements learning based on the number of neighbors within a fixed radius \(r\) of each training point, where \(r\) is a floating-point value specified by the user.

The \(k\)-neighbors classification in KNeighborsClassifier is the most commonly used technique. The optimal choice of the value \(k\) is highly data-dependent: in general a larger \(k\) suppresses the effects of noise, but makes the classification boundaries less distinct.

In cases where the data is not uniformly sampled, radius-based neighbors classification in RadiusNeighborsClassifier can be a better choice. The user specifies a fixed radius \(r\), such that points in sparser neighborhoods use fewer nearest neighbors for the classification. For high-dimensional parameter spaces, this method becomes less effective due to the so-called “curse of dimensionality”.

The basic nearest neighbors classification uses uniform weights: that is, the value assigned to a query point is computed from a simple majority vote of the nearest neighbors. Under some circumstances, it is better to weight the neighbors such that nearer neighbors contribute more to the fit. This can be accomplished through the weights keyword. The default value, weights = 'uniform', assigns uniform weights to each neighbor. weights = 'distance' assigns weights proportional to the inverse of the distance from the query point. Alternatively, a user-defined function of the distance can be supplied to compute the weights.

Nearest Neighbors Classification: an example of classification using nearest neighbors.

Neighbors-based regression can be used in cases where the data labels are continuous rather than discrete variables. The label assigned to a query point is computed based on the mean of the labels of its nearest neighbors.

scikit-learn implements two different neighbors regressors: KNeighborsRegressor implements learning based on the \(k\) nearest neighbors of each query point, where \(k\) is an integer value specified by the user. RadiusNeighborsRegressor implements learning based on the neighbors within a fixed radius \(r\) of the query point, where \(r\) is a floating-point value specified by the user.

The basic nearest neighbors regression uses uniform weights: that is, each point in the local neighborhood contributes uniformly to the classification of a query point. Under some circumstances, it can be advantageous to weight points such that nearby points contribute more to the regression than faraway points. This can be accomplished through the weights keyword. The default value, weights = 'uniform', assigns equal weights to all points. weights = 'distance' assigns weights proportional to the inverse of the distance from the query point. Alternatively, a user-defined function of the distance can be supplied, which will be used to compute the weights.

The use of multi-output nearest neighbors for regression is demonstrated in Face completion with a multi-output estimators. In this example, the inputs X are the pixels of the upper half of faces and the outputs Y are the pixels of the lower half of those faces.

Nearest Neighbors regression: an example of regression using nearest neighbors.

Face completion with a multi-output estimators: an example of multi-output regression using nearest neighbors.

Fast computation of nearest neighbors is an active area of research in machine learning. The most naive neighbor search implementation involves the brute-force computation of distances between all pairs of points in the dataset: for \(N\) samples in \(D\) dimensions, this approach scales as \(O[D N^2]\). Efficient brute-force neighbors searches can be very competitive for small data samples. However, as the number of samples \(N\) grows, the brute-force approach quickly becomes infeasible. In the classes within sklearn.neighbors, brute-force neighbors searches are specified using the keyword algorithm = 'brute', and are computed using the routines available in sklearn.metrics.pairwise.

To address the computational inefficiencies of the brute-force approach, a variety of tree-based data structures have been invented. In general, these structures attempt to reduce the required number of distance calculations by efficiently encoding aggregate distance information for the sample. The basic idea is that if point \(A\) is very distant from point \(B\), and point \(B\) is very close to point \(C\), then we know that points \(A\) and \(C\) are very distant, without having to explicitly calculate their distance. In this way, the computational cost of a nearest neighbors search can be reduced to \(O[D N \log(N)]\) or better. This is a significant improvement over brute-force for large \(N\).

An early approach to taking advantage of this aggregate information was the KD tree data structure (short for K-dimensional tree), which generalizes two-dimensional Quad-trees and 3-dimensional Oct-trees to an arbitrary number of dimensions. The KD tree is a binary tree structure which recursively partitions the parameter space along the data axes, dividing it into nested orthotropic regions into which data points are filed. The construction of a KD tree is very fast: because partitioning is performed only along the data axes, no \(D\)-dimensional distances need to be computed. Once constructed, the nearest neighbor of a query point can be determined with only \(O[\log(N)]\) distance computations. Though the KD tree approach is very fast for low-dimensional (\(D < 20\)) neighbors searches, it becomes inefficient as \(D\) grows very large: this is one manifestation of the so-called “curse of dimensionality”. In scikit-learn, KD tree neighbors searches are specified using the keyword algorithm = 'kd_tree', and are computed using the class KDTree.

“Multidimensional binary search trees used for associative searching”, Bentley, J.L., Communications of the ACM (1975)

To address the inefficiencies of KD Trees in higher dimensions, the ball tree data structure was developed. Where KD trees partition data along Cartesian axes, ball trees partition data in a series of nesting hyper-spheres. This makes tree construction more costly than that of the KD tree, but results in a data structure which can be very efficient on highly structured data, even in very high dimensions.

A ball tree recursively divides the data into nodes defined by a centroid \(C\) and radius \(r\), such that each point in the node lies within the hyper-sphere defined by \(r\) and \(C\). The number of candidate points for a neighbor search is reduced through use of the triangle inequality:

With this setup, a single distance calculation between a test point and the centroid is sufficient to determine a lower and upper bound on the distance to all points within the node. Because of the spherical geometry of the ball tree nodes, it can out-perform a KD-tree in high dimensions, though the actual performance is highly dependent on the structure of the training data. In scikit-learn, ball-tree-based neighbors searches are specified using the keyword algorithm = 'ball_tree', and are computed using the class BallTree. Alternatively, the user can work with the BallTree class directly.

“Five Balltree Construction Algorithms”, Omohundro, S.M., International Computer Science Institute Technical Report (1989)

The optimal algorithm for a given dataset is a complicated choice, and depends on a number of factors:

number of samples \(N\) (i.e. n_samples) and dimensionality \(D\) (i.e. n_features).

Brute force query time grows as \(O[D N]\)

Ball tree query time grows as approximately \(O[D \log(N)]\)

KD tree query time changes with \(D\) in a way that is difficult to precisely characterise. For small \(D\) (less than 20 or so) the cost is approximately \(O[D\log(N)]\), and the KD tree query can be very efficient. For larger \(D\), the cost increases to nearly \(O[DN]\), and the overhead due to the tree structure can lead to queries which are slower than brute force.

For small data sets (\(N\) less than 30 or so), \(\log(N)\) is comparable to \(N\), and brute force algorithms can be more efficient than a tree-based approach. Both KDTree and BallTree address this through providing a leaf size parameter: this controls the number of samples at which a query switches to brute-force. This allows both algorithms to approach the efficiency of a brute-force computation for small \(N\).

data structure: intrinsic dimensionality of the data and/or sparsity of the data. Intrinsic dimensionality refers to the dimension \(d \le D\) of a manifold on which the data lies, which can be linearly or non-linearly embedded in the parameter space. Sparsity refers to the degree to which the data fills the parameter space (this is to be distinguished from the concept as used in “sparse” matrices. The data matrix may have no zero entries, but the structure can still be “sparse” in this sense).

Brute force query time is unchanged by data structure.

Ball tree and KD tree query times can be greatly influenced by data structure. In general, sparser data with a smaller intrinsic dimensionality leads to faster query times. Because the KD tree internal representation is aligned with the parameter axes, it will not generally show as much improvement as ball tree for arbitrarily structured data.

Datasets used in machine learning tend to be very structured, and are very well-suited for tree-based queries.

number of neighbors \(k\) requested for a query point.

Brute force query time is largely unaffected by the value of \(k\)

Ball tree and KD tree query time will become slower as \(k\) increases. This is due to two effects: first, a larger \(k\) leads to the necessity to search a larger portion of the parameter space. Second, using \(k > 1\) requires internal queueing of results as the tree is traversed.

As \(k\) becomes large compared to \(N\), the ability to prune branches in a tree-based query is reduced. In this situation, Brute force queries can be more efficient.

number of query points. Both the ball tree and the KD Tree require a construction phase. The cost of this construction becomes negligible when amortized over many queries. If only a small number of queries will be performed, however, the construction can make up a significant fraction of the total cost. If very few query points will be required, brute force is better than a tree-based method.

Currently, algorithm = 'auto' selects 'brute' if any of the following conditions are verified:

metric = 'precomputed'

effective_metric_ isn’t in the VALID_METRICS list for either 'kd_tree' or 'ball_tree'

Otherwise, it selects the first out of 'kd_tree' and 'ball_tree' that has effective_metric_ in its VALID_METRICS list. This heuristic is based on the following assumptions:

the number of query points is at least the same order as the number of training points

leaf_size is close to its default value of 30

when \(D > 15\), the intrinsic dimensionality of the data is generally too high for tree-based methods

As noted above, for small sample sizes a brute force search can be more efficient than a tree-based query. This fact is accounted for in the ball tree and KD tree by internally switching to brute force searches within leaf nodes. The level of this switch can be specified with the parameter leaf_size. This parameter choice has many effects:

A larger leaf_size leads to a faster tree construction time, because fewer nodes need to be created

Both a large or small leaf_size can lead to suboptimal query cost. For leaf_size approaching 1, the overhead involved in traversing nodes can significantly slow query times. For leaf_size approaching the size of the training set, queries become essentially brute force. A good compromise between these is leaf_size = 30, the default value of the parameter.

As leaf_size increases, the memory required to store a tree structure decreases. This is especially important in the case of ball tree, which stores a \(D\)-dimensional centroid for each node. The required storage space for BallTree is approximately 1 / leaf_size times the size of the training set.

leaf_size is not referenced for brute force queries.

For a list of available metrics, see the documentation of the DistanceMetric class and the metrics listed in sklearn.metrics.pairwise.PAIRWISE_DISTANCE_FUNCTIONS. Note that the “cosine” metric uses cosine_distances.

A list of valid metrics for any of the above algorithms can be obtained by using their valid_metric attribute. For example, valid metrics for KDTree can be generated by:

The NearestCentroid classifier is a simple algorithm that represents each class by the centroid of its members. In effect, this makes it similar to the label updating phase of the KMeans algorithm. It also has no parameters to choose, making it a good baseline classifier. It does, however, suffer on non-convex classes, as well as when classes have drastically different variances, as equal variance in all dimensions is assumed. See Linear Discriminant Analysis (LinearDiscriminantAnalysis) and Quadratic Discriminant Analysis (QuadraticDiscriminantAnalysis) for more complex methods that do not make this assumption. Usage of the default NearestCentroid is simple:

The NearestCentroid classifier has a shrink_threshold parameter, which implements the nearest shrunken centroid classifier. In effect, the value of each feature for each centroid is divided by the within-class variance of that feature. The feature values are then reduced by shrink_threshold. Most notably, if a particular feature value crosses zero, it is set to zero. In effect, this removes the feature from affecting the classification. This is useful, for example, for removing noisy features.

In the example below, using a small shrink threshold increases the accuracy of the model from 0.81 to 0.82.

Nearest Centroid Classification: an example of classification using nearest centroid with different shrink thresholds.

Many scikit-learn estimators rely on nearest neighbors: Several classifiers and regressors such as KNeighborsClassifier and KNeighborsRegressor, but also some clustering methods such as DBSCAN and SpectralClustering, and some manifold embeddings such as TSNE and Isomap.

All these estimators can compute internally the nearest neighbors, but most of them also accept precomputed nearest neighbors sparse graph, as given by kneighbors_graph and radius_neighbors_graph. With mode mode='connectivity', these functions return a binary adjacency sparse graph as required, for instance, in SpectralClustering. Whereas with mode='distance', they return a distance sparse graph as required, for instance, in DBSCAN. To include these functions in a scikit-learn pipeline, one can also use the corresponding classes KNeighborsTransformer and RadiusNeighborsTransformer. The benefits of this sparse graph API are multiple.

First, the precomputed graph can be reused multiple times, for instance while varying a parameter of the estimator. This can be done manually by the user, or using the caching properties of the scikit-learn pipeline:

Second, precomputing the graph can give finer control on the nearest neighbors estimation, for instance enabling multiprocessing though the parameter n_jobs, which might not be available in all estimators.

Finally, the precomputation can be performed by custom estimators to use different implementations, such as approximate nearest neighbors methods, or implementation with special data types. The precomputed neighbors sparse graph needs to be formatted as in radius_neighbors_graph output:

a CSR matrix (although COO, CSC or LIL will be accepted).

only explicitly store nearest neighborhoods of each sample with respect to the training data. This should include those at 0 distance from a query point, including the matrix diagonal when computing the nearest neighborhoods between the training data and itself.

each row’s data should store the distance in increasing order (optional. Unsorted data will be stable-sorted, adding a computational overhead).

all values in data should be non-negative.

there should be no duplicate indices in any row (see scipy/scipy#5807).

if the algorithm being passed the precomputed matrix uses k nearest neighbors (as opposed to radius neighborhood), at least k neighbors must be stored in each row (or k+1, as explained in the following note).

When a specific number of neighbors is queried (using KNeighborsTransformer), the definition of n_neighbors is ambiguous since it can either include each training point as its own neighbor, or exclude them. Neither choice is perfect, since including them leads to a different number of non-self neighbors during training and testing, while excluding them leads to a difference between fit(X).transform(X) and fit_transform(X), which is against scikit-learn API. In KNeighborsTransformer we use the definition which includes each training point as its own neighbor in the count of n_neighbors. However, for compatibility reasons with other estimators which use the other definition, one extra neighbor will be computed when mode == 'distance'. To maximise compatibility with all estimators, a safe choice is to always include one extra neighbor in a custom nearest neighbors estimator, since unnecessary neighbors will be filtered by following estimators.

Approximate nearest neighbors in TSNE: an example of pipelining KNeighborsTransformer and TSNE. Also proposes two custom nearest neighbors estimators based on external packages.

Caching nearest neighbors: an example of pipelining KNeighborsTransformer and KNeighborsClassifier to enable caching of the neighbors graph during a hyper-parameter grid-search.

Neighborhood Components Analysis (NCA, NeighborhoodComponentsAnalysis) is a distance metric learning algorithm which aims to improve the accuracy of nearest neighbors classification compared to the standard Euclidean distance. The algorithm directly maximizes a stochastic variant of the leave-one-out k-nearest neighbors (KNN) score on the training set. It can also learn a low-dimensional linear projection of data that can be used for data visualization and fast classification.

In the above illustrating figure, we consider some points from a randomly generated dataset. We focus on the stochastic KNN classification of point no. 3. The thickness of a link between sample 3 and another point is proportional to their distance, and can be seen as the relative weight (or probability) that a stochastic nearest neighbor prediction rule would assign to this point. In the original space, sample 3 has many stochastic neighbors from various classes, so the right class is not very likely. However, in the projected space learned by NCA, the only stochastic neighbors with non-negligible weight are from the same class as sample 3, guaranteeing that the latter will be well classified. See the mathematical formulation for more details.

Combined with a nearest neighbors classifier (KNeighborsClassifier), NCA is attractive for classification because it can naturally handle multi-class problems without any increase in the model size, and does not introduce additional parameters that require fine-tuning by the user.

NCA classification has been shown to work well in practice for data sets of varying size and difficulty. In contrast to related methods such as Linear Discriminant Analysis, NCA does not make any assumptions about the class distributions. The nearest neighbor classification can naturally produce highly irregular decision boundaries.

To use this model for classification, one needs to combine a NeighborhoodComponentsAnalysis instance that learns the optimal transformation with a KNeighborsClassifier instance that performs the classification in the projected space. Here is an example using the two classes:

The plot shows decision boundaries for Nearest Neighbor Classification and Neighborhood Components Analysis classification on the iris dataset, when training and scoring on only two features, for visualisation purposes.

NCA can be used to perform supervised dimensionality reduction. The input data are projected onto a linear subspace consisting of the directions which minimize the NCA objective. The desired dimensionality can be set using the parameter n_components. For instance, the following figure shows a comparison of dimensionality reduction with Principal Component Analysis (PCA), Linear Discriminant Analysis (LinearDiscriminantAnalysis) and Neighborhood Component Analysis (NeighborhoodComponentsAnalysis) on the Digits dataset, a dataset with size \(n_{samples} = 1797\) and \(n_{features} = 64\). The data set is split into a training and a test set of equal size, then standardized. For evaluation the 3-nearest neighbor classification accuracy is computed on the 2-dimensional projected points found by each method. Each data sample belongs to one of 10 classes.

Comparing Nearest Neighbors with and without Neighborhood Components Analysis

Dimensionality Reduction with Neighborhood Components Analysis

Manifold learning on handwritten digits: Locally Linear Embedding, Isomap…

The goal of NCA is to learn an optimal linear transformation matrix of size (n_components, n_features), which maximises the sum over all samples \(i\) of the probability \(p_i\) that \(i\) is correctly classified, i.e.:

with \(N\) = n_samples and \(p_i\) the probability of sample \(i\) being correctly classified according to a stochastic nearest neighbors rule in the learned embedded space:

where \(C_i\) is the set of points in the same class as sample \(i\), and \(p_{i j}\) is the softmax over Euclidean distances in the embedded space:

NCA can be seen as learning a (squared) Mahalanobis distance metric:

where \(M = L^T L\) is a symmetric positive semi-definite matrix of size (n_features, n_features).

This implementation follows what is explained in the original paper [1]. For the optimisation method, it currently uses scipy’s L-BFGS-B with a full gradient computation at each iteration, to avoid to tune the learning rate and provide stable learning.

See the examples below and the docstring of NeighborhoodComponentsAnalysis.fit for further information.

NCA stores a matrix of pairwise distances, taking n_samples ** 2 memory. Time complexity depends on the number of iterations done by the optimisation algorithm. However, one can set the maximum number of iterations with the argument max_iter. For each iteration, time complexity is O(n_components x n_samples x min(n_samples, n_features)).

Here the transform operation returns \(LX^T\), therefore its time complexity equals n_components * n_features * n_samples_test. There is no added space complexity in the operation.

“Neighbourhood Components Analysis”, J. Goldberger, S. Roweis, G. Hinton, R. Salakhutdinov, Advances in Neural Information Processing Systems, Vol. 17, May 2005, pp. 513-520.

Wikipedia entry on Neighborhood Components Analysis

**Examples:**

Example 1 (sql):
```sql
>>> from sklearn.neighbors import NearestNeighbors
>>> import numpy as np
>>> X = np.array([[-1, -1], [-2, -1], [-3, -2], [1, 1], [2, 1], [3, 2]])
>>> nbrs = NearestNeighbors(n_neighbors=2, algorithm='ball_tree').fit(X)
>>> distances, indices = nbrs.kneighbors(X)
>>> indices
array([[0, 1],
       [1, 0],
       [2, 1],
       [3, 4],
       [4, 3],
       [5, 4]]...)
>>> distances
array([[0.        , 1.        ],
       [0.        , 1.        ],
       [0.        , 1.41421356],
       [0.        , 1.        ],
       [0.        , 1.        ],
       [0.        , 1.41421356]])
```

Example 2 (json):
```json
>>> nbrs.kneighbors_graph(X).toarray()
array([[1., 1., 0., 0., 0., 0.],
       [1., 1., 0., 0., 0., 0.],
       [0., 1., 1., 0., 0., 0.],
       [0., 0., 0., 1., 1., 0.],
       [0., 0., 0., 1., 1., 0.],
       [0., 0., 0., 0., 1., 1.]])
```

Example 3 (sql):
```sql
>>> from sklearn.neighbors import KDTree
>>> import numpy as np
>>> X = np.array([[-1, -1], [-2, -1], [-3, -2], [1, 1], [2, 1], [3, 2]])
>>> kdt = KDTree(X, leaf_size=30, metric='euclidean')
>>> kdt.query(X, k=2, return_distance=False)
array([[0, 1],
       [1, 0],
       [2, 1],
       [3, 4],
       [4, 3],
       [5, 4]]...)
```

Example 4 (sql):
```sql
>>> from sklearn.neighbors import KDTree, BallTree
>>> KDTree.valid_metrics
['euclidean', 'l2', 'minkowski', 'p', 'manhattan', 'cityblock', 'l1', 'chebyshev', 'infinity']
>>> BallTree.valid_metrics
['euclidean', 'l2', 'minkowski', 'p', 'manhattan', 'cityblock', 'l1', 'chebyshev', 'infinity', 'seuclidean', 'mahalanobis', 'hamming', 'canberra', 'braycurtis', 'jaccard', 'dice', 'rogerstanimoto', 'russellrao', 'sokalmichener', 'sokalsneath', 'haversine', 'pyfunc']
```

---

## ConstantKernel#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.gaussian_process.kernels.ConstantKernel.html

**Contents:**
- ConstantKernel#
- Gallery examples#

Can be used as part of a product-kernel where it scales the magnitude of the other factor (kernel) or as part of a sum-kernel, where it modifies the mean of the Gaussian process.

Adding a constant kernel is equivalent to adding a constant:

Read more in the User Guide.

Added in version 0.18.

The constant value which defines the covariance: k(x_1, x_2) = constant_value

The lower and upper bound on constant_value. If set to “fixed”, constant_value cannot be changed during hyperparameter tuning.

Return the kernel k(X, Y) and optionally its gradient.

Left argument of the returned kernel k(X, Y)

Right argument of the returned kernel k(X, Y). If None, k(X, X) is evaluated instead.

Determines whether the gradient with respect to the log of the kernel hyperparameter is computed. Only supported when Y is None.

The gradient of the kernel k(X, X) with respect to the log of the hyperparameter of the kernel. Only returned when eval_gradient is True.

Returns the log-transformed bounds on the theta.

The log-transformed bounds on the kernel’s hyperparameters theta

Returns a clone of self with given hyperparameters theta.

Returns the diagonal of the kernel k(X, X).

The result of this method is identical to np.diag(self(X)); however, it can be evaluated more efficiently since only the diagonal is evaluated.

Argument to the kernel.

Diagonal of kernel k(X, X)

Get parameters of this kernel.

If True, will return the parameters for this estimator and contained subobjects that are estimators.

Parameter names mapped to their values.

Returns a list of all hyperparameter specifications.

Returns whether the kernel is stationary.

Returns the number of non-fixed hyperparameters of the kernel.

Whether the kernel works only on fixed-length feature vectors.

Set the parameters of this kernel.

The method works on simple kernels as well as on nested kernels. The latter have parameters of the form <component>__<parameter> so that it’s possible to update each component of a nested object.

Returns the (flattened, log-transformed) non-fixed hyperparameters.

Note that theta are typically the log-transformed values of the kernel’s hyperparameters as this representation of the search space is more amenable for hyperparameter search, as hyperparameters like length-scales naturally live on a log-scale.

The non-fixed, log-transformed hyperparameters of the kernel

Iso-probability lines for Gaussian Processes classification (GPC)

Illustration of prior and posterior Gaussian process for different kernels

**Examples:**

Example 1 (unknown):
```unknown
kernel = RBF() + ConstantKernel(constant_value=2)
```

Example 2 (unknown):
```unknown
kernel = RBF() + 2
```

Example 3 (sql):
```sql
>>> from sklearn.datasets import make_friedman2
>>> from sklearn.gaussian_process import GaussianProcessRegressor
>>> from sklearn.gaussian_process.kernels import RBF, ConstantKernel
>>> X, y = make_friedman2(n_samples=500, noise=0, random_state=0)
>>> kernel = RBF() + ConstantKernel(constant_value=2)
>>> gpr = GaussianProcessRegressor(kernel=kernel, alpha=5,
...         random_state=0).fit(X, y)
>>> gpr.score(X, y)
0.3696
>>> gpr.predict(X[:1,:], return_std=True)
(array([606.1]), array([0.248]))
```

---

## davies_bouldin_score#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.metrics.davies_bouldin_score.html

**Contents:**
- davies_bouldin_score#

Compute the Davies-Bouldin score.

The score is defined as the average similarity measure of each cluster with its most similar cluster, where similarity is the ratio of within-cluster distances to between-cluster distances. Thus, clusters which are farther apart and less dispersed will result in a better score.

The minimum score is zero, with lower values indicating better clustering.

Read more in the User Guide.

Added in version 0.20.

A list of n_features-dimensional data points. Each row corresponds to a single data point.

Predicted labels for each sample.

The resulting Davies-Bouldin score.

Davies, David L.; Bouldin, Donald W. (1979). “A Cluster Separation Measure”. IEEE Transactions on Pattern Analysis and Machine Intelligence. PAMI-1 (2): 224-227

**Examples:**

Example 1 (sql):
```sql
>>> from sklearn.metrics import davies_bouldin_score
>>> X = [[0, 1], [1, 1], [3, 4]]
>>> labels = [0, 0, 1]
>>> davies_bouldin_score(X, labels)
0.12...
```

---

## 

**URL:** https://scikit-learn.org/stable/modules/classes.html

---

## BaggingClassifier#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.BaggingClassifier.html

**Contents:**
- BaggingClassifier#

A Bagging classifier.

A Bagging classifier is an ensemble meta-estimator that fits base classifiers each on random subsets of the original dataset and then aggregate their individual predictions (either by voting or by averaging) to form a final prediction. Such a meta-estimator can typically be used as a way to reduce the variance of a black-box estimator (e.g., a decision tree), by introducing randomization into its construction procedure and then making an ensemble out of it.

This algorithm encompasses several works from the literature. When random subsets of the dataset are drawn as random subsets of the samples, then this algorithm is known as Pasting [1]. If samples are drawn with replacement, then the method is known as Bagging [2]. When random subsets of the dataset are drawn as random subsets of the features, then the method is known as Random Subspaces [3]. Finally, when base estimators are built on subsets of both samples and features, then the method is known as Random Patches [4].

Read more in the User Guide.

Added in version 0.15.

The base estimator to fit on random subsets of the dataset. If None, then the base estimator is a DecisionTreeClassifier.

Added in version 1.2: base_estimator was renamed to estimator.

The number of base estimators in the ensemble.

The number of samples to draw from X to train each base estimator (with replacement by default, see bootstrap for more details).

If None, then draw X.shape[0] samples irrespective of sample_weight.

If int, then draw max_samples samples.

If float, then draw max_samples * X.shape[0] unweighted samples or max_samples * sample_weight.sum() weighted samples.

The number of features to draw from X to train each base estimator ( without replacement by default, see bootstrap_features for more details).

If int, then draw max_features features.

If float, then draw max(1, int(max_features * n_features_in_)) features.

Whether samples are drawn with replacement. If False, sampling without replacement is performed. If fitting with sample_weight, it is strongly recommended to choose True, as only drawing with replacement will ensure the expected frequency semantics of sample_weight.

Whether features are drawn with replacement.

Whether to use out-of-bag samples to estimate the generalization error. Only available if bootstrap=True.

When set to True, reuse the solution of the previous call to fit and add more estimators to the ensemble, otherwise, just fit a whole new ensemble. See the Glossary.

Added in version 0.17: warm_start constructor parameter.

The number of jobs to run in parallel for both fit and predict. None means 1 unless in a joblib.parallel_backend context. -1 means using all processors. See Glossary for more details.

Controls the random resampling of the original dataset (sample wise and feature wise). If the base estimator accepts a random_state attribute, a different seed is generated for each instance in the ensemble. Pass an int for reproducible output across multiple function calls. See Glossary.

Controls the verbosity when fitting and predicting.

The base estimator from which the ensemble is grown.

Added in version 1.2: base_estimator_ was renamed to estimator_.

Number of features seen during fit.

Added in version 0.24.

Names of features seen during fit. Defined only when X has feature names that are all strings.

Added in version 1.0.

The collection of fitted base estimators.

The subset of drawn samples for each base estimator.

The subset of drawn features for each base estimator.

The number of classes.

Score of the training dataset obtained using an out-of-bag estimate. This attribute exists only when oob_score is True.

Decision function computed with out-of-bag estimate on the training set. If n_estimators is small it might be possible that a data point was never left out during the bootstrap. In this case, oob_decision_function_ might contain NaN. This attribute exists only when oob_score is True.

L. Breiman, “Pasting small votes for classification in large databases and on-line”, Machine Learning, 36(1), 85-103, 1999.

L. Breiman, “Bagging predictors”, Machine Learning, 24(2), 123-140, 1996.

T. Ho, “The random subspace method for constructing decision forests”, Pattern Analysis and Machine Intelligence, 20(8), 832-844, 1998.

G. Louppe and P. Geurts, “Ensembles on Random Patches”, Machine Learning and Knowledge Discovery in Databases, 346-361, 2012.

Average of the decision functions of the base classifiers.

The training input samples. Sparse matrices are accepted only if they are supported by the base estimator.

Parameters routed to the decision_function method of the sub-estimators via the metadata routing API.

Added in version 1.7: Only available if sklearn.set_config(enable_metadata_routing=True) is set. See Metadata Routing User Guide for more details.

The decision function of the input samples. The columns correspond to the classes in sorted order, as they appear in the attribute classes_. Regression and binary classification are special cases with k == 1, otherwise k==n_classes.

Build a Bagging ensemble of estimators from the training set (X, y).

The training input samples. Sparse matrices are accepted only if they are supported by the base estimator.

The target values (class labels in classification, real numbers in regression).

Sample weights. If None, then samples are equally weighted. Used as probabilities to sample the training set. Note that the expected frequency semantics for the sample_weight parameter are only fulfilled when sampling with replacement bootstrap=True and using a float or integer max_samples (instead of the default max_samples=None).

Parameters to pass to the underlying estimators.

Added in version 1.5: Only available if enable_metadata_routing=True, which can be set by using sklearn.set_config(enable_metadata_routing=True). See Metadata Routing User Guide for more details.

Get metadata routing of this object.

Please check User Guide on how the routing mechanism works.

Added in version 1.5.

A MetadataRouter encapsulating routing information.

Get parameters for this estimator.

If True, will return the parameters for this estimator and contained subobjects that are estimators.

Parameter names mapped to their values.

The predicted class of an input sample is computed as the class with the highest mean predicted probability. If base estimators do not implement a predict_proba method, then it resorts to voting.

The training input samples. Sparse matrices are accepted only if they are supported by the base estimator.

Parameters routed to the predict_proba (if available) or the predict method (otherwise) of the sub-estimators via the metadata routing API.

Added in version 1.7: Only available if sklearn.set_config(enable_metadata_routing=True) is set. See Metadata Routing User Guide for more details.

The predicted classes.

Predict class log-probabilities for X.

The predicted class log-probabilities of an input sample is computed as the log of the mean predicted class probabilities of the base estimators in the ensemble.

The training input samples. Sparse matrices are accepted only if they are supported by the base estimator.

Parameters routed to the predict_log_proba, the predict_proba or the proba method of the sub-estimators via the metadata routing API. The routing is tried in the mentioned order depending on whether this method is available on the sub-estimator.

Added in version 1.7: Only available if sklearn.set_config(enable_metadata_routing=True) is set. See Metadata Routing User Guide for more details.

The class log-probabilities of the input samples. The order of the classes corresponds to that in the attribute classes_.

Predict class probabilities for X.

The predicted class probabilities of an input sample is computed as the mean predicted class probabilities of the base estimators in the ensemble. If base estimators do not implement a predict_proba method, then it resorts to voting and the predicted class probabilities of an input sample represents the proportion of estimators predicting each class.

The training input samples. Sparse matrices are accepted only if they are supported by the base estimator.

Parameters routed to the predict_proba (if available) or the predict method (otherwise) of the sub-estimators via the metadata routing API.

Added in version 1.7: Only available if sklearn.set_config(enable_metadata_routing=True) is set. See Metadata Routing User Guide for more details.

The class probabilities of the input samples. The order of the classes corresponds to that in the attribute classes_.

Return accuracy on provided data and labels.

In multi-label classification, this is the subset accuracy which is a harsh metric since you require for each sample that each label set be correctly predicted.

Mean accuracy of self.predict(X) w.r.t. y.

Configure whether metadata should be requested to be passed to the fit method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to fit if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to fit.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Added in version 1.3.

Metadata routing for sample_weight parameter in fit.

Set the parameters of this estimator.

The method works on simple estimators as well as on nested objects (such as Pipeline). The latter have parameters of the form <component>__<parameter> so that it’s possible to update each component of a nested object.

Estimator parameters.

Configure whether metadata should be requested to be passed to the score method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to score if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to score.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Added in version 1.3.

Metadata routing for sample_weight parameter in score.

**Examples:**

Example 1 (sql):
```sql
>>> from sklearn.svm import SVC
>>> from sklearn.ensemble import BaggingClassifier
>>> from sklearn.datasets import make_classification
>>> X, y = make_classification(n_samples=100, n_features=4,
...                            n_informative=2, n_redundant=0,
...                            random_state=0, shuffle=False)
>>> clf = BaggingClassifier(estimator=SVC(),
...                         n_estimators=10, random_state=0).fit(X, y)
>>> clf.predict([[0, 0, 0, 0]])
array([1])
```

---

## Exponentiation#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.gaussian_process.kernels.Exponentiation.html

**Contents:**
- Exponentiation#

The Exponentiation kernel takes one base kernel and a scalar parameter \(p\) and combines them via

Note that the __pow__ magic method is overridden, so Exponentiation(RBF(), 2) is equivalent to using the ** operator with RBF() ** 2.

Read more in the User Guide.

Added in version 0.18.

The exponent for the base kernel

Return the kernel k(X, Y) and optionally its gradient.

Left argument of the returned kernel k(X, Y)

Right argument of the returned kernel k(X, Y). If None, k(X, X) is evaluated instead.

Determines whether the gradient with respect to the log of the kernel hyperparameter is computed.

The gradient of the kernel k(X, X) with respect to the log of the hyperparameter of the kernel. Only returned when eval_gradient is True.

Returns the log-transformed bounds on the theta.

The log-transformed bounds on the kernel’s hyperparameters theta

Returns a clone of self with given hyperparameters theta.

Returns the diagonal of the kernel k(X, X).

The result of this method is identical to np.diag(self(X)); however, it can be evaluated more efficiently since only the diagonal is evaluated.

Argument to the kernel.

Diagonal of kernel k(X, X)

Get parameters of this kernel.

If True, will return the parameters for this estimator and contained subobjects that are estimators.

Parameter names mapped to their values.

Returns a list of all hyperparameter.

Returns whether the kernel is stationary.

Returns the number of non-fixed hyperparameters of the kernel.

Returns whether the kernel is defined on discrete structures.

Set the parameters of this kernel.

The method works on simple kernels as well as on nested kernels. The latter have parameters of the form <component>__<parameter> so that it’s possible to update each component of a nested object.

Returns the (flattened, log-transformed) non-fixed hyperparameters.

Note that theta are typically the log-transformed values of the kernel’s hyperparameters as this representation of the search space is more amenable for hyperparameter search, as hyperparameters like length-scales naturally live on a log-scale.

The non-fixed, log-transformed hyperparameters of the kernel

**Examples:**

Example 1 (sql):
```sql
>>> from sklearn.datasets import make_friedman2
>>> from sklearn.gaussian_process import GaussianProcessRegressor
>>> from sklearn.gaussian_process.kernels import (RationalQuadratic,
...            Exponentiation)
>>> X, y = make_friedman2(n_samples=500, noise=0, random_state=0)
>>> kernel = Exponentiation(RationalQuadratic(), exponent=2)
>>> gpr = GaussianProcessRegressor(kernel=kernel, alpha=5,
...         random_state=0).fit(X, y)
>>> gpr.score(X, y)
0.419
>>> gpr.predict(X[:1,:], return_std=True)
(array([635.5]), array([0.559]))
```

---

## 

**URL:** https://scikit-learn.org/stable/_sources/modules/feature_selection.rst.txt

---

## SelectPercentile#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectPercentile.html

**Contents:**
- SelectPercentile#
- Gallery examples#

Select features according to a percentile of the highest scores.

Read more in the User Guide.

Function taking two arrays X and y, and returning a pair of arrays (scores, pvalues) or a single array with scores. Default is f_classif (see below “See Also”). The default function only works with classification tasks.

Added in version 0.18.

Percent of features to keep.

p-values of feature scores, None if score_func returned only scores.

Number of features seen during fit.

Added in version 0.24.

Names of features seen during fit. Defined only when X has feature names that are all strings.

Added in version 1.0.

ANOVA F-value between label/feature for classification tasks.

Mutual information for a discrete target.

Chi-squared stats of non-negative features for classification tasks.

F-value between label/feature for regression tasks.

Mutual information for a continuous target.

Select features based on the k highest scores.

Select features based on a false positive rate test.

Select features based on an estimated false discovery rate.

Select features based on family-wise error rate.

Univariate feature selector with configurable mode.

Ties between features with equal scores will be broken in an unspecified way.

This filter supports unsupervised feature selection that only requests X for computing the scores.

Run score function on (X, y) and get the appropriate features.

The training input samples.

The target values (class labels in classification, real numbers in regression). If the selector is unsupervised then y can be set to None.

Returns the instance itself.

Fit to data, then transform it.

Fits transformer to X and y with optional parameters fit_params and returns a transformed version of X.

Target values (None for unsupervised transformations).

Additional fit parameters. Pass only if the estimator accepts additional params in its fit method.

Mask feature names according to selected features.

If input_features is None, then feature_names_in_ is used as feature names in. If feature_names_in_ is not defined, then the following input feature names are generated: ["x0", "x1", ..., "x(n_features_in_ - 1)"].

If input_features is an array-like, then input_features must match feature_names_in_ if feature_names_in_ is defined.

Transformed feature names.

Get metadata routing of this object.

Please check User Guide on how the routing mechanism works.

A MetadataRequest encapsulating routing information.

Get parameters for this estimator.

If True, will return the parameters for this estimator and contained subobjects that are estimators.

Parameter names mapped to their values.

Get a mask, or integer index, of the features selected.

If True, the return value will be an array of integers, rather than a boolean mask.

An index that selects the retained features from a feature vector. If indices is False, this is a boolean array of shape [# input features], in which an element is True iff its corresponding feature is selected for retention. If indices is True, this is an integer array of shape [# output features] whose values are indices into the input feature vector.

Reverse the transformation operation.

X with columns of zeros inserted where features would have been removed by transform.

Set output container.

See Introducing the set_output API for an example on how to use the API.

Configure output of transform and fit_transform.

"default": Default output format of a transformer

"pandas": DataFrame output

"polars": Polars output

None: Transform configuration is unchanged

Added in version 1.4: "polars" option was added.

Set the parameters of this estimator.

The method works on simple estimators as well as on nested objects (such as Pipeline). The latter have parameters of the form <component>__<parameter> so that it’s possible to update each component of a nested object.

Estimator parameters.

Reduce X to the selected features.

The input samples with only the selected features.

Feature agglomeration vs. univariate selection

Column Transformer with Mixed Types

Introducing the set_output API

SVM-Anova: SVM with univariate feature selection

**Examples:**

Example 1 (sql):
```sql
>>> from sklearn.datasets import load_digits
>>> from sklearn.feature_selection import SelectPercentile, chi2
>>> X, y = load_digits(return_X_y=True)
>>> X.shape
(1797, 64)
>>> X_new = SelectPercentile(chi2, percentile=10).fit_transform(X, y)
>>> X_new.shape
(1797, 7)
```

---

## OneClassSVM#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.svm.OneClassSVM.html

**Contents:**
- OneClassSVM#
- Gallery examples#

Unsupervised Outlier Detection.

Estimate the support of a high-dimensional distribution.

The implementation is based on libsvm.

Read more in the User Guide.

Specifies the kernel type to be used in the algorithm. If none is given, ‘rbf’ will be used. If a callable is given it is used to precompute the kernel matrix.

Degree of the polynomial kernel function (‘poly’). Must be non-negative. Ignored by all other kernels.

Kernel coefficient for ‘rbf’, ‘poly’ and ‘sigmoid’.

if gamma='scale' (default) is passed then it uses 1 / (n_features * X.var()) as value of gamma,

if ‘auto’, uses 1 / n_features

if float, must be non-negative.

Changed in version 0.22: The default value of gamma changed from ‘auto’ to ‘scale’.

Independent term in kernel function. It is only significant in ‘poly’ and ‘sigmoid’.

Tolerance for stopping criterion.

An upper bound on the fraction of training errors and a lower bound of the fraction of support vectors. Should be in the interval (0, 1]. By default 0.5 will be taken.

Whether to use the shrinking heuristic. See the User Guide.

Specify the size of the kernel cache (in MB).

Enable verbose output. Note that this setting takes advantage of a per-process runtime setting in libsvm that, if enabled, may not work properly in a multithreaded context.

Hard limit on iterations within solver, or -1 for no limit.

Weights assigned to the features when kernel="linear".

Coefficients of the support vectors in the decision function.

0 if correctly fitted, 1 otherwise (will raise warning)

Constant in the decision function.

Number of features seen during fit.

Added in version 0.24.

Names of features seen during fit. Defined only when X has feature names that are all strings.

Added in version 1.0.

Number of iterations run by the optimization routine to fit the model.

Added in version 1.1.

Number of support vectors for each class.

Offset used to define the decision function from the raw scores. We have the relation: decision_function = score_samples - offset_. The offset is the opposite of intercept_ and is provided for consistency with other outlier detection algorithms.

Added in version 0.20.

Array dimensions of training vector X.

Indices of support vectors.

Solves linear One-Class SVM using Stochastic Gradient Descent.

Unsupervised Outlier Detection using Local Outlier Factor (LOF).

Isolation Forest Algorithm.

For a more extended example, see Species distribution modeling

Signed distance to the separating hyperplane.

Signed distance is positive for an inlier and negative for an outlier.

Returns the decision function of the samples.

Detect the soft boundary of the set of samples X.

Set of samples, where n_samples is the number of samples and n_features is the number of features.

Not used, present for API consistency by convention.

Per-sample weights. Rescale C per sample. Higher weights force the classifier to put more emphasis on these points.

If X is not a C-ordered contiguous array it is copied.

Perform fit on X and returns labels for X.

Returns -1 for outliers and 1 for inliers.

Not used, present for API consistency by convention.

Arguments to be passed to fit.

Added in version 1.4.

1 for inliers, -1 for outliers.

Get metadata routing of this object.

Please check User Guide on how the routing mechanism works.

A MetadataRequest encapsulating routing information.

Get parameters for this estimator.

If True, will return the parameters for this estimator and contained subobjects that are estimators.

Parameter names mapped to their values.

Perform classification on samples in X.

For a one-class model, +1 or -1 is returned.

For kernel=”precomputed”, the expected shape of X is (n_samples_test, n_samples_train).

Class labels for samples in X.

Raw scoring function of the samples.

Returns the (unshifted) scoring function of the samples.

Configure whether metadata should be requested to be passed to the fit method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to fit if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to fit.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Added in version 1.3.

Metadata routing for sample_weight parameter in fit.

Set the parameters of this estimator.

The method works on simple estimators as well as on nested objects (such as Pipeline). The latter have parameters of the form <component>__<parameter> so that it’s possible to update each component of a nested object.

Estimator parameters.

Outlier detection on a real data set

Species distribution modeling

One-Class SVM versus One-Class SVM using Stochastic Gradient Descent

Comparing anomaly detection algorithms for outlier detection on toy datasets

One-class SVM with non-linear kernel (RBF)

**Examples:**

Example 1 (sql):
```sql
>>> from sklearn.svm import OneClassSVM
>>> X = [[0], [0.44], [0.45], [0.46], [1]]
>>> clf = OneClassSVM(gamma='auto').fit(X)
>>> clf.predict(X)
array([-1,  1,  1,  1, -1])
>>> clf.score_samples(X)
array([1.7798, 2.0547, 2.0556, 2.0561, 1.7332])
```

---

## CCA#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.cross_decomposition.CCA.html

**Contents:**
- CCA#
- Gallery examples#

Canonical Correlation Analysis, also known as “Mode B” PLS.

For a comparison between other cross decomposition algorithms, see Compare cross decomposition methods.

Read more in the User Guide.

Number of components to keep. Should be in [1, min(n_samples, n_features, n_targets)].

Whether to scale X and y.

The maximum number of iterations of the power method.

The tolerance used as convergence criteria in the power method: the algorithm stops whenever the squared norm of u_i - u_{i-1} is less than tol, where u corresponds to the left singular vector.

Whether to copy X and y in fit before applying centering, and potentially scaling. If False, these operations will be done inplace, modifying both arrays.

The left singular vectors of the cross-covariance matrices of each iteration.

The right singular vectors of the cross-covariance matrices of each iteration.

The projection matrix used to transform X.

The projection matrix used to transform y.

The coefficients of the linear model such that y is approximated as y = X @ coef_.T + intercept_.

The intercepts of the linear model such that y is approximated as y = X @ coef_.T + intercept_.

Added in version 1.1.

Number of iterations of the power method, for each component.

Number of features seen during fit.

Names of features seen during fit. Defined only when X has feature names that are all strings.

Added in version 1.0.

Partial Least Squares transformer and regressor.

Partial Least Square SVD.

Training vectors, where n_samples is the number of samples and n_features is the number of predictors.

Target vectors, where n_samples is the number of samples and n_targets is the number of response variables.

Learn and apply the dimension reduction on the train data.

Training vectors, where n_samples is the number of samples and n_features is the number of predictors.

Target vectors, where n_samples is the number of samples and n_targets is the number of response variables.

Return x_scores if y is not given, (x_scores, y_scores) otherwise.

Get output feature names for transformation.

The feature names out will prefixed by the lowercased class name. For example, if the transformer outputs 3 features, then the feature names out are: ["class_name0", "class_name1", "class_name2"].

Only used to validate feature names with the names seen in fit.

Transformed feature names.

Get metadata routing of this object.

Please check User Guide on how the routing mechanism works.

A MetadataRequest encapsulating routing information.

Get parameters for this estimator.

If True, will return the parameters for this estimator and contained subobjects that are estimators.

Parameter names mapped to their values.

Transform data back to its original space.

New data, where n_samples is the number of samples and n_components is the number of pls components.

New target, where n_samples is the number of samples and n_components is the number of pls components.

Return the reconstructed X data.

Return the reconstructed X target. Only returned when y is given.

This transformation will only be exact if n_components=n_features.

Predict targets of given samples.

Whether to copy X or perform in-place normalization.

Returns predicted values.

This call requires the estimation of a matrix of shape (n_features, n_targets), which may be an issue in high dimensional space.

Return coefficient of determination on test data.

The coefficient of determination, \(R^2\), is defined as \((1 - \frac{u}{v})\), where \(u\) is the residual sum of squares ((y_true - y_pred)** 2).sum() and \(v\) is the total sum of squares ((y_true - y_true.mean()) ** 2).sum(). The best possible score is 1.0 and it can be negative (because the model can be arbitrarily worse). A constant model that always predicts the expected value of y, disregarding the input features, would get a \(R^2\) score of 0.0.

Test samples. For some estimators this may be a precomputed kernel matrix or a list of generic objects instead with shape (n_samples, n_samples_fitted), where n_samples_fitted is the number of samples used in the fitting for the estimator.

\(R^2\) of self.predict(X) w.r.t. y.

The \(R^2\) score used when calling score on a regressor uses multioutput='uniform_average' from version 0.23 to keep consistent with default value of r2_score. This influences the score method of all the multioutput regressors (except for MultiOutputRegressor).

Set output container.

See Introducing the set_output API for an example on how to use the API.

Configure output of transform and fit_transform.

"default": Default output format of a transformer

"pandas": DataFrame output

"polars": Polars output

None: Transform configuration is unchanged

Added in version 1.4: "polars" option was added.

Set the parameters of this estimator.

The method works on simple estimators as well as on nested objects (such as Pipeline). The latter have parameters of the form <component>__<parameter> so that it’s possible to update each component of a nested object.

Estimator parameters.

Configure whether metadata should be requested to be passed to the predict method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to predict if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to predict.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Added in version 1.3.

Metadata routing for copy parameter in predict.

Configure whether metadata should be requested to be passed to the score method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to score if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to score.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Added in version 1.3.

Metadata routing for sample_weight parameter in score.

Configure whether metadata should be requested to be passed to the transform method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to transform if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to transform.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Added in version 1.3.

Metadata routing for copy parameter in transform.

Apply the dimension reduction.

Samples to transform.

Whether to copy X and y, or perform in-place normalization.

Return x_scores if y is not given, (x_scores, y_scores) otherwise.

Compare cross decomposition methods

Multilabel classification

**Examples:**

Example 1 (csharp):
```csharp
>>> from sklearn.cross_decomposition import CCA
>>> X = [[0., 0., 1.], [1.,0.,0.], [2.,2.,2.], [3.,5.,4.]]
>>> y = [[0.1, -0.2], [0.9, 1.1], [6.2, 5.9], [11.9, 12.3]]
>>> cca = CCA(n_components=1)
>>> cca.fit(X, y)
CCA(n_components=1)
>>> X_c, y_c = cca.transform(X, y)
```

---

## ClassifierChain#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.multioutput.ClassifierChain.html

**Contents:**
- ClassifierChain#
- Gallery examples#

A multi-label model that arranges binary classifiers into a chain.

Each model makes a prediction in the order specified by the chain using all of the available features provided to the model plus the predictions of models that are earlier in the chain.

For an example of how to use ClassifierChain and benefit from its ensemble, see ClassifierChain on a yeast dataset example.

Read more in the User Guide.

Added in version 0.19.

The base estimator from which the classifier chain is built.

If None, the order will be determined by the order of columns in the label matrix Y.:

The order of the chain can be explicitly set by providing a list of integers. For example, for a chain of length 5.:

means that the first model in the chain will make predictions for column 1 in the Y matrix, the second model will make predictions for column 3, etc.

If order is random a random ordering will be used.

Determines whether to use cross validated predictions or true labels for the results of previous estimators in the chain. Possible inputs for cv are:

None, to use true labels when fitting,

integer, to specify the number of folds in a (Stratified)KFold,

An iterable yielding (train, test) splits as arrays of indices.

Prediction method to be used by estimators in the chain for the ‘prediction’ features of previous estimators in the chain.

if str, name of the method;

if a list of str, provides the method names in order of preference. The method used corresponds to the first method in the list that is implemented by base_estimator.

Added in version 1.5.

If order='random', determines random number generation for the chain order. In addition, it controls the random seed given at each base_estimator at each chaining iteration. Thus, it is only used when base_estimator exposes a random_state. Pass an int for reproducible output across multiple function calls. See Glossary.

If True, chain progress is output as each model is completed.

Added in version 1.2.

Use estimator instead.

Deprecated since version 1.7: base_estimator is deprecated and will be removed in 1.9. Use estimator instead.

A list of arrays of length len(estimators_) containing the class labels for each estimator in the chain.

A list of clones of base_estimator.

The order of labels in the classifier chain.

Prediction method used by estimators in the chain for the prediction features.

Number of features seen during fit. Only defined if the underlying base_estimator exposes such an attribute when fit.

Added in version 0.24.

Names of features seen during fit. Defined only when X has feature names that are all strings.

Added in version 1.0.

Equivalent for regression.

Classifies each output independently rather than chaining.

Jesse Read, Bernhard Pfahringer, Geoff Holmes, Eibe Frank, “Classifier Chains for Multi-label Classification”, 2009.

Evaluate the decision_function of the models in the chain.

Returns the decision function of the sample for each model in the chain.

Fit the model to data matrix X and targets Y.

Parameters passed to the fit method of each step.

Only available if enable_metadata_routing=True. See the User Guide.

Added in version 1.3.

Get metadata routing of this object.

Please check User Guide on how the routing mechanism works.

Added in version 1.3.

A MetadataRouter encapsulating routing information.

Get parameters for this estimator.

If True, will return the parameters for this estimator and contained subobjects that are estimators.

Parameter names mapped to their values.

Predict on the data matrix X using the ClassifierChain model.

The predicted values.

Predict logarithm of probability estimates.

The predicted logarithm of the probabilities.

Predict probability estimates.

The predicted probabilities.

Return accuracy on provided data and labels.

In multi-label classification, this is the subset accuracy which is a harsh metric since you require for each sample that each label set be correctly predicted.

Mean accuracy of self.predict(X) w.r.t. y.

Set the parameters of this estimator.

The method works on simple estimators as well as on nested objects (such as Pipeline). The latter have parameters of the form <component>__<parameter> so that it’s possible to update each component of a nested object.

Estimator parameters.

Configure whether metadata should be requested to be passed to the score method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to score if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to score.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Added in version 1.3.

Metadata routing for sample_weight parameter in score.

Multilabel classification using a classifier chain

**Examples:**

Example 1 (unknown):
```unknown
order = [0, 1, 2, ..., Y.shape[1] - 1]
```

Example 2 (unknown):
```unknown
order = [1, 3, 2, 4, 0]
```

Example 3 (sql):
```sql
>>> from sklearn.datasets import make_multilabel_classification
>>> from sklearn.linear_model import LogisticRegression
>>> from sklearn.model_selection import train_test_split
>>> from sklearn.multioutput import ClassifierChain
>>> X, Y = make_multilabel_classification(
...    n_samples=12, n_classes=3, random_state=0
... )
>>> X_train, X_test, Y_train, Y_test = train_test_split(
...    X, Y, random_state=0
... )
>>> base_lr = LogisticRegression(solver='lbfgs', random_state=0)
>>> chain = ClassifierChain(base_lr, order='random', random_state=0)
>>> chain.fit(X_train, Y_train).predict(X_test)
array([[1., 1., 0.],
       [1., 0., 0.],
       [0., 1., 0.]])
>>> chain.predict_proba(X_test)
array([[0.8387, 0.9431, 0.4576],
       [0.8878, 0.3684, 0.2640],
       [0.0321, 0.9935, 0.0626]])
```

---

## 3.2. Tuning the hyper-parameters of an estimator#

**URL:** https://scikit-learn.org/stable/modules/grid_search.html

**Contents:**
- 3.2. Tuning the hyper-parameters of an estimator#
- 3.2.1. Exhaustive Grid Search#
- 3.2.2. Randomized Parameter Optimization#
- 3.2.3. Searching for optimal parameters with successive halving#
  - 3.2.3.1. Aggressive elimination of candidates#
  - 3.2.3.2. Analyzing results with the cv_results_ attribute#
- 3.2.4. Tips for parameter search#
  - 3.2.4.1. Specifying an objective metric#
  - 3.2.4.2. Specifying multiple metrics for evaluation#
  - 3.2.4.3. Composite estimators and parameter spaces#

Hyper-parameters are parameters that are not directly learnt within estimators. In scikit-learn they are passed as arguments to the constructor of the estimator classes. Typical examples include C, kernel and gamma for Support Vector Classifier, alpha for Lasso, etc.

It is possible and recommended to search the hyper-parameter space for the best cross validation score.

Any parameter provided when constructing an estimator may be optimized in this manner. Specifically, to find the names and current values for all parameters for a given estimator, use:

A search consists of:

an estimator (regressor or classifier such as sklearn.svm.SVC());

a method for searching or sampling candidates;

a cross-validation scheme; and

Two generic approaches to parameter search are provided in scikit-learn: for given values, GridSearchCV exhaustively considers all parameter combinations, while RandomizedSearchCV can sample a given number of candidates from a parameter space with a specified distribution. Both these tools have successive halving counterparts HalvingGridSearchCV and HalvingRandomSearchCV, which can be much faster at finding a good parameter combination.

After describing these tools we detail best practices applicable to these approaches. Some models allow for specialized, efficient parameter search strategies, outlined in Alternatives to brute force parameter search.

Note that it is common that a small subset of those parameters can have a large impact on the predictive or computation performance of the model while others can be left to their default values. It is recommended to read the docstring of the estimator class to get a finer understanding of their expected behavior, possibly by reading the enclosed reference to the literature.

The grid search provided by GridSearchCV exhaustively generates candidates from a grid of parameter values specified with the param_grid parameter. For instance, the following param_grid:

specifies that two grids should be explored: one with a linear kernel and C values in [1, 10, 100, 1000], and the second one with an RBF kernel, and the cross-product of C values ranging in [1, 10, 100, 1000] and gamma values in [0.001, 0.0001].

The GridSearchCV instance implements the usual estimator API: when “fitting” it on a dataset all the possible combinations of parameter values are evaluated and the best combination is retained.

See Nested versus non-nested cross-validation for an example of Grid Search within a cross validation loop on the iris dataset. This is the best practice for evaluating the performance of a model with grid search.

See Sample pipeline for text feature extraction and evaluation for an example of Grid Search coupling parameters from a text documents feature extractor (n-gram count vectorizer and TF-IDF transformer) with a classifier (here a linear SVM trained with SGD with either elastic net or L2 penalty) using a Pipeline instance.

See Nested versus non-nested cross-validation for an example of Grid Search within a cross validation loop on the iris dataset. This is the best practice for evaluating the performance of a model with grid search.

See Demonstration of multi-metric evaluation on cross_val_score and GridSearchCV for an example of GridSearchCV being used to evaluate multiple metrics simultaneously.

See Balance model complexity and cross-validated score for an example of using refit=callable interface in GridSearchCV. The example shows how this interface adds a certain amount of flexibility in identifying the “best” estimator. This interface can also be used in multiple metrics evaluation.

See Statistical comparison of models using grid search for an example of how to do a statistical comparison on the outputs of GridSearchCV.

While using a grid of parameter settings is currently the most widely used method for parameter optimization, other search methods have more favorable properties. RandomizedSearchCV implements a randomized search over parameters, where each setting is sampled from a distribution over possible parameter values. This has two main benefits over an exhaustive search:

A budget can be chosen independent of the number of parameters and possible values.

Adding parameters that do not influence the performance does not decrease efficiency.

Specifying how parameters should be sampled is done using a dictionary, very similar to specifying parameters for GridSearchCV. Additionally, a computation budget, being the number of sampled candidates or sampling iterations, is specified using the n_iter parameter. For each parameter, either a distribution over possible values or a list of discrete choices (which will be sampled uniformly) can be specified:

This example uses the scipy.stats module, which contains many useful distributions for sampling parameters, such as expon, gamma, uniform, loguniform or randint.

In principle, any function can be passed that provides a rvs (random variate sample) method to sample a value. A call to the rvs function should provide independent random samples from possible parameter values on consecutive calls.

The distributions in scipy.stats prior to version scipy 0.16 do not allow specifying a random state. Instead, they use the global numpy random state, that can be seeded via np.random.seed or set using np.random.set_state. However, beginning scikit-learn 0.18, the sklearn.model_selection module sets the random state provided by the user if scipy >= 0.16 is also available.

For continuous parameters, such as C above, it is important to specify a continuous distribution to take full advantage of the randomization. This way, increasing n_iter will always lead to a finer search.

A continuous log-uniform random variable is the continuous version of a log-spaced parameter. For example to specify the equivalent of C from above, loguniform(1, 100) can be used instead of [1, 10, 100].

Mirroring the example above in grid search, we can specify a continuous random variable that is log-uniformly distributed between 1e0 and 1e3:

Comparing randomized search and grid search for hyperparameter estimation compares the usage and efficiency of randomized search and grid search.

Bergstra, J. and Bengio, Y., Random search for hyper-parameter optimization, The Journal of Machine Learning Research (2012)

Scikit-learn also provides the HalvingGridSearchCV and HalvingRandomSearchCV estimators that can be used to search a parameter space using successive halving [1] [2]. Successive halving (SH) is like a tournament among candidate parameter combinations. SH is an iterative selection process where all candidates (the parameter combinations) are evaluated with a small amount of resources at the first iteration. Only some of these candidates are selected for the next iteration, which will be allocated more resources. For parameter tuning, the resource is typically the number of training samples, but it can also be an arbitrary numeric parameter such as n_estimators in a random forest.

The resource increase chosen should be large enough so that a large improvement in scores is obtained when taking into account statistical significance.

As illustrated in the figure below, only a subset of candidates ‘survive’ until the last iteration. These are the candidates that have consistently ranked among the top-scoring candidates across all iterations. Each iteration is allocated an increasing amount of resources per candidate, here the number of samples.

We here briefly describe the main parameters, but each parameter and their interactions are described more in detail in the dropdown section below. The factor (> 1) parameter controls the rate at which the resources grow, and the rate at which the number of candidates decreases. In each iteration, the number of resources per candidate is multiplied by factor and the number of candidates is divided by the same factor. Along with resource and min_resources, factor is the most important parameter to control the search in our implementation, though a value of 3 usually works well. factor effectively controls the number of iterations in HalvingGridSearchCV and the number of candidates (by default) and iterations in HalvingRandomSearchCV. aggressive_elimination=True can also be used if the number of available resources is small. More control is available through tuning the min_resources parameter.

These estimators are still experimental: their predictions and their API might change without any deprecation cycle. To use them, you need to explicitly import enable_halving_search_cv:

Comparison between grid search and successive halving

Successive Halving Iterations

The sections below dive into technical aspects of successive halving.

Beside factor, the two main parameters that influence the behaviour of a successive halving search are the min_resources parameter, and the number of candidates (or parameter combinations) that are evaluated. min_resources is the amount of resources allocated at the first iteration for each candidate. The number of candidates is specified directly in HalvingRandomSearchCV, and is determined from the param_grid parameter of HalvingGridSearchCV.

Consider a case where the resource is the number of samples, and where we have 1000 samples. In theory, with min_resources=10 and factor=2, we are able to run at most 7 iterations with the following number of samples: [10, 20, 40, 80, 160, 320, 640].

But depending on the number of candidates, we might run less than 7 iterations: if we start with a small number of candidates, the last iteration might use less than 640 samples, which means not using all the available resources (samples). For example if we start with 5 candidates, we only need 2 iterations: 5 candidates for the first iteration, then 5 // 2 = 2 candidates at the second iteration, after which we know which candidate performs the best (so we don’t need a third one). We would only be using at most 20 samples which is a waste since we have 1000 samples at our disposal. On the other hand, if we start with a high number of candidates, we might end up with a lot of candidates at the last iteration, which may not always be ideal: it means that many candidates will run with the full resources, basically reducing the procedure to standard search.

In the case of HalvingRandomSearchCV, the number of candidates is set by default such that the last iteration uses as much of the available resources as possible. For HalvingGridSearchCV, the number of candidates is determined by the param_grid parameter. Changing the value of min_resources will impact the number of possible iterations, and as a result will also have an effect on the ideal number of candidates.

Another consideration when choosing min_resources is whether or not it is easy to discriminate between good and bad candidates with a small amount of resources. For example, if you need a lot of samples to distinguish between good and bad parameters, a high min_resources is recommended. On the other hand if the distinction is clear even with a small amount of samples, then a small min_resources may be preferable since it would speed up the computation.

Notice in the example above that the last iteration does not use the maximum amount of resources available: 1000 samples are available, yet only 640 are used, at most. By default, both HalvingRandomSearchCV and HalvingGridSearchCV try to use as many resources as possible in the last iteration, with the constraint that this amount of resources must be a multiple of both min_resources and factor (this constraint will be clear in the next section). HalvingRandomSearchCV achieves this by sampling the right amount of candidates, while HalvingGridSearchCV achieves this by properly setting min_resources.

At any iteration i, each candidate is allocated a given amount of resources which we denote n_resources_i. This quantity is controlled by the parameters factor and min_resources as follows (factor is strictly greater than 1):

where min_resources == n_resources_0 is the amount of resources used at the first iteration. factor also defines the proportions of candidates that will be selected for the next iteration:

So in the first iteration, we use min_resources resources n_candidates times. In the second iteration, we use min_resources * factor resources n_candidates // factor times. The third again multiplies the resources per candidate and divides the number of candidates. This process stops when the maximum amount of resource per candidate is reached, or when we have identified the best candidate. The best candidate is identified at the iteration that is evaluating factor or less candidates (see just below for an explanation).

Here is an example with min_resources=3 and factor=2, starting with 70 candidates:

the process stops at the first iteration which evaluates factor=2 candidates: the best candidate is the best out of these 2 candidates. It is not necessary to run an additional iteration, since it would only evaluate one candidate (namely the best one, which we have already identified). For this reason, in general, we want the last iteration to run at most factor candidates. If the last iteration evaluates more than factor candidates, then this last iteration reduces to a regular search (as in RandomizedSearchCV or GridSearchCV).

each n_resources_i is a multiple of both factor and min_resources (which is confirmed by its definition above).

The amount of resources that is used at each iteration can be found in the n_resources_ attribute.

By default, the resource is defined in terms of number of samples. That is, each iteration will use an increasing amount of samples to train on. You can however manually specify a parameter to use as the resource with the resource parameter. Here is an example where the resource is defined in terms of the number of estimators of a random forest:

Note that it is not possible to budget on a parameter that is part of the parameter grid.

As mentioned above, the number of resources that is used at each iteration depends on the min_resources parameter. If you have a lot of resources available but start with a low number of resources, some of them might be wasted (i.e. not used):

The search process will only use 80 resources at most, while our maximum amount of available resources is n_samples=1000. Here, we have min_resources = r_0 = 20.

For HalvingGridSearchCV, by default, the min_resources parameter is set to ‘exhaust’. This means that min_resources is automatically set such that the last iteration can use as many resources as possible, within the max_resources limit:

min_resources was here automatically set to 250, which results in the last iteration using all the resources. The exact value that is used depends on the number of candidate parameters, on max_resources and on factor.

For HalvingRandomSearchCV, exhausting the resources can be done in 2 ways:

by setting min_resources='exhaust', just like for HalvingGridSearchCV;

by setting n_candidates='exhaust'.

Both options are mutually exclusive: using min_resources='exhaust' requires knowing the number of candidates, and symmetrically n_candidates='exhaust' requires knowing min_resources.

In general, exhausting the total number of resources leads to a better final candidate parameter, and is slightly more time-intensive.

Using the aggressive_elimination parameter, you can force the search process to end up with less than factor candidates at the last iteration.

Ideally, we want the last iteration to evaluate factor candidates. We then just have to pick the best one. When the number of available resources is small with respect to the number of candidates, the last iteration may have to evaluate more than factor candidates:

Since we cannot use more than max_resources=40 resources, the process has to stop at the second iteration which evaluates more than factor=2 candidates.

When using aggressive_elimination, the process will eliminate as many candidates as necessary using min_resources resources:

Notice that we end with 2 candidates at the last iteration since we have eliminated enough candidates during the first iterations, using n_resources = min_resources = 20.

The cv_results_ attribute contains useful information for analyzing the results of a search. It can be converted to a pandas dataframe with df = pd.DataFrame(est.cv_results_). The cv_results_ attribute of HalvingGridSearchCV and HalvingRandomSearchCV is similar to that of GridSearchCV and RandomizedSearchCV, with additional information related to the successive halving process.

{‘criterion’: ‘log_loss’, ‘max_depth’: None, ‘max_features’: 9, ‘min_samples_split’: 5}

{‘criterion’: ‘gini’, ‘max_depth’: None, ‘max_features’: 8, ‘min_samples_split’: 7}

{‘criterion’: ‘gini’, ‘max_depth’: None, ‘max_features’: 10, ‘min_samples_split’: 10}

{‘criterion’: ‘log_loss’, ‘max_depth’: None, ‘max_features’: 6, ‘min_samples_split’: 6}

{‘criterion’: ‘log_loss’, ‘max_depth’: None, ‘max_features’: 9, ‘min_samples_split’: 10}

{‘criterion’: ‘gini’, ‘max_depth’: None, ‘max_features’: 10, ‘min_samples_split’: 10}

{‘criterion’: ‘gini’, ‘max_depth’: None, ‘max_features’: 10, ‘min_samples_split’: 4}

{‘criterion’: ‘log_loss’, ‘max_depth’: None, ‘max_features’: 9, ‘min_samples_split’: 10}

{‘criterion’: ‘gini’, ‘max_depth’: None, ‘max_features’: 10, ‘min_samples_split’: 4}

Each row corresponds to a given parameter combination (a candidate) and a given iteration. The iteration is given by the iter column. The n_resources column tells you how many resources were used.

In the example above, the best parameter combination is {'criterion': 'log_loss', 'max_depth': None, 'max_features': 9, 'min_samples_split': 10} since it has reached the last iteration (3) with the highest score: 0.96.

K. Jamieson, A. Talwalkar, Non-stochastic Best Arm Identification and Hyperparameter Optimization, in proc. of Machine Learning Research, 2016.

L. Li, K. Jamieson, G. DeSalvo, A. Rostamizadeh, A. Talwalkar, Hyperband: A Novel Bandit-Based Approach to Hyperparameter Optimization, in Machine Learning Research 18, 2018.

By default, parameter search uses the score function of the estimator to evaluate a parameter setting. These are the sklearn.metrics.accuracy_score for classification and sklearn.metrics.r2_score for regression. For some applications, other scoring functions are better suited (for example in unbalanced classification, the accuracy score is often uninformative), see Which scoring function should I use? for some guidance. An alternative scoring function can be specified via the scoring parameter of most parameter search tools, see The scoring parameter: defining model evaluation rules for more details.

GridSearchCV and RandomizedSearchCV allow specifying multiple metrics for the scoring parameter.

Multimetric scoring can either be specified as a list of strings of predefined scores names or a dict mapping the scorer name to the scorer function and/or the predefined scorer name(s). See Using multiple metric evaluation for more details.

When specifying multiple metrics, the refit parameter must be set to the metric (string) for which the best_params_ will be found and used to build the best_estimator_ on the whole dataset. If the search should not be refit, set refit=False. Leaving refit to the default value None will result in an error when using multiple metrics.

See Demonstration of multi-metric evaluation on cross_val_score and GridSearchCV for an example usage.

HalvingRandomSearchCV and HalvingGridSearchCV do not support multimetric scoring.

GridSearchCV and RandomizedSearchCV allow searching over parameters of composite or nested estimators such as Pipeline, ColumnTransformer, VotingClassifier or CalibratedClassifierCV using a dedicated <estimator>__<parameter> syntax:

Here, <estimator> is the parameter name of the nested estimator, in this case estimator. If the meta-estimator is constructed as a collection of estimators as in pipeline.Pipeline, then <estimator> refers to the name of the estimator, see Access to nested parameters. In practice, there can be several levels of nesting:

Please refer to Pipeline: chaining estimators for performing parameter searches over pipelines.

Model selection by evaluating various parameter settings can be seen as a way to use the labeled data to “train” the parameters of the grid.

When evaluating the resulting model it is important to do it on held-out samples that were not seen during the grid search process: it is recommended to split the data into a development set (to be fed to the GridSearchCV instance) and an evaluation set to compute performance metrics.

This can be done by using the train_test_split utility function.

The parameter search tools evaluate each parameter combination on each data fold independently. Computations can be run in parallel by using the keyword n_jobs=-1. See function signature for more details, and also the Glossary entry for n_jobs.

Some parameter settings may result in a failure to fit one or more folds of the data. By default, the score for those settings will be np.nan. This can be controlled by setting error_score="raise" to raise an exception if one fit fails, or for example error_score=0 to set another value for the score of failing parameter combinations.

Some models can fit data for a range of values of some parameter almost as efficiently as fitting the estimator for a single value of the parameter. This feature can be leveraged to perform a more efficient cross-validation used for model selection of this parameter.

The most common parameter amenable to this strategy is the parameter encoding the strength of the regularizer. In this case we say that we compute the regularization path of the estimator.

Here is the list of such models:

linear_model.ElasticNetCV(*[, l1_ratio, ...])

Elastic Net model with iterative fitting along a regularization path.

linear_model.LarsCV(*[, fit_intercept, ...])

Cross-validated Least Angle Regression model.

linear_model.LassoCV(*[, eps, n_alphas, ...])

Lasso linear model with iterative fitting along a regularization path.

linear_model.LassoLarsCV(*[, fit_intercept, ...])

Cross-validated Lasso, using the LARS algorithm.

linear_model.LogisticRegressionCV(*[, Cs, ...])

Logistic Regression CV (aka logit, MaxEnt) classifier.

linear_model.MultiTaskElasticNetCV(*[, ...])

Multi-task L1/L2 ElasticNet with built-in cross-validation.

linear_model.MultiTaskLassoCV(*[, eps, ...])

Multi-task Lasso model trained with L1/L2 mixed-norm as regularizer.

linear_model.OrthogonalMatchingPursuitCV(*)

Cross-validated Orthogonal Matching Pursuit model (OMP).

linear_model.RidgeCV([alphas, ...])

Ridge regression with built-in cross-validation.

linear_model.RidgeClassifierCV([alphas, ...])

Ridge classifier with built-in cross-validation.

Some models can offer an information-theoretic closed-form formula of the optimal estimate of the regularization parameter by computing a single regularization path (instead of several when using cross-validation).

Here is the list of models benefiting from the Akaike Information Criterion (AIC) or the Bayesian Information Criterion (BIC) for automated model selection:

linear_model.LassoLarsIC([criterion, ...])

Lasso model fit with Lars using BIC or AIC for model selection.

When using ensemble methods based upon bagging, i.e. generating new training sets using sampling with replacement, part of the training set remains unused. For each classifier in the ensemble, a different part of the training set is left out.

This left out portion can be used to estimate the generalization error without having to rely on a separate validation set. This estimate comes “for free” as no additional data is needed and can be used for model selection.

This is currently implemented in the following classes:

ensemble.RandomForestClassifier([...])

A random forest classifier.

ensemble.RandomForestRegressor([...])

A random forest regressor.

ensemble.ExtraTreesClassifier([...])

An extra-trees classifier.

ensemble.ExtraTreesRegressor([n_estimators, ...])

An extra-trees regressor.

ensemble.GradientBoostingClassifier(*[, ...])

Gradient Boosting for classification.

ensemble.GradientBoostingRegressor(*[, ...])

Gradient Boosting for regression.

**Examples:**

Example 1 (unknown):
```unknown
estimator.get_params()
```

Example 2 (json):
```json
param_grid = [
  {'C': [1, 10, 100, 1000], 'kernel': ['linear']},
  {'C': [1, 10, 100, 1000], 'gamma': [0.001, 0.0001], 'kernel': ['rbf']},
 ]
```

Example 3 (json):
```json
{'C': scipy.stats.expon(scale=100), 'gamma': scipy.stats.expon(scale=.1),
  'kernel': ['rbf'], 'class_weight':['balanced', None]}
```

Example 4 (json):
```json
from sklearn.utils.fixes import loguniform
{'C': loguniform(1e0, 1e3),
 'gamma': loguniform(1e-4, 1e-3),
 'kernel': ['rbf'],
 'class_weight':['balanced', None]}
```

---

## RandomTreesEmbedding#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomTreesEmbedding.html

**Contents:**
- RandomTreesEmbedding#
- Gallery examples#

An ensemble of totally random trees.

An unsupervised transformation of a dataset to a high-dimensional sparse representation. A datapoint is coded according to which leaf of each tree it is sorted into. Using a one-hot encoding of the leaves, this leads to a binary coding with as many ones as there are trees in the forest.

The dimensionality of the resulting representation is n_out <= n_estimators * max_leaf_nodes. If max_leaf_nodes == None, the number of leaf nodes is at most n_estimators * 2 ** max_depth.

For an example of applying Random Trees Embedding to non-linear classification, see Hashing feature transformation using Totally Random Trees.

Read more in the User Guide.

Number of trees in the forest.

Changed in version 0.22: The default value of n_estimators changed from 10 to 100 in 0.22.

The maximum depth of each tree. If None, then nodes are expanded until all leaves are pure or until all leaves contain less than min_samples_split samples.

The minimum number of samples required to split an internal node:

If int, then consider min_samples_split as the minimum number.

If float, then min_samples_split is a fraction and ceil(min_samples_split * n_samples) is the minimum number of samples for each split.

Changed in version 0.18: Added float values for fractions.

The minimum number of samples required to be at a leaf node. A split point at any depth will only be considered if it leaves at least min_samples_leaf training samples in each of the left and right branches. This may have the effect of smoothing the model, especially in regression.

If int, then consider min_samples_leaf as the minimum number.

If float, then min_samples_leaf is a fraction and ceil(min_samples_leaf * n_samples) is the minimum number of samples for each node.

Changed in version 0.18: Added float values for fractions.

The minimum weighted fraction of the sum total of weights (of all the input samples) required to be at a leaf node. Samples have equal weight when sample_weight is not provided.

Grow trees with max_leaf_nodes in best-first fashion. Best nodes are defined as relative reduction in impurity. If None then unlimited number of leaf nodes.

A node will be split if this split induces a decrease of the impurity greater than or equal to this value.

The weighted impurity decrease equation is the following:

where N is the total number of samples, N_t is the number of samples at the current node, N_t_L is the number of samples in the left child, and N_t_R is the number of samples in the right child.

N, N_t, N_t_R and N_t_L all refer to the weighted sum, if sample_weight is passed.

Added in version 0.19.

Whether or not to return a sparse CSR matrix, as default behavior, or to return a dense array compatible with dense pipeline operators.

The number of jobs to run in parallel. fit, transform, decision_path and apply are all parallelized over the trees. None means 1 unless in a joblib.parallel_backend context. -1 means using all processors. See Glossary for more details.

Controls the generation of the random y used to fit the trees and the draw of the splits for each feature at the trees’ nodes. See Glossary for details.

Controls the verbosity when fitting and predicting.

When set to True, reuse the solution of the previous call to fit and add more estimators to the ensemble, otherwise, just fit a whole new forest. See Glossary and Fitting additional trees for details.

The child estimator template used to create the collection of fitted sub-estimators.

Added in version 1.2: base_estimator_ was renamed to estimator_.

The collection of fitted sub-estimators.

The impurity-based feature importances.

Number of features seen during fit.

Added in version 0.24.

Names of features seen during fit. Defined only when X has feature names that are all strings.

Added in version 1.0.

The number of outputs when fit is performed.

One-hot encoder used to create the sparse embedding.

The subset of drawn samples for each base estimator.

An extra-trees classifier.

An extra-trees regressor.

A random forest classifier.

A random forest regressor.

An extremely randomized tree classifier.

An extremely randomized tree regressor.

P. Geurts, D. Ernst., and L. Wehenkel, “Extremely randomized trees”, Machine Learning, 63(1), 3-42, 2006.

Moosmann, F. and Triggs, B. and Jurie, F. “Fast discriminative visual codebooks using randomized clustering forests” NIPS 2007.

Apply trees in the forest to X, return leaf indices.

The input samples. Internally, its dtype will be converted to dtype=np.float32. If a sparse matrix is provided, it will be converted into a sparse csr_matrix.

For each datapoint x in X and for each tree in the forest, return the index of the leaf x ends up in.

Return the decision path in the forest.

Added in version 0.18.

The input samples. Internally, its dtype will be converted to dtype=np.float32. If a sparse matrix is provided, it will be converted into a sparse csr_matrix.

Return a node indicator matrix where non zero elements indicates that the samples goes through the nodes. The matrix is of CSR format.

The columns from indicator[n_nodes_ptr[i]:n_nodes_ptr[i+1]] gives the indicator value for the i-th estimator.

The input samples. Use dtype=np.float32 for maximum efficiency. Sparse matrices are also supported, use sparse csc_matrix for maximum efficiency.

Not used, present for API consistency by convention.

Sample weights. If None, then samples are equally weighted. Splits that would create child nodes with net zero or negative weight are ignored while searching for a split in each node. In the case of classification, splits are also ignored if they would result in any single class carrying a negative weight in either child node.

Returns the instance itself.

Fit estimator and transform dataset.

Input data used to build forests. Use dtype=np.float32 for maximum efficiency.

Not used, present for API consistency by convention.

Sample weights. If None, then samples are equally weighted. Splits that would create child nodes with net zero or negative weight are ignored while searching for a split in each node. In the case of classification, splits are also ignored if they would result in any single class carrying a negative weight in either child node.

Get output feature names for transformation.

Only used to validate feature names with the names seen in fit.

Transformed feature names, in the format of randomtreesembedding_{tree}_{leaf}, where tree is the tree used to generate the leaf and leaf is the index of a leaf node in that tree. Note that the node indexing scheme is used to index both nodes with children (split nodes) and leaf nodes. Only the latter can be present as output features. As a consequence, there are missing indices in the output feature names.

Get metadata routing of this object.

Please check User Guide on how the routing mechanism works.

A MetadataRequest encapsulating routing information.

Get parameters for this estimator.

If True, will return the parameters for this estimator and contained subobjects that are estimators.

Parameter names mapped to their values.

Configure whether metadata should be requested to be passed to the fit method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to fit if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to fit.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Added in version 1.3.

Metadata routing for sample_weight parameter in fit.

Set output container.

See Introducing the set_output API for an example on how to use the API.

Configure output of transform and fit_transform.

"default": Default output format of a transformer

"pandas": DataFrame output

"polars": Polars output

None: Transform configuration is unchanged

Added in version 1.4: "polars" option was added.

Set the parameters of this estimator.

The method works on simple estimators as well as on nested objects (such as Pipeline). The latter have parameters of the form <component>__<parameter> so that it’s possible to update each component of a nested object.

Estimator parameters.

Input data to be transformed. Use dtype=np.float32 for maximum efficiency. Sparse matrices are also supported, use sparse csr_matrix for maximum efficiency.

Feature transformations with ensembles of trees

Hashing feature transformation using Totally Random Trees

Manifold learning on handwritten digits: Locally Linear Embedding, Isomap…

**Examples:**

Example 1 (yaml):
```yaml
N_t / N * (impurity - N_t_R / N_t * right_impurity
                    - N_t_L / N_t * left_impurity)
```

Example 2 (csharp):
```csharp
>>> from sklearn.ensemble import RandomTreesEmbedding
>>> X = [[0,0], [1,0], [0,1], [-1,0], [0,-1]]
>>> random_trees = RandomTreesEmbedding(
...    n_estimators=5, random_state=0, max_depth=1).fit(X)
>>> X_sparse_embedding = random_trees.transform(X)
>>> X_sparse_embedding.toarray()
array([[0., 1., 1., 0., 1., 0., 0., 1., 1., 0.],
       [0., 1., 1., 0., 1., 0., 0., 1., 1., 0.],
       [0., 1., 0., 1., 0., 1., 0., 1., 0., 1.],
       [1., 0., 1., 0., 1., 0., 1., 0., 1., 0.],
       [0., 1., 1., 0., 1., 0., 0., 1., 1., 0.]])
```

---

## 1.11. Ensembles: Gradient boosting, random forests, bagging, voting, stacking#

**URL:** https://scikit-learn.org/stable/modules/ensemble.html

**Contents:**
- 1.11. Ensembles: Gradient boosting, random forests, bagging, voting, stacking#
- 1.11.1. Gradient-boosted trees#
  - 1.11.1.1. Histogram-Based Gradient Boosting#
    - 1.11.1.1.1. Usage#
    - 1.11.1.1.2. Missing values support#
    - 1.11.1.1.3. Sample weight support#
    - 1.11.1.1.4. Categorical Features Support#
    - 1.11.1.1.5. Monotonic Constraints#
    - 1.11.1.1.6. Interaction constraints#
    - 1.11.1.1.7. Low-level parallelism#

Ensemble methods combine the predictions of several base estimators built with a given learning algorithm in order to improve generalizability / robustness over a single estimator.

Two very famous examples of ensemble methods are gradient-boosted trees and random forests.

More generally, ensemble models can be applied to any base learner beyond trees, in averaging methods such as Bagging methods, model stacking, or Voting, or in boosting, as AdaBoost.

Gradient Tree Boosting or Gradient Boosted Decision Trees (GBDT) is a generalization of boosting to arbitrary differentiable loss functions, see the seminal work of [Friedman2001]. GBDT is an excellent model for both regression and classification, in particular for tabular data.

GradientBoostingClassifier vs HistGradientBoostingClassifier

Scikit-learn provides two implementations of gradient-boosted trees: HistGradientBoostingClassifier vs GradientBoostingClassifier for classification, and the corresponding classes for regression. The former can be orders of magnitude faster than the latter when the number of samples is larger than tens of thousands of samples.

Missing values and categorical data are natively supported by the Hist… version, removing the need for additional preprocessing such as imputation.

GradientBoostingClassifier and GradientBoostingRegressor might be preferred for small sample sizes since binning may lead to split points that are too approximate in this setting.

Scikit-learn 0.21 introduced two new implementations of gradient boosted trees, namely HistGradientBoostingClassifier and HistGradientBoostingRegressor, inspired by LightGBM (See [LightGBM]).

These histogram-based estimators can be orders of magnitude faster than GradientBoostingClassifier and GradientBoostingRegressor when the number of samples is larger than tens of thousands of samples.

They also have built-in support for missing values, which avoids the need for an imputer.

These fast estimators first bin the input samples X into integer-valued bins (typically 256 bins) which tremendously reduces the number of splitting points to consider, and allows the algorithm to leverage integer-based data structures (histograms) instead of relying on sorted continuous values when building the trees. The API of these estimators is slightly different, and some of the features from GradientBoostingClassifier and GradientBoostingRegressor are not yet supported, for instance some loss functions.

Partial Dependence and Individual Conditional Expectation Plots

Comparing Random Forests and Histogram Gradient Boosting models

Most of the parameters are unchanged from GradientBoostingClassifier and GradientBoostingRegressor. One exception is the max_iter parameter that replaces n_estimators, and controls the number of iterations of the boosting process:

Available losses for regression are:

‘squared_error’, which is the default loss;

‘absolute_error’, which is less sensitive to outliers than the squared error;

‘gamma’, which is well suited to model strictly positive outcomes;

‘poisson’, which is well suited to model counts and frequencies;

‘quantile’, which allows for estimating a conditional quantile that can later be used to obtain prediction intervals.

For classification, ‘log_loss’ is the only option. For binary classification it uses the binary log loss, also known as binomial deviance or binary cross-entropy. For n_classes >= 3, it uses the multi-class log loss function, with multinomial deviance and categorical cross-entropy as alternative names. The appropriate loss version is selected based on y passed to fit.

The size of the trees can be controlled through the max_leaf_nodes, max_depth, and min_samples_leaf parameters.

The number of bins used to bin the data is controlled with the max_bins parameter. Using less bins acts as a form of regularization. It is generally recommended to use as many bins as possible (255), which is the default.

The l2_regularization parameter acts as a regularizer for the loss function, and corresponds to \(\lambda\) in the following expression (see equation (2) in [XGBoost]):

It is important to notice that the loss term \(l(\hat{y}_i, y_i)\) describes only half of the actual loss function except for the pinball loss and absolute error.

The index \(k\) refers to the k-th tree in the ensemble of trees. In the case of regression and binary classification, gradient boosting models grow one tree per iteration, then \(k\) runs up to max_iter. In the case of multiclass classification problems, the maximal value of the index \(k\) is n_classes \(\times\) max_iter.

If \(T_k\) denotes the number of leaves in the k-th tree, then \(w_k\) is a vector of length \(T_k\), which contains the leaf values of the form w = -sum_gradient / (sum_hessian + l2_regularization) (see equation (5) in [XGBoost]).

The leaf values \(w_k\) are derived by dividing the sum of the gradients of the loss function by the combined sum of hessians. Adding the regularization to the denominator penalizes the leaves with small hessians (flat regions), resulting in smaller updates. Those \(w_k\) values contribute then to the model’s prediction for a given input that ends up in the corresponding leaf. The final prediction is the sum of the base prediction and the contributions from each tree. The result of that sum is then transformed by the inverse link function depending on the choice of the loss function (see Mathematical formulation).

Notice that the original paper [XGBoost] introduces a term \(\gamma\sum_k T_k\) that penalizes the number of leaves (making it a smooth version of max_leaf_nodes) not presented here as it is not implemented in scikit-learn; whereas \(\lambda\) penalizes the magnitude of the individual tree predictions before being rescaled by the learning rate, see Shrinkage via learning rate.

Note that early-stopping is enabled by default if the number of samples is larger than 10,000. The early-stopping behaviour is controlled via the early_stopping, scoring, validation_fraction, n_iter_no_change, and tol parameters. It is possible to early-stop using an arbitrary scorer, or just the training or validation loss. Note that for technical reasons, using a callable as a scorer is significantly slower than using the loss. By default, early-stopping is performed if there are at least 10,000 samples in the training set, using the validation loss.

HistGradientBoostingClassifier and HistGradientBoostingRegressor have built-in support for missing values (NaNs).

During training, the tree grower learns at each split point whether samples with missing values should go to the left or right child, based on the potential gain. When predicting, samples with missing values are assigned to the left or right child consequently:

When the missingness pattern is predictive, the splits can be performed on whether the feature value is missing or not:

If no missing values were encountered for a given feature during training, then samples with missing values are mapped to whichever child has the most samples.

Features in Histogram Gradient Boosting Trees

HistGradientBoostingClassifier and HistGradientBoostingRegressor support sample weights during fit.

The following toy example demonstrates that samples with a sample weight of zero are ignored:

As you can see, the [1, 0] is comfortably classified as 1 since the first two samples are ignored due to their sample weights.

Implementation detail: taking sample weights into account amounts to multiplying the gradients (and the hessians) by the sample weights. Note that the binning stage (specifically the quantiles computation) does not take the weights into account.

HistGradientBoostingClassifier and HistGradientBoostingRegressor have native support for categorical features: they can consider splits on non-ordered, categorical data.

For datasets with categorical features, using the native categorical support is often better than relying on one-hot encoding (OneHotEncoder), because one-hot encoding requires more tree depth to achieve equivalent splits. It is also usually better to rely on the native categorical support rather than to treat categorical features as continuous (ordinal), which happens for ordinal-encoded categorical data, since categories are nominal quantities where order does not matter.

To enable categorical support, a boolean mask can be passed to the categorical_features parameter, indicating which feature is categorical. In the following, the first feature will be treated as categorical and the second feature as numerical:

Equivalently, one can pass a list of integers indicating the indices of the categorical features:

When the input is a DataFrame, it is also possible to pass a list of column names:

Finally, when the input is a DataFrame we can use categorical_features="from_dtype" in which case all columns with a categorical dtype will be treated as categorical features.

The cardinality of each categorical feature must be less than the max_bins parameter. For an example using histogram-based gradient boosting on categorical features, see Categorical Feature Support in Gradient Boosting.

If there are missing values during training, the missing values will be treated as a proper category. If there are no missing values during training, then at prediction time, missing values are mapped to the child node that has the most samples (just like for continuous features). When predicting, categories that were not seen during fit time will be treated as missing values.

The canonical way of considering categorical splits in a tree is to consider all of the \(2^{K - 1} - 1\) partitions, where \(K\) is the number of categories. This can quickly become prohibitive when \(K\) is large. Fortunately, since gradient boosting trees are always regression trees (even for classification problems), there exists a faster strategy that can yield equivalent splits. First, the categories of a feature are sorted according to the variance of the target, for each category k. Once the categories are sorted, one can consider continuous partitions, i.e. treat the categories as if they were ordered continuous values (see Fisher [Fisher1958] for a formal proof). As a result, only \(K - 1\) splits need to be considered instead of \(2^{K - 1} - 1\). The initial sorting is a \(\mathcal{O}(K \log(K))\) operation, leading to a total complexity of \(\mathcal{O}(K \log(K) + K)\), instead of \(\mathcal{O}(2^K)\).

Categorical Feature Support in Gradient Boosting

Depending on the problem at hand, you may have prior knowledge indicating that a given feature should in general have a positive (or negative) effect on the target value. For example, all else being equal, a higher credit score should increase the probability of getting approved for a loan. Monotonic constraints allow you to incorporate such prior knowledge into the model.

For a predictor \(F\) with two features:

a monotonic increase constraint is a constraint of the form:

a monotonic decrease constraint is a constraint of the form:

You can specify a monotonic constraint on each feature using the monotonic_cst parameter. For each feature, a value of 0 indicates no constraint, while 1 and -1 indicate a monotonic increase and monotonic decrease constraint, respectively:

In a binary classification context, imposing a monotonic increase (decrease) constraint means that higher values of the feature are supposed to have a positive (negative) effect on the probability of samples to belong to the positive class.

Nevertheless, monotonic constraints only marginally constrain feature effects on the output. For instance, monotonic increase and decrease constraints cannot be used to enforce the following modelling constraint:

Also, monotonic constraints are not supported for multiclass classification.

For a practical implementation of monotonic constraints with the histogram-based gradient boosting, including how they can improve generalization when domain knowledge is available, see Monotonic Constraints.

Since categories are unordered quantities, it is not possible to enforce monotonic constraints on categorical features.

Features in Histogram Gradient Boosting Trees

A priori, the histogram gradient boosted trees are allowed to use any feature to split a node into child nodes. This creates so called interactions between features, i.e. usage of different features as split along a branch. Sometimes, one wants to restrict the possible interactions, see [Mayer2022]. This can be done by the parameter interaction_cst, where one can specify the indices of features that are allowed to interact. For instance, with 3 features in total, interaction_cst=[{0}, {1}, {2}] forbids all interactions. The constraints [{0, 1}, {1, 2}] specify two groups of possibly interacting features. Features 0 and 1 may interact with each other, as well as features 1 and 2. But note that features 0 and 2 are forbidden to interact. The following depicts a tree and the possible splits of the tree:

LightGBM uses the same logic for overlapping groups.

Note that features not listed in interaction_cst are automatically assigned an interaction group for themselves. With again 3 features, this means that [{0}] is equivalent to [{0}, {1, 2}].

Partial Dependence and Individual Conditional Expectation Plots

M. Mayer, S.C. Bourassa, M. Hoesli, and D.F. Scognamiglio. 2022. Machine Learning Applications to Land and Structure Valuation. Journal of Risk and Financial Management 15, no. 5: 193

HistGradientBoostingClassifier and HistGradientBoostingRegressor use OpenMP for parallelization through Cython. For more details on how to control the number of threads, please refer to our Parallelism notes.

The following parts are parallelized:

mapping samples from real values to integer-valued bins (finding the bin thresholds is however sequential)

building histograms is parallelized over features

finding the best split point at a node is parallelized over features

during fit, mapping samples into the left and right children is parallelized over samples

gradient and hessians computations are parallelized over samples

predicting is parallelized over samples

The bottleneck of a gradient boosting procedure is building the decision trees. Building a traditional decision tree (as in the other GBDTs GradientBoostingClassifier and GradientBoostingRegressor) requires sorting the samples at each node (for each feature). Sorting is needed so that the potential gain of a split point can be computed efficiently. Splitting a single node has thus a complexity of \(\mathcal{O}(n_\text{features} \times n \log(n))\) where \(n\) is the number of samples at the node.

HistGradientBoostingClassifier and HistGradientBoostingRegressor, in contrast, do not require sorting the feature values and instead use a data-structure called a histogram, where the samples are implicitly ordered. Building a histogram has a \(\mathcal{O}(n)\) complexity, so the node splitting procedure has a \(\mathcal{O}(n_\text{features} \times n)\) complexity, much smaller than the previous one. In addition, instead of considering \(n\) split points, we consider only max_bins split points, which might be much smaller.

In order to build histograms, the input data X needs to be binned into integer-valued bins. This binning procedure does require sorting the feature values, but it only happens once at the very beginning of the boosting process (not at each node, like in GradientBoostingClassifier and GradientBoostingRegressor).

Finally, many parts of the implementation of HistGradientBoostingClassifier and HistGradientBoostingRegressor are parallelized.

Tianqi Chen, Carlos Guestrin, “XGBoost: A Scalable Tree Boosting System”

Ke et. al. “LightGBM: A Highly Efficient Gradient BoostingDecision Tree”

Fisher, W.D. (1958). “On Grouping for Maximum Homogeneity” Journal of the American Statistical Association, 53, 789-798.

The usage and the parameters of GradientBoostingClassifier and GradientBoostingRegressor are described below. The 2 most important parameters of these estimators are n_estimators and learning_rate.

GradientBoostingClassifier supports both binary and multi-class classification. The following example shows how to fit a gradient boosting classifier with 100 decision stumps as weak learners:

The number of weak learners (i.e. regression trees) is controlled by the parameter n_estimators; The size of each tree can be controlled either by setting the tree depth via max_depth or by setting the number of leaf nodes via max_leaf_nodes. The learning_rate is a hyper-parameter in the range (0.0, 1.0] that controls overfitting via shrinkage .

Classification with more than 2 classes requires the induction of n_classes regression trees at each iteration, thus, the total number of induced trees equals n_classes * n_estimators. For datasets with a large number of classes we strongly recommend to use HistGradientBoostingClassifier as an alternative to GradientBoostingClassifier .

GradientBoostingRegressor supports a number of different loss functions for regression which can be specified via the argument loss; the default loss function for regression is squared error ('squared_error').

The figure below shows the results of applying GradientBoostingRegressor with least squares loss and 500 base learners to the diabetes dataset (sklearn.datasets.load_diabetes). The plot shows the train and test error at each iteration. The train error at each iteration is stored in the train_score_ attribute of the gradient boosting model. The test error at each iteration can be obtained via the staged_predict method which returns a generator that yields the predictions at each stage. Plots like these can be used to determine the optimal number of trees (i.e. n_estimators) by early stopping.

Gradient Boosting regression

Gradient Boosting Out-of-Bag estimates

Both GradientBoostingRegressor and GradientBoostingClassifier support warm_start=True which allows you to add more estimators to an already fitted model.

The size of the regression tree base learners defines the level of variable interactions that can be captured by the gradient boosting model. In general, a tree of depth h can capture interactions of order h . There are two ways in which the size of the individual regression trees can be controlled.

If you specify max_depth=h then complete binary trees of depth h will be grown. Such trees will have (at most) 2**h leaf nodes and 2**h - 1 split nodes.

Alternatively, you can control the tree size by specifying the number of leaf nodes via the parameter max_leaf_nodes. In this case, trees will be grown using best-first search where nodes with the highest improvement in impurity will be expanded first. A tree with max_leaf_nodes=k has k - 1 split nodes and thus can model interactions of up to order max_leaf_nodes - 1 .

We found that max_leaf_nodes=k gives comparable results to max_depth=k-1 but is significantly faster to train at the expense of a slightly higher training error. The parameter max_leaf_nodes corresponds to the variable J in the chapter on gradient boosting in [Friedman2001] and is related to the parameter interaction.depth in R’s gbm package where max_leaf_nodes == interaction.depth + 1 .

We first present GBRT for regression, and then detail the classification case.

GBRT regressors are additive models whose prediction \(\hat{y}_i\) for a given input \(x_i\) is of the following form:

where the \(h_m\) are estimators called weak learners in the context of boosting. Gradient Tree Boosting uses decision tree regressors of fixed size as weak learners. The constant M corresponds to the n_estimators parameter.

Similar to other boosting algorithms, a GBRT is built in a greedy fashion:

where the newly added tree \(h_m\) is fitted in order to minimize a sum of losses \(L_m\), given the previous ensemble \(F_{m-1}\):

where \(l(y_i, F(x_i))\) is defined by the loss parameter, detailed in the next section.

By default, the initial model \(F_{0}\) is chosen as the constant that minimizes the loss: for a least-squares loss, this is the empirical mean of the target values. The initial model can also be specified via the init argument.

Using a first-order Taylor approximation, the value of \(l\) can be approximated as follows:

Briefly, a first-order Taylor approximation says that \(l(z) \approx l(a) + (z - a) \frac{\partial l}{\partial z}(a)\). Here, \(z\) corresponds to \(F_{m - 1}(x_i) + h_m(x_i)\), and \(a\) corresponds to \(F_{m-1}(x_i)\)

The quantity \(\left[ \frac{\partial l(y_i, F(x_i))}{\partial F(x_i)} \right]_{F=F_{m - 1}}\) is the derivative of the loss with respect to its second parameter, evaluated at \(F_{m-1}(x)\). It is easy to compute for any given \(F_{m - 1}(x_i)\) in a closed form since the loss is differentiable. We will denote it by \(g_i\).

Removing the constant terms, we have:

This is minimized if \(h(x_i)\) is fitted to predict a value that is proportional to the negative gradient \(-g_i\). Therefore, at each iteration, the estimator \(h_m\) is fitted to predict the negative gradients of the samples. The gradients are updated at each iteration. This can be considered as some kind of gradient descent in a functional space.

For some losses, e.g. 'absolute_error' where the gradients are \(\pm 1\), the values predicted by a fitted \(h_m\) are not accurate enough: the tree can only output integer values. As a result, the leaves values of the tree \(h_m\) are modified once the tree is fitted, such that the leaves values minimize the loss \(L_m\). The update is loss-dependent: for the absolute error loss, the value of a leaf is updated to the median of the samples in that leaf.

Gradient boosting for classification is very similar to the regression case. However, the sum of the trees \(F_M(x_i) = \sum_m h_m(x_i)\) is not homogeneous to a prediction: it cannot be a class, since the trees predict continuous values.

The mapping from the value \(F_M(x_i)\) to a class or a probability is loss-dependent. For the log-loss, the probability that \(x_i\) belongs to the positive class is modeled as \(p(y_i = 1 | x_i) = \sigma(F_M(x_i))\) where \(\sigma\) is the sigmoid or expit function.

For multiclass classification, K trees (for K classes) are built at each of the \(M\) iterations. The probability that \(x_i\) belongs to class k is modeled as a softmax of the \(F_{M,k}(x_i)\) values.

Note that even for a classification task, the \(h_m\) sub-estimator is still a regressor, not a classifier. This is because the sub-estimators are trained to predict (negative) gradients, which are always continuous quantities.

The following loss functions are supported and can be specified using the parameter loss:

Squared error ('squared_error'): The natural choice for regression due to its superior computational properties. The initial model is given by the mean of the target values.

Absolute error ('absolute_error'): A robust loss function for regression. The initial model is given by the median of the target values.

Huber ('huber'): Another robust loss function that combines least squares and least absolute deviation; use alpha to control the sensitivity with regards to outliers (see [Friedman2001] for more details).

Quantile ('quantile'): A loss function for quantile regression. Use 0 < alpha < 1 to specify the quantile. This loss function can be used to create prediction intervals (see Prediction Intervals for Gradient Boosting Regression).

Binary log-loss ('log-loss'): The binomial negative log-likelihood loss function for binary classification. It provides probability estimates. The initial model is given by the log odds-ratio.

Multi-class log-loss ('log-loss'): The multinomial negative log-likelihood loss function for multi-class classification with n_classes mutually exclusive classes. It provides probability estimates. The initial model is given by the prior probability of each class. At each iteration n_classes regression trees have to be constructed which makes GBRT rather inefficient for data sets with a large number of classes.

Exponential loss ('exponential'): The same loss function as AdaBoostClassifier. Less robust to mislabeled examples than 'log-loss'; can only be used for binary classification.

[Friedman2001] proposed a simple regularization strategy that scales the contribution of each weak learner by a constant factor \(\nu\):

The parameter \(\nu\) is also called the learning rate because it scales the step length of the gradient descent procedure; it can be set via the learning_rate parameter.

The parameter learning_rate strongly interacts with the parameter n_estimators, the number of weak learners to fit. Smaller values of learning_rate require larger numbers of weak learners to maintain a constant training error. Empirical evidence suggests that small values of learning_rate favor better test error. [HTF] recommend to set the learning rate to a small constant (e.g. learning_rate <= 0.1) and choose n_estimators large enough that early stopping applies, see Early stopping in Gradient Boosting for a more detailed discussion of the interaction between learning_rate and n_estimators see [R2007].

[Friedman2002] proposed stochastic gradient boosting, which combines gradient boosting with bootstrap averaging (bagging). At each iteration the base classifier is trained on a fraction subsample of the available training data. The subsample is drawn without replacement. A typical value of subsample is 0.5.

The figure below illustrates the effect of shrinkage and subsampling on the goodness-of-fit of the model. We can clearly see that shrinkage outperforms no-shrinkage. Subsampling with shrinkage can further increase the accuracy of the model. Subsampling without shrinkage, on the other hand, does poorly.

Another strategy to reduce the variance is by subsampling the features analogous to the random splits in RandomForestClassifier. The number of subsampled features can be controlled via the max_features parameter.

Using a small max_features value can significantly decrease the runtime.

Stochastic gradient boosting allows to compute out-of-bag estimates of the test deviance by computing the improvement in deviance on the examples that are not included in the bootstrap sample (i.e. the out-of-bag examples). The improvements are stored in the attribute oob_improvement_. oob_improvement_[i] holds the improvement in terms of the loss on the OOB samples if you add the i-th stage to the current predictions. Out-of-bag estimates can be used for model selection, for example to determine the optimal number of iterations. OOB estimates are usually very pessimistic thus we recommend to use cross-validation instead and only use OOB if cross-validation is too time consuming.

Gradient Boosting regularization

Gradient Boosting Out-of-Bag estimates

OOB Errors for Random Forests

Individual decision trees can be interpreted easily by simply visualizing the tree structure. Gradient boosting models, however, comprise hundreds of regression trees thus they cannot be easily interpreted by visual inspection of the individual trees. Fortunately, a number of techniques have been proposed to summarize and interpret gradient boosting models.

Often features do not contribute equally to predict the target response; in many situations the majority of the features are in fact irrelevant. When interpreting a model, the first question usually is: what are those important features and how do they contribute in predicting the target response?

Individual decision trees intrinsically perform feature selection by selecting appropriate split points. This information can be used to measure the importance of each feature; the basic idea is: the more often a feature is used in the split points of a tree the more important that feature is. This notion of importance can be extended to decision tree ensembles by simply averaging the impurity-based feature importance of each tree (see Feature importance evaluation for more details).

The feature importance scores of a fit gradient boosting model can be accessed via the feature_importances_ property:

Note that this computation of feature importance is based on entropy, and it is distinct from sklearn.inspection.permutation_importance which is based on permutation of the features.

Gradient Boosting regression

Friedman, J.H. (2001). Greedy function approximation: A gradient boosting machine. Annals of Statistics, 29, 1189-1232.

Friedman, J.H. (2002). Stochastic gradient boosting.. Computational Statistics & Data Analysis, 38, 367-378.

G. Ridgeway (2006). Generalized Boosted Models: A guide to the gbm package

The sklearn.ensemble module includes two averaging algorithms based on randomized decision trees: the RandomForest algorithm and the Extra-Trees method. Both algorithms are perturb-and-combine techniques [B1998] specifically designed for trees. This means a diverse set of classifiers is created by introducing randomness in the classifier construction. The prediction of the ensemble is given as the averaged prediction of the individual classifiers.

As other classifiers, forest classifiers have to be fitted with two arrays: a sparse or dense array X of shape (n_samples, n_features) holding the training samples, and an array Y of shape (n_samples,) holding the target values (class labels) for the training samples:

Like decision trees, forests of trees also extend to multi-output problems (if Y is an array of shape (n_samples, n_outputs)).

In random forests (see RandomForestClassifier and RandomForestRegressor classes), each tree in the ensemble is built from a sample drawn with replacement (i.e., a bootstrap sample) from the training set.

During the construction of each tree in the forest, a random subset of the features is considered. The size of this subset is controlled by the max_features parameter; it may include either all input features or a random subset of them (see the parameter tuning guidelines for more details).

The purpose of these two sources of randomness (bootstrapping the samples and randomly selecting features at each split) is to decrease the variance of the forest estimator. Indeed, individual decision trees typically exhibit high variance and tend to overfit. The injected randomness in forests yield decision trees with somewhat decoupled prediction errors. By taking an average of those predictions, some errors can cancel out. Random forests achieve a reduced variance by combining diverse trees, sometimes at the cost of a slight increase in bias. In practice the variance reduction is often significant hence yielding an overall better model.

When growing each tree in the forest, the “best” split (i.e. equivalent to passing splitter="best" to the underlying decision trees) is chosen according to the impurity criterion. See the CART mathematical formulation for more details.

In contrast to the original publication [B2001], the scikit-learn implementation combines classifiers by averaging their probabilistic prediction, instead of letting each classifier vote for a single class.

A competitive alternative to random forests are Histogram-Based Gradient Boosting (HGBT) models:

Building trees: Random forests typically rely on deep trees (that overfit individually) which uses much computational resources, as they require several splittings and evaluations of candidate splits. Boosting models build shallow trees (that underfit individually) which are faster to fit and predict.

Sequential boosting: In HGBT, the decision trees are built sequentially, where each tree is trained to correct the errors made by the previous ones. This allows them to iteratively improve the model’s performance using relatively few trees. In contrast, random forests use a majority vote to predict the outcome, which can require a larger number of trees to achieve the same level of accuracy.

Efficient binning: HGBT uses an efficient binning algorithm that can handle large datasets with a high number of features. The binning algorithm can pre-process the data to speed up the subsequent tree construction (see Why it’s faster). In contrast, the scikit-learn implementation of random forests does not use binning and relies on exact splitting, which can be computationally expensive.

Overall, the computational cost of HGBT versus RF depends on the specific characteristics of the dataset and the modeling task. It’s a good idea to try both models and compare their performance and computational efficiency on your specific problem to determine which model is the best fit.

Comparing Random Forests and Histogram Gradient Boosting models

In extremely randomized trees (see ExtraTreesClassifier and ExtraTreesRegressor classes), randomness goes one step further in the way splits are computed. As in random forests, a random subset of candidate features is used, but instead of looking for the most discriminative thresholds, thresholds are drawn at random for each candidate feature and the best of these randomly-generated thresholds is picked as the splitting rule. This usually allows to reduce the variance of the model a bit more, at the expense of a slightly greater increase in bias:

The main parameters to adjust when using these methods is n_estimators and max_features. The former is the number of trees in the forest. The larger the better, but also the longer it will take to compute. In addition, note that results will stop getting significantly better beyond a critical number of trees. The latter is the size of the random subsets of features to consider when splitting a node. The lower the greater the reduction of variance, but also the greater the increase in bias. Empirical good default values are max_features=1.0 or equivalently max_features=None (always considering all features instead of a random subset) for regression problems, and max_features="sqrt" (using a random subset of size sqrt(n_features)) for classification tasks (where n_features is the number of features in the data). The default value of max_features=1.0 is equivalent to bagged trees and more randomness can be achieved by setting smaller values (e.g. 0.3 is a typical default in the literature). Good results are often achieved when setting max_depth=None in combination with min_samples_split=2 (i.e., when fully developing the trees). Bear in mind though that these values are usually not optimal, and might result in models that consume a lot of RAM. The best parameter values should always be cross-validated. In addition, note that in random forests, bootstrap samples are used by default (bootstrap=True) while the default strategy for extra-trees is to use the whole dataset (bootstrap=False). When using bootstrap sampling the generalization error can be estimated on the left out or out-of-bag samples. This can be enabled by setting oob_score=True.

The size of the model with the default parameters is \(O( M * N * log (N) )\), where \(M\) is the number of trees and \(N\) is the number of samples. In order to reduce the size of the model, you can change these parameters: min_samples_split, max_leaf_nodes, max_depth and min_samples_leaf.

Finally, this module also features the parallel construction of the trees and the parallel computation of the predictions through the n_jobs parameter. If n_jobs=k then computations are partitioned into k jobs, and run on k cores of the machine. If n_jobs=-1 then all cores available on the machine are used. Note that because of inter-process communication overhead, the speedup might not be linear (i.e., using k jobs will unfortunately not be k times as fast). Significant speedup can still be achieved though when building a large number of trees, or when building a single tree requires a fair amount of time (e.g., on large datasets).

Plot the decision surfaces of ensembles of trees on the iris dataset

Face completion with a multi-output estimators

Breiman, “Random Forests”, Machine Learning, 45(1), 5-32, 2001.

Breiman, “Arcing Classifiers”, Annals of Statistics 1998.

P. Geurts, D. Ernst., and L. Wehenkel, “Extremely randomized trees”, Machine Learning, 63(1), 3-42, 2006.

The relative rank (i.e. depth) of a feature used as a decision node in a tree can be used to assess the relative importance of that feature with respect to the predictability of the target variable. Features used at the top of the tree contribute to the final prediction decision of a larger fraction of the input samples. The expected fraction of the samples they contribute to can thus be used as an estimate of the relative importance of the features. In scikit-learn, the fraction of samples a feature contributes to is combined with the decrease in impurity from splitting them to create a normalized estimate of the predictive power of that feature.

By averaging the estimates of predictive ability over several randomized trees one can reduce the variance of such an estimate and use it for feature selection. This is known as the mean decrease in impurity, or MDI. Refer to [L2014] for more information on MDI and feature importance evaluation with Random Forests.

The impurity-based feature importances computed on tree-based models suffer from two flaws that can lead to misleading conclusions. First they are computed on statistics derived from the training dataset and therefore do not necessarily inform us on which features are most important to make good predictions on held-out dataset. Secondly, they favor high cardinality features, that is features with many unique values. Permutation feature importance is an alternative to impurity-based feature importance that does not suffer from these flaws. These two methods of obtaining feature importance are explored in: Permutation Importance vs Random Forest Feature Importance (MDI).

In practice those estimates are stored as an attribute named feature_importances_ on the fitted model. This is an array with shape (n_features,) whose values are positive and sum to 1.0. The higher the value, the more important is the contribution of the matching feature to the prediction function.

Feature importances with a forest of trees

G. Louppe, “Understanding Random Forests: From Theory to Practice”, PhD Thesis, U. of Liege, 2014.

RandomTreesEmbedding implements an unsupervised transformation of the data. Using a forest of completely random trees, RandomTreesEmbedding encodes the data by the indices of the leaves a data point ends up in. This index is then encoded in a one-of-K manner, leading to a high dimensional, sparse binary coding. This coding can be computed very efficiently and can then be used as a basis for other learning tasks. The size and sparsity of the code can be influenced by choosing the number of trees and the maximum depth per tree. For each tree in the ensemble, the coding contains one entry of one. The size of the coding is at most n_estimators * 2 ** max_depth, the maximum number of leaves in the forest.

As neighboring data points are more likely to lie within the same leaf of a tree, the transformation performs an implicit, non-parametric density estimation.

Hashing feature transformation using Totally Random Trees

Manifold learning on handwritten digits: Locally Linear Embedding, Isomap… compares non-linear dimensionality reduction techniques on handwritten digits.

Feature transformations with ensembles of trees compares supervised and unsupervised tree based feature transformations.

Manifold learning techniques can also be useful to derive non-linear representations of feature space, also these approaches focus also on dimensionality reduction.

RandomForest, Extra-Trees and RandomTreesEmbedding estimators all support warm_start=True which allows you to add more trees to an already fitted model.

When random_state is also set, the internal random state is also preserved between fit calls. This means that training a model once with n estimators is the same as building the model iteratively via multiple fit calls, where the final number of estimators is equal to n.

Note that this differs from the usual behavior of random_state in that it does not result in the same result across different calls.

In ensemble algorithms, bagging methods form a class of algorithms which build several instances of a black-box estimator on random subsets of the original training set and then aggregate their individual predictions to form a final prediction. These methods are used as a way to reduce the variance of a base estimator (e.g., a decision tree), by introducing randomization into its construction procedure and then making an ensemble out of it. In many cases, bagging methods constitute a very simple way to improve with respect to a single model, without making it necessary to adapt the underlying base algorithm. As they provide a way to reduce overfitting, bagging methods work best with strong and complex models (e.g., fully developed decision trees), in contrast with boosting methods which usually work best with weak models (e.g., shallow decision trees).

Bagging methods come in many flavours but mostly differ from each other by the way they draw random subsets of the training set:

When random subsets of the dataset are drawn as random subsets of the samples, then this algorithm is known as Pasting [B1999].

When samples are drawn with replacement, then the method is known as Bagging [B1996].

When random subsets of the dataset are drawn as random subsets of the features, then the method is known as Random Subspaces [H1998].

Finally, when base estimators are built on subsets of both samples and features, then the method is known as Random Patches [LG2012].

In scikit-learn, bagging methods are offered as a unified BaggingClassifier meta-estimator (resp. BaggingRegressor), taking as input a user-specified estimator along with parameters specifying the strategy to draw random subsets. In particular, max_samples and max_features control the size of the subsets (in terms of samples and features), while bootstrap and bootstrap_features control whether samples and features are drawn with or without replacement. When using a subset of the available samples the generalization accuracy can be estimated with the out-of-bag samples by setting oob_score=True. As an example, the snippet below illustrates how to instantiate a bagging ensemble of KNeighborsClassifier estimators, each built on random subsets of 50% of the samples and 50% of the features.

Single estimator versus bagging: bias-variance decomposition

L. Breiman, “Pasting small votes for classification in large databases and on-line”, Machine Learning, 36(1), 85-103, 1999.

L. Breiman, “Bagging predictors”, Machine Learning, 24(2), 123-140, 1996.

T. Ho, “The random subspace method for constructing decision forests”, Pattern Analysis and Machine Intelligence, 20(8), 832-844, 1998.

G. Louppe and P. Geurts, “Ensembles on Random Patches”, Machine Learning and Knowledge Discovery in Databases, 346-361, 2012.

The idea behind the VotingClassifier is to combine conceptually different machine learning classifiers and use a majority vote or the average predicted probabilities (soft vote) to predict the class labels. Such a classifier can be useful for a set of equally well performing models in order to balance out their individual weaknesses.

In majority voting, the predicted class label for a particular sample is the class label that represents the majority (mode) of the class labels predicted by each individual classifier.

E.g., if the prediction for a given sample is

classifier 1 -> class 1

classifier 2 -> class 1

classifier 3 -> class 2

the VotingClassifier (with voting='hard') would classify the sample as “class 1” based on the majority class label.

In the cases of a tie, the VotingClassifier will select the class based on the ascending sort order. E.g., in the following scenario

classifier 1 -> class 2

classifier 2 -> class 1

the class label 1 will be assigned to the sample.

The following example shows how to fit the majority rule classifier:

In contrast to majority voting (hard voting), soft voting returns the class label as argmax of the sum of predicted probabilities.

Specific weights can be assigned to each classifier via the weights parameter. When weights are provided, the predicted class probabilities for each classifier are collected, multiplied by the classifier weight, and averaged. The final class label is then derived from the class label with the highest average probability.

To illustrate this with a simple example, let’s assume we have 3 classifiers and a 3-class classification problem where we assign equal weights to all classifiers: w1=1, w2=1, w3=1.

The weighted average probabilities for a sample would then be calculated as follows:

Here, the predicted class label is 2, since it has the highest average predicted probability. See the example on Visualizing the probabilistic predictions of a VotingClassifier for a demonstration of how the predicted class label can be obtained from the weighted average of predicted probabilities.

The following figure illustrates how the decision regions may change when a soft VotingClassifier is trained with weights on three linear models:

In order to predict the class labels based on the predicted class-probabilities (scikit-learn estimators in the VotingClassifier must support predict_proba method):

Optionally, weights can be provided for the individual classifiers:

The VotingClassifier can also be used together with GridSearchCV in order to tune the hyperparameters of the individual estimators:

The idea behind the VotingRegressor is to combine conceptually different machine learning regressors and return the average predicted values. Such a regressor can be useful for a set of equally well performing models in order to balance out their individual weaknesses.

The following example shows how to fit the VotingRegressor:

Plot individual and voting regression predictions

Stacked generalization is a method for combining estimators to reduce their biases [W1992] [HTF]. More precisely, the predictions of each individual estimator are stacked together and used as input to a final estimator to compute the prediction. This final estimator is trained through cross-validation.

The StackingClassifier and StackingRegressor provide such strategies which can be applied to classification and regression problems.

The estimators parameter corresponds to the list of the estimators which are stacked together in parallel on the input data. It should be given as a list of names and estimators:

The final_estimator will use the predictions of the estimators as input. It needs to be a classifier or a regressor when using StackingClassifier or StackingRegressor, respectively:

To train the estimators and final_estimator, the fit method needs to be called on the training data:

During training, the estimators are fitted on the whole training data X_train. They will be used when calling predict or predict_proba. To generalize and avoid over-fitting, the final_estimator is trained on out-samples using sklearn.model_selection.cross_val_predict internally.

For StackingClassifier, note that the output of the estimators is controlled by the parameter stack_method and it is called by each estimator. This parameter is either a string, being estimator method names, or 'auto' which will automatically identify an available method depending on the availability, tested in the order of preference: predict_proba, decision_function and predict.

A StackingRegressor and StackingClassifier can be used as any other regressor or classifier, exposing a predict, predict_proba, or decision_function method, e.g.:

Note that it is also possible to get the output of the stacked estimators using the transform method:

In practice, a stacking predictor predicts as good as the best predictor of the base layer and even sometimes outperforms it by combining the different strengths of these predictors. However, training a stacking predictor is computationally expensive.

For StackingClassifier, when using stack_method_='predict_proba', the first column is dropped when the problem is a binary classification problem. Indeed, both probability columns predicted by each estimator are perfectly collinear.

Multiple stacking layers can be achieved by assigning final_estimator to a StackingClassifier or StackingRegressor:

Combine predictors using stacking

Wolpert, David H. “Stacked generalization.” Neural networks 5.2 (1992): 241-259.

The module sklearn.ensemble includes the popular boosting algorithm AdaBoost, introduced in 1995 by Freund and Schapire [FS1995].

The core principle of AdaBoost is to fit a sequence of weak learners (i.e., models that are only slightly better than random guessing, such as small decision trees) on repeatedly modified versions of the data. The predictions from all of them are then combined through a weighted majority vote (or sum) to produce the final prediction. The data modifications at each so-called boosting iteration consists of applying weights \(w_1\), \(w_2\), …, \(w_N\) to each of the training samples. Initially, those weights are all set to \(w_i = 1/N\), so that the first step simply trains a weak learner on the original data. For each successive iteration, the sample weights are individually modified and the learning algorithm is reapplied to the reweighted data. At a given step, those training examples that were incorrectly predicted by the boosted model induced at the previous step have their weights increased, whereas the weights are decreased for those that were predicted correctly. As iterations proceed, examples that are difficult to predict receive ever-increasing influence. Each subsequent weak learner is thereby forced to concentrate on the examples that are missed by the previous ones in the sequence [HTF].

AdaBoost can be used both for classification and regression problems:

For multi-class classification, AdaBoostClassifier implements AdaBoost.SAMME [ZZRH2009].

For regression, AdaBoostRegressor implements AdaBoost.R2 [D1997].

The following example shows how to fit an AdaBoost classifier with 100 weak learners:

The number of weak learners is controlled by the parameter n_estimators. The learning_rate parameter controls the contribution of the weak learners in the final combination. By default, weak learners are decision stumps. Different weak learners can be specified through the estimator parameter. The main parameters to tune to obtain good results are n_estimators and the complexity of the base estimators (e.g., its depth max_depth or minimum required number of samples to consider a split min_samples_split).

Multi-class AdaBoosted Decision Trees shows the performance of AdaBoost on a multi-class problem.

Two-class AdaBoost shows the decision boundary and decision function values for a non-linearly separable two-class problem using AdaBoost-SAMME.

Decision Tree Regression with AdaBoost demonstrates regression with the AdaBoost.R2 algorithm.

Y. Freund, and R. Schapire, “A Decision-Theoretic Generalization of On-Line Learning and an Application to Boosting”, 1997.

Zhu, H. Zou, S. Rosset, T. Hastie. “Multi-class AdaBoost”, 2009.

Drucker. “Improving Regressors using Boosting Techniques”, 1997.

T. Hastie, R. Tibshirani and J. Friedman, “Elements of Statistical Learning Ed. 2”, Springer, 2009.

**Examples:**

Example 1 (sql):
```sql
>>> from sklearn.ensemble import HistGradientBoostingClassifier
>>> from sklearn.datasets import make_hastie_10_2

>>> X, y = make_hastie_10_2(random_state=0)
>>> X_train, X_test = X[:2000], X[2000:]
>>> y_train, y_test = y[:2000], y[2000:]

>>> clf = HistGradientBoostingClassifier(max_iter=100).fit(X_train, y_train)
>>> clf.score(X_test, y_test)
0.8965
```

Example 2 (sql):
```sql
>>> from sklearn.ensemble import HistGradientBoostingClassifier
>>> import numpy as np

>>> X = np.array([0, 1, 2, np.nan]).reshape(-1, 1)
>>> y = [0, 0, 1, 1]

>>> gbdt = HistGradientBoostingClassifier(min_samples_leaf=1).fit(X, y)
>>> gbdt.predict(X)
array([0, 0, 1, 1])
```

Example 3 (unknown):
```unknown
>>> X = np.array([0, np.nan, 1, 2, np.nan]).reshape(-1, 1)
>>> y = [0, 1, 0, 0, 1]
>>> gbdt = HistGradientBoostingClassifier(min_samples_leaf=1,
...                                       max_depth=2,
...                                       learning_rate=1,
...                                       max_iter=1).fit(X, y)
>>> gbdt.predict(X)
array([0, 1, 0, 0, 1])
```

Example 4 (unknown):
```unknown
>>> X = [[1, 0],
...      [1, 0],
...      [1, 0],
...      [0, 1]]
>>> y = [0, 0, 1, 0]
>>> # ignore the first 2 training samples by setting their weight to 0
>>> sample_weight = [0, 0, 1, 1]
>>> gb = HistGradientBoostingClassifier(min_samples_leaf=1)
>>> gb.fit(X, y, sample_weight=sample_weight)
HistGradientBoostingClassifier(...)
>>> gb.predict([[1, 0]])
array([1])
>>> gb.predict_proba([[1, 0]])[0, 1]
np.float64(0.999)
```

---

## NeighborhoodComponentsAnalysis#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.NeighborhoodComponentsAnalysis.html

**Contents:**
- NeighborhoodComponentsAnalysis#
- Gallery examples#

Neighborhood Components Analysis.

Neighborhood Component Analysis (NCA) is a machine learning algorithm for metric learning. It learns a linear transformation in a supervised fashion to improve the classification accuracy of a stochastic nearest neighbors rule in the transformed space.

Read more in the User Guide.

Preferred dimensionality of the projected space. If None it will be set to n_features.

Initialization of the linear transformation. Possible options are 'auto', 'pca', 'lda', 'identity', 'random', and a numpy array of shape (n_features_a, n_features_b).

Depending on n_components, the most reasonable initialization is chosen. If n_components <= min(n_features, n_classes - 1) we use 'lda', as it uses labels information. If not, but n_components < min(n_features, n_samples), we use 'pca', as it projects data in meaningful directions (those of higher variance). Otherwise, we just use 'identity'.

n_components principal components of the inputs passed to fit will be used to initialize the transformation. (See PCA)

min(n_components, n_classes) most discriminative components of the inputs passed to fit will be used to initialize the transformation. (If n_components > n_classes, the rest of the components will be zero.) (See LinearDiscriminantAnalysis)

If n_components is strictly smaller than the dimensionality of the inputs passed to fit, the identity matrix will be truncated to the first n_components rows.

The initial transformation will be a random array of shape (n_components, n_features). Each value is sampled from the standard normal distribution.

n_features_b must match the dimensionality of the inputs passed to fit and n_features_a must be less than or equal to that. If n_components is not None, n_features_a must match it.

If True and fit has been called before, the solution of the previous call to fit is used as the initial linear transformation (n_components and init will be ignored).

Maximum number of iterations in the optimization.

Convergence tolerance for the optimization.

If not None, this function is called after every iteration of the optimizer, taking as arguments the current solution (flattened transformation matrix) and the number of iterations. This might be useful in case one wants to examine or store the transformation found after each iteration.

If 0, no progress messages will be printed. If 1, progress messages will be printed to stdout. If > 1, progress messages will be printed and the disp parameter of scipy.optimize.minimize will be set to verbose - 2.

A pseudo random number generator object or a seed for it if int. If init='random', random_state is used to initialize the random transformation. If init='pca', random_state is passed as an argument to PCA when initializing the transformation. Pass an int for reproducible results across multiple function calls. See Glossary.

The linear transformation learned during fitting.

Number of features seen during fit.

Added in version 0.24.

Counts the number of iterations performed by the optimizer.

Pseudo random number generator object used during initialization.

Names of features seen during fit. Defined only when X has feature names that are all strings.

Added in version 1.0.

Linear Discriminant Analysis.

Principal component analysis (PCA).

J. Goldberger, G. Hinton, S. Roweis, R. Salakhutdinov. “Neighbourhood Components Analysis”. Advances in Neural Information Processing Systems. 17, 513-520, 2005. https://www.cs.toronto.edu/~rsalakhu/papers/ncanips.pdf

Wikipedia entry on Neighborhood Components Analysis https://en.wikipedia.org/wiki/Neighbourhood_components_analysis

Fit the model according to the given training data.

The training samples.

The corresponding training labels.

Fit to data, then transform it.

Fits transformer to X and y with optional parameters fit_params and returns a transformed version of X.

Target values (None for unsupervised transformations).

Additional fit parameters. Pass only if the estimator accepts additional params in its fit method.

Get output feature names for transformation.

The feature names out will prefixed by the lowercased class name. For example, if the transformer outputs 3 features, then the feature names out are: ["class_name0", "class_name1", "class_name2"].

Only used to validate feature names with the names seen in fit.

Transformed feature names.

Get metadata routing of this object.

Please check User Guide on how the routing mechanism works.

A MetadataRequest encapsulating routing information.

Get parameters for this estimator.

If True, will return the parameters for this estimator and contained subobjects that are estimators.

Parameter names mapped to their values.

Set output container.

See Introducing the set_output API for an example on how to use the API.

Configure output of transform and fit_transform.

"default": Default output format of a transformer

"pandas": DataFrame output

"polars": Polars output

None: Transform configuration is unchanged

Added in version 1.4: "polars" option was added.

Set the parameters of this estimator.

The method works on simple estimators as well as on nested objects (such as Pipeline). The latter have parameters of the form <component>__<parameter> so that it’s possible to update each component of a nested object.

Estimator parameters.

Apply the learned transformation to the given data.

The data samples transformed.

If fit has not been called before.

Manifold learning on handwritten digits: Locally Linear Embedding, Isomap…

Comparing Nearest Neighbors with and without Neighborhood Components Analysis

Dimensionality Reduction with Neighborhood Components Analysis

Neighborhood Components Analysis Illustration

**Examples:**

Example 1 (csharp):
```csharp
>>> from sklearn.neighbors import NeighborhoodComponentsAnalysis
>>> from sklearn.neighbors import KNeighborsClassifier
>>> from sklearn.datasets import load_iris
>>> from sklearn.model_selection import train_test_split
>>> X, y = load_iris(return_X_y=True)
>>> X_train, X_test, y_train, y_test = train_test_split(X, y,
... stratify=y, test_size=0.7, random_state=42)
>>> nca = NeighborhoodComponentsAnalysis(random_state=42)
>>> nca.fit(X_train, y_train)
NeighborhoodComponentsAnalysis(...)
>>> knn = KNeighborsClassifier(n_neighbors=3)
>>> knn.fit(X_train, y_train)
KNeighborsClassifier(...)
>>> print(knn.score(X_test, y_test))
0.933333...
>>> knn.fit(nca.transform(X_train), y_train)
KNeighborsClassifier(...)
>>> print(knn.score(nca.transform(X_test), y_test))
0.961904...
```

---

## MeanShift#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.cluster.MeanShift.html

**Contents:**
- MeanShift#
- Gallery examples#

Mean shift clustering using a flat kernel.

Mean shift clustering aims to discover “blobs” in a smooth density of samples. It is a centroid-based algorithm, which works by updating candidates for centroids to be the mean of the points within a given region. These candidates are then filtered in a post-processing stage to eliminate near-duplicates to form the final set of centroids.

Seeding is performed using a binning technique for scalability.

For an example of how to use MeanShift clustering, refer to: A demo of the mean-shift clustering algorithm.

Read more in the User Guide.

Bandwidth used in the flat kernel.

If not given, the bandwidth is estimated using sklearn.cluster.estimate_bandwidth; see the documentation for that function for hints on scalability (see also the Notes, below).

Seeds used to initialize kernels. If not set, the seeds are calculated by clustering.get_bin_seeds with bandwidth as the grid size and default values for other parameters.

If true, initial kernel locations are not locations of all points, but rather the location of the discretized version of points, where points are binned onto a grid whose coarseness corresponds to the bandwidth. Setting this option to True will speed up the algorithm because fewer seeds will be initialized. The default value is False. Ignored if seeds argument is not None.

To speed up the algorithm, accept only those bins with at least min_bin_freq points as seeds.

If true, then all points are clustered, even those orphans that are not within any kernel. Orphans are assigned to the nearest kernel. If false, then orphans are given cluster label -1.

The number of jobs to use for the computation. The following tasks benefit from the parallelization:

The search of nearest neighbors for bandwidth estimation and label assignments. See the details in the docstring of the NearestNeighbors class.

Hill-climbing optimization for all seeds.

See Glossary for more details.

None means 1 unless in a joblib.parallel_backend context. -1 means using all processors. See Glossary for more details.

Maximum number of iterations, per seed point before the clustering operation terminates (for that seed point), if has not converged yet.

Added in version 0.22.

Coordinates of cluster centers.

Labels of each point.

Maximum number of iterations performed on each seed.

Added in version 0.22.

Number of features seen during fit.

Added in version 0.24.

Names of features seen during fit. Defined only when X has feature names that are all strings.

Added in version 1.0.

Because this implementation uses a flat kernel and a Ball Tree to look up members of each kernel, the complexity will tend towards O(T*n*log(n)) in lower dimensions, with n the number of samples and T the number of points. In higher dimensions the complexity will tend towards O(T*n^2).

Scalability can be boosted by using fewer seeds, for example by using a higher value of min_bin_freq in the get_bin_seeds function.

Note that the estimate_bandwidth function is much less scalable than the mean shift algorithm and will be the bottleneck if it is used.

Dorin Comaniciu and Peter Meer, “Mean Shift: A robust approach toward feature space analysis”. IEEE Transactions on Pattern Analysis and Machine Intelligence. 2002. pp. 603-619.

For a comparison of Mean Shift clustering with other clustering algorithms, see Comparing different clustering algorithms on toy datasets

Not used, present for API consistency by convention.

Perform clustering on X and returns cluster labels.

Not used, present for API consistency by convention.

Arguments to be passed to fit.

Added in version 1.4.

Get metadata routing of this object.

Please check User Guide on how the routing mechanism works.

A MetadataRequest encapsulating routing information.

Get parameters for this estimator.

If True, will return the parameters for this estimator and contained subobjects that are estimators.

Parameter names mapped to their values.

Predict the closest cluster each sample in X belongs to.

Index of the cluster each sample belongs to.

Set the parameters of this estimator.

The method works on simple estimators as well as on nested objects (such as Pipeline). The latter have parameters of the form <component>__<parameter> so that it’s possible to update each component of a nested object.

Estimator parameters.

Comparing different clustering algorithms on toy datasets

A demo of the mean-shift clustering algorithm

**Examples:**

Example 1 (sql):
```sql
>>> from sklearn.cluster import MeanShift
>>> import numpy as np
>>> X = np.array([[1, 1], [2, 1], [1, 0],
...               [4, 7], [3, 5], [3, 6]])
>>> clustering = MeanShift(bandwidth=2).fit(X)
>>> clustering.labels_
array([1, 1, 1, 0, 0, 0])
>>> clustering.predict([[0, 0], [5, 5]])
array([1, 0])
>>> clustering
MeanShift(bandwidth=2)
```

---

## DictionaryLearning#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.DictionaryLearning.html

**Contents:**
- DictionaryLearning#

Finds a dictionary (a set of atoms) that performs well at sparsely encoding the fitted data.

Solves the optimization problem:

||.||_Fro stands for the Frobenius norm and ||.||_1,1 stands for the entry-wise matrix norm which is the sum of the absolute values of all the entries in the matrix.

Read more in the User Guide.

Number of dictionary elements to extract. If None, then n_components is set to n_features.

Sparsity controlling parameter.

Maximum number of iterations to perform.

Tolerance for numerical error.

'lars': uses the least angle regression method to solve the lasso problem (lars_path);

'cd': uses the coordinate descent method to compute the Lasso solution (Lasso). Lars will be faster if the estimated components are sparse.

Added in version 0.17: cd coordinate descent method to improve speed.

Algorithm used to transform the data:

'lars': uses the least angle regression method (lars_path);

'lasso_lars': uses Lars to compute the Lasso solution.

'lasso_cd': uses the coordinate descent method to compute the Lasso solution (Lasso). 'lasso_lars' will be faster if the estimated components are sparse.

'omp': uses orthogonal matching pursuit to estimate the sparse solution.

'threshold': squashes to zero all coefficients less than alpha from the projection dictionary * X'.

Added in version 0.17: lasso_cd coordinate descent method to improve speed.

Number of nonzero coefficients to target in each column of the solution. This is only used by algorithm='lars' and algorithm='omp'. If None, then transform_n_nonzero_coefs=int(n_features / 10).

If algorithm='lasso_lars' or algorithm='lasso_cd', alpha is the penalty applied to the L1 norm. If algorithm='threshold', alpha is the absolute value of the threshold below which coefficients will be squashed to zero. If None, defaults to alpha.

Changed in version 1.2: When None, default value changed from 1.0 to alpha.

Number of parallel jobs to run. None means 1 unless in a joblib.parallel_backend context. -1 means using all processors. See Glossary for more details.

Initial value for the code, for warm restart. Only used if code_init and dict_init are not None.

Initial values for the dictionary, for warm restart. Only used if code_init and dict_init are not None.

Callable that gets invoked every five iterations.

Added in version 1.3.

To control the verbosity of the procedure.

Whether to split the sparse feature vector into the concatenation of its negative part and its positive part. This can improve the performance of downstream classifiers.

Used for initializing the dictionary when dict_init is not specified, randomly shuffling the data when shuffle is set to True, and updating the dictionary. Pass an int for reproducible results across multiple function calls. See Glossary.

Whether to enforce positivity when finding the code.

Added in version 0.20.

Whether to enforce positivity when finding the dictionary.

Added in version 0.20.

Maximum number of iterations to perform if algorithm='lasso_cd' or 'lasso_lars'.

Added in version 0.22.

dictionary atoms extracted from the data

vector of errors at each iteration

Number of features seen during fit.

Added in version 0.24.

Names of features seen during fit. Defined only when X has feature names that are all strings.

Added in version 1.0.

Number of iterations run.

A faster, less accurate, version of the dictionary learning algorithm.

Mini-batch Sparse Principal Components Analysis.

Find a sparse representation of data from a fixed, precomputed dictionary.

Sparse Principal Components Analysis.

J. Mairal, F. Bach, J. Ponce, G. Sapiro, 2009: Online dictionary learning for sparse coding (https://www.di.ens.fr/~fbach/mairal_icml09.pdf)

We can check the level of sparsity of X_transformed:

We can compare the average squared euclidean norm of the reconstruction error of the sparse coded signal relative to the squared euclidean norm of the original signal:

Fit the model from data in X.

Training vector, where n_samples is the number of samples and n_features is the number of features.

Not used, present for API consistency by convention.

Returns the instance itself.

Fit the model from data in X and return the transformed data.

Training vector, where n_samples is the number of samples and n_features is the number of features.

Not used, present for API consistency by convention.

Get output feature names for transformation.

The feature names out will prefixed by the lowercased class name. For example, if the transformer outputs 3 features, then the feature names out are: ["class_name0", "class_name1", "class_name2"].

Only used to validate feature names with the names seen in fit.

Transformed feature names.

Get metadata routing of this object.

Please check User Guide on how the routing mechanism works.

A MetadataRequest encapsulating routing information.

Get parameters for this estimator.

If True, will return the parameters for this estimator and contained subobjects that are estimators.

Parameter names mapped to their values.

Transform data back to its original space.

Data to be transformed back. Must have the same number of components as the data used to train the model.

Set output container.

See Introducing the set_output API for an example on how to use the API.

Configure output of transform and fit_transform.

"default": Default output format of a transformer

"pandas": DataFrame output

"polars": Polars output

None: Transform configuration is unchanged

Added in version 1.4: "polars" option was added.

Set the parameters of this estimator.

The method works on simple estimators as well as on nested objects (such as Pipeline). The latter have parameters of the form <component>__<parameter> so that it’s possible to update each component of a nested object.

Estimator parameters.

Encode the data as a sparse combination of the dictionary atoms.

Coding method is determined by the object parameter transform_algorithm.

Test data to be transformed, must have the same number of features as the data used to train the model.

**Examples:**

Example 1 (unknown):
```unknown
(U^*,V^*) = argmin 0.5 || X - U V ||_Fro^2 + alpha * || U ||_1,1
            (U,V)
            with || V_k ||_2 <= 1 for all  0 <= k < n_components
```

Example 2 (csharp):
```csharp
>>> import numpy as np
>>> from sklearn.datasets import make_sparse_coded_signal
>>> from sklearn.decomposition import DictionaryLearning
>>> X, dictionary, code = make_sparse_coded_signal(
...     n_samples=30, n_components=15, n_features=20, n_nonzero_coefs=10,
...     random_state=42,
... )
>>> dict_learner = DictionaryLearning(
...     n_components=15, transform_algorithm='lasso_lars', transform_alpha=0.1,
...     random_state=42,
... )
>>> X_transformed = dict_learner.fit(X).transform(X)
```

Example 3 (unknown):
```unknown
>>> np.mean(X_transformed == 0)
np.float64(0.527)
```

Example 4 (unknown):
```unknown
>>> X_hat = X_transformed @ dict_learner.components_
>>> np.mean(np.sum((X_hat - X) ** 2, axis=1) / np.sum(X ** 2, axis=1))
np.float64(0.056)
```

---

## 

**URL:** https://scikit-learn.org/stable/_sources/modules/sgd.rst.txt

---

## 7.2. Feature extraction#

**URL:** https://scikit-learn.org/stable/modules/feature_extraction.html

**Contents:**
- 7.2. Feature extraction#
- 7.2.1. Loading features from dicts#
- 7.2.2. Feature hashing#
- 7.2.3. Text feature extraction#
  - 7.2.3.1. The Bag of Words representation#
  - 7.2.3.2. Sparsity#
  - 7.2.3.3. Common Vectorizer usage#
  - 7.2.3.4. Using stop words#
  - 7.2.3.5. Tf–idf term weighting#
  - 7.2.3.6. Decoding text files#

The sklearn.feature_extraction module can be used to extract features in a format supported by machine learning algorithms from datasets consisting of formats such as text and image.

Feature extraction is very different from Feature selection: the former consists of transforming arbitrary data, such as text or images, into numerical features usable for machine learning. The latter is a machine learning technique applied to these features.

The class DictVectorizer can be used to convert feature arrays represented as lists of standard Python dict objects to the NumPy/SciPy representation used by scikit-learn estimators.

While not particularly fast to process, Python’s dict has the advantages of being convenient to use, being sparse (absent features need not be stored) and storing feature names in addition to values.

DictVectorizer implements what is called one-of-K or “one-hot” coding for categorical (aka nominal, discrete) features. Categorical features are “attribute-value” pairs where the value is restricted to a list of discrete possibilities without ordering (e.g. topic identifiers, types of objects, tags, names…).

In the following, “city” is a categorical attribute while “temperature” is a traditional numerical feature:

DictVectorizer accepts multiple string values for one feature, like, e.g., multiple categories for a movie.

Assume a database classifies each movie using some categories (not mandatory) and its year of release.

DictVectorizer is also a useful representation transformation for training sequence classifiers in Natural Language Processing models that typically work by extracting feature windows around a particular word of interest.

For example, suppose that we have a first algorithm that extracts Part of Speech (PoS) tags that we want to use as complementary tags for training a sequence classifier (e.g. a chunker). The following dict could be such a window of features extracted around the word ‘sat’ in the sentence ‘The cat sat on the mat.’:

This description can be vectorized into a sparse two-dimensional matrix suitable for feeding into a classifier (maybe after being piped into a TfidfTransformer for normalization):

As you can imagine, if one extracts such a context around each individual word of a corpus of documents the resulting matrix will be very wide (many one-hot-features) with most of them being valued to zero most of the time. So as to make the resulting data structure able to fit in memory the DictVectorizer class uses a scipy.sparse matrix by default instead of a numpy.ndarray.

The class FeatureHasher is a high-speed, low-memory vectorizer that uses a technique known as feature hashing, or the “hashing trick”. Instead of building a hash table of the features encountered in training, as the vectorizers do, instances of FeatureHasher apply a hash function to the features to determine their column index in sample matrices directly. The result is increased speed and reduced memory usage, at the expense of inspectability; the hasher does not remember what the input features looked like and has no inverse_transform method.

Since the hash function might cause collisions between (unrelated) features, a signed hash function is used and the sign of the hash value determines the sign of the value stored in the output matrix for a feature. This way, collisions are likely to cancel out rather than accumulate error, and the expected mean of any output feature’s value is zero. This mechanism is enabled by default with alternate_sign=True and is particularly useful for small hash table sizes (n_features < 10000). For large hash table sizes, it can be disabled, to allow the output to be passed to estimators like MultinomialNB or chi2 feature selectors that expect non-negative inputs.

FeatureHasher accepts either mappings (like Python’s dict and its variants in the collections module), (feature, value) pairs, or strings, depending on the constructor parameter input_type. Mappings are treated as lists of (feature, value) pairs, while single strings have an implicit value of 1, so ['feat1', 'feat2', 'feat3'] is interpreted as [('feat1', 1), ('feat2', 1), ('feat3', 1)]. If a single feature occurs multiple times in a sample, the associated values will be summed (so ('feat', 2) and ('feat', 3.5) become ('feat', 5.5)). The output from FeatureHasher is always a scipy.sparse matrix in the CSR format.

Feature hashing can be employed in document classification, but unlike CountVectorizer, FeatureHasher does not do word splitting or any other preprocessing except Unicode-to-UTF-8 encoding; see Vectorizing a large text corpus with the hashing trick, below, for a combined tokenizer/hasher.

As an example, consider a word-level natural language processing task that needs features extracted from (token, part_of_speech) pairs. One could use a Python generator function to extract features:

Then, the raw_X to be fed to FeatureHasher.transform can be constructed using:

and fed to a hasher with:

to get a scipy.sparse matrix X.

Note the use of a generator comprehension, which introduces laziness into the feature extraction: tokens are only processed on demand from the hasher.

FeatureHasher uses the signed 32-bit variant of MurmurHash3. As a result (and because of limitations in scipy.sparse), the maximum number of features supported is currently \(2^{31} - 1\).

The original formulation of the hashing trick by Weinberger et al. used two separate hash functions \(h\) and \(\xi\) to determine the column index and sign of a feature, respectively. The present implementation works under the assumption that the sign bit of MurmurHash3 is independent of its other bits.

Since a simple modulo is used to transform the hash function to a column index, it is advisable to use a power of two as the n_features parameter; otherwise the features will not be mapped evenly to the columns.

Kilian Weinberger, Anirban Dasgupta, John Langford, Alex Smola and Josh Attenberg (2009). Feature hashing for large scale multitask learning. Proc. ICML.

Text Analysis is a major application field for machine learning algorithms. However the raw data, a sequence of symbols, cannot be fed directly to the algorithms themselves as most of them expect numerical feature vectors with a fixed size rather than the raw text documents with variable length.

In order to address this, scikit-learn provides utilities for the most common ways to extract numerical features from text content, namely:

tokenizing strings and giving an integer id for each possible token, for instance by using white-spaces and punctuation as token separators.

counting the occurrences of tokens in each document.

normalizing and weighting with diminishing importance tokens that occur in the majority of samples / documents.

In this scheme, features and samples are defined as follows:

each individual token occurrence frequency (normalized or not) is treated as a feature.

the vector of all the token frequencies for a given document is considered a multivariate sample.

A corpus of documents can thus be represented by a matrix with one row per document and one column per token (e.g. word) occurring in the corpus.

We call vectorization the general process of turning a collection of text documents into numerical feature vectors. This specific strategy (tokenization, counting and normalization) is called the Bag of Words or “Bag of n-grams” representation. Documents are described by word occurrences while completely ignoring the relative position information of the words in the document.

As most documents will typically use a very small subset of the words used in the corpus, the resulting matrix will have many feature values that are zeros (typically more than 99% of them).

For instance a collection of 10,000 short text documents (such as emails) will use a vocabulary with a size in the order of 100,000 unique words in total while each document will use 100 to 1000 unique words individually.

In order to be able to store such a matrix in memory but also to speed up algebraic operations matrix / vector, implementations will typically use a sparse representation such as the implementations available in the scipy.sparse package.

CountVectorizer implements both tokenization and occurrence counting in a single class:

This model has many parameters, however the default values are quite reasonable (please see the reference documentation for the details):

Let’s use it to tokenize and count the word occurrences of a minimalistic corpus of text documents:

The default configuration tokenizes the string by extracting words of at least 2 letters. The specific function that does this step can be requested explicitly:

Each term found by the analyzer during the fit is assigned a unique integer index corresponding to a column in the resulting matrix. This interpretation of the columns can be retrieved as follows:

The converse mapping from feature name to column index is stored in the vocabulary_ attribute of the vectorizer:

Hence words that were not seen in the training corpus will be completely ignored in future calls to the transform method:

Note that in the previous corpus, the first and the last documents have exactly the same words hence are encoded in equal vectors. In particular we lose the information that the last document is an interrogative form. To preserve some of the local ordering information we can extract 2-grams of words in addition to the 1-grams (individual words):

The vocabulary extracted by this vectorizer is hence much bigger and can now resolve ambiguities encoded in local positioning patterns:

In particular the interrogative form “Is this” is only present in the last document:

Stop words are words like “and”, “the”, “him”, which are presumed to be uninformative in representing the content of a text, and which may be removed to avoid them being construed as informative for prediction. Sometimes, however, similar words are useful for prediction, such as in classifying writing style or personality.

There are several known issues in our provided ‘english’ stop word list. It does not aim to be a general, ‘one-size-fits-all’ solution as some tasks may require a more custom solution. See [NQY18] for more details.

Please take care in choosing a stop word list. Popular stop word lists may include words that are highly informative to some tasks, such as computer.

You should also make sure that the stop word list has had the same preprocessing and tokenization applied as the one used in the vectorizer. The word we’ve is split into we and ve by CountVectorizer’s default tokenizer, so if we’ve is in stop_words, but ve is not, ve will be retained from we’ve in transformed text. Our vectorizers will try to identify and warn about some kinds of inconsistencies.

J. Nothman, H. Qin and R. Yurchak (2018). “Stop Word Lists in Free Open-source Software Packages”. In Proc. Workshop for NLP Open Source Software.

In a large text corpus, some words will be very present (e.g. “the”, “a”, “is” in English) hence carrying very little meaningful information about the actual contents of the document. If we were to feed the direct count data directly to a classifier those very frequent terms would shadow the frequencies of rarer yet more interesting terms.

In order to re-weight the count features into floating point values suitable for usage by a classifier it is very common to use the tf–idf transform.

Tf means term-frequency while tf–idf means term-frequency times inverse document-frequency: \(\text{tf-idf(t,d)}=\text{tf(t,d)} \times \text{idf(t)}\).

Using the TfidfTransformer’s default settings, TfidfTransformer(norm='l2', use_idf=True, smooth_idf=True, sublinear_tf=False) the term frequency, the number of times a term occurs in a given document, is multiplied with idf component, which is computed as

\(\text{idf}(t) = \log{\frac{1 + n}{1+\text{df}(t)}} + 1\),

where \(n\) is the total number of documents in the document set, and \(\text{df}(t)\) is the number of documents in the document set that contain term \(t\). The resulting tf-idf vectors are then normalized by the Euclidean norm:

\(v_{norm} = \frac{v}{||v||_2} = \frac{v}{\sqrt{v{_1}^2 + v{_2}^2 + \dots + v{_n}^2}}\).

This was originally a term weighting scheme developed for information retrieval (as a ranking function for search engines results) that has also found good use in document classification and clustering.

The following sections contain further explanations and examples that illustrate how the tf-idfs are computed exactly and how the tf-idfs computed in scikit-learn’s TfidfTransformer and TfidfVectorizer differ slightly from the standard textbook notation that defines the idf as

\(\text{idf}(t) = \log{\frac{n}{1+\text{df}(t)}}.\)

In the TfidfTransformer and TfidfVectorizer with smooth_idf=False, the “1” count is added to the idf instead of the idf’s denominator:

\(\text{idf}(t) = \log{\frac{n}{\text{df}(t)}} + 1\)

This normalization is implemented by the TfidfTransformer class:

Again please see the reference documentation for the details on all the parameters.

Let’s take an example with the following counts. The first term is present 100% of the time hence not very interesting. The two other features only in less than 50% of the time hence probably more representative of the content of the documents:

Each row is normalized to have unit Euclidean norm:

\(v_{norm} = \frac{v}{||v||_2} = \frac{v}{\sqrt{v{_1}^2 + v{_2}^2 + \dots + v{_n}^2}}\)

For example, we can compute the tf-idf of the first term in the first document in the counts array as follows:

\(\text{df}(t)_{\text{term1}} = 6\)

\(\text{idf}(t)_{\text{term1}} = \log \frac{n}{\text{df}(t)} + 1 = \log(1)+1 = 1\)

\(\text{tf-idf}_{\text{term1}} = \text{tf} \times \text{idf} = 3 \times 1 = 3\)

Now, if we repeat this computation for the remaining 2 terms in the document, we get

\(\text{tf-idf}_{\text{term2}} = 0 \times (\log(6/1)+1) = 0\)

\(\text{tf-idf}_{\text{term3}} = 1 \times (\log(6/2)+1) \approx 2.0986\)

and the vector of raw tf-idfs:

\(\text{tf-idf}_{\text{raw}} = [3, 0, 2.0986].\)

Then, applying the Euclidean (L2) norm, we obtain the following tf-idfs for document 1:

\(\frac{[3, 0, 2.0986]}{\sqrt{\big(3^2 + 0^2 + 2.0986^2\big)}} = [ 0.819, 0, 0.573].\)

Furthermore, the default parameter smooth_idf=True adds “1” to the numerator and denominator as if an extra document was seen containing every term in the collection exactly once, which prevents zero divisions:

\(\text{idf}(t) = \log{\frac{1 + n}{1+\text{df}(t)}} + 1\)

Using this modification, the tf-idf of the third term in document 1 changes to 1.8473:

\(\text{tf-idf}_{\text{term3}} = 1 \times \log(7/3)+1 \approx 1.8473\)

And the L2-normalized tf-idf changes to

\(\frac{[3, 0, 1.8473]}{\sqrt{\big(3^2 + 0^2 + 1.8473^2\big)}} = [0.8515, 0, 0.5243]\):

The weights of each feature computed by the fit method call are stored in a model attribute:

As tf-idf is very often used for text features, there is also another class called TfidfVectorizer that combines all the options of CountVectorizer and TfidfTransformer in a single model:

While the tf-idf normalization is often very useful, there might be cases where the binary occurrence markers might offer better features. This can be achieved by using the binary parameter of CountVectorizer. In particular, some estimators such as Bernoulli Naive Bayes explicitly model discrete boolean random variables. Also, very short texts are likely to have noisy tf-idf values while the binary occurrence info is more stable.

As usual the best way to adjust the feature extraction parameters is to use a cross-validated grid search, for instance by pipelining the feature extractor with a classifier:

Sample pipeline for text feature extraction and evaluation

Classification of text documents using sparse features: Feature encoding using a Tf-idf-weighted document-term sparse matrix.

FeatureHasher and DictVectorizer Comparison: Efficiency comparison of the different feature extractors.

Clustering text documents using k-means: Document clustering and comparison with HashingVectorizer.

Sample pipeline for text feature extraction and evaluation: Tuning hyperparamters of TfidfVectorizer as part of a pipeline.

Text is made of characters, but files are made of bytes. These bytes represent characters according to some encoding. To work with text files in Python, their bytes must be decoded to a character set called Unicode. Common encodings are ASCII, Latin-1 (Western Europe), KOI8-R (Russian) and the universal encodings UTF-8 and UTF-16. Many others exist.

An encoding can also be called a ‘character set’, but this term is less accurate: several encodings can exist for a single character set.

The text feature extractors in scikit-learn know how to decode text files, but only if you tell them what encoding the files are in. The CountVectorizer takes an encoding parameter for this purpose. For modern text files, the correct encoding is probably UTF-8, which is therefore the default (encoding="utf-8").

If the text you are loading is not actually encoded with UTF-8, however, you will get a UnicodeDecodeError. The vectorizers can be told to be silent about decoding errors by setting the decode_error parameter to either "ignore" or "replace". See the documentation for the Python function bytes.decode for more details (type help(bytes.decode) at the Python prompt).

If you are having trouble decoding text, here are some things to try:

Find out what the actual encoding of the text is. The file might come with a header or README that tells you the encoding, or there might be some standard encoding you can assume based on where the text comes from.

You may be able to find out what kind of encoding it is in general using the UNIX command file. The Python chardet module comes with a script called chardetect.py that will guess the specific encoding, though you cannot rely on its guess being correct.

You could try UTF-8 and disregard the errors. You can decode byte strings with bytes.decode(errors='replace') to replace all decoding errors with a meaningless character, or set decode_error='replace' in the vectorizer. This may damage the usefulness of your features.

Real text may come from a variety of sources that may have used different encodings, or even be sloppily decoded in a different encoding than the one it was encoded with. This is common in text retrieved from the Web. The Python package ftfy can automatically sort out some classes of decoding errors, so you could try decoding the unknown text as latin-1 and then using ftfy to fix errors.

If the text is in a mish-mash of encodings that is simply too hard to sort out (which is the case for the 20 Newsgroups dataset), you can fall back on a simple single-byte encoding such as latin-1. Some text may display incorrectly, but at least the same sequence of bytes will always represent the same feature.

For example, the following snippet uses chardet (not shipped with scikit-learn, must be installed separately) to figure out the encoding of three texts. It then vectorizes the texts and prints the learned vocabulary. The output is not shown here.

(Depending on the version of chardet, it might get the first one wrong.)

For an introduction to Unicode and character encodings in general, see Joel Spolsky’s Absolute Minimum Every Software Developer Must Know About Unicode.

The bag of words representation is quite simplistic but surprisingly useful in practice.

In particular in a supervised setting it can be successfully combined with fast and scalable linear models to train document classifiers, for instance:

Classification of text documents using sparse features

In an unsupervised setting it can be used to group similar documents together by applying clustering algorithms such as K-means:

Clustering text documents using k-means

Finally it is possible to discover the main topics of a corpus by relaxing the hard assignment constraint of clustering, for instance by using Non-negative matrix factorization (NMF or NNMF):

Topic extraction with Non-negative Matrix Factorization and Latent Dirichlet Allocation

A collection of unigrams (what bag of words is) cannot capture phrases and multi-word expressions, effectively disregarding any word order dependence. Additionally, the bag of words model doesn’t account for potential misspellings or word derivations.

N-grams to the rescue! Instead of building a simple collection of unigrams (n=1), one might prefer a collection of bigrams (n=2), where occurrences of pairs of consecutive words are counted.

One might alternatively consider a collection of character n-grams, a representation resilient against misspellings and derivations.

For example, let’s say we’re dealing with a corpus of two documents: ['words', 'wprds']. The second document contains a misspelling of the word ‘words’. A simple bag of words representation would consider these two as very distinct documents, differing in both of the two possible features. A character 2-gram representation, however, would find the documents matching in 4 out of 8 features, which may help the preferred classifier decide better:

In the above example, char_wb analyzer is used, which creates n-grams only from characters inside word boundaries (padded with space on each side). The char analyzer, alternatively, creates n-grams that span across words:

The word boundaries-aware variant char_wb is especially interesting for languages that use white-spaces for word separation as it generates significantly less noisy features than the raw char variant in that case. For such languages it can increase both the predictive accuracy and convergence speed of classifiers trained using such features while retaining the robustness with regards to misspellings and word derivations.

While some local positioning information can be preserved by extracting n-grams instead of individual words, bag of words and bag of n-grams destroy most of the inner structure of the document and hence most of the meaning carried by that internal structure.

In order to address the wider task of Natural Language Understanding, the local structure of sentences and paragraphs should thus be taken into account. Many such models will thus be casted as “Structured output” problems which are currently outside of the scope of scikit-learn.

The above vectorization scheme is simple but the fact that it holds an in-memory mapping from the string tokens to the integer feature indices (the vocabulary_ attribute) causes several problems when dealing with large datasets:

the larger the corpus, the larger the vocabulary will grow and hence the memory use too,

fitting requires the allocation of intermediate data structures of size proportional to that of the original dataset.

building the word-mapping requires a full pass over the dataset hence it is not possible to fit text classifiers in a strictly online manner.

pickling and un-pickling vectorizers with a large vocabulary_ can be very slow (typically much slower than pickling / un-pickling flat data structures such as a NumPy array of the same size),

it is not easily possible to split the vectorization work into concurrent sub tasks as the vocabulary_ attribute would have to be a shared state with a fine grained synchronization barrier: the mapping from token string to feature index is dependent on the ordering of the first occurrence of each token hence would have to be shared, potentially harming the concurrent workers’ performance to the point of making them slower than the sequential variant.

It is possible to overcome those limitations by combining the “hashing trick” (Feature hashing) implemented by the FeatureHasher class and the text preprocessing and tokenization features of the CountVectorizer.

This combination is implemented in HashingVectorizer, a transformer class that is mostly API compatible with CountVectorizer. HashingVectorizer is stateless, meaning that you don’t have to call fit on it:

You can see that 16 non-zero feature tokens were extracted in the vector output: this is less than the 19 non-zeros extracted previously by the CountVectorizer on the same toy corpus. The discrepancy comes from hash function collisions because of the low value of the n_features parameter.

In a real world setting, the n_features parameter can be left to its default value of 2 ** 20 (roughly one million possible features). If memory or downstream models size is an issue selecting a lower value such as 2 ** 18 might help without introducing too many additional collisions on typical text classification tasks.

Note that the dimensionality does not affect the CPU training time of algorithms which operate on CSR matrices (LinearSVC(dual=True), Perceptron, SGDClassifier) but it does for algorithms that work with CSC matrices (LinearSVC(dual=False), Lasso(), etc.).

Let’s try again with the default setting:

We no longer get the collisions, but this comes at the expense of a much larger dimensionality of the output space. Of course, other terms than the 19 used here might still collide with each other.

The HashingVectorizer also comes with the following limitations:

it is not possible to invert the model (no inverse_transform method), nor to access the original string representation of the features, because of the one-way nature of the hash function that performs the mapping.

it does not provide IDF weighting as that would introduce statefulness in the model. A TfidfTransformer can be appended to it in a pipeline if required.

An interesting development of using a HashingVectorizer is the ability to perform out-of-core scaling. This means that we can learn from data that does not fit into the computer’s main memory.

A strategy to implement out-of-core scaling is to stream data to the estimator in mini-batches. Each mini-batch is vectorized using HashingVectorizer so as to guarantee that the input space of the estimator has always the same dimensionality. The amount of memory used at any time is thus bounded by the size of a mini-batch. Although there is no limit to the amount of data that can be ingested using such an approach, from a practical point of view the learning time is often limited by the CPU time one wants to spend on the task.

For a full-fledged example of out-of-core scaling in a text classification task see Out-of-core classification of text documents.

It is possible to customize the behavior by passing a callable to the vectorizer constructor:

In particular we name:

preprocessor: a callable that takes an entire document as input (as a single string), and returns a possibly transformed version of the document, still as an entire string. This can be used to remove HTML tags, lowercase the entire document, etc.

tokenizer: a callable that takes the output from the preprocessor and splits it into tokens, then returns a list of these.

analyzer: a callable that replaces the preprocessor and tokenizer. The default analyzers all call the preprocessor and tokenizer, but custom analyzers will skip this. N-gram extraction and stop word filtering take place at the analyzer level, so a custom analyzer may have to reproduce these steps.

(Lucene users might recognize these names, but be aware that scikit-learn concepts may not map one-to-one onto Lucene concepts.)

To make the preprocessor, tokenizer and analyzers aware of the model parameters it is possible to derive from the class and override the build_preprocessor, build_tokenizer and build_analyzer factory methods instead of passing custom functions.

If documents are pre-tokenized by an external package, then store them in files (or strings) with the tokens separated by whitespace and pass analyzer=str.split

Fancy token-level analysis such as stemming, lemmatizing, compound splitting, filtering based on part-of-speech, etc. are not included in the scikit-learn codebase, but can be added by customizing either the tokenizer or the analyzer. Here’s a CountVectorizer with a tokenizer and lemmatizer using NLTK:

(Note that this will not filter out punctuation.)

The following example will, for instance, transform some British spelling to American spelling:

for other styles of preprocessing; examples include stemming, lemmatization, or normalizing numerical tokens, with the latter illustrated in:

Biclustering documents with the Spectral Co-clustering algorithm

Customizing the vectorizer can also be useful when handling Asian languages that do not use an explicit word separator such as whitespace.

The extract_patches_2d function extracts patches from an image stored as a two-dimensional array, or three-dimensional with color information along the third axis. For rebuilding an image from all its patches, use reconstruct_from_patches_2d. For example let us generate a 4x4 pixel picture with 3 color channels (e.g. in RGB format):

Let us now try to reconstruct the original image from the patches by averaging on overlapping areas:

The PatchExtractor class works in the same way as extract_patches_2d, only it supports multiple images as input. It is implemented as a scikit-learn transformer, so it can be used in pipelines. See:

Several estimators in scikit-learn can use connectivity information between features or samples. For instance Ward clustering (Hierarchical clustering) can cluster together only neighboring pixels of an image, thus forming contiguous patches:

For this purpose, the estimators use a ‘connectivity’ matrix, giving which samples are connected.

The function img_to_graph returns such a matrix from a 2D or 3D image. Similarly, grid_to_graph builds a connectivity matrix for images given the shape of these images.

These matrices can be used to impose connectivity in estimators that use connectivity information, such as Ward clustering (Hierarchical clustering), but also to build precomputed kernels, or similarity matrices.

A demo of structured Ward hierarchical clustering on an image of coins

Spectral clustering for image segmentation

Feature agglomeration vs. univariate selection

**Examples:**

Example 1 (json):
```json
>>> measurements = [
...     {'city': 'Dubai', 'temperature': 33.},
...     {'city': 'London', 'temperature': 12.},
...     {'city': 'San Francisco', 'temperature': 18.},
... ]

>>> from sklearn.feature_extraction import DictVectorizer
>>> vec = DictVectorizer()

>>> vec.fit_transform(measurements).toarray()
array([[ 1.,  0.,  0., 33.],
       [ 0.,  1.,  0., 12.],
       [ 0.,  0.,  1., 18.]])

>>> vec.get_feature_names_out()
array(['city=Dubai', 'city=London', 'city=San Francisco', 'temperature'], ...)
```

Example 2 (json):
```json
>>> movie_entry = [{'category': ['thriller', 'drama'], 'year': 2003},
...                {'category': ['animation', 'family'], 'year': 2011},
...                {'year': 1974}]
>>> vec.fit_transform(movie_entry).toarray()
array([[0.000e+00, 1.000e+00, 0.000e+00, 1.000e+00, 2.003e+03],
       [1.000e+00, 0.000e+00, 1.000e+00, 0.000e+00, 2.011e+03],
       [0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 1.974e+03]])
>>> vec.get_feature_names_out()
array(['category=animation', 'category=drama', 'category=family',
       'category=thriller', 'year'], ...)
>>> vec.transform({'category': ['thriller'],
...                'unseen_feature': '3'}).toarray()
array([[0., 0., 0., 1., 0.]])
```

Example 3 (unknown):
```unknown
>>> pos_window = [
...     {
...         'word-2': 'the',
...         'pos-2': 'DT',
...         'word-1': 'cat',
...         'pos-1': 'NN',
...         'word+1': 'on',
...         'pos+1': 'PP',
...     },
...     # in a real application one would extract many such dictionaries
... ]
```

Example 4 (jsx):
```jsx
>>> vec = DictVectorizer()
>>> pos_vectorized = vec.fit_transform(pos_window)
>>> pos_vectorized
<Compressed Sparse...dtype 'float64'
  with 6 stored elements and shape (1, 6)>
>>> pos_vectorized.toarray()
array([[1., 1., 1., 1., 1., 1.]])
>>> vec.get_feature_names_out()
array(['pos+1=PP', 'pos-1=NN', 'pos-2=DT', 'word+1=on', 'word-1=cat',
       'word-2=the'], ...)
```

---

## CalibrationDisplay#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.calibration.CalibrationDisplay.html

**Contents:**
- CalibrationDisplay#
- Gallery examples#

Calibration curve (also known as reliability diagram) visualization.

It is recommended to use from_estimator or from_predictions to create a CalibrationDisplay. All parameters are stored as attributes.

Read more about calibration in the User Guide and more about the scikit-learn visualization API in Visualizations.

For an example on how to use the visualization, see Probability Calibration curves.

Added in version 1.0.

The proportion of samples whose class is the positive class (fraction of positives), in each bin.

The mean predicted probability in each bin.

Probability estimates for the positive class, for each sample.

Name of estimator. If None, the estimator name is not shown.

The positive class when calibration curve computed. If not None, this value is displayed in the x- and y-axes labels.

Added in version 1.1.

Axes with calibration curve.

Figure containing the curve.

Compute true and predicted probabilities for a calibration curve.

Plot calibration curve using true and predicted labels.

Plot calibration curve using an estimator and data.

Plot calibration curve using a binary classifier and data.

A calibration curve, also known as a reliability diagram, uses inputs from a binary classifier and plots the average predicted probability for each bin against the fraction of positive classes, on the y-axis.

Extra keyword arguments will be passed to matplotlib.pyplot.plot.

Read more about calibration in the User Guide and more about the scikit-learn visualization API in Visualizations.

Added in version 1.0.

Fitted classifier or a fitted Pipeline in which the last estimator is a classifier. The classifier must have a predict_proba method.

Binary target values.

Number of bins to discretize the [0, 1] interval into when calculating the calibration curve. A bigger number requires more data.

Strategy used to define the widths of the bins.

'uniform': The bins have identical widths.

'quantile': The bins have the same number of samples and depend on predicted probabilities.

The positive class when computing the calibration curve. By default, estimators.classes_[1] is considered as the positive class.

Added in version 1.1.

Name for labeling curve. If None, the name of the estimator is used.

Axes object to plot on. If None, a new figure and axes is created.

If True, plots a reference line representing a perfectly calibrated classifier.

Keyword arguments to be passed to matplotlib.pyplot.plot.

Object that stores computed values.

Plot calibration curve using true and predicted labels.

Plot calibration curve using true labels and predicted probabilities.

Calibration curve, also known as reliability diagram, uses inputs from a binary classifier and plots the average predicted probability for each bin against the fraction of positive classes, on the y-axis.

Extra keyword arguments will be passed to matplotlib.pyplot.plot.

Read more about calibration in the User Guide and more about the scikit-learn visualization API in Visualizations.

Added in version 1.0.

The predicted probabilities of the positive class.

Number of bins to discretize the [0, 1] interval into when calculating the calibration curve. A bigger number requires more data.

Strategy used to define the widths of the bins.

'uniform': The bins have identical widths.

'quantile': The bins have the same number of samples and depend on predicted probabilities.

The positive class when computing the calibration curve. When pos_label=None, if y_true is in {-1, 1} or {0, 1}, pos_label is set to 1, otherwise an error will be raised.

Added in version 1.1.

Name for labeling curve.

Axes object to plot on. If None, a new figure and axes is created.

If True, plots a reference line representing a perfectly calibrated classifier.

Keyword arguments to be passed to matplotlib.pyplot.plot.

Object that stores computed values.

Plot calibration curve using an estimator and data.

Extra keyword arguments will be passed to matplotlib.pyplot.plot.

Axes object to plot on. If None, a new figure and axes is created.

Name for labeling curve. If None, use estimator_name if not None, otherwise no labeling is shown.

If True, plots a reference line representing a perfectly calibrated classifier.

Keyword arguments to be passed to matplotlib.pyplot.plot.

Object that stores computed values.

Probability Calibration curves

Comparison of Calibration of Classifiers

Plot classification probability

Release Highlights for scikit-learn 1.8

**Examples:**

Example 1 (sql):
```sql
>>> from sklearn.datasets import make_classification
>>> from sklearn.model_selection import train_test_split
>>> from sklearn.linear_model import LogisticRegression
>>> from sklearn.calibration import calibration_curve, CalibrationDisplay
>>> X, y = make_classification(random_state=0)
>>> X_train, X_test, y_train, y_test = train_test_split(
...     X, y, random_state=0)
>>> clf = LogisticRegression(random_state=0)
>>> clf.fit(X_train, y_train)
LogisticRegression(random_state=0)
>>> y_prob = clf.predict_proba(X_test)[:, 1]
>>> prob_true, prob_pred = calibration_curve(y_test, y_prob, n_bins=10)
>>> disp = CalibrationDisplay(prob_true, prob_pred, y_prob)
>>> disp.plot()
<...>
```

Example 2 (sql):
```sql
>>> import matplotlib.pyplot as plt
>>> from sklearn.datasets import make_classification
>>> from sklearn.model_selection import train_test_split
>>> from sklearn.linear_model import LogisticRegression
>>> from sklearn.calibration import CalibrationDisplay
>>> X, y = make_classification(random_state=0)
>>> X_train, X_test, y_train, y_test = train_test_split(
...     X, y, random_state=0)
>>> clf = LogisticRegression(random_state=0)
>>> clf.fit(X_train, y_train)
LogisticRegression(random_state=0)
>>> disp = CalibrationDisplay.from_estimator(clf, X_test, y_test)
>>> plt.show()
```

Example 3 (sql):
```sql
>>> import matplotlib.pyplot as plt
>>> from sklearn.datasets import make_classification
>>> from sklearn.model_selection import train_test_split
>>> from sklearn.linear_model import LogisticRegression
>>> from sklearn.calibration import CalibrationDisplay
>>> X, y = make_classification(random_state=0)
>>> X_train, X_test, y_train, y_test = train_test_split(
...     X, y, random_state=0)
>>> clf = LogisticRegression(random_state=0)
>>> clf.fit(X_train, y_train)
LogisticRegression(random_state=0)
>>> y_prob = clf.predict_proba(X_test)[:, 1]
>>> disp = CalibrationDisplay.from_predictions(y_test, y_prob)
>>> plt.show()
```

---

## MultinomialNB#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html

**Contents:**
- MultinomialNB#
- Gallery examples#

Naive Bayes classifier for multinomial models.

The multinomial Naive Bayes classifier is suitable for classification with discrete features (e.g., word counts for text classification). The multinomial distribution normally requires integer feature counts. However, in practice, fractional counts such as tf-idf may also work.

Read more in the User Guide.

Additive (Laplace/Lidstone) smoothing parameter (set alpha=0 and force_alpha=True, for no smoothing).

If False and alpha is less than 1e-10, it will set alpha to 1e-10. If True, alpha will remain unchanged. This may cause numerical errors if alpha is too close to 0.

Added in version 1.2.

Changed in version 1.4: The default value of force_alpha changed to True.

Whether to learn class prior probabilities or not. If false, a uniform prior will be used.

Prior probabilities of the classes. If specified, the priors are not adjusted according to the data.

Number of samples encountered for each class during fitting. This value is weighted by the sample weight when provided.

Smoothed empirical log probability for each class.

Class labels known to the classifier

Number of samples encountered for each (class, feature) during fitting. This value is weighted by the sample weight when provided.

Empirical log probability of features given a class, P(x_i|y).

Number of features seen during fit.

Added in version 0.24.

Names of features seen during fit. Defined only when X has feature names that are all strings.

Added in version 1.0.

Naive Bayes classifier for multivariate Bernoulli models.

Naive Bayes classifier for categorical features.

Complement Naive Bayes classifier.

Gaussian Naive Bayes.

C.D. Manning, P. Raghavan and H. Schuetze (2008). Introduction to Information Retrieval. Cambridge University Press, pp. 234-265. https://nlp.stanford.edu/IR-book/html/htmledition/naive-bayes-text-classification-1.html

Fit Naive Bayes classifier according to X, y.

Training vectors, where n_samples is the number of samples and n_features is the number of features.

Weights applied to individual samples (1. for unweighted).

Returns the instance itself.

Get metadata routing of this object.

Please check User Guide on how the routing mechanism works.

A MetadataRequest encapsulating routing information.

Get parameters for this estimator.

If True, will return the parameters for this estimator and contained subobjects that are estimators.

Parameter names mapped to their values.

Incremental fit on a batch of samples.

This method is expected to be called several times consecutively on different chunks of a dataset so as to implement out-of-core or online learning.

This is especially useful when the whole dataset is too big to fit in memory at once.

This method has some performance overhead hence it is better to call partial_fit on chunks of data that are as large as possible (as long as fitting in the memory budget) to hide the overhead.

Training vectors, where n_samples is the number of samples and n_features is the number of features.

List of all the classes that can possibly appear in the y vector.

Must be provided at the first call to partial_fit, can be omitted in subsequent calls.

Weights applied to individual samples (1. for unweighted).

Returns the instance itself.

Perform classification on an array of test vectors X.

Predicted target values for X.

Return joint log probability estimates for the test vector X.

For each row x of X and class y, the joint log probability is given by log P(x, y) = log P(y) + log P(x|y), where log P(y) is the class prior probability and log P(x|y) is the class-conditional probability.

Returns the joint log-probability of the samples for each class in the model. The columns correspond to the classes in sorted order, as they appear in the attribute classes_.

Return log-probability estimates for the test vector X.

Returns the log-probability of the samples for each class in the model. The columns correspond to the classes in sorted order, as they appear in the attribute classes_.

Return probability estimates for the test vector X.

Returns the probability of the samples for each class in the model. The columns correspond to the classes in sorted order, as they appear in the attribute classes_.

Return accuracy on provided data and labels.

In multi-label classification, this is the subset accuracy which is a harsh metric since you require for each sample that each label set be correctly predicted.

Mean accuracy of self.predict(X) w.r.t. y.

Configure whether metadata should be requested to be passed to the fit method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to fit if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to fit.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Added in version 1.3.

Metadata routing for sample_weight parameter in fit.

Set the parameters of this estimator.

The method works on simple estimators as well as on nested objects (such as Pipeline). The latter have parameters of the form <component>__<parameter> so that it’s possible to update each component of a nested object.

Estimator parameters.

Configure whether metadata should be requested to be passed to the partial_fit method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to partial_fit if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to partial_fit.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Added in version 1.3.

Metadata routing for classes parameter in partial_fit.

Metadata routing for sample_weight parameter in partial_fit.

Configure whether metadata should be requested to be passed to the score method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to score if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to score.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Added in version 1.3.

Metadata routing for sample_weight parameter in score.

Out-of-core classification of text documents

**Examples:**

Example 1 (json):
```json
>>> import numpy as np
>>> rng = np.random.RandomState(1)
>>> X = rng.randint(5, size=(6, 100))
>>> y = np.array([1, 2, 3, 4, 5, 6])
>>> from sklearn.naive_bayes import MultinomialNB
>>> clf = MultinomialNB()
>>> clf.fit(X, y)
MultinomialNB()
>>> print(clf.predict(X[2:3]))
[3]
```

---

## 1.3. Kernel ridge regression#

**URL:** https://scikit-learn.org/stable/modules/kernel_ridge.html

**Contents:**
- 1.3. Kernel ridge regression#

Kernel ridge regression (KRR) [M2012] combines Ridge regression and classification (linear least squares with \(L_2\)-norm regularization) with the kernel trick. It thus learns a linear function in the space induced by the respective kernel and the data. For non-linear kernels, this corresponds to a non-linear function in the original space.

The form of the model learned by KernelRidge is identical to support vector regression (SVR). However, different loss functions are used: KRR uses squared error loss while support vector regression uses \(\epsilon\)-insensitive loss, both combined with \(L_2\) regularization. In contrast to SVR, fitting KernelRidge can be done in closed-form and is typically faster for medium-sized datasets. On the other hand, the learned model is non-sparse and thus slower than SVR, which learns a sparse model for \(\epsilon > 0\), at prediction-time.

The following figure compares KernelRidge and SVR on an artificial dataset, which consists of a sinusoidal target function and strong noise added to every fifth datapoint. The learned model of KernelRidge and SVR is plotted, where both complexity/regularization and bandwidth of the RBF kernel have been optimized using grid-search. The learned functions are very similar; however, fitting KernelRidge is approximately seven times faster than fitting SVR (both with grid-search). However, prediction of 100,000 target values is more than three times faster with SVR since it has learned a sparse model using only approximately 1/3 of the 100 training datapoints as support vectors.

The next figure compares the time for fitting and prediction of KernelRidge and SVR for different sizes of the training set. Fitting KernelRidge is faster than SVR for medium-sized training sets (less than 1000 samples); however, for larger training sets SVR scales better. With regard to prediction time, SVR is faster than KernelRidge for all sizes of the training set because of the learned sparse solution. Note that the degree of sparsity and thus the prediction time depends on the parameters \(\epsilon\) and \(C\) of the SVR; \(\epsilon = 0\) would correspond to a dense model.

Comparison of kernel ridge regression and SVR

“Machine Learning: A Probabilistic Perspective” Murphy, K. P. - chapter 14.4.3, pp. 492-493, The MIT Press, 2012

---

## fowlkes_mallows_score#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.metrics.fowlkes_mallows_score.html

**Contents:**
- fowlkes_mallows_score#

Measure the similarity of two clusterings of a set of points.

Added in version 0.18.

The Fowlkes-Mallows index (FMI) is defined as the geometric mean of the precision and recall:

Where TP is the number of True Positive (i.e. the number of pairs of points that belong to the same cluster in both labels_true and labels_pred), FP is the number of False Positive (i.e. the number of pairs of points that belong to the same cluster in labels_pred but not in labels_true) and FN is the number of False Negative (i.e. the number of pairs of points that belong to the same cluster in labels_true but not in labels_pred).

The score ranges from 0 to 1. A high value indicates a good similarity between two clusters.

Read more in the User Guide.

A clustering of the data into disjoint subsets.

A clustering of the data into disjoint subsets.

Compute contingency matrix internally with sparse matrix.

Deprecated since version 1.7: The sparse parameter is deprecated and will be removed in 1.9. It has no effect.

The resulting Fowlkes-Mallows score.

E. B. Fowkles and C. L. Mallows, 1983. “A method for comparing two hierarchical clusterings”. Journal of the American Statistical Association

Wikipedia entry for the Fowlkes-Mallows Index

Perfect labelings are both homogeneous and complete, hence have score 1.0:

If classes members are completely split across different clusters, the assignment is totally random, hence the FMI is null:

**Examples:**

Example 1 (unknown):
```unknown
FMI = TP / sqrt((TP + FP) * (TP + FN))
```

Example 2 (sql):
```sql
>>> from sklearn.metrics.cluster import fowlkes_mallows_score
>>> fowlkes_mallows_score([0, 0, 1, 1], [0, 0, 1, 1])
1.0
>>> fowlkes_mallows_score([0, 0, 1, 1], [1, 1, 0, 0])
1.0
```

Example 3 (unknown):
```unknown
>>> fowlkes_mallows_score([0, 0, 0, 0], [0, 1, 2, 3])
0.0
```

---

## IsotonicRegression#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.isotonic.IsotonicRegression.html

**Contents:**
- IsotonicRegression#
- Gallery examples#

Isotonic regression model.

Read more in the User Guide.

Added in version 0.13.

Lower bound on the lowest predicted value (the minimum value may still be higher). If not set, defaults to -inf.

Upper bound on the highest predicted value (the maximum may still be lower). If not set, defaults to +inf.

Determines whether the predictions should be constrained to increase or decrease with X. ‘auto’ will decide based on the Spearman correlation estimate’s sign.

Handles how X values outside of the training domain are handled during prediction.

‘nan’, predictions will be NaN.

‘clip’, predictions will be set to the value corresponding to the nearest train interval endpoint.

‘raise’, a ValueError is raised.

Minimum value of input array X_ for left bound.

Maximum value of input array X_ for right bound.

Unique ascending X values used to interpolate the y = f(X) monotonic function.

Added in version 0.24.

De-duplicated y values suitable to interpolate the y = f(X) monotonic function.

Added in version 0.24.

The stepwise interpolating function that covers the input domain X.

Inferred value for increasing.

Ordinary least squares Linear Regression.

Gradient boosting that is a non-parametric model accepting monotonicity constraints.

Function to solve the isotonic regression model.

Ties are broken using the secondary method from de Leeuw, 1977.

Isotonic Median Regression: A Linear Programming Approach Nilotpal Chakravarti Mathematics of Operations Research Vol. 14, No. 2 (May, 1989), pp. 303-308

Isotone Optimization in R : Pool-Adjacent-Violators Algorithm (PAVA) and Active Set Methods de Leeuw, Hornik, Mair Journal of Statistical Software 2009

Correctness of Kruskal’s algorithms for monotone regression with ties de Leeuw, Psychometrica, 1977

Fit the model using X, y as training data.

Changed in version 0.24: Also accepts 2d array with 1 feature.

Weights. If set to None, all weights will be set to 1 (equal weights).

Returns an instance of self.

X is stored for future use, as transform needs X to interpolate new input data.

Fit to data, then transform it.

Fits transformer to X and y with optional parameters fit_params and returns a transformed version of X.

Target values (None for unsupervised transformations).

Additional fit parameters. Pass only if the estimator accepts additional params in its fit method.

Get output feature names for transformation.

An ndarray with one string i.e. [“isotonicregression0”].

Get metadata routing of this object.

Please check User Guide on how the routing mechanism works.

A MetadataRequest encapsulating routing information.

Get parameters for this estimator.

If True, will return the parameters for this estimator and contained subobjects that are estimators.

Parameter names mapped to their values.

Predict new data by linear interpolation.

Return coefficient of determination on test data.

The coefficient of determination, \(R^2\), is defined as \((1 - \frac{u}{v})\), where \(u\) is the residual sum of squares ((y_true - y_pred)** 2).sum() and \(v\) is the total sum of squares ((y_true - y_true.mean()) ** 2).sum(). The best possible score is 1.0 and it can be negative (because the model can be arbitrarily worse). A constant model that always predicts the expected value of y, disregarding the input features, would get a \(R^2\) score of 0.0.

Test samples. For some estimators this may be a precomputed kernel matrix or a list of generic objects instead with shape (n_samples, n_samples_fitted), where n_samples_fitted is the number of samples used in the fitting for the estimator.

\(R^2\) of self.predict(X) w.r.t. y.

The \(R^2\) score used when calling score on a regressor uses multioutput='uniform_average' from version 0.23 to keep consistent with default value of r2_score. This influences the score method of all the multioutput regressors (except for MultiOutputRegressor).

Configure whether metadata should be requested to be passed to the fit method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to fit if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to fit.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Added in version 1.3.

Metadata routing for sample_weight parameter in fit.

Set output container.

See Introducing the set_output API for an example on how to use the API.

Configure output of transform and fit_transform.

"default": Default output format of a transformer

"pandas": DataFrame output

"polars": Polars output

None: Transform configuration is unchanged

Added in version 1.4: "polars" option was added.

Set the parameters of this estimator.

The method works on simple estimators as well as on nested objects (such as Pipeline). The latter have parameters of the form <component>__<parameter> so that it’s possible to update each component of a nested object.

Estimator parameters.

Configure whether metadata should be requested to be passed to the score method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to score if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to score.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Added in version 1.3.

Metadata routing for sample_weight parameter in score.

Transform new data by linear interpolation.

Changed in version 0.24: Also accepts 2d array with 1 feature.

The transformed data.

**Examples:**

Example 1 (sql):
```sql
>>> from sklearn.datasets import make_regression
>>> from sklearn.isotonic import IsotonicRegression
>>> X, y = make_regression(n_samples=10, n_features=1, random_state=41)
>>> iso_reg = IsotonicRegression().fit(X, y)
>>> iso_reg.predict([.1, .2])
array([1.8628, 3.7256])
```

---

## chi2#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.chi2.html

**Contents:**
- chi2#
- Gallery examples#

Compute chi-squared stats between each non-negative feature and class.

This score can be used to select the n_features features with the highest values for the test chi-squared statistic from X, which must contain only non-negative integer feature values such as booleans or frequencies (e.g., term counts in document classification), relative to the classes.

If some of your features are continuous, you need to bin them, for example by using KBinsDiscretizer.

Recall that the chi-square test measures dependence between stochastic variables, so using this function “weeds out” the features that are the most likely to be independent of class and therefore irrelevant for classification.

Read more in the User Guide.

Target vector (class labels).

Chi2 statistics for each feature.

P-values for each feature.

ANOVA F-value between label/feature for classification tasks.

F-value between label/feature for regression tasks.

Complexity of this algorithm is O(n_classes * n_features).

Column Transformer with Mixed Types

**Examples:**

Example 1 (sql):
```sql
>>> import numpy as np
>>> from sklearn.feature_selection import chi2
>>> X = np.array([[1, 1, 3],
...               [0, 1, 5],
...               [5, 4, 1],
...               [6, 6, 2],
...               [1, 4, 0],
...               [0, 0, 0]])
>>> y = np.array([1, 1, 0, 0, 2, 2])
>>> chi2_stats, p_values = chi2(X, y)
>>> chi2_stats
array([15.3,  6.5       ,  8.9])
>>> p_values
array([0.000456, 0.0387, 0.0116 ])
```

---

## GammaRegressor#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.GammaRegressor.html

**Contents:**
- GammaRegressor#
- Gallery examples#

Generalized Linear Model with a Gamma distribution.

This regressor uses the ‘log’ link function.

Read more in the User Guide.

Added in version 0.23.

Constant that multiplies the L2 penalty term and determines the regularization strength. alpha = 0 is equivalent to unpenalized GLMs. In this case, the design matrix X must have full column rank (no collinearities). Values of alpha must be in the range [0.0, inf).

Specifies if a constant (a.k.a. bias or intercept) should be added to the linear predictor X @ coef_ + intercept_.

Algorithm to use in the optimization problem:

Calls scipy’s L-BFGS-B optimizer.

Uses Newton-Raphson steps (in arbitrary precision arithmetic equivalent to iterated reweighted least squares) with an inner Cholesky based solver. This solver is a good choice for n_samples >> n_features, especially with one-hot encoded categorical features with rare categories. Be aware that the memory usage of this solver has a quadratic dependency on n_features because it explicitly computes the Hessian matrix.

Added in version 1.2.

The maximal number of iterations for the solver. Values must be in the range [1, inf).

Stopping criterion. For the lbfgs solver, the iteration will stop when max{|g_j|, j = 1, ..., d} <= tol where g_j is the j-th component of the gradient (derivative) of the objective function. Values must be in the range (0.0, inf).

If set to True, reuse the solution of the previous call to fit as initialization for coef_ and intercept_.

For the lbfgs solver set verbose to any positive number for verbosity. Values must be in the range [0, inf).

Estimated coefficients for the linear predictor (X @ coef_ + intercept_) in the GLM.

Intercept (a.k.a. bias) added to linear predictor.

Number of features seen during fit.

Added in version 0.24.

Actual number of iterations used in the solver.

Names of features seen during fit. Defined only when X has feature names that are all strings.

Added in version 1.0.

Generalized Linear Model with a Poisson distribution.

Generalized Linear Model with a Tweedie distribution.

Fit a Generalized Linear Model.

Get metadata routing of this object.

Please check User Guide on how the routing mechanism works.

A MetadataRequest encapsulating routing information.

Get parameters for this estimator.

If True, will return the parameters for this estimator and contained subobjects that are estimators.

Parameter names mapped to their values.

Predict using GLM with feature matrix X.

Returns predicted values.

Compute D^2, the percentage of deviance explained.

D^2 is a generalization of the coefficient of determination R^2. R^2 uses squared error and D^2 uses the deviance of this GLM, see the User Guide.

D^2 is defined as \(D^2 = 1-\frac{D(y_{true},y_{pred})}{D_{null}}\), \(D_{null}\) is the null deviance, i.e. the deviance of a model with intercept alone, which corresponds to \(y_{pred} = \bar{y}\). The mean \(\bar{y}\) is averaged by sample_weight. Best possible score is 1.0 and it can be negative (because the model can be arbitrarily worse).

True values of target.

D^2 of self.predict(X) w.r.t. y.

Configure whether metadata should be requested to be passed to the fit method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to fit if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to fit.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Added in version 1.3.

Metadata routing for sample_weight parameter in fit.

Set the parameters of this estimator.

The method works on simple estimators as well as on nested objects (such as Pipeline). The latter have parameters of the form <component>__<parameter> so that it’s possible to update each component of a nested object.

Estimator parameters.

Configure whether metadata should be requested to be passed to the score method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to score if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to score.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Added in version 1.3.

Metadata routing for sample_weight parameter in score.

Tweedie regression on insurance claims

Release Highlights for scikit-learn 0.23

**Examples:**

Example 1 (python):
```python
>>> from sklearn import linear_model
>>> clf = linear_model.GammaRegressor()
>>> X = [[1, 2], [2, 3], [3, 4], [4, 3]]
>>> y = [19, 26, 33, 30]
>>> clf.fit(X, y)
GammaRegressor()
>>> clf.score(X, y)
np.float64(0.773)
>>> clf.coef_
array([0.073, 0.067])
>>> clf.intercept_
np.float64(2.896)
>>> clf.predict([[1, 0], [2, 8]])
array([19.483, 35.795])
```

---

## SpectralClustering#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.cluster.SpectralClustering.html

**Contents:**
- SpectralClustering#
- Gallery examples#

Apply clustering to a projection of the normalized Laplacian.

In practice Spectral Clustering is very useful when the structure of the individual clusters is highly non-convex, or more generally when a measure of the center and spread of the cluster is not a suitable description of the complete cluster, such as when clusters are nested circles on the 2D plane.

If the affinity matrix is the adjacency matrix of a graph, this method can be used to find normalized graph cuts [1], [2].

When calling fit, an affinity matrix is constructed using either a kernel function such the Gaussian (aka RBF) kernel with Euclidean distance d(X, X):

or a k-nearest neighbors connectivity matrix.

Alternatively, a user-provided affinity matrix can be specified by setting affinity='precomputed'.

Read more in the User Guide.

The dimension of the projection subspace.

The eigenvalue decomposition strategy to use. AMG requires pyamg to be installed. It can be faster on very large, sparse problems, but may also lead to instabilities. If None, then 'arpack' is used. See [4] for more details regarding 'lobpcg'.

Number of eigenvectors to use for the spectral embedding. If None, defaults to n_clusters.

A pseudo random number generator used for the initialization of the lobpcg eigenvectors decomposition when eigen_solver == 'amg', and for the K-Means initialization. Use an int to make the results deterministic across calls (See Glossary).

When using eigen_solver == 'amg', it is necessary to also fix the global numpy seed with np.random.seed(int) to get deterministic results. See pyamg/pyamg#139 for further information.

Number of time the k-means algorithm will be run with different centroid seeds. The final results will be the best output of n_init consecutive runs in terms of inertia. Only used if assign_labels='kmeans'.

Kernel coefficient for rbf, poly, sigmoid, laplacian and chi2 kernels. Ignored for affinity='nearest_neighbors', affinity='precomputed' or affinity='precomputed_nearest_neighbors'.

‘nearest_neighbors’: construct the affinity matrix by computing a graph of nearest neighbors.

‘rbf’: construct the affinity matrix using a radial basis function (RBF) kernel.

‘precomputed’: interpret X as a precomputed affinity matrix, where larger values indicate greater similarity between instances.

‘precomputed_nearest_neighbors’: interpret X as a sparse graph of precomputed distances, and construct a binary affinity matrix from the n_neighbors nearest neighbors of each instance.

one of the kernels supported by pairwise_kernels.

Only kernels that produce similarity scores (non-negative values that increase with similarity) should be used. This property is not checked by the clustering algorithm.

Number of neighbors to use when constructing the affinity matrix using the nearest neighbors method. Ignored for affinity='rbf'.

Stopping criterion for eigen decomposition of the Laplacian matrix. If eigen_tol="auto" then the passed tolerance will depend on the eigen_solver:

If eigen_solver="arpack", then eigen_tol=0.0;

If eigen_solver="lobpcg" or eigen_solver="amg", then eigen_tol=None which configures the underlying lobpcg solver to automatically resolve the value according to their heuristics. See, scipy.sparse.linalg.lobpcg for details.

Note that when using eigen_solver="lobpcg" or eigen_solver="amg" values of tol<1e-5 may lead to convergence issues and should be avoided.

Added in version 1.2: Added ‘auto’ option.

The strategy for assigning labels in the embedding space. There are two ways to assign labels after the Laplacian embedding. k-means is a popular choice, but it can be sensitive to initialization. Discretization is another approach which is less sensitive to random initialization [3]. The cluster_qr method [5] directly extract clusters from eigenvectors in spectral clustering. In contrast to k-means and discretization, cluster_qr has no tuning parameters and runs no iterations, yet may outperform k-means and discretization in terms of both quality and speed.

Changed in version 1.1: Added new labeling method ‘cluster_qr’.

Degree of the polynomial kernel. Ignored by other kernels.

Zero coefficient for polynomial and sigmoid kernels. Ignored by other kernels.

Parameters (keyword arguments) and values for kernel passed as callable object. Ignored by other kernels.

The number of parallel jobs to run when affinity='nearest_neighbors' or affinity='precomputed_nearest_neighbors'. The neighbors search will be done in parallel. None means 1 unless in a joblib.parallel_backend context. -1 means using all processors. See Glossary for more details.

Added in version 0.24.

Affinity matrix used for clustering. Available only after calling fit.

Number of features seen during fit.

Added in version 0.24.

Names of features seen during fit. Defined only when X has feature names that are all strings.

Added in version 1.0.

Density-Based Spatial Clustering of Applications with Noise.

A distance matrix for which 0 indicates identical elements and high values indicate very dissimilar elements can be transformed into an affinity / similarity matrix that is well-suited for the algorithm by applying the Gaussian (aka RBF, heat) kernel:

where delta is a free parameter representing the width of the Gaussian kernel.

An alternative is to take a symmetric version of the k-nearest neighbors connectivity matrix of the points.

If the pyamg package is installed, it is used: this greatly speeds up computation.

Normalized cuts and image segmentation, 2000 Jianbo Shi, Jitendra Malik

A Tutorial on Spectral Clustering, 2007 Ulrike von Luxburg

Multiclass spectral clustering, 2003 Stella X. Yu, Jianbo Shi

Toward the Optimal Preconditioned Eigensolver: Locally Optimal Block Preconditioned Conjugate Gradient Method, 2001 A. V. Knyazev SIAM Journal on Scientific Computing 23, no. 2, pp. 517-541.

Simple, direct, and efficient multi-way spectral clustering, 2019 Anil Damle, Victor Minden, Lexing Ying

For a comparison of Spectral clustering with other clustering algorithms, see Comparing different clustering algorithms on toy datasets

Perform spectral clustering from features, or affinity matrix.

Training instances to cluster, similarities / affinities between instances if affinity='precomputed', or distances between instances if affinity='precomputed_nearest_neighbors. If a sparse matrix is provided in a format other than csr_matrix, csc_matrix, or coo_matrix, it will be converted into a sparse csr_matrix.

Not used, present here for API consistency by convention.

A fitted instance of the estimator.

Perform spectral clustering on X and return cluster labels.

Training instances to cluster, similarities / affinities between instances if affinity='precomputed', or distances between instances if affinity='precomputed_nearest_neighbors. If a sparse matrix is provided in a format other than csr_matrix, csc_matrix, or coo_matrix, it will be converted into a sparse csr_matrix.

Not used, present here for API consistency by convention.

Get metadata routing of this object.

Please check User Guide on how the routing mechanism works.

A MetadataRequest encapsulating routing information.

Get parameters for this estimator.

If True, will return the parameters for this estimator and contained subobjects that are estimators.

Parameter names mapped to their values.

Set the parameters of this estimator.

The method works on simple estimators as well as on nested objects (such as Pipeline). The latter have parameters of the form <component>__<parameter> so that it’s possible to update each component of a nested object.

Estimator parameters.

Comparing different clustering algorithms on toy datasets

**Examples:**

Example 1 (unknown):
```unknown
np.exp(-gamma * d(X,X) ** 2)
```

Example 2 (unknown):
```unknown
np.exp(- dist_matrix ** 2 / (2. * delta ** 2))
```

Example 3 (sql):
```sql
>>> from sklearn.cluster import SpectralClustering
>>> import numpy as np
>>> X = np.array([[1, 1], [2, 1], [1, 0],
...               [4, 7], [3, 5], [3, 6]])
>>> clustering = SpectralClustering(n_clusters=2,
...         assign_labels='discretize',
...         random_state=0).fit(X)
>>> clustering.labels_
array([1, 1, 1, 0, 0, 0])
>>> clustering
SpectralClustering(assign_labels='discretize', n_clusters=2,
    random_state=0)
```

---

## SelfTrainingClassifier#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.semi_supervised.SelfTrainingClassifier.html

**Contents:**
- SelfTrainingClassifier#
- Gallery examples#

Self-training classifier.

This metaestimator allows a given supervised classifier to function as a semi-supervised classifier, allowing it to learn from unlabeled data. It does this by iteratively predicting pseudo-labels for the unlabeled data and adding them to the training set.

The classifier will continue iterating until either max_iter is reached, or no pseudo-labels were added to the training set in the previous iteration.

Read more in the User Guide.

An estimator object implementing fit and predict_proba. Invoking the fit method will fit a clone of the passed estimator, which will be stored in the estimator_ attribute.

Added in version 1.6: estimator was added to replace base_estimator.

The decision threshold for use with criterion='threshold'. Should be in [0, 1). When using the 'threshold' criterion, a well calibrated classifier should be used.

The selection criterion used to select which labels to add to the training set. If 'threshold', pseudo-labels with prediction probabilities above threshold are added to the dataset. If 'k_best', the k_best pseudo-labels with highest prediction probabilities are added to the dataset. When using the ‘threshold’ criterion, a well calibrated classifier should be used.

The amount of samples to add in each iteration. Only used when criterion='k_best'.

Maximum number of iterations allowed. Should be greater than or equal to 0. If it is None, the classifier will continue to predict labels until no new pseudo-labels are added, or all unlabeled samples have been labeled.

Enable verbose output.

The fitted estimator.

Class labels for each output. (Taken from the trained estimator_).

The labels used for the final fit of the classifier, including pseudo-labels added during fit.

The iteration in which each sample was labeled. When a sample has iteration 0, the sample was already labeled in the original dataset. When a sample has iteration -1, the sample was not labeled in any iteration.

Number of features seen during fit.

Added in version 0.24.

Names of features seen during fit. Defined only when X has feature names that are all strings.

Added in version 1.0.

The number of rounds of self-training, that is the number of times the base estimator is fitted on relabeled variants of the training set.

The reason that fitting was stopped.

'max_iter': n_iter_ reached max_iter.

'no_change': no new labels were predicted.

'all_labeled': all unlabeled samples were labeled before max_iter was reached.

Label propagation classifier.

Label spreading model for semi-supervised learning.

David Yarowsky. 1995. Unsupervised word sense disambiguation rivaling supervised methods. In Proceedings of the 33rd annual meeting on Association for Computational Linguistics (ACL ‘95). Association for Computational Linguistics, Stroudsburg, PA, USA, 189-196.

Call decision function of the estimator.

Array representing the data.

Parameters to pass to the underlying estimator’s decision_function method.

Added in version 1.6: Only available if enable_metadata_routing=True, which can be set by using sklearn.set_config(enable_metadata_routing=True). See Metadata Routing User Guide for more details.

Result of the decision function of the estimator.

Fit self-training classifier using X, y as training data.

Array representing the data.

Array representing the labels. Unlabeled samples should have the label -1.

Parameters to pass to the underlying estimators.

Added in version 1.6: Only available if enable_metadata_routing=True, which can be set by using sklearn.set_config(enable_metadata_routing=True). See Metadata Routing User Guide for more details.

Get metadata routing of this object.

Please check User Guide on how the routing mechanism works.

Added in version 1.6.

A MetadataRouter encapsulating routing information.

Get parameters for this estimator.

If True, will return the parameters for this estimator and contained subobjects that are estimators.

Parameter names mapped to their values.

Predict the classes of X.

Array representing the data.

Parameters to pass to the underlying estimator’s predict method.

Added in version 1.6: Only available if enable_metadata_routing=True, which can be set by using sklearn.set_config(enable_metadata_routing=True). See Metadata Routing User Guide for more details.

Array with predicted labels.

Predict log probability for each possible outcome.

Array representing the data.

Parameters to pass to the underlying estimator’s predict_log_proba method.

Added in version 1.6: Only available if enable_metadata_routing=True, which can be set by using sklearn.set_config(enable_metadata_routing=True). See Metadata Routing User Guide for more details.

Array with log prediction probabilities.

Predict probability for each possible outcome.

Array representing the data.

Parameters to pass to the underlying estimator’s predict_proba method.

Added in version 1.6: Only available if enable_metadata_routing=True, which can be set by using sklearn.set_config(enable_metadata_routing=True). See Metadata Routing User Guide for more details.

Array with prediction probabilities.

Call score on the estimator.

Array representing the data.

Array representing the labels.

Parameters to pass to the underlying estimator’s score method.

Added in version 1.6: Only available if enable_metadata_routing=True, which can be set by using sklearn.set_config(enable_metadata_routing=True). See Metadata Routing User Guide for more details.

Result of calling score on the estimator.

Set the parameters of this estimator.

The method works on simple estimators as well as on nested objects (such as Pipeline). The latter have parameters of the form <component>__<parameter> so that it’s possible to update each component of a nested object.

Estimator parameters.

Release Highlights for scikit-learn 0.24

Effect of varying threshold for self-training

Semi-supervised Classification on a Text Dataset

Decision boundary of semi-supervised classifiers versus SVM on the Iris dataset

**Examples:**

Example 1 (python):
```python
>>> import numpy as np
>>> from sklearn import datasets
>>> from sklearn.semi_supervised import SelfTrainingClassifier
>>> from sklearn.svm import SVC
>>> rng = np.random.RandomState(42)
>>> iris = datasets.load_iris()
>>> random_unlabeled_points = rng.rand(iris.target.shape[0]) < 0.3
>>> iris.target[random_unlabeled_points] = -1
>>> svc = SVC(probability=True, gamma="auto")
>>> self_training_model = SelfTrainingClassifier(svc)
>>> self_training_model.fit(iris.data, iris.target)
SelfTrainingClassifier(...)
```

---

## Kernel#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.gaussian_process.kernels.Kernel.html

**Contents:**
- Kernel#
- Gallery examples#

Base class for all kernels.

Added in version 0.18.

Returns the log-transformed bounds on the theta.

The log-transformed bounds on the kernel’s hyperparameters theta

Returns a clone of self with given hyperparameters theta.

Returns the diagonal of the kernel k(X, X).

The result of this method is identical to np.diag(self(X)); however, it can be evaluated more efficiently since only the diagonal is evaluated.

Left argument of the returned kernel k(X, Y)

Diagonal of kernel k(X, X)

Get parameters of this kernel.

If True, will return the parameters for this estimator and contained subobjects that are estimators.

Parameter names mapped to their values.

Returns a list of all hyperparameter specifications.

Returns whether the kernel is stationary.

Returns the number of non-fixed hyperparameters of the kernel.

Returns whether the kernel is defined on fixed-length feature vectors or generic objects. Defaults to True for backward compatibility.

Set the parameters of this kernel.

The method works on simple kernels as well as on nested kernels. The latter have parameters of the form <component>__<parameter> so that it’s possible to update each component of a nested object.

Returns the (flattened, log-transformed) non-fixed hyperparameters.

Note that theta are typically the log-transformed values of the kernel’s hyperparameters as this representation of the search space is more amenable for hyperparameter search, as hyperparameters like length-scales naturally live on a log-scale.

The non-fixed, log-transformed hyperparameters of the kernel

Gaussian processes on discrete data structures

**Examples:**

Example 1 (python):
```python
>>> from sklearn.gaussian_process.kernels import Kernel, RBF
>>> import numpy as np
>>> class CustomKernel(Kernel):
...     def __init__(self, length_scale=1.0):
...         self.length_scale = length_scale
...     def __call__(self, X, Y=None):
...         if Y is None:
...             Y = X
...         return np.inner(X, X if Y is None else Y) ** 2
...     def diag(self, X):
...         return np.ones(X.shape[0])
...     def is_stationary(self):
...         return True
>>> kernel = CustomKernel(length_scale=2.0)
>>> X = np.array([[1, 2], [3, 4]])
>>> print(kernel(X))
[[ 25 121]
 [121 625]]
```

---

## RidgeClassifier#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.RidgeClassifier.html

**Contents:**
- RidgeClassifier#
- Gallery examples#

Classifier using Ridge regression.

This classifier first converts the target values into {-1, 1} and then treats the problem as a regression task (multi-output regression in the multiclass case).

Read more in the User Guide.

Regularization strength; must be a positive float. Regularization improves the conditioning of the problem and reduces the variance of the estimates. Larger values specify stronger regularization. Alpha corresponds to 1 / (2C) in other linear models such as LogisticRegression or LinearSVC.

Whether to calculate the intercept for this model. If set to false, no intercept will be used in calculations (e.g. data is expected to be already centered).

If True, X will be copied; else, it may be overwritten.

Maximum number of iterations for conjugate gradient solver. The default value is determined by scipy.sparse.linalg.

The precision of the solution (coef_) is determined by tol which specifies a different convergence criterion for each solver:

‘svd’: tol has no impact.

‘cholesky’: tol has no impact.

‘sparse_cg’: norm of residuals smaller than tol.

‘lsqr’: tol is set as atol and btol of scipy.sparse.linalg.lsqr, which control the norm of the residual vector in terms of the norms of matrix and coefficients.

‘sag’ and ‘saga’: relative change of coef smaller than tol.

‘lbfgs’: maximum of the absolute (projected) gradient=max|residuals| smaller than tol.

Changed in version 1.2: Default value changed from 1e-3 to 1e-4 for consistency with other linear models.

Weights associated with classes in the form {class_label: weight}. If not given, all classes are supposed to have weight one.

The “balanced” mode uses the values of y to automatically adjust weights inversely proportional to class frequencies in the input data as n_samples / (n_classes * np.bincount(y)).

Solver to use in the computational routines:

‘auto’ chooses the solver automatically based on the type of data.

‘svd’ uses a Singular Value Decomposition of X to compute the Ridge coefficients. It is the most stable solver, in particular more stable for singular matrices than ‘cholesky’ at the cost of being slower.

‘cholesky’ uses the standard scipy.linalg.solve function to obtain a closed-form solution.

‘sparse_cg’ uses the conjugate gradient solver as found in scipy.sparse.linalg.cg. As an iterative algorithm, this solver is more appropriate than ‘cholesky’ for large-scale data (possibility to set tol and max_iter).

‘lsqr’ uses the dedicated regularized least-squares routine scipy.sparse.linalg.lsqr. It is the fastest and uses an iterative procedure.

‘sag’ uses a Stochastic Average Gradient descent, and ‘saga’ uses its unbiased and more flexible version named SAGA. Both methods use an iterative procedure, and are often faster than other solvers when both n_samples and n_features are large. Note that ‘sag’ and ‘saga’ fast convergence is only guaranteed on features with approximately the same scale. You can preprocess the data with a scaler from sklearn.preprocessing.

Added in version 0.17: Stochastic Average Gradient descent solver.

Added in version 0.19: SAGA solver.

‘lbfgs’ uses L-BFGS-B algorithm implemented in scipy.optimize.minimize. It can be used only when positive is True.

When set to True, forces the coefficients to be positive. Only ‘lbfgs’ solver is supported in this case.

Used when solver == ‘sag’ or ‘saga’ to shuffle the data. See Glossary for details.

Coefficient of the features in the decision function.

coef_ is of shape (1, n_features) when the given problem is binary.

Independent term in decision function. Set to 0.0 if fit_intercept = False.

Actual number of iterations for each target. Available only for sag and lsqr solvers. Other solvers will return None.

Number of features seen during fit.

Added in version 0.24.

Names of features seen during fit. Defined only when X has feature names that are all strings.

Added in version 1.0.

The solver that was used at fit time by the computational routines.

Added in version 1.5.

Ridge classifier with built-in cross validation.

For multi-class classification, n_class classifiers are trained in a one-versus-all approach. Concretely, this is implemented by taking advantage of the multi-variate response support in Ridge.

Predict confidence scores for samples.

The confidence score for a sample is proportional to the signed distance of that sample to the hyperplane.

The data matrix for which we want to get the confidence scores.

Confidence scores per (n_samples, n_classes) combination. In the binary case, confidence score for self.classes_[1] where >0 means this class would be predicted.

Fit Ridge classifier model.

Individual weights for each sample. If given a float, every sample will have the same weight.

Added in version 0.17: sample_weight support to RidgeClassifier.

Instance of the estimator.

Get metadata routing of this object.

Please check User Guide on how the routing mechanism works.

A MetadataRequest encapsulating routing information.

Get parameters for this estimator.

If True, will return the parameters for this estimator and contained subobjects that are estimators.

Parameter names mapped to their values.

Predict class labels for samples in X.

The data matrix for which we want to predict the targets.

Vector or matrix containing the predictions. In binary and multiclass problems, this is a vector containing n_samples. In a multilabel problem, it returns a matrix of shape (n_samples, n_outputs).

Return accuracy on provided data and labels.

In multi-label classification, this is the subset accuracy which is a harsh metric since you require for each sample that each label set be correctly predicted.

Mean accuracy of self.predict(X) w.r.t. y.

Configure whether metadata should be requested to be passed to the fit method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to fit if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to fit.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Added in version 1.3.

Metadata routing for sample_weight parameter in fit.

Set the parameters of this estimator.

The method works on simple estimators as well as on nested objects (such as Pipeline). The latter have parameters of the form <component>__<parameter> so that it’s possible to update each component of a nested object.

Estimator parameters.

Configure whether metadata should be requested to be passed to the score method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to score if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to score.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Added in version 1.3.

Metadata routing for sample_weight parameter in score.

Classification of text documents using sparse features

**Examples:**

Example 1 (sql):
```sql
>>> from sklearn.datasets import load_breast_cancer
>>> from sklearn.linear_model import RidgeClassifier
>>> X, y = load_breast_cancer(return_X_y=True)
>>> clf = RidgeClassifier().fit(X, y)
>>> clf.score(X, y)
0.9595...
```

---

## OAS#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.covariance.OAS.html

**Contents:**
- OAS#
- Gallery examples#

Oracle Approximating Shrinkage Estimator.

Read more in the User Guide.

Specify if the estimated precision is stored.

If True, data will not be centered before computation. Useful when working with data whose mean is almost, but not exactly zero. If False (default), data will be centered before computation.

Estimated covariance matrix.

Estimated location, i.e. the estimated mean.

Estimated pseudo inverse matrix. (stored only if store_precision is True)

coefficient in the convex combination used for the computation of the shrunk estimate. Range is [0, 1].

Number of features seen during fit.

Added in version 0.24.

Names of features seen during fit. Defined only when X has feature names that are all strings.

Added in version 1.0.

An object for detecting outliers in a Gaussian distributed dataset.

Maximum likelihood covariance estimator.

Sparse inverse covariance estimation with an l1-penalized estimator.

Sparse inverse covariance with cross-validated choice of the l1 penalty.

LedoitWolf Estimator.

Minimum Covariance Determinant (robust estimator of covariance).

Covariance estimator with shrinkage.

The regularised covariance is:

(1 - shrinkage) * cov + shrinkage * mu * np.identity(n_features),

where mu = trace(cov) / n_features and shrinkage is given by the OAS formula (see [1]).

The shrinkage formulation implemented here differs from Eq. 23 in [1]. In the original article, formula (23) states that 2/p (p being the number of features) is multiplied by Trace(cov*cov) in both the numerator and denominator, but this operation is omitted because for a large p, the value of 2/p is so small that it doesn’t affect the value of the estimator.

“Shrinkage algorithms for MMSE covariance estimation.”, Chen, Y., Wiesel, A., Eldar, Y. C., & Hero, A. O. IEEE Transactions on Signal Processing, 58(10), 5016-5029, 2010.

See also Shrinkage covariance estimation: LedoitWolf vs OAS and max-likelihood and Ledoit-Wolf vs OAS estimation for more detailed examples.

Compute the Mean Squared Error between two covariance estimators.

The covariance to compare with.

The type of norm used to compute the error. Available error types: - ‘frobenius’ (default): sqrt(tr(A^t.A)) - ‘spectral’: sqrt(max(eigenvalues(A^t.A)) where A is the error (comp_cov - self.covariance_).

If True (default), the squared error norm is divided by n_features. If False, the squared error norm is not rescaled.

Whether to compute the squared error norm or the error norm. If True (default), the squared error norm is returned. If False, the error norm is returned.

The Mean Squared Error (in the sense of the Frobenius norm) between self and comp_cov covariance estimators.

Fit the Oracle Approximating Shrinkage covariance model to X.

Training data, where n_samples is the number of samples and n_features is the number of features.

Not used, present for API consistency by convention.

Returns the instance itself.

Get metadata routing of this object.

Please check User Guide on how the routing mechanism works.

A MetadataRequest encapsulating routing information.

Get parameters for this estimator.

If True, will return the parameters for this estimator and contained subobjects that are estimators.

Parameter names mapped to their values.

Getter for the precision matrix.

The precision matrix associated to the current covariance object.

Compute the squared Mahalanobis distances of given observations.

For a detailed example of how outliers affects the Mahalanobis distance, see Robust covariance estimation and Mahalanobis distances relevance.

The observations, the Mahalanobis distances of the which we compute. Observations are assumed to be drawn from the same distribution than the data used in fit.

Squared Mahalanobis distances of the observations.

Compute the log-likelihood of X_test under the estimated Gaussian model.

The Gaussian model is defined by its mean and covariance matrix which are represented respectively by self.location_ and self.covariance_.

Test data of which we compute the likelihood, where n_samples is the number of samples and n_features is the number of features. X_test is assumed to be drawn from the same distribution than the data used in fit (including centering).

Not used, present for API consistency by convention.

The log-likelihood of X_test with self.location_ and self.covariance_ as estimators of the Gaussian model mean and covariance matrix respectively.

Set the parameters of this estimator.

The method works on simple estimators as well as on nested objects (such as Pipeline). The latter have parameters of the form <component>__<parameter> so that it’s possible to update each component of a nested object.

Estimator parameters.

Normal, Ledoit-Wolf and OAS Linear Discriminant Analysis for classification

Shrinkage covariance estimation: LedoitWolf vs OAS and max-likelihood

Ledoit-Wolf vs OAS estimation

**Examples:**

Example 1 (sql):
```sql
>>> import numpy as np
>>> from sklearn.covariance import OAS
>>> from sklearn.datasets import make_gaussian_quantiles
>>> real_cov = np.array([[.8, .3],
...                      [.3, .4]])
>>> rng = np.random.RandomState(0)
>>> X = rng.multivariate_normal(mean=[0, 0],
...                             cov=real_cov,
...                             size=500)
>>> oas = OAS().fit(X)
>>> oas.covariance_
array([[0.7533, 0.2763],
       [0.2763, 0.3964]])
>>> oas.precision_
array([[ 1.7833, -1.2431 ],
       [-1.2431,  3.3889]])
>>> oas.shrinkage_
np.float64(0.0195)
```

---

## SGDClassifier#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html

**Contents:**
- SGDClassifier#
- Gallery examples#

Linear classifiers (SVM, logistic regression, etc.) with SGD training.

This estimator implements regularized linear models with stochastic gradient descent (SGD) learning: the gradient of the loss is estimated each sample at a time and the model is updated along the way with a decreasing strength schedule (aka learning rate). SGD allows minibatch (online/out-of-core) learning via the partial_fit method. For best results using the default learning rate schedule, the data should have zero mean and unit variance.

This implementation works with data represented as dense or sparse arrays of floating point values for the features. The model it fits can be controlled with the loss parameter; by default, it fits a linear support vector machine (SVM).

The regularizer is a penalty added to the loss function that shrinks model parameters towards the zero vector using either the squared euclidean norm L2 or the absolute norm L1 or a combination of both (Elastic Net). If the parameter update crosses the 0.0 value because of the regularizer, the update is truncated to 0.0 to allow for learning sparse models and achieve online feature selection.

Read more in the User Guide.

The loss function to be used.

‘hinge’ gives a linear SVM.

‘log_loss’ gives logistic regression, a probabilistic classifier.

‘modified_huber’ is another smooth loss that brings tolerance to outliers as well as probability estimates.

‘squared_hinge’ is like hinge but is quadratically penalized.

‘perceptron’ is the linear loss used by the perceptron algorithm.

The other losses, ‘squared_error’, ‘huber’, ‘epsilon_insensitive’ and ‘squared_epsilon_insensitive’ are designed for regression but can be useful in classification as well; see SGDRegressor for a description.

More details about the losses formulas can be found in the User Guide and you can find a visualisation of the loss functions in SGD: convex loss functions.

The penalty (aka regularization term) to be used. Defaults to ‘l2’ which is the standard regularizer for linear SVM models. ‘l1’ and ‘elasticnet’ might bring sparsity to the model (feature selection) not achievable with ‘l2’. No penalty is added when set to None.

You can see a visualisation of the penalties in SGD: Penalties.

Constant that multiplies the regularization term. The higher the value, the stronger the regularization. Also used to compute the learning rate when learning_rate is set to ‘optimal’. Values must be in the range [0.0, inf).

The Elastic Net mixing parameter, with 0 <= l1_ratio <= 1. l1_ratio=0 corresponds to L2 penalty, l1_ratio=1 to L1. Only used if penalty is ‘elasticnet’. Values must be in the range [0.0, 1.0] or can be None if penalty is not elasticnet.

Changed in version 1.7: l1_ratio can be None when penalty is not “elasticnet”.

Whether the intercept should be estimated or not. If False, the data is assumed to be already centered.

The maximum number of passes over the training data (aka epochs). It only impacts the behavior in the fit method, and not the partial_fit method. Values must be in the range [1, inf).

Added in version 0.19.

The stopping criterion. If it is not None, training will stop when (loss > best_loss - tol) for n_iter_no_change consecutive epochs. Convergence is checked against the training loss or the validation loss depending on the early_stopping parameter. Values must be in the range [0.0, inf).

Added in version 0.19.

Whether or not the training data should be shuffled after each epoch.

The verbosity level. Values must be in the range [0, inf).

Epsilon in the epsilon-insensitive loss functions; only if loss is ‘huber’, ‘epsilon_insensitive’, or ‘squared_epsilon_insensitive’. For ‘huber’, determines the threshold at which it becomes less important to get the prediction exactly right. For epsilon-insensitive, any differences between the current prediction and the correct label are ignored if they are less than this threshold. Values must be in the range [0.0, inf).

The number of CPUs to use to do the OVA (One Versus All, for multi-class problems) computation. None means 1 unless in a joblib.parallel_backend context. -1 means using all processors. See Glossary for more details.

Used for shuffling the data, when shuffle is set to True. Pass an int for reproducible output across multiple function calls. See Glossary. Integer values must be in the range [0, 2**32 - 1].

The learning rate schedule:

‘constant’: eta = eta0

‘optimal’: eta = 1.0 / (alpha * (t + t0)) where t0 is chosen by a heuristic proposed by Leon Bottou.

‘invscaling’: eta = eta0 / pow(t, power_t)

‘adaptive’: eta = eta0, as long as the training keeps decreasing. Each time n_iter_no_change consecutive epochs fail to decrease the training loss by tol or fail to increase validation score by tol if early_stopping is True, the current learning rate is divided by 5.

‘pa1’: passive-aggressive algorithm 1, see [1]. Only with loss='hinge'. Update is w += eta y x with eta = min(eta0, loss/||x||**2).

‘pa2’: passive-aggressive algorithm 2, see [1]. Only with loss='hinge'. Update is w += eta y x with eta = hinge_loss / (||x||**2 + 1/(2 eta0)).

Added in version 0.20: Added ‘adaptive’ option.

Added in version 1.8: Added options ‘pa1’ and ‘pa2’

The initial learning rate for the ‘constant’, ‘invscaling’ or ‘adaptive’ schedules. The default value is 0.01, but note that eta0 is not used by the default learning rate ‘optimal’. Values must be in the range (0.0, inf).

For PA-1 (learning_rate=pa1) and PA-II (pa2), it specifies the aggressiveness parameter for the passive-agressive algorithm, see [1] where it is called C:

For PA-I it is the maximum step size.

For PA-II it regularizes the step size (the smaller eta0 the more it regularizes).

As a general rule-of-thumb for PA, eta0 should be small when the data is noisy.

The exponent for inverse scaling learning rate. Values must be in the range [0.0, inf).

Deprecated since version 1.8: Negative values for power_t are deprecated in version 1.8 and will raise an error in 1.10. Use values in the range [0.0, inf) instead.

Whether to use early stopping to terminate training when validation score is not improving. If set to True, it will automatically set aside a stratified fraction of training data as validation and terminate training when validation score returned by the score method is not improving by at least tol for n_iter_no_change consecutive epochs.

See Early stopping of Stochastic Gradient Descent for an example of the effects of early stopping.

Added in version 0.20: Added ‘early_stopping’ option

The proportion of training data to set aside as validation set for early stopping. Must be between 0 and 1. Only used if early_stopping is True. Values must be in the range (0.0, 1.0).

Added in version 0.20: Added ‘validation_fraction’ option

Number of iterations with no improvement to wait before stopping fitting. Convergence is checked against the training loss or the validation loss depending on the early_stopping parameter. Integer values must be in the range [1, max_iter).

Added in version 0.20: Added ‘n_iter_no_change’ option

Preset for the class_weight fit parameter.

Weights associated with classes. If not given, all classes are supposed to have weight one.

The “balanced” mode uses the values of y to automatically adjust weights inversely proportional to class frequencies in the input data as n_samples / (n_classes * np.bincount(y)).

When set to True, reuse the solution of the previous call to fit as initialization, otherwise, just erase the previous solution. See the Glossary.

Repeatedly calling fit or partial_fit when warm_start is True can result in a different solution than when calling fit a single time because of the way the data is shuffled. If a dynamic learning rate is used, the learning rate is adapted depending on the number of samples already seen. Calling fit resets this counter, while partial_fit will result in increasing the existing counter.

When set to True, computes the averaged SGD weights across all updates and stores the result in the coef_ attribute. If set to an int greater than 1, averaging will begin once the total number of samples seen reaches average. So average=10 will begin averaging after seeing 10 samples. Integer values must be in the range [1, n_samples].

Weights assigned to the features.

Constants in decision function.

The actual number of iterations before reaching the stopping criterion. For multiclass fits, it is the maximum over every binary fit.

Number of weight updates performed during training. Same as (n_iter_ * n_samples + 1).

Number of features seen during fit.

Added in version 0.24.

Names of features seen during fit. Defined only when X has feature names that are all strings.

Added in version 1.0.

Linear support vector classification.

Inherits from SGDClassifier. Perceptron() is equivalent to SGDClassifier(loss="perceptron", eta0=1, learning_rate="constant", penalty=None).

Online Passive-Aggressive Algorithms <http://jmlr.csail.mit.edu/papers/volume7/crammer06a/crammer06a.pdf> K. Crammer, O. Dekel, J. Keshat, S. Shalev-Shwartz, Y. Singer - JMLR (2006)

Predict confidence scores for samples.

The confidence score for a sample is proportional to the signed distance of that sample to the hyperplane.

The data matrix for which we want to get the confidence scores.

Confidence scores per (n_samples, n_classes) combination. In the binary case, confidence score for self.classes_[1] where >0 means this class would be predicted.

Convert coefficient matrix to dense array format.

Converts the coef_ member (back) to a numpy.ndarray. This is the default format of coef_ and is required for fitting, so calling this method is only required on models that have previously been sparsified; otherwise, it is a no-op.

Fit linear model with Stochastic Gradient Descent.

The initial coefficients to warm-start the optimization.

The initial intercept to warm-start the optimization.

Weights applied to individual samples. If not provided, uniform weights are assumed. These weights will be multiplied with class_weight (passed through the constructor) if class_weight is specified.

Returns an instance of self.

Get metadata routing of this object.

Please check User Guide on how the routing mechanism works.

A MetadataRequest encapsulating routing information.

Get parameters for this estimator.

If True, will return the parameters for this estimator and contained subobjects that are estimators.

Parameter names mapped to their values.

Perform one epoch of stochastic gradient descent on given samples.

Internally, this method uses max_iter = 1. Therefore, it is not guaranteed that a minimum of the cost function is reached after calling it once. Matters such as objective convergence, early stopping, and learning rate adjustments should be handled by the user.

Subset of the training data.

Subset of the target values.

Classes across all calls to partial_fit. Can be obtained by via np.unique(y_all), where y_all is the target vector of the entire dataset. This argument is required for the first call to partial_fit and can be omitted in the subsequent calls. Note that y doesn’t need to contain all labels in classes.

Weights applied to individual samples. If not provided, uniform weights are assumed.

Returns an instance of self.

Predict class labels for samples in X.

The data matrix for which we want to get the predictions.

Vector containing the class labels for each sample.

Log of probability estimates.

This method is only available for log loss and modified Huber loss.

When loss=”modified_huber”, probability estimates may be hard zeros and ones, so taking the logarithm is not possible.

See predict_proba for details.

Input data for prediction.

Returns the log-probability of the sample for each class in the model, where classes are ordered as they are in self.classes_.

Probability estimates.

This method is only available for log loss and modified Huber loss.

Multiclass probability estimates are derived from binary (one-vs.-rest) estimates by simple normalization, as recommended by Zadrozny and Elkan.

Binary probability estimates for loss=”modified_huber” are given by (clip(decision_function(X), -1, 1) + 1) / 2. For other loss functions it is necessary to perform proper probability calibration by wrapping the classifier with CalibratedClassifierCV instead.

Input data for prediction.

Returns the probability of the sample for each class in the model, where classes are ordered as they are in self.classes_.

Zadrozny and Elkan, “Transforming classifier scores into multiclass probability estimates”, SIGKDD’02, https://dl.acm.org/doi/pdf/10.1145/775047.775151

The justification for the formula in the loss=”modified_huber” case is in the appendix B in: http://jmlr.csail.mit.edu/papers/volume2/zhang02c/zhang02c.pdf

Return accuracy on provided data and labels.

In multi-label classification, this is the subset accuracy which is a harsh metric since you require for each sample that each label set be correctly predicted.

Mean accuracy of self.predict(X) w.r.t. y.

Configure whether metadata should be requested to be passed to the fit method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to fit if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to fit.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Added in version 1.3.

Metadata routing for coef_init parameter in fit.

Metadata routing for intercept_init parameter in fit.

Metadata routing for sample_weight parameter in fit.

Set the parameters of this estimator.

The method works on simple estimators as well as on nested objects (such as Pipeline). The latter have parameters of the form <component>__<parameter> so that it’s possible to update each component of a nested object.

Estimator parameters.

Configure whether metadata should be requested to be passed to the partial_fit method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to partial_fit if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to partial_fit.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Added in version 1.3.

Metadata routing for classes parameter in partial_fit.

Metadata routing for sample_weight parameter in partial_fit.

Configure whether metadata should be requested to be passed to the score method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to score if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to score.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Added in version 1.3.

Metadata routing for sample_weight parameter in score.

Convert coefficient matrix to sparse format.

Converts the coef_ member to a scipy.sparse matrix, which for L1-regularized models can be much more memory- and storage-efficient than the usual numpy.ndarray representation.

The intercept_ member is not converted.

For non-sparse models, i.e. when there are not many zeros in coef_, this may actually increase memory usage, so use this method with care. A rule of thumb is that the number of zero elements, which can be computed with (coef_ == 0).sum(), must be more than 50% for this to provide significant benefits.

After calling this method, further fitting with the partial_fit method (if any) will not work until you call densify.

Model Complexity Influence

Out-of-core classification of text documents

Early stopping of Stochastic Gradient Descent

Plot multi-class SGD on the iris dataset

SGD: convex loss functions

SGD: Maximum margin separating hyperplane

SGD: Weighted samples

Explicit feature map approximation for RBF kernels

Comparing randomized search and grid search for hyperparameter estimation

Release Highlights for scikit-learn 1.6

Semi-supervised Classification on a Text Dataset

Classification of text documents using sparse features

**Examples:**

Example 1 (python):
```python
>>> import numpy as np
>>> from sklearn.linear_model import SGDClassifier
>>> from sklearn.preprocessing import StandardScaler
>>> from sklearn.pipeline import make_pipeline
>>> X = np.array([[-1, -1], [-2, -1], [1, 1], [2, 1]])
>>> Y = np.array([1, 1, 2, 2])
>>> # Always scale the input. The most convenient way is to use a pipeline.
>>> clf = make_pipeline(StandardScaler(),
...                     SGDClassifier(max_iter=1000, tol=1e-3))
>>> clf.fit(X, Y)
Pipeline(steps=[('standardscaler', StandardScaler()),
                ('sgdclassifier', SGDClassifier())])
>>> print(clf.predict([[-0.8, -1]]))
[1]
```

---

## LassoCV#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LassoCV.html

**Contents:**
- LassoCV#
- Gallery examples#

Lasso linear model with iterative fitting along a regularization path.

See glossary entry for cross-validation estimator.

The best model is selected by cross-validation.

The optimization objective for Lasso is:

Read more in the User Guide.

Length of the path. eps=1e-3 means that alpha_min / alpha_max = 1e-3.

Number of alphas along the regularization path.

Deprecated since version 1.7: n_alphas was deprecated in 1.7 and will be removed in 1.9. Use alphas instead.

Values of alphas to test along the regularization path. If int, alphas values are generated automatically. If array-like, list of alpha values to use.

Changed in version 1.7: alphas accepts an integer value which removes the need to pass n_alphas.

Deprecated since version 1.7: alphas=None was deprecated in 1.7 and will be removed in 1.9, at which point the default value will be set to 100.

Whether to calculate the intercept for this model. If set to false, no intercept will be used in calculations (i.e. data is expected to be centered).

Whether to use a precomputed Gram matrix to speed up calculations. If set to 'auto' let us decide. The Gram matrix can also be passed as argument.

The maximum number of iterations.

The tolerance for the optimization: if the updates are smaller or equal to tol, the optimization code checks the dual gap for optimality and continues until it is smaller or equal to tol.

If True, X will be copied; else, it may be overwritten.

Determines the cross-validation splitting strategy. Possible inputs for cv are:

None, to use the default 5-fold cross-validation,

int, to specify the number of folds.

An iterable yielding (train, test) splits as arrays of indices.

For int/None inputs, KFold is used.

Refer User Guide for the various cross-validation strategies that can be used here.

Changed in version 0.22: cv default value if None changed from 3-fold to 5-fold.

Number of CPUs to use during the cross validation. None means 1 unless in a joblib.parallel_backend context. -1 means using all processors. See Glossary for more details.

If positive, restrict regression coefficients to be positive.

The seed of the pseudo random number generator that selects a random feature to update. Used when selection == ‘random’. Pass an int for reproducible output across multiple function calls. See Glossary.

If set to ‘random’, a random coefficient is updated every iteration rather than looping over features sequentially by default. This (setting to ‘random’) often leads to significantly faster convergence especially when tol is higher than 1e-4.

The amount of penalization chosen by cross validation.

Parameter vector (w in the cost function formula).

Independent term in decision function.

Mean square error for the test set on each fold, varying alpha.

The grid of alphas used for fitting.

The dual gap at the end of the optimization for the optimal alpha (alpha_).

Number of iterations run by the coordinate descent solver to reach the specified tolerance for the optimal alpha.

Number of features seen during fit.

Added in version 0.24.

Names of features seen during fit. Defined only when X has feature names that are all strings.

Added in version 1.0.

Compute Least Angle Regression or Lasso path using LARS algorithm.

Compute Lasso path with coordinate descent.

The Lasso is a linear model that estimates sparse coefficients.

Lasso model fit with Least Angle Regression a.k.a. Lars.

Lasso linear model with iterative fitting along a regularization path.

Cross-validated Lasso using the LARS algorithm.

In fit, once the best parameter alpha is found through cross-validation, the model is fit again using the entire training set.

To avoid unnecessary memory duplication the X argument of the fit method should be directly passed as a Fortran-contiguous numpy array.

For an example, see examples/linear_model/plot_lasso_model_selection.py.

LassoCV leads to different results than a hyperparameter search using GridSearchCV with a Lasso model. In LassoCV, a model for a given penalty alpha is warm started using the coefficients of the closest model (trained at the previous iteration) on the regularization path. It tends to speed up the hyperparameter search.

The underlying coordinate descent solver uses gap safe screening rules to speedup fitting time, see User Guide on coordinate descent.

Fit Lasso model with coordinate descent.

Fit is on grid of alphas and best alpha estimated by cross-validation.

Training data. Pass directly as Fortran-contiguous data to avoid unnecessary memory duplication. If y is mono-output, X can be sparse. Note that large sparse matrices and arrays requiring int64 indices are not accepted.

Sample weights used for fitting and evaluation of the weighted mean squared error of each cv-fold. Note that the cross validated MSE that is finally used to find the best model is the unweighted mean over the (weighted) MSEs of each test fold.

Parameters to be passed to the CV splitter.

Added in version 1.4: Only available if enable_metadata_routing=True, which can be set by using sklearn.set_config(enable_metadata_routing=True). See Metadata Routing User Guide for more details.

Returns an instance of fitted model.

Get metadata routing of this object.

Please check User Guide on how the routing mechanism works.

Added in version 1.4.

A MetadataRouter encapsulating routing information.

Get parameters for this estimator.

If True, will return the parameters for this estimator and contained subobjects that are estimators.

Parameter names mapped to their values.

Compute Lasso path with coordinate descent.

The Lasso optimization function varies for mono and multi-outputs.

For mono-output tasks it is:

For multi-output tasks it is:

i.e. the sum of norm of each row.

Read more in the User Guide.

Training data. Pass directly as Fortran-contiguous data to avoid unnecessary memory duplication. If y is mono-output then X can be sparse.

Length of the path. eps=1e-3 means that alpha_min / alpha_max = 1e-3.

Number of alphas along the regularization path.

List of alphas where to compute the models. If None alphas are set automatically.

Whether to use a precomputed Gram matrix to speed up calculations. If set to 'auto' let us decide. The Gram matrix can also be passed as argument.

Xy = np.dot(X.T, y) that can be precomputed. It is useful only when the Gram matrix is precomputed.

If True, X will be copied; else, it may be overwritten.

The initial values of the coefficients.

Whether to return the number of iterations or not.

If set to True, forces coefficients to be positive. (Only allowed when y.ndim == 1).

Keyword arguments passed to the coordinate descent solver.

The alphas along the path where models are computed.

Coefficients along the path.

The dual gaps at the end of the optimization for each alpha.

The number of iterations taken by the coordinate descent optimizer to reach the specified tolerance for each alpha.

Compute Least Angle Regression or Lasso path using LARS algorithm.

The Lasso is a linear model that estimates sparse coefficients.

Lasso model fit with Least Angle Regression a.k.a. Lars.

Lasso linear model with iterative fitting along a regularization path.

Cross-validated Lasso using the LARS algorithm.

Estimator that can be used to transform signals into sparse linear combination of atoms from a fixed.

For an example, see examples/linear_model/plot_lasso_lasso_lars_elasticnet_path.py.

To avoid unnecessary memory duplication the X argument of the fit method should be directly passed as a Fortran-contiguous numpy array.

Note that in certain cases, the Lars solver may be significantly faster to implement this functionality. In particular, linear interpolation can be used to retrieve model coefficients between the values output by lars_path.

The underlying coordinate descent solver uses gap safe screening rules to speedup fitting time, see User Guide on coordinate descent.

Comparing lasso_path and lars_path with interpolation:

Predict using the linear model.

Returns predicted values.

Return coefficient of determination on test data.

The coefficient of determination, \(R^2\), is defined as \((1 - \frac{u}{v})\), where \(u\) is the residual sum of squares ((y_true - y_pred)** 2).sum() and \(v\) is the total sum of squares ((y_true - y_true.mean()) ** 2).sum(). The best possible score is 1.0 and it can be negative (because the model can be arbitrarily worse). A constant model that always predicts the expected value of y, disregarding the input features, would get a \(R^2\) score of 0.0.

Test samples. For some estimators this may be a precomputed kernel matrix or a list of generic objects instead with shape (n_samples, n_samples_fitted), where n_samples_fitted is the number of samples used in the fitting for the estimator.

\(R^2\) of self.predict(X) w.r.t. y.

The \(R^2\) score used when calling score on a regressor uses multioutput='uniform_average' from version 0.23 to keep consistent with default value of r2_score. This influences the score method of all the multioutput regressors (except for MultiOutputRegressor).

Configure whether metadata should be requested to be passed to the fit method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to fit if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to fit.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Added in version 1.3.

Metadata routing for sample_weight parameter in fit.

Set the parameters of this estimator.

The method works on simple estimators as well as on nested objects (such as Pipeline). The latter have parameters of the form <component>__<parameter> so that it’s possible to update each component of a nested object.

Estimator parameters.

Configure whether metadata should be requested to be passed to the score method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to score if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to score.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Added in version 1.3.

Metadata routing for sample_weight parameter in score.

Combine predictors using stacking

Common pitfalls in the interpretation of coefficients of linear models

L1-based models for Sparse Signals

Lasso model selection: AIC-BIC / cross-validation

**Examples:**

Example 1 (unknown):
```unknown
(1 / (2 * n_samples)) * ||y - Xw||^2_2 + alpha * ||w||_1
```

Example 2 (sql):
```sql
>>> from sklearn.linear_model import LassoCV
>>> from sklearn.datasets import make_regression
>>> X, y = make_regression(noise=4, random_state=0)
>>> reg = LassoCV(cv=5, random_state=0).fit(X, y)
>>> reg.score(X, y)
0.9993
>>> reg.predict(X[:1,])
array([-79.4755331])
```

Example 3 (unknown):
```unknown
(1 / (2 * n_samples)) * ||y - Xw||^2_2 + alpha * ||w||_1
```

Example 4 (unknown):
```unknown
(1 / (2 * n_samples)) * ||Y - XW||^2_Fro + alpha * ||W||_21
```

---

## lars_path_gram#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.lars_path_gram.html

**Contents:**
- lars_path_gram#

The lars_path in the sufficient stats mode.

The optimization objective for the case method=’lasso’ is:

in the case of method=’lar’, the objective function is only known in the form of an implicit equation (see discussion in [1]).

Read more in the User Guide.

Equivalent size of sample.

Maximum number of iterations to perform, set to infinity for no limit.

Minimum correlation along the path. It corresponds to the regularization parameter alpha parameter in the Lasso.

Specifies the returned model. Select 'lar' for Least Angle Regression, 'lasso' for the Lasso.

If False, X is overwritten.

The machine-precision regularization in the computation of the Cholesky diagonal factors. Increase this for very ill-conditioned systems. Unlike the tol parameter in some iterative optimization-based algorithms, this parameter does not control the tolerance of the optimization.

If False, Gram is overwritten.

Controls output verbosity.

If return_path==True returns the entire path, else returns only the last point of the path.

Whether to return the number of iterations.

Restrict coefficients to be >= 0. This option is only allowed with method ‘lasso’. Note that the model coefficients will not converge to the ordinary-least-squares solution for small values of alpha. Only coefficients up to the smallest alpha value (alphas_[alphas_ > 0.].min() when fit_path=True) reached by the stepwise Lars-Lasso algorithm are typically in congruence with the solution of the coordinate descent lasso_path function.

Maximum of covariances (in absolute value) at each iteration. n_alphas is either max_iter, n_features or the number of nodes in the path with alpha >= alpha_min, whichever is smaller.

Indices of active variables at the end of the path.

Coefficients along the path.

Number of iterations run. Returned only if return_n_iter is set to True.

Compute Lasso path with coordinate descent.

Lasso model fit with Least Angle Regression a.k.a. Lars.

Least Angle Regression model a.k.a. LAR.

Cross-validated Lasso, using the LARS algorithm.

Cross-validated Least Angle Regression model.

“Least Angle Regression”, Efron et al. http://statweb.stanford.edu/~tibs/ftp/lars.pdf

Wikipedia entry on the Least-angle regression

Wikipedia entry on the Lasso

**Examples:**

Example 1 (unknown):
```unknown
(1 / (2 * n_samples)) * ||y - Xw||^2_2 + alpha * ||w||_1
```

Example 2 (sql):
```sql
>>> from sklearn.linear_model import lars_path_gram
>>> from sklearn.datasets import make_regression
>>> X, y, true_coef = make_regression(
...    n_samples=100, n_features=5, n_informative=2, coef=True, random_state=0
... )
>>> true_coef
array([ 0.        ,  0.        ,  0.        , 97.9, 45.7])
>>> alphas, _, estimated_coef = lars_path_gram(X.T @ y, X.T @ X, n_samples=100)
>>> alphas.shape
(3,)
>>> estimated_coef
array([[ 0.     ,  0.     ,  0.     ],
       [ 0.     ,  0.     ,  0.     ],
       [ 0.     ,  0.     ,  0.     ],
       [ 0.     , 46.96, 97.99],
       [ 0.     ,  0.     , 45.70]])
```

---

## 1.9. Naive Bayes#

**URL:** https://scikit-learn.org/stable/modules/naive_bayes.html

**Contents:**
- 1.9. Naive Bayes#
- 1.9.1. Gaussian Naive Bayes#
- 1.9.2. Multinomial Naive Bayes#
- 1.9.3. Complement Naive Bayes#
- 1.9.4. Bernoulli Naive Bayes#
- 1.9.5. Categorical Naive Bayes#
- 1.9.6. Out-of-core naive Bayes model fitting#

Naive Bayes methods are a set of supervised learning algorithms based on applying Bayes’ theorem with the “naive” assumption of conditional independence between every pair of features given the value of the class variable. Bayes’ theorem states the following relationship, given class variable \(y\) and dependent feature vector \(x_1\) through \(x_n\), :

Using the naive conditional independence assumption that

for all \(i\), this relationship is simplified to

Since \(P(x_1, \dots, x_n)\) is constant given the input, we can use the following classification rule:

and we can use Maximum A Posteriori (MAP) estimation to estimate \(P(y)\) and \(P(x_i \mid y)\); the former is then the relative frequency of class \(y\) in the training set.

The different naive Bayes classifiers differ mainly by the assumptions they make regarding the distribution of \(P(x_i \mid y)\).

In spite of their apparently over-simplified assumptions, naive Bayes classifiers have worked quite well in many real-world situations, famously document classification and spam filtering. They require a small amount of training data to estimate the necessary parameters. (For theoretical reasons why naive Bayes works well, and on which types of data it does, see the references below.)

Naive Bayes learners and classifiers can be extremely fast compared to more sophisticated methods. The decoupling of the class conditional feature distributions means that each distribution can be independently estimated as a one dimensional distribution. This in turn helps to alleviate problems stemming from the curse of dimensionality.

On the flip side, although naive Bayes is known as a decent classifier, it is known to be a bad estimator, so the probability outputs from predict_proba are not to be taken too seriously.

H. Zhang (2004). The optimality of Naive Bayes. Proc. FLAIRS.

GaussianNB implements the Gaussian Naive Bayes algorithm for classification. The likelihood of the features is assumed to be Gaussian:

The parameters \(\sigma_y\) and \(\mu_y\) are estimated using maximum likelihood.

MultinomialNB implements the naive Bayes algorithm for multinomially distributed data, and is one of the two classic naive Bayes variants used in text classification (where the data are typically represented as word vector counts, although tf-idf vectors are also known to work well in practice). The distribution is parametrized by vectors \(\theta_y = (\theta_{y1},\ldots,\theta_{yn})\) for each class \(y\), where \(n\) is the number of features (in text classification, the size of the vocabulary) and \(\theta_{yi}\) is the probability \(P(x_i \mid y)\) of feature \(i\) appearing in a sample belonging to class \(y\).

The parameters \(\theta_y\) are estimated by a smoothed version of maximum likelihood, i.e. relative frequency counting:

where \(N_{yi} = \sum_{x \in T} x_i\) is the number of times feature \(i\) appears in all samples of class \(y\) in the training set \(T\), and \(N_{y} = \sum_{i=1}^{n} N_{yi}\) is the total count of all features for class \(y\).

The smoothing priors \(\alpha \ge 0\) account for features not present in the learning samples and prevent zero probabilities in further computations. Setting \(\alpha = 1\) is called Laplace smoothing, while \(\alpha < 1\) is called Lidstone smoothing.

ComplementNB implements the complement naive Bayes (CNB) algorithm. CNB is an adaptation of the standard multinomial naive Bayes (MNB) algorithm that is particularly suited for imbalanced data sets. Specifically, CNB uses statistics from the complement of each class to compute the model’s weights. The inventors of CNB show empirically that the parameter estimates for CNB are more stable than those for MNB. Further, CNB regularly outperforms MNB (often by a considerable margin) on text classification tasks.

The procedure for calculating the weights is as follows:

where the summations are over all documents \(j\) not in class \(c\), \(d_{ij}\) is either the count or tf-idf value of term \(i\) in document \(j\), \(\alpha_i\) is a smoothing hyperparameter like that found in MNB, and \(\alpha = \sum_{i} \alpha_i\). The second normalization addresses the tendency for longer documents to dominate parameter estimates in MNB. The classification rule is:

i.e., a document is assigned to the class that is the poorest complement match.

Rennie, J. D., Shih, L., Teevan, J., & Karger, D. R. (2003). Tackling the poor assumptions of naive bayes text classifiers. In ICML (Vol. 3, pp. 616-623).

BernoulliNB implements the naive Bayes training and classification algorithms for data that is distributed according to multivariate Bernoulli distributions; i.e., there may be multiple features but each one is assumed to be a binary-valued (Bernoulli, boolean) variable. Therefore, this class requires samples to be represented as binary-valued feature vectors; if handed any other kind of data, a BernoulliNB instance may binarize its input (depending on the binarize parameter).

The decision rule for Bernoulli naive Bayes is based on

which differs from multinomial NB’s rule in that it explicitly penalizes the non-occurrence of a feature \(i\) that is an indicator for class \(y\), where the multinomial variant would simply ignore a non-occurring feature.

In the case of text classification, word occurrence vectors (rather than word count vectors) may be used to train and use this classifier. BernoulliNB might perform better on some datasets, especially those with shorter documents. It is advisable to evaluate both models, if time permits.

C.D. Manning, P. Raghavan and H. Schütze (2008). Introduction to Information Retrieval. Cambridge University Press, pp. 234-265.

A. McCallum and K. Nigam (1998). A comparison of event models for Naive Bayes text classification. Proc. AAAI/ICML-98 Workshop on Learning for Text Categorization, pp. 41-48.

V. Metsis, I. Androutsopoulos and G. Paliouras (2006). Spam filtering with Naive Bayes – Which Naive Bayes? 3rd Conf. on Email and Anti-Spam (CEAS).

CategoricalNB implements the categorical naive Bayes algorithm for categorically distributed data. It assumes that each feature, which is described by the index \(i\), has its own categorical distribution.

For each feature \(i\) in the training set \(X\), CategoricalNB estimates a categorical distribution for each feature i of X conditioned on the class y. The index set of the samples is defined as \(J = \{ 1, \dots, m \}\), with \(m\) as the number of samples.

The probability of category \(t\) in feature \(i\) given class \(c\) is estimated as:

where \(N_{tic} = |\{j \in J \mid x_{ij} = t, y_j = c\}|\) is the number of times category \(t\) appears in the samples \(x_{i}\), which belong to class \(c\), \(N_{c} = |\{ j \in J\mid y_j = c\}|\) is the number of samples with class c, \(\alpha\) is a smoothing parameter and \(n_i\) is the number of available categories of feature \(i\).

CategoricalNB assumes that the sample matrix \(X\) is encoded (for instance with the help of OrdinalEncoder) such that all categories for each feature \(i\) are represented with numbers \(0, ..., n_i - 1\) where \(n_i\) is the number of available categories of feature \(i\).

Naive Bayes models can be used to tackle large scale classification problems for which the full training set might not fit in memory. To handle this case, MultinomialNB, BernoulliNB, and GaussianNB expose a partial_fit method that can be used incrementally as done with other classifiers as demonstrated in Out-of-core classification of text documents. All naive Bayes classifiers support sample weighting.

Contrary to the fit method, the first call to partial_fit needs to be passed the list of all the expected class labels.

For an overview of available strategies in scikit-learn, see also the out-of-core learning documentation.

The partial_fit method call of naive Bayes models introduces some computational overhead. It is recommended to use data chunk sizes that are as large as possible, that is as the available RAM allows.

**Examples:**

Example 1 (python):
```python
>>> from sklearn.datasets import load_iris
>>> from sklearn.model_selection import train_test_split
>>> from sklearn.naive_bayes import GaussianNB
>>> X, y = load_iris(return_X_y=True)
>>> X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=0)
>>> gnb = GaussianNB()
>>> y_pred = gnb.fit(X_train, y_train).predict(X_test)
>>> print("Number of mislabeled points out of a total %d points : %d"
...       % (X_test.shape[0], (y_test != y_pred).sum()))
Number of mislabeled points out of a total 75 points : 4
```

---

## 

**URL:** https://scikit-learn.org/stable/_sources/modules/neighbors.rst.txt

---

## locally_linear_embedding#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.manifold.locally_linear_embedding.html

**Contents:**
- locally_linear_embedding#
- Gallery examples#

Perform a Locally Linear Embedding analysis on the data.

Read more in the User Guide.

Sample data, shape = (n_samples, n_features), in the form of a numpy array or a NearestNeighbors object.

Number of neighbors to consider for each point.

Number of coordinates for the manifold.

Regularization constant, multiplies the trace of the local covariance matrix of the distances.

auto : algorithm will attempt to choose the best method for input data

For this method, M may be a dense matrix, sparse matrix, or general linear operator. Warning: ARPACK can be unstable for some problems. It is best to try several random seeds in order to check results.

decomposition. For this method, M must be an array or matrix type. This method should be avoided for large problems.

Tolerance for ‘arpack’ method Not used if eigen_solver==’dense’.

Maximum number of iterations for the arpack solver.

n_neighbors > n_components * (1 + (n_components + 1) / 2. see reference [2]

Tolerance for Hessian eigenmapping method. Only used if method == ‘hessian’.

Tolerance for modified LLE method. Only used if method == ‘modified’.

Determines the random number generator when solver == ‘arpack’. Pass an int for reproducible results across multiple function calls. See Glossary.

The number of parallel jobs to run for neighbors search. None means 1 unless in a joblib.parallel_backend context. -1 means using all processors. See Glossary for more details.

Reconstruction error for the embedding vectors. Equivalent to norm(Y - W Y, 'fro')**2, where W are the reconstruction weights.

Roweis, S. & Saul, L. Nonlinear dimensionality reduction by locally linear embedding. Science 290:2323 (2000).

Donoho, D. & Grimes, C. Hessian eigenmaps: Locally linear embedding techniques for high-dimensional data. Proc Natl Acad Sci U S A. 100:5591 (2003).

Zhang, Z. & Wang, J. MLLE: Modified Locally Linear Embedding Using Multiple Weights.

Zhang, Z. & Zha, H. Principal manifolds and nonlinear dimensionality reduction via tangent space alignment. Journal of Shanghai Univ. 8:406 (2004)

Swiss Roll And Swiss-Hole Reduction

**Examples:**

Example 1 (sql):
```sql
>>> from sklearn.datasets import load_digits
>>> from sklearn.manifold import locally_linear_embedding
>>> X, _ = load_digits(return_X_y=True)
>>> X.shape
(1797, 64)
>>> embedding, _ = locally_linear_embedding(X[:100],n_neighbors=5, n_components=2)
>>> embedding.shape
(100, 2)
```

---

## QuantileRegressor#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.QuantileRegressor.html

**Contents:**
- QuantileRegressor#
- Gallery examples#

Linear regression model that predicts conditional quantiles.

The linear QuantileRegressor optimizes the pinball loss for a desired quantile and is robust to outliers.

This model uses an L1 regularization like Lasso.

Read more in the User Guide.

Added in version 1.0.

The quantile that the model tries to predict. It must be strictly between 0 and 1. If 0.5 (default), the model predicts the 50% quantile, i.e. the median.

Regularization constant that multiplies the L1 penalty term.

Whether or not to fit the intercept.

Method used by scipy.optimize.linprog to solve the linear programming formulation.

It is recommended to use the highs methods because they are the fastest ones. Solvers “highs-ds”, “highs-ipm” and “highs” support sparse input data and, in fact, always convert to sparse csc.

From scipy>=1.11.0, “interior-point” is not available anymore.

Changed in version 1.4: The default of solver changed to "highs" in version 1.4.

Additional parameters passed to scipy.optimize.linprog as options. If None and if solver='interior-point', then {"lstsq": True} is passed to scipy.optimize.linprog for the sake of stability.

Estimated coefficients for the features.

The intercept of the model, aka bias term.

Number of features seen during fit.

Added in version 0.24.

Names of features seen during fit. Defined only when X has feature names that are all strings.

Added in version 1.0.

The actual number of iterations performed by the solver.

The Lasso is a linear model that estimates sparse coefficients with l1 regularization.

Linear regression model that is robust to outliers.

Fit the model according to the given training data.

Get metadata routing of this object.

Please check User Guide on how the routing mechanism works.

A MetadataRequest encapsulating routing information.

Get parameters for this estimator.

If True, will return the parameters for this estimator and contained subobjects that are estimators.

Parameter names mapped to their values.

Predict using the linear model.

Returns predicted values.

Return coefficient of determination on test data.

The coefficient of determination, \(R^2\), is defined as \((1 - \frac{u}{v})\), where \(u\) is the residual sum of squares ((y_true - y_pred)** 2).sum() and \(v\) is the total sum of squares ((y_true - y_true.mean()) ** 2).sum(). The best possible score is 1.0 and it can be negative (because the model can be arbitrarily worse). A constant model that always predicts the expected value of y, disregarding the input features, would get a \(R^2\) score of 0.0.

Test samples. For some estimators this may be a precomputed kernel matrix or a list of generic objects instead with shape (n_samples, n_samples_fitted), where n_samples_fitted is the number of samples used in the fitting for the estimator.

\(R^2\) of self.predict(X) w.r.t. y.

The \(R^2\) score used when calling score on a regressor uses multioutput='uniform_average' from version 0.23 to keep consistent with default value of r2_score. This influences the score method of all the multioutput regressors (except for MultiOutputRegressor).

Configure whether metadata should be requested to be passed to the fit method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to fit if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to fit.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Added in version 1.3.

Metadata routing for sample_weight parameter in fit.

Set the parameters of this estimator.

The method works on simple estimators as well as on nested objects (such as Pipeline). The latter have parameters of the form <component>__<parameter> so that it’s possible to update each component of a nested object.

Estimator parameters.

Configure whether metadata should be requested to be passed to the score method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to score if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to score.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Added in version 1.3.

Metadata routing for sample_weight parameter in score.

**Examples:**

Example 1 (sql):
```sql
>>> from sklearn.linear_model import QuantileRegressor
>>> import numpy as np
>>> n_samples, n_features = 10, 2
>>> rng = np.random.RandomState(0)
>>> y = rng.randn(n_samples)
>>> X = rng.randn(n_samples, n_features)
>>> # the two following lines are optional in practice
>>> from sklearn.utils.fixes import sp_version, parse_version
>>> reg = QuantileRegressor(quantile=0.8).fit(X, y)
>>> np.mean(y <= reg.predict(X))
np.float64(0.8)
```

---

## DummyRegressor#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.dummy.DummyRegressor.html

**Contents:**
- DummyRegressor#
- Gallery examples#

Regressor that makes predictions using simple rules.

This regressor is useful as a simple baseline to compare with other (real) regressors. Do not use it for real problems.

Read more in the User Guide.

Added in version 0.13.

Strategy to use to generate predictions.

“mean”: always predicts the mean of the training set

“median”: always predicts the median of the training set

“quantile”: always predicts a specified quantile of the training set, provided with the quantile parameter.

“constant”: always predicts a constant value that is provided by the user.

The explicit constant as predicted by the “constant” strategy. This parameter is useful only for the “constant” strategy.

The quantile to predict using the “quantile” strategy. A quantile of 0.5 corresponds to the median, while 0.0 to the minimum and 1.0 to the maximum.

Mean or median or quantile of the training targets or constant value given by the user.

Number of features seen during fit.

Names of features seen during fit. Defined only when X has feature names that are all strings.

Classifier that makes predictions using simple rules.

Fit the baseline regressor.

Get metadata routing of this object.

Please check User Guide on how the routing mechanism works.

A MetadataRequest encapsulating routing information.

Get parameters for this estimator.

If True, will return the parameters for this estimator and contained subobjects that are estimators.

Parameter names mapped to their values.

Perform classification on test vectors X.

Whether to return the standard deviation of posterior prediction. All zeros in this case.

Added in version 0.20.

Predicted target values for X.

Standard deviation of predictive distribution of query points.

Return the coefficient of determination R^2 of the prediction.

The coefficient R^2 is defined as (1 - u/v), where u is the residual sum of squares ((y_true - y_pred) ** 2).sum() and v is the total sum of squares ((y_true - y_true.mean()) ** 2).sum(). The best possible score is 1.0 and it can be negative (because the model can be arbitrarily worse). A constant model that always predicts the expected value of y, disregarding the input features, would get a R^2 score of 0.0.

Test samples. Passing None as test samples gives the same result as passing real test samples, since DummyRegressor operates independently of the sampled observations.

R^2 of self.predict(X) w.r.t. y.

Configure whether metadata should be requested to be passed to the fit method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to fit if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to fit.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Added in version 1.3.

Metadata routing for sample_weight parameter in fit.

Set the parameters of this estimator.

The method works on simple estimators as well as on nested objects (such as Pipeline). The latter have parameters of the form <component>__<parameter> so that it’s possible to update each component of a nested object.

Estimator parameters.

Configure whether metadata should be requested to be passed to the predict method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to predict if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to predict.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Added in version 1.3.

Metadata routing for return_std parameter in predict.

Configure whether metadata should be requested to be passed to the score method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to score if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to score.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Added in version 1.3.

Metadata routing for sample_weight parameter in score.

Poisson regression and non-normal loss

Tweedie regression on insurance claims

**Examples:**

Example 1 (sql):
```sql
>>> import numpy as np
>>> from sklearn.dummy import DummyRegressor
>>> X = np.array([1.0, 2.0, 3.0, 4.0])
>>> y = np.array([2.0, 3.0, 5.0, 10.0])
>>> dummy_regr = DummyRegressor(strategy="mean")
>>> dummy_regr.fit(X, y)
DummyRegressor()
>>> dummy_regr.predict(X)
array([5., 5., 5., 5.])
>>> dummy_regr.score(X, y)
0.0
```

---

## 2.6. Covariance estimation#

**URL:** https://scikit-learn.org/stable/modules/covariance.html

**Contents:**
- 2.6. Covariance estimation#
- 2.6.1. Empirical covariance#
- 2.6.2. Shrunk Covariance#
  - 2.6.2.1. Basic shrinkage#
  - 2.6.2.2. Ledoit-Wolf shrinkage#
  - 2.6.2.3. Oracle Approximating Shrinkage#
- 2.6.3. Sparse inverse covariance#
- 2.6.4. Robust Covariance Estimation#
  - 2.6.4.1. Minimum Covariance Determinant#

Many statistical problems require the estimation of a population’s covariance matrix, which can be seen as an estimation of data set scatter plot shape. Most of the time, such an estimation has to be done on a sample whose properties (size, structure, homogeneity) have a large influence on the estimation’s quality. The sklearn.covariance package provides tools for accurately estimating a population’s covariance matrix under various settings.

We assume that the observations are independent and identically distributed (i.i.d.).

The covariance matrix of a data set is known to be well approximated by the classical maximum likelihood estimator (or “empirical covariance”), provided the number of observations is large enough compared to the number of features (the variables describing the observations). More precisely, the Maximum Likelihood Estimator of a sample is an asymptotically unbiased estimator of the corresponding population’s covariance matrix.

The empirical covariance matrix of a sample can be computed using the empirical_covariance function of the package, or by fitting an EmpiricalCovariance object to the data sample with the EmpiricalCovariance.fit method. Be careful that results depend on whether the data are centered, so one may want to use the assume_centered parameter accurately. More precisely, if assume_centered=True, then all features in the train and test sets should have a mean of zero. If not, both should be centered by the user, or assume_centered=False should be used.

See Shrinkage covariance estimation: LedoitWolf vs OAS and max-likelihood for an example on how to fit an EmpiricalCovariance object to data.

Despite being an asymptotically unbiased estimator of the covariance matrix, the Maximum Likelihood Estimator is not a good estimator of the eigenvalues of the covariance matrix, so the precision matrix obtained from its inversion is not accurate. Sometimes, it even occurs that the empirical covariance matrix cannot be inverted for numerical reasons. To avoid such an inversion problem, a transformation of the empirical covariance matrix has been introduced: the shrinkage.

In scikit-learn, this transformation (with a user-defined shrinkage coefficient) can be directly applied to a pre-computed covariance with the shrunk_covariance method. Also, a shrunk estimator of the covariance can be fitted to data with a ShrunkCovariance object and its ShrunkCovariance.fit method. Again, results depend on whether the data are centered, so one may want to use the assume_centered parameter accurately.

Mathematically, this shrinkage consists in reducing the ratio between the smallest and the largest eigenvalues of the empirical covariance matrix. It can be done by simply shifting every eigenvalue according to a given offset, which is equivalent of finding the l2-penalized Maximum Likelihood Estimator of the covariance matrix. In practice, shrinkage boils down to a simple convex transformation : \(\Sigma_{\rm shrunk} = (1-\alpha)\hat{\Sigma} + \alpha\frac{{\rm Tr}\hat{\Sigma}}{p}\rm Id\).

Choosing the amount of shrinkage, \(\alpha\) amounts to setting a bias/variance trade-off, and is discussed below.

See Shrinkage covariance estimation: LedoitWolf vs OAS and max-likelihood for an example on how to fit a ShrunkCovariance object to data.

In their 2004 paper [1], O. Ledoit and M. Wolf propose a formula to compute the optimal shrinkage coefficient \(\alpha\) that minimizes the Mean Squared Error between the estimated and the real covariance matrix.

The Ledoit-Wolf estimator of the covariance matrix can be computed on a sample with the ledoit_wolf function of the sklearn.covariance package, or it can be otherwise obtained by fitting a LedoitWolf object to the same sample.

Case when population covariance matrix is isotropic

It is important to note that when the number of samples is much larger than the number of features, one would expect that no shrinkage would be necessary. The intuition behind this is that if the population covariance is full rank, when the number of samples grows, the sample covariance will also become positive definite. As a result, no shrinkage would be necessary and the method should automatically do this.

This, however, is not the case in the Ledoit-Wolf procedure when the population covariance happens to be a multiple of the identity matrix. In this case, the Ledoit-Wolf shrinkage estimate approaches 1 as the number of samples increases. This indicates that the optimal estimate of the covariance matrix in the Ledoit-Wolf sense is a multiple of the identity. Since the population covariance is already a multiple of the identity matrix, the Ledoit-Wolf solution is indeed a reasonable estimate.

See Shrinkage covariance estimation: LedoitWolf vs OAS and max-likelihood for an example on how to fit a LedoitWolf object to data and for visualizing the performances of the Ledoit-Wolf estimator in terms of likelihood.

O. Ledoit and M. Wolf, “A Well-Conditioned Estimator for Large-Dimensional Covariance Matrices”, Journal of Multivariate Analysis, Volume 88, Issue 2, February 2004, pages 365-411.

Under the assumption that the data are Gaussian distributed, Chen et al. [2] derived a formula aimed at choosing a shrinkage coefficient that yields a smaller Mean Squared Error than the one given by Ledoit and Wolf’s formula. The resulting estimator is known as the Oracle Shrinkage Approximating estimator of the covariance.

The OAS estimator of the covariance matrix can be computed on a sample with the oas function of the sklearn.covariance package, or it can be otherwise obtained by fitting an OAS object to the same sample.

Bias-variance trade-off when setting the shrinkage: comparing the choices of Ledoit-Wolf and OAS estimators#

“Shrinkage algorithms for MMSE covariance estimation.”, Chen, Y., Wiesel, A., Eldar, Y. C., & Hero, A. O. IEEE Transactions on Signal Processing, 58(10), 5016-5029, 2010.

See Shrinkage covariance estimation: LedoitWolf vs OAS and max-likelihood for an example on how to fit an OAS object to data.

See Ledoit-Wolf vs OAS estimation to visualize the Mean Squared Error difference between a LedoitWolf and an OAS estimator of the covariance.

The matrix inverse of the covariance matrix, often called the precision matrix, is proportional to the partial correlation matrix. It gives the partial independence relationship. In other words, if two features are independent conditionally on the others, the corresponding coefficient in the precision matrix will be zero. This is why it makes sense to estimate a sparse precision matrix: the estimation of the covariance matrix is better conditioned by learning independence relations from the data. This is known as covariance selection.

In the small-samples situation, in which n_samples is on the order of n_features or smaller, sparse inverse covariance estimators tend to work better than shrunk covariance estimators. However, in the opposite situation, or for very correlated data, they can be numerically unstable. In addition, unlike shrinkage estimators, sparse estimators are able to recover off-diagonal structure.

The GraphicalLasso estimator uses an l1 penalty to enforce sparsity on the precision matrix: the higher its alpha parameter, the more sparse the precision matrix. The corresponding GraphicalLassoCV object uses cross-validation to automatically set the alpha parameter.

A comparison of maximum likelihood, shrinkage and sparse estimates of the covariance and precision matrix in the very small samples settings.#

Recovering a graphical structure from correlations in the data is a challenging thing. If you are interested in such recovery keep in mind that:

Recovery is easier from a correlation matrix than a covariance matrix: standardize your observations before running GraphicalLasso

If the underlying graph has nodes with much more connections than the average node, the algorithm will miss some of these connections.

If your number of observations is not large compared to the number of edges in your underlying graph, you will not recover it.

Even if you are in favorable recovery conditions, the alpha parameter chosen by cross-validation (e.g. using the GraphicalLassoCV object) will lead to selecting too many edges. However, the relevant edges will have heavier weights than the irrelevant ones.

The mathematical formulation is the following:

Where \(K\) is the precision matrix to be estimated, and \(S\) is the sample covariance matrix. \(\|K\|_1\) is the sum of the absolute values of off-diagonal coefficients of \(K\). The algorithm employed to solve this problem is the GLasso algorithm, from the Friedman 2008 Biostatistics paper. It is the same algorithm as in the R glasso package.

Sparse inverse covariance estimation: example on synthetic data showing some recovery of a structure, and comparing to other covariance estimators.

Visualizing the stock market structure: example on real stock market data, finding which symbols are most linked.

Friedman et al, “Sparse inverse covariance estimation with the graphical lasso”, Biostatistics 9, pp 432, 2008

Real data sets are often subject to measurement or recording errors. Regular but uncommon observations may also appear for a variety of reasons. Observations which are very uncommon are called outliers. The empirical covariance estimator and the shrunk covariance estimators presented above are very sensitive to the presence of outliers in the data. Therefore, one should use robust covariance estimators to estimate the covariance of its real data sets. Alternatively, robust covariance estimators can be used to perform outlier detection and discard/downweight some observations according to further processing of the data.

The sklearn.covariance package implements a robust estimator of covariance, the Minimum Covariance Determinant [3].

The Minimum Covariance Determinant estimator is a robust estimator of a data set’s covariance introduced by P.J. Rousseeuw in [3]. The idea is to find a given proportion (h) of “good” observations which are not outliers and compute their empirical covariance matrix. This empirical covariance matrix is then rescaled to compensate the performed selection of observations (“consistency step”). Having computed the Minimum Covariance Determinant estimator, one can give weights to observations according to their Mahalanobis distance, leading to a reweighted estimate of the covariance matrix of the data set (“reweighting step”).

Rousseeuw and Van Driessen [4] developed the FastMCD algorithm in order to compute the Minimum Covariance Determinant. This algorithm is used in scikit-learn when fitting an MCD object to data. The FastMCD algorithm also computes a robust estimate of the data set location at the same time.

Raw estimates can be accessed as raw_location_ and raw_covariance_ attributes of a MinCovDet robust covariance estimator object.

P. J. Rousseeuw. Least median of squares regression. J. Am Stat Ass, 79:871, 1984.

A Fast Algorithm for the Minimum Covariance Determinant Estimator, 1999, American Statistical Association and the American Society for Quality, TECHNOMETRICS.

See Robust vs Empirical covariance estimate for an example on how to fit a MinCovDet object to data and see how the estimate remains accurate despite the presence of outliers.

See Robust covariance estimation and Mahalanobis distances relevance to visualize the difference between EmpiricalCovariance and MinCovDet covariance estimators in terms of Mahalanobis distance (so we get a better estimate of the precision matrix too).

Influence of outliers on location and covariance estimates

Separating inliers from outliers using a Mahalanobis distance

---

## RANSACRegressor#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.RANSACRegressor.html

**Contents:**
- RANSACRegressor#
- Gallery examples#

RANSAC (RANdom SAmple Consensus) algorithm.

RANSAC is an iterative algorithm for the robust estimation of parameters from a subset of inliers from the complete data set.

Read more in the User Guide.

Base estimator object which implements the following methods:

fit(X, y): Fit model to given training data and target values.

score(X, y): Returns the mean accuracy on the given test data, which is used for the stop criterion defined by stop_score. Additionally, the score is used to decide which of two equally large consensus sets is chosen as the better one.

predict(X): Returns predicted values using the linear model, which is used to compute residual error using loss function.

If estimator is None, then LinearRegression is used for target values of dtype float.

Note that the current implementation only supports regression estimators.

Minimum number of samples chosen randomly from original data. Treated as an absolute number of samples for min_samples >= 1, treated as a relative number ceil(min_samples * X.shape[0]) for min_samples < 1. This is typically chosen as the minimal number of samples necessary to estimate the given estimator. By default a LinearRegression estimator is assumed and min_samples is chosen as X.shape[1] + 1. This parameter is highly dependent upon the model, so if a estimator other than LinearRegression is used, the user must provide a value.

Maximum residual for a data sample to be classified as an inlier. By default the threshold is chosen as the MAD (median absolute deviation) of the target values y. Points whose residuals are strictly equal to the threshold are considered as inliers.

This function is called with the randomly selected data before the model is fitted to it: is_data_valid(X, y). If its return value is False the current randomly chosen sub-sample is skipped.

This function is called with the estimated model and the randomly selected data: is_model_valid(model, X, y). If its return value is False the current randomly chosen sub-sample is skipped. Rejecting samples with this function is computationally costlier than with is_data_valid. is_model_valid should therefore only be used if the estimated model is needed for making the rejection decision.

Maximum number of iterations for random sample selection.

Maximum number of iterations that can be skipped due to finding zero inliers or invalid data defined by is_data_valid or invalid models defined by is_model_valid.

Added in version 0.19.

Stop iteration if at least this number of inliers are found.

Stop iteration if score is greater equal than this threshold.

RANSAC iteration stops if at least one outlier-free set of the training data is sampled in RANSAC. This requires to generate at least N samples (iterations):

where the probability (confidence) is typically set to high value such as 0.99 (the default) and e is the current fraction of inliers w.r.t. the total number of samples.

String inputs, ‘absolute_error’ and ‘squared_error’ are supported which find the absolute error and squared error per sample respectively.

If loss is a callable, then it should be a function that takes two arrays as inputs, the true and predicted value and returns a 1-D array with the i-th value of the array corresponding to the loss on X[i].

If the loss on a sample is greater than the residual_threshold, then this sample is classified as an outlier.

Added in version 0.18.

The generator used to initialize the centers. Pass an int for reproducible output across multiple function calls. See Glossary.

Final model fitted on the inliers predicted by the “best” model found during RANSAC sampling (copy of the estimator object).

Number of random selection trials until one of the stop criteria is met. It is always <= max_trials.

Boolean mask of inliers classified as True.

Number of iterations skipped due to finding zero inliers.

Added in version 0.19.

Number of iterations skipped due to invalid data defined by is_data_valid.

Added in version 0.19.

Number of iterations skipped due to an invalid model defined by is_model_valid.

Added in version 0.19.

Number of features seen during fit.

Added in version 0.24.

Names of features seen during fit. Defined only when X has feature names that are all strings.

Added in version 1.0.

Linear regression model that is robust to outliers.

Theil-Sen Estimator robust multivariate regression model.

Fitted by minimizing a regularized empirical loss with SGD.

https://en.wikipedia.org/wiki/RANSAC

https://www.sri.com/wp-content/uploads/2021/12/ransac-publication.pdf

https://bmva-archive.org.uk/bmvc/2009/Papers/Paper355/Paper355.pdf

For a more detailed example, see Robust linear model estimation using RANSAC

Fit estimator using RANSAC algorithm.

Individual weights for each sample raises error if sample_weight is passed and estimator fit method does not support it.

Added in version 0.18.

Parameters routed to the fit method of the sub-estimator via the metadata routing API.

Added in version 1.5: Only available if sklearn.set_config(enable_metadata_routing=True) is set. See Metadata Routing User Guide for more details.

Fitted RANSACRegressor estimator.

If no valid consensus set could be found. This occurs if is_data_valid and is_model_valid return False for all max_trials randomly chosen sub-samples.

Get metadata routing of this object.

Please check User Guide on how the routing mechanism works.

Added in version 1.5.

A MetadataRouter encapsulating routing information.

Get parameters for this estimator.

If True, will return the parameters for this estimator and contained subobjects that are estimators.

Parameter names mapped to their values.

Predict using the estimated model.

This is a wrapper for estimator_.predict(X).

Parameters routed to the predict method of the sub-estimator via the metadata routing API.

Added in version 1.5: Only available if sklearn.set_config(enable_metadata_routing=True) is set. See Metadata Routing User Guide for more details.

Returns predicted values.

Return the score of the prediction.

This is a wrapper for estimator_.score(X, y).

Parameters routed to the score method of the sub-estimator via the metadata routing API.

Added in version 1.5: Only available if sklearn.set_config(enable_metadata_routing=True) is set. See Metadata Routing User Guide for more details.

Score of the prediction.

Configure whether metadata should be requested to be passed to the fit method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to fit if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to fit.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Added in version 1.3.

Metadata routing for sample_weight parameter in fit.

Set the parameters of this estimator.

The method works on simple estimators as well as on nested objects (such as Pipeline). The latter have parameters of the form <component>__<parameter> so that it’s possible to update each component of a nested object.

Estimator parameters.

Robust linear model estimation using RANSAC

Robust linear estimator fitting

**Examples:**

Example 1 (unknown):
```unknown
N >= log(1 - probability) / log(1 - e**m)
```

Example 2 (sql):
```sql
>>> from sklearn.linear_model import RANSACRegressor
>>> from sklearn.datasets import make_regression
>>> X, y = make_regression(
...     n_samples=200, n_features=2, noise=4.0, random_state=0)
>>> reg = RANSACRegressor(random_state=0).fit(X, y)
>>> reg.score(X, y)
0.9885
>>> reg.predict(X[:1,])
array([-31.9417])
```

---

## 

**URL:** https://scikit-learn.org/stable/_sources/modules/kernel_ridge.rst.txt

---

## MinCovDet#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.covariance.MinCovDet.html

**Contents:**
- MinCovDet#
- Gallery examples#

Minimum Covariance Determinant (MCD): robust estimator of covariance.

The Minimum Covariance Determinant covariance estimator is to be applied on Gaussian-distributed data, but could still be relevant on data drawn from a unimodal, symmetric distribution. It is not meant to be used with multi-modal data (the algorithm used to fit a MinCovDet object is likely to fail in such a case). One should consider projection pursuit methods to deal with multi-modal datasets.

Read more in the User Guide.

Specify if the estimated precision is stored.

If True, the support of the robust location and the covariance estimates is computed, and a covariance estimate is recomputed from it, without centering the data. Useful to work with data whose mean is significantly equal to zero but is not exactly zero. If False, the robust location and covariance are directly computed with the FastMCD algorithm without additional treatment.

The proportion of points to be included in the support of the raw MCD estimate. Default is None, which implies that the minimum value of support_fraction will be used within the algorithm: (n_samples + n_features + 1) / 2 * n_samples. The parameter must be in the range (0, 1].

Determines the pseudo random number generator for shuffling the data. Pass an int for reproducible results across multiple function calls. See Glossary.

The raw robust estimated location before correction and re-weighting.

The raw robust estimated covariance before correction and re-weighting.

A mask of the observations that have been used to compute the raw robust estimates of location and shape, before correction and re-weighting.

Estimated robust location.

For an example of comparing raw robust estimates with the true location and covariance, refer to Robust vs Empirical covariance estimate.

Estimated robust covariance matrix.

Estimated pseudo inverse matrix. (stored only if store_precision is True)

A mask of the observations that have been used to compute the robust estimates of location and shape.

Mahalanobis distances of the training set (on which fit is called) observations.

Number of features seen during fit.

Added in version 0.24.

Names of features seen during fit. Defined only when X has feature names that are all strings.

Added in version 1.0.

An object for detecting outliers in a Gaussian distributed dataset.

Maximum likelihood covariance estimator.

Sparse inverse covariance estimation with an l1-penalized estimator.

Sparse inverse covariance with cross-validated choice of the l1 penalty.

LedoitWolf Estimator.

Oracle Approximating Shrinkage Estimator.

Covariance estimator with shrinkage.

P. J. Rousseeuw. Least median of squares regression. J. Am Stat Ass, 79:871, 1984.

A Fast Algorithm for the Minimum Covariance Determinant Estimator, 1999, American Statistical Association and the American Society for Quality, TECHNOMETRICS

R. W. Butler, P. L. Davies and M. Jhun, Asymptotics For The Minimum Covariance Determinant Estimator, The Annals of Statistics, 1993, Vol. 21, No. 3, 1385-1400

Apply a correction to raw Minimum Covariance Determinant estimates.

Correction using the asymptotic correction factor derived by [Croux1999].

The data matrix, with p features and n samples. The data set must be the one which was used to compute the raw estimates.

Corrected robust covariance estimate.

Influence Function and Efficiency of the Minimum Covariance Determinant Scatter Matrix Estimator, 1999, Journal of Multivariate Analysis, Volume 71, Issue 2, Pages 161-190

Compute the Mean Squared Error between two covariance estimators.

The covariance to compare with.

The type of norm used to compute the error. Available error types: - ‘frobenius’ (default): sqrt(tr(A^t.A)) - ‘spectral’: sqrt(max(eigenvalues(A^t.A)) where A is the error (comp_cov - self.covariance_).

If True (default), the squared error norm is divided by n_features. If False, the squared error norm is not rescaled.

Whether to compute the squared error norm or the error norm. If True (default), the squared error norm is returned. If False, the error norm is returned.

The Mean Squared Error (in the sense of the Frobenius norm) between self and comp_cov covariance estimators.

Fit a Minimum Covariance Determinant with the FastMCD algorithm.

Training data, where n_samples is the number of samples and n_features is the number of features.

Not used, present for API consistency by convention.

Returns the instance itself.

Get metadata routing of this object.

Please check User Guide on how the routing mechanism works.

A MetadataRequest encapsulating routing information.

Get parameters for this estimator.

If True, will return the parameters for this estimator and contained subobjects that are estimators.

Parameter names mapped to their values.

Getter for the precision matrix.

The precision matrix associated to the current covariance object.

Compute the squared Mahalanobis distances of given observations.

For a detailed example of how outliers affects the Mahalanobis distance, see Robust covariance estimation and Mahalanobis distances relevance.

The observations, the Mahalanobis distances of the which we compute. Observations are assumed to be drawn from the same distribution than the data used in fit.

Squared Mahalanobis distances of the observations.

Re-weight raw Minimum Covariance Determinant estimates.

Re-weight observations using Rousseeuw’s method (equivalent to deleting outlying observations from the data set before computing location and covariance estimates) described in [RVDriessen].

Corrects the re-weighted covariance to be consistent at the normal distribution, following [Croux1999].

The data matrix, with p features and n samples. The data set must be the one which was used to compute the raw estimates.

Re-weighted robust location estimate.

Re-weighted robust covariance estimate.

A mask of the observations that have been used to compute the re-weighted robust location and covariance estimates.

A Fast Algorithm for the Minimum Covariance Determinant Estimator, 1999, American Statistical Association and the American Society for Quality, TECHNOMETRICS

Influence Function and Efficiency of the Minimum Covariance Determinant Scatter Matrix Estimator, 1999, Journal of Multivariate Analysis, Volume 71, Issue 2, Pages 161-190

Compute the log-likelihood of X_test under the estimated Gaussian model.

The Gaussian model is defined by its mean and covariance matrix which are represented respectively by self.location_ and self.covariance_.

Test data of which we compute the likelihood, where n_samples is the number of samples and n_features is the number of features. X_test is assumed to be drawn from the same distribution than the data used in fit (including centering).

Not used, present for API consistency by convention.

The log-likelihood of X_test with self.location_ and self.covariance_ as estimators of the Gaussian model mean and covariance matrix respectively.

Set the parameters of this estimator.

The method works on simple estimators as well as on nested objects (such as Pipeline). The latter have parameters of the form <component>__<parameter> so that it’s possible to update each component of a nested object.

Estimator parameters.

Robust covariance estimation and Mahalanobis distances relevance

Robust vs Empirical covariance estimate

**Examples:**

Example 1 (sql):
```sql
>>> import numpy as np
>>> from sklearn.covariance import MinCovDet
>>> from sklearn.datasets import make_gaussian_quantiles
>>> real_cov = np.array([[.8, .3],
...                      [.3, .4]])
>>> rng = np.random.RandomState(0)
>>> X = rng.multivariate_normal(mean=[0, 0],
...                                   cov=real_cov,
...                                   size=500)
>>> cov = MinCovDet(random_state=0).fit(X)
>>> cov.covariance_
array([[0.8102, 0.2736],
       [0.2736, 0.3330]])
>>> cov.location_
array([0.0769 , 0.0397])
```

---

## kneighbors_graph#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.kneighbors_graph.html

**Contents:**
- kneighbors_graph#
- Gallery examples#

Compute the (weighted) graph of k-Neighbors for points in X.

Read more in the User Guide.

Number of neighbors for each sample.

Type of returned matrix: ‘connectivity’ will return the connectivity matrix with ones and zeros, and ‘distance’ will return the distances between neighbors according to the given metric.

Metric to use for distance computation. Default is “minkowski”, which results in the standard Euclidean distance when p = 2. See the documentation of scipy.spatial.distance and the metrics listed in distance_metrics for valid metric values.

Power parameter for the Minkowski metric. When p = 1, this is equivalent to using manhattan_distance (l1), and euclidean_distance (l2) for p = 2. For arbitrary p, minkowski_distance (l_p) is used. This parameter is expected to be positive.

Additional keyword arguments for the metric function.

Whether or not to mark each sample as the first nearest neighbor to itself. If ‘auto’, then True is used for mode=’connectivity’ and False for mode=’distance’.

The number of parallel jobs to run for neighbors search. None means 1 unless in a joblib.parallel_backend context. -1 means using all processors. See Glossary for more details.

Graph where A[i, j] is assigned the weight of edge that connects i to j. The matrix is of CSR format.

Compute the (weighted) graph of Neighbors for points in X.

Comparing different clustering algorithms on toy datasets

Hierarchical clustering with and without structure

**Examples:**

Example 1 (sql):
```sql
>>> X = [[0], [3], [1]]
>>> from sklearn.neighbors import kneighbors_graph
>>> A = kneighbors_graph(X, 2, mode='connectivity', include_self=True)
>>> A.toarray()
array([[1., 0., 1.],
       [0., 1., 1.],
       [1., 0., 1.]])
```

---

## mutual_info_regression#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.mutual_info_regression.html

**Contents:**
- mutual_info_regression#
- Gallery examples#

Estimate mutual information for a continuous target variable.

Mutual information (MI) [1] between two random variables is a non-negative value, which measures the dependency between the variables. It is equal to zero if and only if two random variables are independent, and higher values mean higher dependency.

The function relies on nonparametric methods based on entropy estimation from k-nearest neighbors distances as described in [2] and [3]. Both methods are based on the idea originally proposed in [4].

It can be used for univariate features selection, read more in the User Guide.

If bool, then determines whether to consider all features discrete or continuous. If array, then it should be either a boolean mask with shape (n_features,) or array with indices of discrete features. If ‘auto’, it is assigned to False for dense X and to True for sparse X.

Number of neighbors to use for MI estimation for continuous variables, see [2] and [3]. Higher values reduce variance of the estimation, but could introduce a bias.

Whether to make a copy of the given data. If set to False, the initial data will be overwritten.

Determines random number generation for adding small noise to continuous variables in order to remove repeated values. Pass an int for reproducible results across multiple function calls. See Glossary.

The number of jobs to use for computing the mutual information. The parallelization is done on the columns of X.

None means 1 unless in a joblib.parallel_backend context. -1 means using all processors. See Glossary for more details.

Added in version 1.5.

Estimated mutual information between each feature and the target in nat units.

The term “discrete features” is used instead of naming them “categorical”, because it describes the essence more accurately. For example, pixel intensities of an image are discrete features (but hardly categorical) and you will get better results if mark them as such. Also note, that treating a continuous variable as discrete and vice versa will usually give incorrect results, so be attentive about that.

True mutual information can’t be negative. If its estimate turns out to be negative, it is replaced by zero.

Mutual Information on Wikipedia.

A. Kraskov, H. Stogbauer and P. Grassberger, “Estimating mutual information”. Phys. Rev. E 69, 2004.

B. C. Ross “Mutual Information between Discrete and Continuous Data Sets”. PLoS ONE 9(2), 2014.

L. F. Kozachenko, N. N. Leonenko, “Sample Estimate of the Entropy of a Random Vector”, Probl. Peredachi Inf., 23:2 (1987), 9-16

Comparison of F-test and mutual information

**Examples:**

Example 1 (sql):
```sql
>>> from sklearn.datasets import make_regression
>>> from sklearn.feature_selection import mutual_info_regression
>>> X, y = make_regression(
...     n_samples=50, n_features=3, n_informative=1, noise=1e-4, random_state=42
... )
>>> mutual_info_regression(X, y)
array([0.117, 2.645, 0.0287])
```

---

## GradientBoostingRegressor#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingRegressor.html

**Contents:**
- GradientBoostingRegressor#
- Gallery examples#

Gradient Boosting for regression.

This estimator builds an additive model in a forward stage-wise fashion; it allows for the optimization of arbitrary differentiable loss functions. In each stage a regression tree is fit on the negative gradient of the given loss function.

HistGradientBoostingRegressor is a much faster variant of this algorithm for intermediate and large datasets (n_samples >= 10_000) and supports monotonic constraints.

Read more in the User Guide.

Loss function to be optimized. ‘squared_error’ refers to the squared error for regression. ‘absolute_error’ refers to the absolute error of regression and is a robust loss function. ‘huber’ is a combination of the two. ‘quantile’ allows quantile regression (use alpha to specify the quantile). See Prediction Intervals for Gradient Boosting Regression for an example that demonstrates quantile regression for creating prediction intervals with loss='quantile'.

Learning rate shrinks the contribution of each tree by learning_rate. There is a trade-off between learning_rate and n_estimators. Values must be in the range [0.0, inf).

The number of boosting stages to perform. Gradient boosting is fairly robust to over-fitting so a large number usually results in better performance. Values must be in the range [1, inf).

The fraction of samples to be used for fitting the individual base learners. If smaller than 1.0 this results in Stochastic Gradient Boosting. subsample interacts with the parameter n_estimators. Choosing subsample < 1.0 leads to a reduction of variance and an increase in bias. Values must be in the range (0.0, 1.0].

The function to measure the quality of a split. Supported criteria are “friedman_mse” for the mean squared error with improvement score by Friedman, “squared_error” for mean squared error. The default value of “friedman_mse” is generally the best as it can provide a better approximation in some cases.

Added in version 0.18.

The minimum number of samples required to split an internal node:

If int, values must be in the range [2, inf).

If float, values must be in the range (0.0, 1.0] and min_samples_split will be ceil(min_samples_split * n_samples).

Changed in version 0.18: Added float values for fractions.

The minimum number of samples required to be at a leaf node. A split point at any depth will only be considered if it leaves at least min_samples_leaf training samples in each of the left and right branches. This may have the effect of smoothing the model, especially in regression.

If int, values must be in the range [1, inf).

If float, values must be in the range (0.0, 1.0) and min_samples_leaf will be ceil(min_samples_leaf * n_samples).

Changed in version 0.18: Added float values for fractions.

The minimum weighted fraction of the sum total of weights (of all the input samples) required to be at a leaf node. Samples have equal weight when sample_weight is not provided. Values must be in the range [0.0, 0.5].

Maximum depth of the individual regression estimators. The maximum depth limits the number of nodes in the tree. Tune this parameter for best performance; the best value depends on the interaction of the input variables. If None, then nodes are expanded until all leaves are pure or until all leaves contain less than min_samples_split samples. If int, values must be in the range [1, inf).

A node will be split if this split induces a decrease of the impurity greater than or equal to this value. Values must be in the range [0.0, inf).

The weighted impurity decrease equation is the following:

where N is the total number of samples, N_t is the number of samples at the current node, N_t_L is the number of samples in the left child, and N_t_R is the number of samples in the right child.

N, N_t, N_t_R and N_t_L all refer to the weighted sum, if sample_weight is passed.

Added in version 0.19.

An estimator object that is used to compute the initial predictions. init has to provide fit and predict. If ‘zero’, the initial raw predictions are set to zero. By default a DummyEstimator is used, predicting either the average target value (for loss=’squared_error’), or a quantile for the other losses.

Controls the random seed given to each Tree estimator at each boosting iteration. In addition, it controls the random permutation of the features at each split (see Notes for more details). It also controls the random splitting of the training data to obtain a validation set if n_iter_no_change is not None. Pass an int for reproducible output across multiple function calls. See Glossary.

The number of features to consider when looking for the best split:

If int, values must be in the range [1, inf).

If float, values must be in the range (0.0, 1.0] and the features considered at each split will be max(1, int(max_features * n_features_in_)).

If “sqrt”, then max_features=sqrt(n_features).

If “log2”, then max_features=log2(n_features).

If None, then max_features=n_features.

Choosing max_features < n_features leads to a reduction of variance and an increase in bias.

Note: the search for a split does not stop until at least one valid partition of the node samples is found, even if it requires to effectively inspect more than max_features features.

The alpha-quantile of the huber loss function and the quantile loss function. Only if loss='huber' or loss='quantile'. Values must be in the range (0.0, 1.0).

Enable verbose output. If 1 then it prints progress and performance once in a while (the more trees the lower the frequency). If greater than 1 then it prints progress and performance for every tree. Values must be in the range [0, inf).

Grow trees with max_leaf_nodes in best-first fashion. Best nodes are defined as relative reduction in impurity. Values must be in the range [2, inf). If None, then unlimited number of leaf nodes.

When set to True, reuse the solution of the previous call to fit and add more estimators to the ensemble, otherwise, just erase the previous solution. See the Glossary.

The proportion of training data to set aside as validation set for early stopping. Values must be in the range (0.0, 1.0). Only used if n_iter_no_change is set to an integer.

Added in version 0.20.

n_iter_no_change is used to decide if early stopping will be used to terminate training when validation score is not improving. By default it is set to None to disable early stopping. If set to a number, it will set aside validation_fraction size of the training data as validation and terminate training when validation score is not improving in all of the previous n_iter_no_change numbers of iterations. Values must be in the range [1, inf). See Early stopping in Gradient Boosting.

Added in version 0.20.

Tolerance for the early stopping. When the loss is not improving by at least tol for n_iter_no_change iterations (if set to a number), the training stops. Values must be in the range [0.0, inf).

Added in version 0.20.

Complexity parameter used for Minimal Cost-Complexity Pruning. The subtree with the largest cost complexity that is smaller than ccp_alpha will be chosen. By default, no pruning is performed. Values must be in the range [0.0, inf). See Minimal Cost-Complexity Pruning for details. See Post pruning decision trees with cost complexity pruning for an example of such pruning.

Added in version 0.22.

The number of estimators as selected by early stopping (if n_iter_no_change is specified). Otherwise it is set to n_estimators.

The number of trees that are built at each iteration. For regressors, this is always 1.

Added in version 1.4.0.

The impurity-based feature importances.

The improvement in loss on the out-of-bag samples relative to the previous iteration. oob_improvement_[0] is the improvement in loss of the first stage over the init estimator. Only available if subsample < 1.0.

The full history of the loss values on the out-of-bag samples. Only available if subsample < 1.0.

Added in version 1.3.

The last value of the loss on the out-of-bag samples. It is the same as oob_scores_[-1]. Only available if subsample < 1.0.

Added in version 1.3.

The i-th score train_score_[i] is the loss of the model at iteration i on the in-bag sample. If subsample == 1 this is the loss on the training data.

The estimator that provides the initial predictions. Set via the init argument.

The collection of fitted sub-estimators.

Number of features seen during fit.

Added in version 0.24.

Names of features seen during fit. Defined only when X has feature names that are all strings.

Added in version 1.0.

The inferred value of max_features.

Histogram-based Gradient Boosting Classification Tree.

A decision tree regressor.

A random forest regressor.

The features are always randomly permuted at each split. Therefore, the best found split may vary, even with the same training data and max_features=n_features, if the improvement of the criterion is identical for several splits enumerated during the search of the best split. To obtain a deterministic behaviour during fitting, random_state has to be fixed.

J. Friedman, Greedy Function Approximation: A Gradient Boosting Machine, The Annals of Statistics, Vol. 29, No. 5, 2001.

Friedman, Stochastic Gradient Boosting, 1999

T. Hastie, R. Tibshirani and J. Friedman. Elements of Statistical Learning Ed. 2, Springer, 2009.

For a detailed example of utilizing GradientBoostingRegressor to fit an ensemble of weak predictive models, please refer to Gradient Boosting regression.

Apply trees in the ensemble to X, return leaf indices.

Added in version 0.17.

The input samples. Internally, its dtype will be converted to dtype=np.float32. If a sparse matrix is provided, it will be converted to a sparse csr_matrix.

For each datapoint x in X and for each tree in the ensemble, return the index of the leaf x ends up in each estimator.

Fit the gradient boosting model.

The input samples. Internally, it will be converted to dtype=np.float32 and if a sparse matrix is provided to a sparse csr_matrix.

Target values (strings or integers in classification, real numbers in regression) For classification, labels must correspond to classes.

Sample weights. If None, then samples are equally weighted. Splits that would create child nodes with net zero or negative weight are ignored while searching for a split in each node. In the case of classification, splits are also ignored if they would result in any single class carrying a negative weight in either child node.

The monitor is called after each iteration with the current iteration, a reference to the estimator and the local variables of _fit_stages as keyword arguments callable(i, self, locals()). If the callable returns True the fitting procedure is stopped. The monitor can be used for various things such as computing held-out estimates, early stopping, model introspect, and snapshotting.

Get metadata routing of this object.

Please check User Guide on how the routing mechanism works.

A MetadataRequest encapsulating routing information.

Get parameters for this estimator.

If True, will return the parameters for this estimator and contained subobjects that are estimators.

Parameter names mapped to their values.

Predict regression target for X.

The input samples. Internally, it will be converted to dtype=np.float32 and if a sparse matrix is provided to a sparse csr_matrix.

The predicted values.

Return coefficient of determination on test data.

The coefficient of determination, \(R^2\), is defined as \((1 - \frac{u}{v})\), where \(u\) is the residual sum of squares ((y_true - y_pred)** 2).sum() and \(v\) is the total sum of squares ((y_true - y_true.mean()) ** 2).sum(). The best possible score is 1.0 and it can be negative (because the model can be arbitrarily worse). A constant model that always predicts the expected value of y, disregarding the input features, would get a \(R^2\) score of 0.0.

Test samples. For some estimators this may be a precomputed kernel matrix or a list of generic objects instead with shape (n_samples, n_samples_fitted), where n_samples_fitted is the number of samples used in the fitting for the estimator.

\(R^2\) of self.predict(X) w.r.t. y.

The \(R^2\) score used when calling score on a regressor uses multioutput='uniform_average' from version 0.23 to keep consistent with default value of r2_score. This influences the score method of all the multioutput regressors (except for MultiOutputRegressor).

Configure whether metadata should be requested to be passed to the fit method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to fit if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to fit.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Added in version 1.3.

Metadata routing for monitor parameter in fit.

Metadata routing for sample_weight parameter in fit.

Set the parameters of this estimator.

The method works on simple estimators as well as on nested objects (such as Pipeline). The latter have parameters of the form <component>__<parameter> so that it’s possible to update each component of a nested object.

Estimator parameters.

Configure whether metadata should be requested to be passed to the score method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to score if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to score.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Added in version 1.3.

Metadata routing for sample_weight parameter in score.

Predict regression target at each stage for X.

This method allows monitoring (i.e. determine error on testing set) after each stage.

The input samples. Internally, it will be converted to dtype=np.float32 and if a sparse matrix is provided to a sparse csr_matrix.

The predicted value of the input samples.

Model Complexity Influence

Early stopping in Gradient Boosting

Prediction Intervals for Gradient Boosting Regression

Gradient Boosting regression

Plot individual and voting regression predictions

**Examples:**

Example 1 (yaml):
```yaml
N_t / N * (impurity - N_t_R / N_t * right_impurity
                    - N_t_L / N_t * left_impurity)
```

Example 2 (sql):
```sql
>>> from sklearn.datasets import make_regression
>>> from sklearn.ensemble import GradientBoostingRegressor
>>> from sklearn.model_selection import train_test_split
>>> X, y = make_regression(random_state=0)
>>> X_train, X_test, y_train, y_test = train_test_split(
...     X, y, random_state=0)
>>> reg = GradientBoostingRegressor(random_state=0)
>>> reg.fit(X_train, y_train)
GradientBoostingRegressor(random_state=0)
>>> reg.predict(X_test[1:2])
array([-61.1])
>>> reg.score(X_test, y_test)
0.4...
```

---

## NuSVC#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.svm.NuSVC.html

**Contents:**
- NuSVC#

Nu-Support Vector Classification.

Similar to SVC but uses a parameter to control the number of support vectors.

The implementation is based on libsvm.

Read more in the User Guide.

An upper bound on the fraction of margin errors (see User Guide) and a lower bound of the fraction of support vectors. Should be in the interval (0, 1].

Specifies the kernel type to be used in the algorithm. If none is given, ‘rbf’ will be used. If a callable is given it is used to precompute the kernel matrix. For an intuitive visualization of different kernel types see Plot classification boundaries with different SVM Kernels.

Degree of the polynomial kernel function (‘poly’). Must be non-negative. Ignored by all other kernels.

Kernel coefficient for ‘rbf’, ‘poly’ and ‘sigmoid’.

if gamma='scale' (default) is passed then it uses 1 / (n_features * X.var()) as value of gamma,

if ‘auto’, uses 1 / n_features

if float, must be non-negative.

Changed in version 0.22: The default value of gamma changed from ‘auto’ to ‘scale’.

Independent term in kernel function. It is only significant in ‘poly’ and ‘sigmoid’.

Whether to use the shrinking heuristic. See the User Guide.

Whether to enable probability estimates. This must be enabled prior to calling fit, will slow down that method as it internally uses 5-fold cross-validation, and predict_proba may be inconsistent with predict. Read more in the User Guide.

Tolerance for stopping criterion.

Specify the size of the kernel cache (in MB).

Set the parameter C of class i to class_weight[i]*C for SVC. If not given, all classes are supposed to have weight one. The “balanced” mode uses the values of y to automatically adjust weights inversely proportional to class frequencies as n_samples / (n_classes * np.bincount(y)).

Enable verbose output. Note that this setting takes advantage of a per-process runtime setting in libsvm that, if enabled, may not work properly in a multithreaded context.

Hard limit on iterations within solver, or -1 for no limit.

Whether to return a one-vs-rest (‘ovr’) decision function of shape (n_samples, n_classes) as all other classifiers, or the original one-vs-one (‘ovo’) decision function of libsvm which has shape (n_samples, n_classes * (n_classes - 1) / 2). However, one-vs-one (‘ovo’) is always used as multi-class strategy. The parameter is ignored for binary classification.

Changed in version 0.19: decision_function_shape is ‘ovr’ by default.

Added in version 0.17: decision_function_shape=’ovr’ is recommended.

Changed in version 0.17: Deprecated decision_function_shape=’ovo’ and None.

If true, decision_function_shape='ovr', and number of classes > 2, predict will break ties according to the confidence values of decision_function; otherwise the first class among the tied classes is returned. Please note that breaking ties comes at a relatively high computational cost compared to a simple predict. See SVM Tie Breaking Example for an example of its usage with decision_function_shape='ovr'.

Added in version 0.22.

Controls the pseudo random number generation for shuffling the data for probability estimates. Ignored when probability is False. Pass an int for reproducible output across multiple function calls. See Glossary.

Multipliers of parameter C of each class. Computed based on the class_weight parameter.

The unique classes labels.

Weights assigned to the features when kernel="linear".

Dual coefficients of the support vector in the decision function (see Mathematical formulation), multiplied by their targets. For multiclass, coefficient for all 1-vs-1 classifiers. The layout of the coefficients in the multiclass case is somewhat non-trivial. See the multi-class section of the User Guide for details.

0 if correctly fitted, 1 if the algorithm did not converge.

Constants in decision function.

Number of features seen during fit.

Added in version 0.24.

Names of features seen during fit. Defined only when X has feature names that are all strings.

Added in version 1.0.

Number of iterations run by the optimization routine to fit the model. The shape of this attribute depends on the number of models optimized which in turn depends on the number of classes.

Added in version 1.1.

Indices of support vectors.

Number of support vectors for each class.

0 if correctly fitted, 1 if the algorithm did not converge.

Parameter learned in Platt scaling when probability=True.

Parameter learned in Platt scaling when probability=True.

Array dimensions of training vector X.

Support Vector Machine for classification using libsvm.

Scalable linear Support Vector Machine for classification using liblinear.

LIBSVM: A Library for Support Vector Machines

Platt, John (1999). “Probabilistic Outputs for Support Vector Machines and Comparisons to Regularized Likelihood Methods”

Evaluate the decision function for the samples in X.

Returns the decision function of the sample for each class in the model. If decision_function_shape=’ovr’, the shape is (n_samples, n_classes).

If decision_function_shape=’ovo’, the function values are proportional to the distance of the samples X to the separating hyperplane. If the exact distances are required, divide the function values by the norm of the weight vector (coef_). See also this question for further details. If decision_function_shape=’ovr’, the decision function is a monotonic transformation of ovo decision function.

Fit the SVM model according to the given training data.

Training vectors, where n_samples is the number of samples and n_features is the number of features. For kernel=”precomputed”, the expected shape of X is (n_samples, n_samples).

Target values (class labels in classification, real numbers in regression).

Per-sample weights. Rescale C per sample. Higher weights force the classifier to put more emphasis on these points.

If X and y are not C-ordered and contiguous arrays of np.float64 and X is not a scipy.sparse.csr_matrix, X and/or y may be copied.

If X is a dense array, then the other methods will not support sparse matrices as input.

Get metadata routing of this object.

Please check User Guide on how the routing mechanism works.

A MetadataRequest encapsulating routing information.

Get parameters for this estimator.

If True, will return the parameters for this estimator and contained subobjects that are estimators.

Parameter names mapped to their values.

Perform classification on samples in X.

For a one-class model, +1 or -1 is returned.

For kernel=”precomputed”, the expected shape of X is (n_samples_test, n_samples_train).

Class labels for samples in X.

Compute log probabilities of possible outcomes for samples in X.

The model need to have probability information computed at training time: fit with attribute probability set to True.

For kernel=”precomputed”, the expected shape of X is (n_samples_test, n_samples_train).

Returns the log-probabilities of the sample for each class in the model. The columns correspond to the classes in sorted order, as they appear in the attribute classes_.

The probability model is created using cross validation, so the results can be slightly different than those obtained by predict. Also, it will produce meaningless results on very small datasets.

Compute probabilities of possible outcomes for samples in X.

The model needs to have probability information computed at training time: fit with attribute probability set to True.

For kernel=”precomputed”, the expected shape of X is (n_samples_test, n_samples_train).

Returns the probability of the sample for each class in the model. The columns correspond to the classes in sorted order, as they appear in the attribute classes_.

The probability model is created using cross validation, so the results can be slightly different than those obtained by predict. Also, it will produce meaningless results on very small datasets.

Return accuracy on provided data and labels.

In multi-label classification, this is the subset accuracy which is a harsh metric since you require for each sample that each label set be correctly predicted.

Mean accuracy of self.predict(X) w.r.t. y.

Configure whether metadata should be requested to be passed to the fit method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to fit if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to fit.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Added in version 1.3.

Metadata routing for sample_weight parameter in fit.

Set the parameters of this estimator.

The method works on simple estimators as well as on nested objects (such as Pipeline). The latter have parameters of the form <component>__<parameter> so that it’s possible to update each component of a nested object.

Estimator parameters.

Configure whether metadata should be requested to be passed to the score method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to score if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to score.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Added in version 1.3.

Metadata routing for sample_weight parameter in score.

**Examples:**

Example 1 (python):
```python
>>> import numpy as np
>>> X = np.array([[-1, -1], [-2, -1], [1, 1], [2, 1]])
>>> y = np.array([1, 1, 2, 2])
>>> from sklearn.pipeline import make_pipeline
>>> from sklearn.preprocessing import StandardScaler
>>> from sklearn.svm import NuSVC
>>> clf = make_pipeline(StandardScaler(), NuSVC())
>>> clf.fit(X, y)
Pipeline(steps=[('standardscaler', StandardScaler()), ('nusvc', NuSVC())])
>>> print(clf.predict([[-0.8, -1]]))
[1]
```

---

## export_text#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.tree.export_text.html

**Contents:**
- export_text#

Build a text report showing the rules of a decision tree.

Note that backwards compatibility may not be supported.

The decision tree estimator to be exported. It can be an instance of DecisionTreeClassifier or DecisionTreeRegressor.

An array containing the feature names. If None generic names will be used (“feature_0”, “feature_1”, …).

Names of each of the target classes in ascending numerical order. Only relevant for classification and not supported for multi-output.

if None, the class names are delegated to decision_tree.classes_;

otherwise, class_names will be used as class names instead of decision_tree.classes_. The length of class_names must match the length of decision_tree.classes_.

Added in version 1.3.

Only the first max_depth levels of the tree are exported. Truncated branches will be marked with “…”.

Number of spaces between edges. The higher it is, the wider the result.

Number of decimal digits to display.

If true the classification weights will be exported on each leaf. The classification weights are the number of samples each class.

Text summary of all the rules in the decision tree.

**Examples:**

Example 1 (python):
```python
>>> from sklearn.datasets import load_iris
>>> from sklearn.tree import DecisionTreeClassifier
>>> from sklearn.tree import export_text
>>> iris = load_iris()
>>> X = iris['data']
>>> y = iris['target']
>>> decision_tree = DecisionTreeClassifier(random_state=0, max_depth=2)
>>> decision_tree = decision_tree.fit(X, y)
>>> r = export_text(decision_tree, feature_names=iris['feature_names'])
>>> print(r)
|--- petal width (cm) <= 0.80
|   |--- class: 0
|--- petal width (cm) >  0.80
|   |--- petal width (cm) <= 1.75
|   |   |--- class: 1
|   |--- petal width (cm) >  1.75
|   |   |--- class: 2
```

---

## Matern#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.gaussian_process.kernels.Matern.html

**Contents:**
- Matern#
- Gallery examples#

The class of Matern kernels is a generalization of the RBF. It has an additional parameter \(\nu\) which controls the smoothness of the resulting function. The smaller \(\nu\), the less smooth the approximated function is. As \(\nu\rightarrow\infty\), the kernel becomes equivalent to the RBF kernel. When \(\nu = 1/2\), the Matérn kernel becomes identical to the absolute exponential kernel. Important intermediate values are \(\nu=1.5\) (once differentiable functions) and \(\nu=2.5\) (twice differentiable functions).

The kernel is given by:

where \(d(\cdot,\cdot)\) is the Euclidean distance, \(K_{\nu}(\cdot)\) is a modified Bessel function and \(\Gamma(\cdot)\) is the gamma function. See [1], Chapter 4, Section 4.2, for details regarding the different variants of the Matern kernel.

Read more in the User Guide.

Added in version 0.18.

The length scale of the kernel. If a float, an isotropic kernel is used. If an array, an anisotropic kernel is used where each dimension of l defines the length-scale of the respective feature dimension.

The lower and upper bound on ‘length_scale’. If set to “fixed”, ‘length_scale’ cannot be changed during hyperparameter tuning.

The parameter nu controlling the smoothness of the learned function. The smaller nu, the less smooth the approximated function is. For nu=inf, the kernel becomes equivalent to the RBF kernel and for nu=0.5 to the absolute exponential kernel. Important intermediate values are nu=1.5 (once differentiable functions) and nu=2.5 (twice differentiable functions). Note that values of nu not in [0.5, 1.5, 2.5, inf] incur a considerably higher computational cost (appr. 10 times higher) since they require to evaluate the modified Bessel function. Furthermore, in contrast to l, nu is kept fixed to its initial value and not optimized.

Carl Edward Rasmussen, Christopher K. I. Williams (2006). “Gaussian Processes for Machine Learning”. The MIT Press.

Return the kernel k(X, Y) and optionally its gradient.

Left argument of the returned kernel k(X, Y)

Right argument of the returned kernel k(X, Y). If None, k(X, X) if evaluated instead.

Determines whether the gradient with respect to the log of the kernel hyperparameter is computed. Only supported when Y is None.

The gradient of the kernel k(X, X) with respect to the log of the hyperparameter of the kernel. Only returned when eval_gradient is True.

Returns the log-transformed bounds on the theta.

The log-transformed bounds on the kernel’s hyperparameters theta

Returns a clone of self with given hyperparameters theta.

Returns the diagonal of the kernel k(X, X).

The result of this method is identical to np.diag(self(X)); however, it can be evaluated more efficiently since only the diagonal is evaluated.

Left argument of the returned kernel k(X, Y)

Diagonal of kernel k(X, X)

Get parameters of this kernel.

If True, will return the parameters for this estimator and contained subobjects that are estimators.

Parameter names mapped to their values.

Returns a list of all hyperparameter specifications.

Returns whether the kernel is stationary.

Returns the number of non-fixed hyperparameters of the kernel.

Returns whether the kernel is defined on fixed-length feature vectors or generic objects. Defaults to True for backward compatibility.

Set the parameters of this kernel.

The method works on simple kernels as well as on nested kernels. The latter have parameters of the form <component>__<parameter> so that it’s possible to update each component of a nested object.

Returns the (flattened, log-transformed) non-fixed hyperparameters.

Note that theta are typically the log-transformed values of the kernel’s hyperparameters as this representation of the search space is more amenable for hyperparameter search, as hyperparameters like length-scales naturally live on a log-scale.

The non-fixed, log-transformed hyperparameters of the kernel

Illustration of prior and posterior Gaussian process for different kernels

**Examples:**

Example 1 (json):
```json
>>> from sklearn.datasets import load_iris
>>> from sklearn.gaussian_process import GaussianProcessClassifier
>>> from sklearn.gaussian_process.kernels import Matern
>>> X, y = load_iris(return_X_y=True)
>>> kernel = 1.0 * Matern(length_scale=1.0, nu=1.5)
>>> gpc = GaussianProcessClassifier(kernel=kernel,
...         random_state=0).fit(X, y)
>>> gpc.score(X, y)
0.9866
>>> gpc.predict_proba(X[:2,:])
array([[0.8513, 0.0368, 0.1117],
        [0.8086, 0.0693, 0.1220]])
```

---

## TweedieRegressor#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.TweedieRegressor.html

**Contents:**
- TweedieRegressor#
- Gallery examples#

Generalized Linear Model with a Tweedie distribution.

This estimator can be used to model different GLMs depending on the power parameter, which determines the underlying distribution.

Read more in the User Guide.

Added in version 0.23.

The power determines the underlying target distribution according to the following table:

Compound Poisson Gamma

For 0 < power < 1, no distribution exists.

Constant that multiplies the L2 penalty term and determines the regularization strength. alpha = 0 is equivalent to unpenalized GLMs. In this case, the design matrix X must have full column rank (no collinearities). Values of alpha must be in the range [0.0, inf).

Specifies if a constant (a.k.a. bias or intercept) should be added to the linear predictor (X @ coef + intercept).

The link function of the GLM, i.e. mapping from linear predictor X @ coeff + intercept to prediction y_pred. Option ‘auto’ sets the link depending on the chosen power parameter as follows:

‘identity’ for power <= 0, e.g. for the Normal distribution

‘log’ for power > 0, e.g. for Poisson, Gamma and Inverse Gaussian distributions

Algorithm to use in the optimization problem:

Calls scipy’s L-BFGS-B optimizer.

Uses Newton-Raphson steps (in arbitrary precision arithmetic equivalent to iterated reweighted least squares) with an inner Cholesky based solver. This solver is a good choice for n_samples >> n_features, especially with one-hot encoded categorical features with rare categories. Be aware that the memory usage of this solver has a quadratic dependency on n_features because it explicitly computes the Hessian matrix.

Added in version 1.2.

The maximal number of iterations for the solver. Values must be in the range [1, inf).

Stopping criterion. For the lbfgs solver, the iteration will stop when max{|g_j|, j = 1, ..., d} <= tol where g_j is the j-th component of the gradient (derivative) of the objective function. Values must be in the range (0.0, inf).

If set to True, reuse the solution of the previous call to fit as initialization for coef_ and intercept_ .

For the lbfgs solver set verbose to any positive number for verbosity. Values must be in the range [0, inf).

Estimated coefficients for the linear predictor (X @ coef_ + intercept_) in the GLM.

Intercept (a.k.a. bias) added to linear predictor.

Actual number of iterations used in the solver.

Number of features seen during fit.

Added in version 0.24.

Names of features seen during fit. Defined only when X has feature names that are all strings.

Added in version 1.0.

Generalized Linear Model with a Poisson distribution.

Generalized Linear Model with a Gamma distribution.

Fit a Generalized Linear Model.

Get metadata routing of this object.

Please check User Guide on how the routing mechanism works.

A MetadataRequest encapsulating routing information.

Get parameters for this estimator.

If True, will return the parameters for this estimator and contained subobjects that are estimators.

Parameter names mapped to their values.

Predict using GLM with feature matrix X.

Returns predicted values.

Compute D^2, the percentage of deviance explained.

D^2 is a generalization of the coefficient of determination R^2. R^2 uses squared error and D^2 uses the deviance of this GLM, see the User Guide.

D^2 is defined as \(D^2 = 1-\frac{D(y_{true},y_{pred})}{D_{null}}\), \(D_{null}\) is the null deviance, i.e. the deviance of a model with intercept alone, which corresponds to \(y_{pred} = \bar{y}\). The mean \(\bar{y}\) is averaged by sample_weight. Best possible score is 1.0 and it can be negative (because the model can be arbitrarily worse).

True values of target.

D^2 of self.predict(X) w.r.t. y.

Configure whether metadata should be requested to be passed to the fit method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to fit if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to fit.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Added in version 1.3.

Metadata routing for sample_weight parameter in fit.

Set the parameters of this estimator.

The method works on simple estimators as well as on nested objects (such as Pipeline). The latter have parameters of the form <component>__<parameter> so that it’s possible to update each component of a nested object.

Estimator parameters.

Configure whether metadata should be requested to be passed to the score method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to score if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to score.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Added in version 1.3.

Metadata routing for sample_weight parameter in score.

Tweedie regression on insurance claims

Release Highlights for scikit-learn 0.23

**Examples:**

Example 1 (python):
```python
>>> from sklearn import linear_model
>>> clf = linear_model.TweedieRegressor()
>>> X = [[1, 2], [2, 3], [3, 4], [4, 3]]
>>> y = [2, 3.5, 5, 5.5]
>>> clf.fit(X, y)
TweedieRegressor()
>>> clf.score(X, y)
np.float64(0.839)
>>> clf.coef_
array([0.599, 0.299])
>>> clf.intercept_
np.float64(1.600)
>>> clf.predict([[1, 1], [3, 4]])
array([2.500, 4.599])
```

---

## AdaBoostRegressor#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostRegressor.html

**Contents:**
- AdaBoostRegressor#
- Gallery examples#

An AdaBoost regressor.

An AdaBoost [1] regressor is a meta-estimator that begins by fitting a regressor on the original dataset and then fits additional copies of the regressor on the same dataset but where the weights of instances are adjusted according to the error of the current prediction. As such, subsequent regressors focus more on difficult cases.

This class implements the algorithm known as AdaBoost.R2 [2].

Read more in the User Guide.

Added in version 0.14.

The base estimator from which the boosted ensemble is built. If None, then the base estimator is DecisionTreeRegressor initialized with max_depth=3.

Added in version 1.2: base_estimator was renamed to estimator.

The maximum number of estimators at which boosting is terminated. In case of perfect fit, the learning procedure is stopped early. Values must be in the range [1, inf).

Weight applied to each regressor at each boosting iteration. A higher learning rate increases the contribution of each regressor. There is a trade-off between the learning_rate and n_estimators parameters. Values must be in the range (0.0, inf).

The loss function to use when updating the weights after each boosting iteration.

Controls the random seed given at each estimator at each boosting iteration. Thus, it is only used when estimator exposes a random_state. In addition, it controls the bootstrap of the weights used to train the estimator at each boosting iteration. Pass an int for reproducible output across multiple function calls. See Glossary.

The base estimator from which the ensemble is grown.

Added in version 1.2: base_estimator_ was renamed to estimator_.

The collection of fitted sub-estimators.

Weights for each estimator in the boosted ensemble.

Regression error for each estimator in the boosted ensemble.

The impurity-based feature importances.

Number of features seen during fit.

Added in version 0.24.

Names of features seen during fit. Defined only when X has feature names that are all strings.

Added in version 1.0.

An AdaBoost classifier.

Gradient Boosting Classification Tree.

A decision tree regressor.

Y. Freund, R. Schapire, “A Decision-Theoretic Generalization of on-Line Learning and an Application to Boosting”, 1995.

Drucker, “Improving Regressors using Boosting Techniques”, 1997.

For a detailed example of utilizing AdaBoostRegressor to fit a sequence of decision trees as weak learners, please refer to Decision Tree Regression with AdaBoost.

Build a boosted classifier/regressor from the training set (X, y).

The training input samples. Sparse matrix can be CSC, CSR, COO, DOK, or LIL. COO, DOK, and LIL are converted to CSR.

Sample weights. If None, the sample weights are initialized to 1 / n_samples.

Raise NotImplementedError.

This estimator does not support metadata routing yet.

Get parameters for this estimator.

If True, will return the parameters for this estimator and contained subobjects that are estimators.

Parameter names mapped to their values.

Predict regression value for X.

The predicted regression value of an input sample is computed as the weighted median prediction of the regressors in the ensemble.

The training input samples. Sparse matrix can be CSC, CSR, COO, DOK, or LIL. COO, DOK, and LIL are converted to CSR.

The predicted regression values.

Return coefficient of determination on test data.

The coefficient of determination, \(R^2\), is defined as \((1 - \frac{u}{v})\), where \(u\) is the residual sum of squares ((y_true - y_pred)** 2).sum() and \(v\) is the total sum of squares ((y_true - y_true.mean()) ** 2).sum(). The best possible score is 1.0 and it can be negative (because the model can be arbitrarily worse). A constant model that always predicts the expected value of y, disregarding the input features, would get a \(R^2\) score of 0.0.

Test samples. For some estimators this may be a precomputed kernel matrix or a list of generic objects instead with shape (n_samples, n_samples_fitted), where n_samples_fitted is the number of samples used in the fitting for the estimator.

\(R^2\) of self.predict(X) w.r.t. y.

The \(R^2\) score used when calling score on a regressor uses multioutput='uniform_average' from version 0.23 to keep consistent with default value of r2_score. This influences the score method of all the multioutput regressors (except for MultiOutputRegressor).

Configure whether metadata should be requested to be passed to the fit method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to fit if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to fit.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Added in version 1.3.

Metadata routing for sample_weight parameter in fit.

Set the parameters of this estimator.

The method works on simple estimators as well as on nested objects (such as Pipeline). The latter have parameters of the form <component>__<parameter> so that it’s possible to update each component of a nested object.

Estimator parameters.

Configure whether metadata should be requested to be passed to the score method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to score if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to score.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Added in version 1.3.

Metadata routing for sample_weight parameter in score.

Return staged predictions for X.

The predicted regression value of an input sample is computed as the weighted median prediction of the regressors in the ensemble.

This generator method yields the ensemble prediction after each iteration of boosting and therefore allows monitoring, such as to determine the prediction on a test set after each boost.

The training input samples.

The predicted regression values.

Return staged scores for X, y.

This generator method yields the ensemble score after each iteration of boosting and therefore allows monitoring, such as to determine the score on a test set after each boost.

The training input samples. Sparse matrix can be CSC, CSR, COO, DOK, or LIL. COO, DOK, and LIL are converted to CSR.

Decision Tree Regression with AdaBoost

**Examples:**

Example 1 (sql):
```sql
>>> from sklearn.ensemble import AdaBoostRegressor
>>> from sklearn.datasets import make_regression
>>> X, y = make_regression(n_features=4, n_informative=2,
...                        random_state=0, shuffle=False)
>>> regr = AdaBoostRegressor(random_state=0, n_estimators=100)
>>> regr.fit(X, y)
AdaBoostRegressor(n_estimators=100, random_state=0)
>>> regr.predict([[0, 0, 0, 0]])
array([4.7972])
>>> regr.score(X, y)
0.9771
```

---

## SVC#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html

**Contents:**
- SVC#
- Gallery examples#

C-Support Vector Classification.

The implementation is based on libsvm. The fit time scales at least quadratically with the number of samples and may be impractical beyond tens of thousands of samples. For large datasets consider using LinearSVC or SGDClassifier instead, possibly after a Nystroem transformer or other Kernel Approximation.

The multiclass support is handled according to a one-vs-one scheme.

For details on the precise mathematical formulation of the provided kernel functions and how gamma, coef0 and degree affect each other, see the corresponding section in the narrative documentation: Kernel functions.

To learn how to tune SVC’s hyperparameters, see the following example: Nested versus non-nested cross-validation

Read more in the User Guide.

Regularization parameter. The strength of the regularization is inversely proportional to C. Must be strictly positive. The penalty is a squared l2 penalty. For an intuitive visualization of the effects of scaling the regularization parameter C, see Scaling the regularization parameter for SVCs.

Specifies the kernel type to be used in the algorithm. If none is given, ‘rbf’ will be used. If a callable is given it is used to pre-compute the kernel matrix from data matrices; that matrix should be an array of shape (n_samples, n_samples). For an intuitive visualization of different kernel types see Plot classification boundaries with different SVM Kernels.

Degree of the polynomial kernel function (‘poly’). Must be non-negative. Ignored by all other kernels.

Kernel coefficient for ‘rbf’, ‘poly’ and ‘sigmoid’.

if gamma='scale' (default) is passed then it uses 1 / (n_features * X.var()) as value of gamma,

if ‘auto’, uses 1 / n_features

if float, must be non-negative.

Changed in version 0.22: The default value of gamma changed from ‘auto’ to ‘scale’.

Independent term in kernel function. It is only significant in ‘poly’ and ‘sigmoid’.

Whether to use the shrinking heuristic. See the User Guide.

Whether to enable probability estimates. This must be enabled prior to calling fit, will slow down that method as it internally uses 5-fold cross-validation, and predict_proba may be inconsistent with predict. Read more in the User Guide.

Tolerance for stopping criterion.

Specify the size of the kernel cache (in MB).

Set the parameter C of class i to class_weight[i]*C for SVC. If not given, all classes are supposed to have weight one. The “balanced” mode uses the values of y to automatically adjust weights inversely proportional to class frequencies in the input data as n_samples / (n_classes * np.bincount(y)).

Enable verbose output. Note that this setting takes advantage of a per-process runtime setting in libsvm that, if enabled, may not work properly in a multithreaded context.

Hard limit on iterations within solver, or -1 for no limit.

Whether to return a one-vs-rest (‘ovr’) decision function of shape (n_samples, n_classes) as all other classifiers, or the original one-vs-one (‘ovo’) decision function of libsvm which has shape (n_samples, n_classes * (n_classes - 1) / 2). However, note that internally, one-vs-one (‘ovo’) is always used as a multi-class strategy to train models; an ovr matrix is only constructed from the ovo matrix. The parameter is ignored for binary classification.

Changed in version 0.19: decision_function_shape is ‘ovr’ by default.

Added in version 0.17: decision_function_shape=’ovr’ is recommended.

Changed in version 0.17: Deprecated decision_function_shape=’ovo’ and None.

If true, decision_function_shape='ovr', and number of classes > 2, predict will break ties according to the confidence values of decision_function; otherwise the first class among the tied classes is returned. Please note that breaking ties comes at a relatively high computational cost compared to a simple predict. See SVM Tie Breaking Example for an example of its usage with decision_function_shape='ovr'.

Added in version 0.22.

Controls the pseudo random number generation for shuffling the data for probability estimates. Ignored when probability is False. Pass an int for reproducible output across multiple function calls. See Glossary.

Multipliers of parameter C for each class. Computed based on the class_weight parameter.

Weights assigned to the features when kernel="linear".

Dual coefficients of the support vector in the decision function (see Mathematical formulation), multiplied by their targets. For multiclass, coefficient for all 1-vs-1 classifiers. The layout of the coefficients in the multiclass case is somewhat non-trivial. See the multi-class section of the User Guide for details.

0 if correctly fitted, 1 otherwise (will raise warning)

Constants in decision function.

Number of features seen during fit.

Added in version 0.24.

Names of features seen during fit. Defined only when X has feature names that are all strings.

Added in version 1.0.

Number of iterations run by the optimization routine to fit the model. The shape of this attribute depends on the number of models optimized which in turn depends on the number of classes.

Added in version 1.1.

Indices of support vectors.

Support vectors. An empty array if kernel is precomputed.

Number of support vectors for each class.

Parameter learned in Platt scaling when probability=True.

Parameter learned in Platt scaling when probability=True.

Array dimensions of training vector X.

Support Vector Machine for Regression implemented using libsvm.

Scalable Linear Support Vector Machine for classification implemented using liblinear. Check the See Also section of LinearSVC for more comparison element.

LIBSVM: A Library for Support Vector Machines

Platt, John (1999). “Probabilistic Outputs for Support Vector Machines and Comparisons to Regularized Likelihood Methods”

For a comparison of the SVC with other classifiers see: Plot classification probability.

Evaluate the decision function for the samples in X.

Returns the decision function of the sample for each class in the model. If decision_function_shape=’ovr’, the shape is (n_samples, n_classes).

If decision_function_shape=’ovo’, the function values are proportional to the distance of the samples X to the separating hyperplane. If the exact distances are required, divide the function values by the norm of the weight vector (coef_). See also this question for further details. If decision_function_shape=’ovr’, the decision function is a monotonic transformation of ovo decision function.

Fit the SVM model according to the given training data.

Training vectors, where n_samples is the number of samples and n_features is the number of features. For kernel=”precomputed”, the expected shape of X is (n_samples, n_samples).

Target values (class labels in classification, real numbers in regression).

Per-sample weights. Rescale C per sample. Higher weights force the classifier to put more emphasis on these points.

If X and y are not C-ordered and contiguous arrays of np.float64 and X is not a scipy.sparse.csr_matrix, X and/or y may be copied.

If X is a dense array, then the other methods will not support sparse matrices as input.

Get metadata routing of this object.

Please check User Guide on how the routing mechanism works.

A MetadataRequest encapsulating routing information.

Get parameters for this estimator.

If True, will return the parameters for this estimator and contained subobjects that are estimators.

Parameter names mapped to their values.

Perform classification on samples in X.

For a one-class model, +1 or -1 is returned.

For kernel=”precomputed”, the expected shape of X is (n_samples_test, n_samples_train).

Class labels for samples in X.

Compute log probabilities of possible outcomes for samples in X.

The model need to have probability information computed at training time: fit with attribute probability set to True.

For kernel=”precomputed”, the expected shape of X is (n_samples_test, n_samples_train).

Returns the log-probabilities of the sample for each class in the model. The columns correspond to the classes in sorted order, as they appear in the attribute classes_.

The probability model is created using cross validation, so the results can be slightly different than those obtained by predict. Also, it will produce meaningless results on very small datasets.

Compute probabilities of possible outcomes for samples in X.

The model needs to have probability information computed at training time: fit with attribute probability set to True.

For kernel=”precomputed”, the expected shape of X is (n_samples_test, n_samples_train).

Returns the probability of the sample for each class in the model. The columns correspond to the classes in sorted order, as they appear in the attribute classes_.

The probability model is created using cross validation, so the results can be slightly different than those obtained by predict. Also, it will produce meaningless results on very small datasets.

Return accuracy on provided data and labels.

In multi-label classification, this is the subset accuracy which is a harsh metric since you require for each sample that each label set be correctly predicted.

Mean accuracy of self.predict(X) w.r.t. y.

Configure whether metadata should be requested to be passed to the fit method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to fit if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to fit.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Added in version 1.3.

Metadata routing for sample_weight parameter in fit.

Set the parameters of this estimator.

The method works on simple estimators as well as on nested objects (such as Pipeline). The latter have parameters of the form <component>__<parameter> so that it’s possible to update each component of a nested object.

Estimator parameters.

Configure whether metadata should be requested to be passed to the score method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to score if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to score.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Added in version 1.3.

Metadata routing for sample_weight parameter in score.

Faces recognition example using eigenfaces and SVMs

Classifier comparison

Recognizing hand-written digits

Concatenating multiple feature extraction methods

Scalable learning with polynomial kernel approximation

Explicit feature map approximation for RBF kernels

Multilabel classification

ROC Curve with Visualization API

Evaluate the performance of a classifier with Confusion Matrix

Custom refit strategy of a grid search with cross-validation

Statistical comparison of models using grid search

Plotting Learning Curves and Checking Models’ Scalability

Nested versus non-nested cross-validation

Test with permutations the significance of a classification score

Receiver Operating Characteristic (ROC) with cross validation

Comparison between grid search and successive halving

Feature discretization

Release Highlights for scikit-learn 0.22

Release Highlights for scikit-learn 0.24

Effect of varying threshold for self-training

Decision boundary of semi-supervised classifiers versus SVM on the Iris dataset

SVM with custom kernel

Plot different SVM classifiers in the iris dataset

SVM: Maximum margin separating hyperplane

SVM: Separating hyperplane for unbalanced classes

SVM-Anova: SVM with univariate feature selection

Plot classification boundaries with different SVM Kernels

SVM Tie Breaking Example

SVM: Weighted samples

**Examples:**

Example 1 (sql):
```sql
>>> import numpy as np
>>> from sklearn.pipeline import make_pipeline
>>> from sklearn.preprocessing import StandardScaler
>>> X = np.array([[-1, -1], [-2, -1], [1, 1], [2, 1]])
>>> y = np.array([1, 1, 2, 2])
>>> from sklearn.svm import SVC
>>> clf = make_pipeline(StandardScaler(), SVC(gamma='auto'))
>>> clf.fit(X, y)
Pipeline(steps=[('standardscaler', StandardScaler()),
                ('svc', SVC(gamma='auto'))])
```

Example 2 (json):
```json
>>> print(clf.predict([[-0.8, -1]]))
[1]
```

---

## 7.9. Transforming the prediction target (y)#

**URL:** https://scikit-learn.org/stable/modules/preprocessing_targets.html

**Contents:**
- 7.9. Transforming the prediction target (y)#
- 7.9.1. Label binarization#
  - 7.9.1.1. LabelBinarizer#
  - 7.9.1.2. MultiLabelBinarizer#
- 7.9.2. Label encoding#

These are transformers that are not intended to be used on features, only on supervised learning targets. See also Transforming target in regression if you want to transform the prediction target for learning, but evaluate the model in the original (untransformed) space.

LabelBinarizer is a utility class to help create a label indicator matrix from a list of multiclass labels:

Using this format can enable multiclass classification in estimators that support the label indicator matrix format.

LabelBinarizer is not needed if you are using an estimator that already supports multiclass data.

For more information about multiclass classification, refer to Multiclass classification.

In multilabel learning, the joint set of binary classification tasks is expressed with a label binary indicator array: each sample is one row of a 2d array of shape (n_samples, n_classes) with binary values where the one, i.e. the non zero elements, corresponds to the subset of labels for that sample. An array such as np.array([[1, 0, 0], [0, 1, 1], [0, 0, 0]]) represents label 0 in the first sample, labels 1 and 2 in the second sample, and no labels in the third sample.

Producing multilabel data as a list of sets of labels may be more intuitive. The MultiLabelBinarizer transformer can be used to convert between a collection of collections of labels and the indicator format:

For more information about multilabel classification, refer to Multilabel classification.

LabelEncoder is a utility class to help normalize labels such that they contain only values between 0 and n_classes-1. This is sometimes useful for writing efficient Cython routines. LabelEncoder can be used as follows:

It can also be used to transform non-numerical labels (as long as they are hashable and comparable) to numerical labels:

**Examples:**

Example 1 (csharp):
```csharp
>>> from sklearn import preprocessing
>>> lb = preprocessing.LabelBinarizer()
>>> lb.fit([1, 2, 6, 4, 2])
LabelBinarizer()
>>> lb.classes_
array([1, 2, 4, 6])
>>> lb.transform([1, 6])
array([[1, 0, 0, 0],
       [0, 0, 0, 1]])
```

Example 2 (sql):
```sql
>>> from sklearn.preprocessing import MultiLabelBinarizer
>>> y = [[2, 3, 4], [2], [0, 1, 3], [0, 1, 2, 3, 4], [0, 1, 2]]
>>> MultiLabelBinarizer().fit_transform(y)
array([[0, 0, 1, 1, 1],
       [0, 0, 1, 0, 0],
       [1, 1, 0, 1, 0],
       [1, 1, 1, 1, 1],
       [1, 1, 1, 0, 0]])
```

Example 3 (csharp):
```csharp
>>> from sklearn import preprocessing
>>> le = preprocessing.LabelEncoder()
>>> le.fit([1, 2, 2, 6])
LabelEncoder()
>>> le.classes_
array([1, 2, 6])
>>> le.transform([1, 1, 2, 6])
array([0, 0, 1, 2])
>>> le.inverse_transform([0, 0, 1, 2])
array([1, 1, 2, 6])
```

Example 4 (csharp):
```csharp
>>> le = preprocessing.LabelEncoder()
>>> le.fit(["paris", "paris", "tokyo", "amsterdam"])
LabelEncoder()
>>> list(le.classes_)
[np.str_('amsterdam'), np.str_('paris'), np.str_('tokyo')]
>>> le.transform(["tokyo", "tokyo", "paris"])
array([2, 2, 1])
>>> list(le.inverse_transform([2, 2, 1]))
[np.str_('tokyo'), np.str_('tokyo'), np.str_('paris')]
```

---

## TheilSenRegressor#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.TheilSenRegressor.html

**Contents:**
- TheilSenRegressor#
- Gallery examples#

Theil-Sen Estimator: robust multivariate regression model.

The algorithm calculates least square solutions on subsets with size n_subsamples of the samples in X. Any value of n_subsamples between the number of features and samples leads to an estimator with a compromise between robustness and efficiency. Since the number of least square solutions is “n_samples choose n_subsamples”, it can be extremely large and can therefore be limited with max_subpopulation. If this limit is reached, the subsets are chosen randomly. In a final step, the spatial median (or L1 median) is calculated of all least square solutions.

Read more in the User Guide.

Whether to calculate the intercept for this model. If set to false, no intercept will be used in calculations.

Instead of computing with a set of cardinality ‘n choose k’, where n is the number of samples and k is the number of subsamples (at least number of features), consider only a stochastic subpopulation of a given maximal size if ‘n choose k’ is larger than max_subpopulation. For other than small problem sizes this parameter will determine memory usage and runtime if n_subsamples is not changed. Note that the data type should be int but floats such as 1e4 can be accepted too.

Number of samples to calculate the parameters. This is at least the number of features (plus 1 if fit_intercept=True) and the number of samples as a maximum. A lower number leads to a higher breakdown point and a low efficiency while a high number leads to a low breakdown point and a high efficiency. If None, take the minimum number of subsamples leading to maximal robustness. If n_subsamples is set to n_samples, Theil-Sen is identical to least squares.

Maximum number of iterations for the calculation of spatial median.

Tolerance when calculating spatial median.

A random number generator instance to define the state of the random permutations generator. Pass an int for reproducible output across multiple function calls. See Glossary.

Number of CPUs to use during the cross validation. None means 1 unless in a joblib.parallel_backend context. -1 means using all processors. See Glossary for more details.

Verbose mode when fitting the model.

Coefficients of the regression model (median of distribution).

Estimated intercept of regression model.

Approximated breakdown point.

Number of iterations needed for the spatial median.

Number of combinations taken into account from ‘n choose k’, where n is the number of samples and k is the number of subsamples.

Number of features seen during fit.

Added in version 0.24.

Names of features seen during fit. Defined only when X has feature names that are all strings.

Added in version 1.0.

Linear regression model that is robust to outliers.

RANSAC (RANdom SAmple Consensus) algorithm.

Fitted by minimizing a regularized empirical loss with SGD.

Theil-Sen Estimators in a Multiple Linear Regression Model, 2009 Xin Dang, Hanxiang Peng, Xueqin Wang and Heping Zhang http://home.olemiss.edu/~xdang/papers/MTSE.pdf

Fitted TheilSenRegressor estimator.

Get metadata routing of this object.

Please check User Guide on how the routing mechanism works.

A MetadataRequest encapsulating routing information.

Get parameters for this estimator.

If True, will return the parameters for this estimator and contained subobjects that are estimators.

Parameter names mapped to their values.

Predict using the linear model.

Returns predicted values.

Return coefficient of determination on test data.

The coefficient of determination, \(R^2\), is defined as \((1 - \frac{u}{v})\), where \(u\) is the residual sum of squares ((y_true - y_pred)** 2).sum() and \(v\) is the total sum of squares ((y_true - y_true.mean()) ** 2).sum(). The best possible score is 1.0 and it can be negative (because the model can be arbitrarily worse). A constant model that always predicts the expected value of y, disregarding the input features, would get a \(R^2\) score of 0.0.

Test samples. For some estimators this may be a precomputed kernel matrix or a list of generic objects instead with shape (n_samples, n_samples_fitted), where n_samples_fitted is the number of samples used in the fitting for the estimator.

\(R^2\) of self.predict(X) w.r.t. y.

The \(R^2\) score used when calling score on a regressor uses multioutput='uniform_average' from version 0.23 to keep consistent with default value of r2_score. This influences the score method of all the multioutput regressors (except for MultiOutputRegressor).

Set the parameters of this estimator.

The method works on simple estimators as well as on nested objects (such as Pipeline). The latter have parameters of the form <component>__<parameter> so that it’s possible to update each component of a nested object.

Estimator parameters.

Configure whether metadata should be requested to be passed to the score method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to score if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to score.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Added in version 1.3.

Metadata routing for sample_weight parameter in score.

Robust linear estimator fitting

**Examples:**

Example 1 (sql):
```sql
>>> from sklearn.linear_model import TheilSenRegressor
>>> from sklearn.datasets import make_regression
>>> X, y = make_regression(
...     n_samples=200, n_features=2, noise=4.0, random_state=0)
>>> reg = TheilSenRegressor(random_state=0).fit(X, y)
>>> reg.score(X, y)
0.9884
>>> reg.predict(X[:1,])
array([-31.5871])
```

---

## 

**URL:** https://scikit-learn.org/stable/_sources/modules/decomposition.rst.txt

---

## OrthogonalMatchingPursuit#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.OrthogonalMatchingPursuit.html

**Contents:**
- OrthogonalMatchingPursuit#
- Gallery examples#

Orthogonal Matching Pursuit model (OMP).

Read more in the User Guide.

Desired number of non-zero entries in the solution. Ignored if tol is set. When None and tol is also None, this value is either set to 10% of n_features or 1, whichever is greater.

Maximum squared norm of the residual. If not None, overrides n_nonzero_coefs.

Whether to calculate the intercept for this model. If set to false, no intercept will be used in calculations (i.e. data is expected to be centered).

Whether to use a precomputed Gram and Xy matrix to speed up calculations. Improves performance when n_targets or n_samples is very large.

Parameter vector (w in the formula).

Independent term in decision function.

Number of active features across every target.

The number of non-zero coefficients in the solution or None when tol is set. If n_nonzero_coefs is None and tol is None this value is either set to 10% of n_features or 1, whichever is greater.

Number of features seen during fit.

Added in version 0.24.

Names of features seen during fit. Defined only when X has feature names that are all strings.

Added in version 1.0.

Solves n_targets Orthogonal Matching Pursuit problems.

Solves n_targets Orthogonal Matching Pursuit problems using only the Gram matrix X.T * X and the product X.T * y.

Compute Least Angle Regression or Lasso path using LARS algorithm.

Least Angle Regression model a.k.a. LAR.

Lasso model fit with Least Angle Regression a.k.a. Lars.

Generic sparse coding. Each column of the result is the solution to a Lasso problem.

Cross-validated Orthogonal Matching Pursuit model (OMP).

Orthogonal matching pursuit was introduced in G. Mallat, Z. Zhang, Matching pursuits with time-frequency dictionaries, IEEE Transactions on Signal Processing, Vol. 41, No. 12. (December 1993), pp. 3397-3415. (https://www.di.ens.fr/~mallat/papiers/MallatPursuit93.pdf)

This implementation is based on Rubinstein, R., Zibulevsky, M. and Elad, M., Efficient Implementation of the K-SVD Algorithm using Batch Orthogonal Matching Pursuit Technical Report - CS Technion, April 2008. https://www.cs.technion.ac.il/~ronrubin/Publications/KSVD-OMP-v2.pdf

Fit the model using X, y as training data.

Target values. Will be cast to X’s dtype if necessary.

Returns an instance of self.

Get metadata routing of this object.

Please check User Guide on how the routing mechanism works.

A MetadataRequest encapsulating routing information.

Get parameters for this estimator.

If True, will return the parameters for this estimator and contained subobjects that are estimators.

Parameter names mapped to their values.

Predict using the linear model.

Returns predicted values.

Return coefficient of determination on test data.

The coefficient of determination, \(R^2\), is defined as \((1 - \frac{u}{v})\), where \(u\) is the residual sum of squares ((y_true - y_pred)** 2).sum() and \(v\) is the total sum of squares ((y_true - y_true.mean()) ** 2).sum(). The best possible score is 1.0 and it can be negative (because the model can be arbitrarily worse). A constant model that always predicts the expected value of y, disregarding the input features, would get a \(R^2\) score of 0.0.

Test samples. For some estimators this may be a precomputed kernel matrix or a list of generic objects instead with shape (n_samples, n_samples_fitted), where n_samples_fitted is the number of samples used in the fitting for the estimator.

\(R^2\) of self.predict(X) w.r.t. y.

The \(R^2\) score used when calling score on a regressor uses multioutput='uniform_average' from version 0.23 to keep consistent with default value of r2_score. This influences the score method of all the multioutput regressors (except for MultiOutputRegressor).

Set the parameters of this estimator.

The method works on simple estimators as well as on nested objects (such as Pipeline). The latter have parameters of the form <component>__<parameter> so that it’s possible to update each component of a nested object.

Estimator parameters.

Configure whether metadata should be requested to be passed to the score method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to score if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to score.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Added in version 1.3.

Metadata routing for sample_weight parameter in score.

Orthogonal Matching Pursuit

**Examples:**

Example 1 (sql):
```sql
>>> from sklearn.linear_model import OrthogonalMatchingPursuit
>>> from sklearn.datasets import make_regression
>>> X, y = make_regression(noise=4, random_state=0)
>>> reg = OrthogonalMatchingPursuit().fit(X, y)
>>> reg.score(X, y)
0.9991
>>> reg.predict(X[:1,])
array([-78.3854])
```

---

## BernoulliNB#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.BernoulliNB.html

**Contents:**
- BernoulliNB#
- Gallery examples#

Naive Bayes classifier for multivariate Bernoulli models.

Like MultinomialNB, this classifier is suitable for discrete data. The difference is that while MultinomialNB works with occurrence counts, BernoulliNB is designed for binary/boolean features.

Read more in the User Guide.

Additive (Laplace/Lidstone) smoothing parameter (set alpha=0 and force_alpha=True, for no smoothing).

If False and alpha is less than 1e-10, it will set alpha to 1e-10. If True, alpha will remain unchanged. This may cause numerical errors if alpha is too close to 0.

Added in version 1.2.

Changed in version 1.4: The default value of force_alpha changed to True.

Threshold for binarizing (mapping to booleans) of sample features. If None, input is presumed to already consist of binary vectors.

Whether to learn class prior probabilities or not. If false, a uniform prior will be used.

Prior probabilities of the classes. If specified, the priors are not adjusted according to the data.

Number of samples encountered for each class during fitting. This value is weighted by the sample weight when provided.

Log probability of each class (smoothed).

Class labels known to the classifier

Number of samples encountered for each (class, feature) during fitting. This value is weighted by the sample weight when provided.

Empirical log probability of features given a class, P(x_i|y).

Number of features seen during fit.

Added in version 0.24.

Names of features seen during fit. Defined only when X has feature names that are all strings.

Added in version 1.0.

Naive Bayes classifier for categorical features.

The Complement Naive Bayes classifier described in Rennie et al. (2003).

Gaussian Naive Bayes (GaussianNB).

Naive Bayes classifier for multinomial models.

C.D. Manning, P. Raghavan and H. Schuetze (2008). Introduction to Information Retrieval. Cambridge University Press, pp. 234-265. https://nlp.stanford.edu/IR-book/html/htmledition/the-bernoulli-model-1.html

A. McCallum and K. Nigam (1998). A comparison of event models for naive Bayes text classification. Proc. AAAI/ICML-98 Workshop on Learning for Text Categorization, pp. 41-48.

V. Metsis, I. Androutsopoulos and G. Paliouras (2006). Spam filtering with naive Bayes – Which naive Bayes? 3rd Conf. on Email and Anti-Spam (CEAS).

Fit Naive Bayes classifier according to X, y.

Training vectors, where n_samples is the number of samples and n_features is the number of features.

Weights applied to individual samples (1. for unweighted).

Returns the instance itself.

Get metadata routing of this object.

Please check User Guide on how the routing mechanism works.

A MetadataRequest encapsulating routing information.

Get parameters for this estimator.

If True, will return the parameters for this estimator and contained subobjects that are estimators.

Parameter names mapped to their values.

Incremental fit on a batch of samples.

This method is expected to be called several times consecutively on different chunks of a dataset so as to implement out-of-core or online learning.

This is especially useful when the whole dataset is too big to fit in memory at once.

This method has some performance overhead hence it is better to call partial_fit on chunks of data that are as large as possible (as long as fitting in the memory budget) to hide the overhead.

Training vectors, where n_samples is the number of samples and n_features is the number of features.

List of all the classes that can possibly appear in the y vector.

Must be provided at the first call to partial_fit, can be omitted in subsequent calls.

Weights applied to individual samples (1. for unweighted).

Returns the instance itself.

Perform classification on an array of test vectors X.

Predicted target values for X.

Return joint log probability estimates for the test vector X.

For each row x of X and class y, the joint log probability is given by log P(x, y) = log P(y) + log P(x|y), where log P(y) is the class prior probability and log P(x|y) is the class-conditional probability.

Returns the joint log-probability of the samples for each class in the model. The columns correspond to the classes in sorted order, as they appear in the attribute classes_.

Return log-probability estimates for the test vector X.

Returns the log-probability of the samples for each class in the model. The columns correspond to the classes in sorted order, as they appear in the attribute classes_.

Return probability estimates for the test vector X.

Returns the probability of the samples for each class in the model. The columns correspond to the classes in sorted order, as they appear in the attribute classes_.

Return accuracy on provided data and labels.

In multi-label classification, this is the subset accuracy which is a harsh metric since you require for each sample that each label set be correctly predicted.

Mean accuracy of self.predict(X) w.r.t. y.

Configure whether metadata should be requested to be passed to the fit method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to fit if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to fit.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Added in version 1.3.

Metadata routing for sample_weight parameter in fit.

Set the parameters of this estimator.

The method works on simple estimators as well as on nested objects (such as Pipeline). The latter have parameters of the form <component>__<parameter> so that it’s possible to update each component of a nested object.

Estimator parameters.

Configure whether metadata should be requested to be passed to the partial_fit method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to partial_fit if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to partial_fit.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Added in version 1.3.

Metadata routing for classes parameter in partial_fit.

Metadata routing for sample_weight parameter in partial_fit.

Configure whether metadata should be requested to be passed to the score method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to score if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to score.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Added in version 1.3.

Metadata routing for sample_weight parameter in score.

Hashing feature transformation using Totally Random Trees

**Examples:**

Example 1 (json):
```json
>>> import numpy as np
>>> rng = np.random.RandomState(1)
>>> X = rng.randint(5, size=(6, 100))
>>> Y = np.array([1, 2, 3, 4, 4, 5])
>>> from sklearn.naive_bayes import BernoulliNB
>>> clf = BernoulliNB()
>>> clf.fit(X, Y)
BernoulliNB()
>>> print(clf.predict(X[2:3]))
[3]
```

---

## MultiTaskElasticNet#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.MultiTaskElasticNet.html

**Contents:**
- MultiTaskElasticNet#

Multi-task ElasticNet model trained with L1/L2 mixed-norm as regularizer.

The optimization objective for MultiTaskElasticNet is:

i.e. the sum of norms of each row.

Read more in the User Guide.

Constant that multiplies the L1/L2 term. Defaults to 1.0.

The ElasticNet mixing parameter, with 0 < l1_ratio <= 1. For l1_ratio = 1 the penalty is an L1/L2 penalty. For l1_ratio = 0 it is an L2 penalty. For 0 < l1_ratio < 1, the penalty is a combination of L1/L2 and L2.

Whether to calculate the intercept for this model. If set to false, no intercept will be used in calculations (i.e. data is expected to be centered).

If True, X will be copied; else, it may be overwritten.

The maximum number of iterations.

The tolerance for the optimization: if the updates are smaller or equal to tol, the optimization code checks the dual gap for optimality and continues until it is smaller or equal to tol.

When set to True, reuse the solution of the previous call to fit as initialization, otherwise, just erase the previous solution. See the Glossary.

The seed of the pseudo random number generator that selects a random feature to update. Used when selection == ‘random’. Pass an int for reproducible output across multiple function calls. See Glossary.

If set to ‘random’, a random coefficient is updated every iteration rather than looping over features sequentially by default. This (setting to ‘random’) often leads to significantly faster convergence especially when tol is higher than 1e-4.

Independent term in decision function.

Parameter vector (W in the cost function formula). If a 1D y is passed in at fit (non multi-task usage), coef_ is then a 1D array. Note that coef_ stores the transpose of W, W.T.

Number of iterations run by the coordinate descent solver to reach the specified tolerance.

The dual gaps at the end of the optimization.

The tolerance scaled scaled by the variance of the target y.

Sparse representation of the fitted coef_.

Number of features seen during fit.

Added in version 0.24.

Names of features seen during fit. Defined only when X has feature names that are all strings.

Added in version 1.0.

Multi-task L1/L2 ElasticNet with built-in cross-validation.

Linear regression with combined L1 and L2 priors as regularizer.

Multi-task Lasso model trained with L1/L2 mixed-norm as regularizer.

The algorithm used to fit the model is coordinate descent.

To avoid unnecessary memory duplication the X and y arguments of the fit method should be directly passed as Fortran-contiguous numpy arrays.

Fit MultiTaskElasticNet model with coordinate descent.

Target. Will be cast to X’s dtype if necessary.

Coordinate descent is an algorithm that considers each column of data at a time hence it will automatically convert the X input as a Fortran-contiguous numpy array if necessary.

To avoid memory re-allocation it is advised to allocate the initial data in memory directly using that format.

Get metadata routing of this object.

Please check User Guide on how the routing mechanism works.

A MetadataRequest encapsulating routing information.

Get parameters for this estimator.

If True, will return the parameters for this estimator and contained subobjects that are estimators.

Parameter names mapped to their values.

Compute elastic net path with coordinate descent.

The elastic net optimization function varies for mono and multi-outputs.

For mono-output tasks it is:

For multi-output tasks it is:

i.e. the sum of norm of each row.

Read more in the User Guide.

Training data. Pass directly as Fortran-contiguous data to avoid unnecessary memory duplication. If y is mono-output then X can be sparse.

Number between 0 and 1 passed to elastic net (scaling between l1 and l2 penalties). l1_ratio=1 corresponds to the Lasso.

Length of the path. eps=1e-3 means that alpha_min / alpha_max = 1e-3.

Number of alphas along the regularization path.

List of alphas where to compute the models. If None alphas are set automatically.

Whether to use a precomputed Gram matrix to speed up calculations. If set to 'auto' let us decide. The Gram matrix can also be passed as argument.

Xy = np.dot(X.T, y) that can be precomputed. It is useful only when the Gram matrix is precomputed.

If True, X will be copied; else, it may be overwritten.

The initial values of the coefficients.

Whether to return the number of iterations or not.

If set to True, forces coefficients to be positive. (Only allowed when y.ndim == 1).

If set to False, the input validation checks are skipped (including the Gram matrix when provided). It is assumed that they are handled by the caller.

Keyword arguments passed to the coordinate descent solver.

The alphas along the path where models are computed.

Coefficients along the path.

The dual gaps at the end of the optimization for each alpha.

The number of iterations taken by the coordinate descent optimizer to reach the specified tolerance for each alpha. (Is returned when return_n_iter is set to True).

Multi-task ElasticNet model trained with L1/L2 mixed-norm as regularizer.

Multi-task L1/L2 ElasticNet with built-in cross-validation.

Linear regression with combined L1 and L2 priors as regularizer.

Elastic Net model with iterative fitting along a regularization path.

For an example, see examples/linear_model/plot_lasso_lasso_lars_elasticnet_path.py.

The underlying coordinate descent solver uses gap safe screening rules to speedup fitting time, see User Guide on coordinate descent.

Predict using the linear model.

Returns predicted values.

Return coefficient of determination on test data.

The coefficient of determination, \(R^2\), is defined as \((1 - \frac{u}{v})\), where \(u\) is the residual sum of squares ((y_true - y_pred)** 2).sum() and \(v\) is the total sum of squares ((y_true - y_true.mean()) ** 2).sum(). The best possible score is 1.0 and it can be negative (because the model can be arbitrarily worse). A constant model that always predicts the expected value of y, disregarding the input features, would get a \(R^2\) score of 0.0.

Test samples. For some estimators this may be a precomputed kernel matrix or a list of generic objects instead with shape (n_samples, n_samples_fitted), where n_samples_fitted is the number of samples used in the fitting for the estimator.

\(R^2\) of self.predict(X) w.r.t. y.

The \(R^2\) score used when calling score on a regressor uses multioutput='uniform_average' from version 0.23 to keep consistent with default value of r2_score. This influences the score method of all the multioutput regressors (except for MultiOutputRegressor).

Configure whether metadata should be requested to be passed to the fit method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to fit if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to fit.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Added in version 1.3.

Metadata routing for sample_weight parameter in fit.

Set the parameters of this estimator.

The method works on simple estimators as well as on nested objects (such as Pipeline). The latter have parameters of the form <component>__<parameter> so that it’s possible to update each component of a nested object.

Estimator parameters.

Configure whether metadata should be requested to be passed to the score method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to score if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to score.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Added in version 1.3.

Metadata routing for sample_weight parameter in score.

**Examples:**

Example 1 (unknown):
```unknown
(1 / (2 * n_samples)) * ||Y - XW||_Fro^2
+ alpha * l1_ratio * ||W||_21
+ 0.5 * alpha * (1 - l1_ratio) * ||W||_Fro^2
```

Example 2 (unknown):
```unknown
||W||_21 = sum_i sqrt(sum_j W_ij ^ 2)
```

Example 3 (python):
```python
>>> from sklearn import linear_model
>>> clf = linear_model.MultiTaskElasticNet(alpha=0.1)
>>> clf.fit([[0,0], [1, 1], [2, 2]], [[0, 0], [1, 1], [2, 2]])
MultiTaskElasticNet(alpha=0.1)
>>> print(clf.coef_)
[[0.45663524 0.45612256]
 [0.45663524 0.45612256]]
>>> print(clf.intercept_)
[0.0872422 0.0872422]
```

Example 4 (unknown):
```unknown
1 / (2 * n_samples) * ||y - Xw||^2_2
+ alpha * l1_ratio * ||w||_1
+ 0.5 * alpha * (1 - l1_ratio) * ||w||^2_2
```

---

## RidgeClassifierCV#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.RidgeClassifierCV.html

**Contents:**
- RidgeClassifierCV#

Ridge classifier with built-in cross-validation.

See glossary entry for cross-validation estimator.

By default, it performs Leave-One-Out Cross-Validation. Currently, only the n_features > n_samples case is handled efficiently.

Read more in the User Guide.

Array of alpha values to try. Regularization strength; must be a positive float. Regularization improves the conditioning of the problem and reduces the variance of the estimates. Larger values specify stronger regularization. Alpha corresponds to 1 / (2C) in other linear models such as LogisticRegression or LinearSVC. If using Leave-One-Out cross-validation, alphas must be strictly positive.

Whether to calculate the intercept for this model. If set to false, no intercept will be used in calculations (i.e. data is expected to be centered).

The scoring method to use for cross-validation. Options:

str: see String name scorers for options.

callable: a scorer callable object (e.g., function) with signature scorer(estimator, X, y). See Callable scorers for details.

None: negative mean squared error if cv is None (i.e. when using leave-one-out cross-validation), or accuracy otherwise.

Determines the cross-validation splitting strategy. Possible inputs for cv are:

None, to use the efficient Leave-One-Out cross-validation

integer, to specify the number of folds.

An iterable yielding (train, test) splits as arrays of indices.

Refer User Guide for the various cross-validation strategies that can be used here.

Weights associated with classes in the form {class_label: weight}. If not given, all classes are supposed to have weight one.

The “balanced” mode uses the values of y to automatically adjust weights inversely proportional to class frequencies in the input data as n_samples / (n_classes * np.bincount(y)).

Flag indicating if the cross-validation results corresponding to each alpha should be stored in the cv_results_ attribute (see below). This flag is only compatible with cv=None (i.e. using Leave-One-Out Cross-Validation).

Changed in version 1.5: Parameter name changed from store_cv_values to store_cv_results.

Cross-validation results for each alpha (only if store_cv_results=True and cv=None). After fit() has been called, this attribute will contain the mean squared errors if scoring is None otherwise it will contain standardized per point prediction values.

Changed in version 1.5: cv_values_ changed to cv_results_.

Coefficient of the features in the decision function.

coef_ is of shape (1, n_features) when the given problem is binary.

Independent term in decision function. Set to 0.0 if fit_intercept = False.

Estimated regularization parameter.

Score of base estimator with best alpha.

Added in version 0.23.

Number of features seen during fit.

Added in version 0.24.

Names of features seen during fit. Defined only when X has feature names that are all strings.

Added in version 1.0.

Ridge regression with built-in cross validation.

For multi-class classification, n_class classifiers are trained in a one-versus-all approach. Concretely, this is implemented by taking advantage of the multi-variate response support in Ridge.

Predict confidence scores for samples.

The confidence score for a sample is proportional to the signed distance of that sample to the hyperplane.

The data matrix for which we want to get the confidence scores.

Confidence scores per (n_samples, n_classes) combination. In the binary case, confidence score for self.classes_[1] where >0 means this class would be predicted.

Fit Ridge classifier with cv.

Training vectors, where n_samples is the number of samples and n_features is the number of features. When using GCV, will be cast to float64 if necessary.

Target values. Will be cast to X’s dtype if necessary.

Individual weights for each sample. If given a float, every sample will have the same weight.

Parameters to be passed to the underlying scorer.

Added in version 1.5: Only available if enable_metadata_routing=True, which can be set by using sklearn.set_config(enable_metadata_routing=True). See Metadata Routing User Guide for more details.

Get metadata routing of this object.

Please check User Guide on how the routing mechanism works.

Added in version 1.5.

A MetadataRouter encapsulating routing information.

Get parameters for this estimator.

If True, will return the parameters for this estimator and contained subobjects that are estimators.

Parameter names mapped to their values.

Predict class labels for samples in X.

The data matrix for which we want to predict the targets.

Vector or matrix containing the predictions. In binary and multiclass problems, this is a vector containing n_samples. In a multilabel problem, it returns a matrix of shape (n_samples, n_outputs).

Return accuracy on provided data and labels.

In multi-label classification, this is the subset accuracy which is a harsh metric since you require for each sample that each label set be correctly predicted.

Mean accuracy of self.predict(X) w.r.t. y.

Configure whether metadata should be requested to be passed to the fit method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to fit if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to fit.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Added in version 1.3.

Metadata routing for sample_weight parameter in fit.

Set the parameters of this estimator.

The method works on simple estimators as well as on nested objects (such as Pipeline). The latter have parameters of the form <component>__<parameter> so that it’s possible to update each component of a nested object.

Estimator parameters.

Configure whether metadata should be requested to be passed to the score method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to score if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to score.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Added in version 1.3.

Metadata routing for sample_weight parameter in score.

**Examples:**

Example 1 (sql):
```sql
>>> from sklearn.datasets import load_breast_cancer
>>> from sklearn.linear_model import RidgeClassifierCV
>>> X, y = load_breast_cancer(return_X_y=True)
>>> clf = RidgeClassifierCV(alphas=[1e-3, 1e-2, 1e-1, 1]).fit(X, y)
>>> clf.score(X, y)
0.9630...
```

---

## KNeighborsRegressor#

**URL:** https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsRegressor.html

**Contents:**
- KNeighborsRegressor#
- Gallery examples#

Regression based on k-nearest neighbors.

The target is predicted by local interpolation of the targets associated of the nearest neighbors in the training set.

Read more in the User Guide.

Added in version 0.9.

Number of neighbors to use by default for kneighbors queries.

Weight function used in prediction. Possible values:

‘uniform’ : uniform weights. All points in each neighborhood are weighted equally.

‘distance’ : weight points by the inverse of their distance. in this case, closer neighbors of a query point will have a greater influence than neighbors which are further away.

[callable] : a user-defined function which accepts an array of distances, and returns an array of the same shape containing the weights.

Uniform weights are used by default.

See the following example for a demonstration of the impact of different weighting schemes on predictions: Nearest Neighbors regression.

Algorithm used to compute the nearest neighbors:

‘ball_tree’ will use BallTree

‘kd_tree’ will use KDTree

‘brute’ will use a brute-force search.

‘auto’ will attempt to decide the most appropriate algorithm based on the values passed to fit method.

Note: fitting on sparse input will override the setting of this parameter, using brute force.

Leaf size passed to BallTree or KDTree. This can affect the speed of the construction and query, as well as the memory required to store the tree. The optimal value depends on the nature of the problem.

Power parameter for the Minkowski metric. When p = 1, this is equivalent to using manhattan_distance (l1), and euclidean_distance (l2) for p = 2. For arbitrary p, minkowski_distance (l_p) is used.

Metric to use for distance computation. Default is “minkowski”, which results in the standard Euclidean distance when p = 2. See the documentation of scipy.spatial.distance and the metrics listed in distance_metrics for valid metric values.

If metric is “precomputed”, X is assumed to be a distance matrix and must be square during fit. X may be a sparse graph, in which case only “nonzero” elements may be considered neighbors.

If metric is a callable function, it takes two arrays representing 1D vectors as inputs and must return one value indicating the distance between those vectors. This works for Scipy’s metrics, but is less efficient than passing the metric name as a string.

If metric is a DistanceMetric object, it will be passed directly to the underlying computation routines.

Additional keyword arguments for the metric function.

The number of parallel jobs to run for neighbors search. None means 1 unless in a joblib.parallel_backend context. -1 means using all processors. See Glossary for more details. Doesn’t affect fit method.

The distance metric to use. It will be same as the metric parameter or a synonym of it, e.g. ‘euclidean’ if the metric parameter set to ‘minkowski’ and p parameter set to 2.

Additional keyword arguments for the metric function. For most metrics will be same with metric_params parameter, but may also contain the p parameter value if the effective_metric_ attribute is set to ‘minkowski’.

Number of features seen during fit.

Added in version 0.24.

Names of features seen during fit. Defined only when X has feature names that are all strings.

Added in version 1.0.

Number of samples in the fitted data.

Unsupervised learner for implementing neighbor searches.

Regression based on neighbors within a fixed radius.

Classifier implementing the k-nearest neighbors vote.

Classifier implementing a vote among neighbors within a given radius.

See Nearest Neighbors in the online documentation for a discussion of the choice of algorithm and leaf_size.

Regarding the Nearest Neighbors algorithms, if it is found that two neighbors, neighbor k+1 and k, have identical distances but different labels, the results will depend on the ordering of the training data.

https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm

Fit the k-nearest neighbors regressor from the training dataset.

The fitted k-nearest neighbors regressor.

Get metadata routing of this object.

Please check User Guide on how the routing mechanism works.

A MetadataRequest encapsulating routing information.

Get parameters for this estimator.

If True, will return the parameters for this estimator and contained subobjects that are estimators.

Parameter names mapped to their values.

Find the K-neighbors of a point.

Returns indices of and distances to the neighbors of each point.

The query point or points. If not provided, neighbors of each indexed point are returned. In this case, the query point is not considered its own neighbor.

Number of neighbors required for each sample. The default is the value passed to the constructor.

Whether or not to return the distances.

Array representing the lengths to points, only present if return_distance=True.

Indices of the nearest points in the population matrix.

In the following example, we construct a NearestNeighbors class from an array representing our data set and ask who’s the closest point to [1,1,1]

As you can see, it returns [[0.5]], and [[2]], which means that the element is at distance 0.5 and is the third element of samples (indexes start at 0). You can also query for multiple points:

Compute the (weighted) graph of k-Neighbors for points in X.

The query point or points. If not provided, neighbors of each indexed point are returned. In this case, the query point is not considered its own neighbor. For metric='precomputed' the shape should be (n_queries, n_indexed). Otherwise the shape should be (n_queries, n_features).

Number of neighbors for each sample. The default is the value passed to the constructor.

Type of returned matrix: ‘connectivity’ will return the connectivity matrix with ones and zeros, in ‘distance’ the edges are distances between points, type of distance depends on the selected metric parameter in NearestNeighbors class.

n_samples_fit is the number of samples in the fitted data. A[i, j] gives the weight of the edge connecting i to j. The matrix is of CSR format.

Compute the (weighted) graph of Neighbors for points in X.

Predict the target for the provided data.

Test samples. If None, predictions for all indexed points are returned; in this case, points are not considered their own neighbors.

Return coefficient of determination on test data.

The coefficient of determination, \(R^2\), is defined as \((1 - \frac{u}{v})\), where \(u\) is the residual sum of squares ((y_true - y_pred)** 2).sum() and \(v\) is the total sum of squares ((y_true - y_true.mean()) ** 2).sum(). The best possible score is 1.0 and it can be negative (because the model can be arbitrarily worse). A constant model that always predicts the expected value of y, disregarding the input features, would get a \(R^2\) score of 0.0.

Test samples. For some estimators this may be a precomputed kernel matrix or a list of generic objects instead with shape (n_samples, n_samples_fitted), where n_samples_fitted is the number of samples used in the fitting for the estimator.

\(R^2\) of self.predict(X) w.r.t. y.

The \(R^2\) score used when calling score on a regressor uses multioutput='uniform_average' from version 0.23 to keep consistent with default value of r2_score. This influences the score method of all the multioutput regressors (except for MultiOutputRegressor).

Set the parameters of this estimator.

The method works on simple estimators as well as on nested objects (such as Pipeline). The latter have parameters of the form <component>__<parameter> so that it’s possible to update each component of a nested object.

Estimator parameters.

Configure whether metadata should be requested to be passed to the score method.

Note that this method is only relevant when this estimator is used as a sub-estimator within a meta-estimator and metadata routing is enabled with enable_metadata_routing=True (see sklearn.set_config). Please check the User Guide on how the routing mechanism works.

The options for each parameter are:

True: metadata is requested, and passed to score if provided. The request is ignored if metadata is not provided.

False: metadata is not requested and the meta-estimator will not pass it to score.

None: metadata is not requested, and the meta-estimator will raise an error if the user provides it.

str: metadata should be passed to the meta-estimator with this given alias instead of the original name.

The default (sklearn.utils.metadata_routing.UNCHANGED) retains the existing request. This allows you to change the request for some parameters and not others.

Added in version 1.3.

Metadata routing for sample_weight parameter in score.

Imputing missing values with variants of IterativeImputer

Face completion with a multi-output estimators

Nearest Neighbors regression

**Examples:**

Example 1 (python):
```python
>>> X = [[0], [1], [2], [3]]
>>> y = [0, 0, 1, 1]
>>> from sklearn.neighbors import KNeighborsRegressor
>>> neigh = KNeighborsRegressor(n_neighbors=2)
>>> neigh.fit(X, y)
KNeighborsRegressor(...)
>>> print(neigh.predict([[1.5]]))
[0.5]
```

Example 2 (python):
```python
>>> samples = [[0., 0., 0.], [0., .5, 0.], [1., 1., .5]]
>>> from sklearn.neighbors import NearestNeighbors
>>> neigh = NearestNeighbors(n_neighbors=1)
>>> neigh.fit(samples)
NearestNeighbors(n_neighbors=1)
>>> print(neigh.kneighbors([[1., 1., 1.]]))
(array([[0.5]]), array([[2]]))
```

Example 3 (json):
```json
>>> X = [[0., 1., 0.], [1., 0., 1.]]
>>> neigh.kneighbors(X, return_distance=False)
array([[1],
       [2]]...)
```

Example 4 (sql):
```sql
>>> X = [[0], [3], [1]]
>>> from sklearn.neighbors import NearestNeighbors
>>> neigh = NearestNeighbors(n_neighbors=2)
>>> neigh.fit(X)
NearestNeighbors(n_neighbors=2)
>>> A = neigh.kneighbors_graph(X)
>>> A.toarray()
array([[1., 0., 1.],
       [0., 1., 1.],
       [1., 0., 1.]])
```

---

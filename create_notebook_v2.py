import nbformat as nbf

nb = nbf.v4.new_notebook()

# 1. Intro
intro_md = """\
# ğŸ›ï¸ ë„¤ì´ë²„ ì‡¼í•‘(í…€ë¸”ëŸ¬) ë§¤ì¶œ ìµœì í™” ë°ì´í„° ë¶„ì„
### Data Analysis Project: Pricing Strategy Optimization
**Author**: Data Analyst Sebokoh  
**Date**: 2026.01.28

---
## 1. í”„ë¡œì íŠ¸ ê°œìš” (Executive Summary)
ë³¸ ë¶„ì„ì€ ë„¤ì´ë²„ ì‡¼í•‘ 'í…€ë¸”ëŸ¬' ì¹´í…Œê³ ë¦¬ì˜ 2,110ê°œ ìƒí’ˆ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ **ë§¤ì¶œì„ ê·¹ëŒ€í™”í•  ìˆ˜ ìˆëŠ” 3ê°€ì§€ ì „ëµ(Triple-Core Strategy)**ì„ ìˆ˜ë¦½í•˜ëŠ” ê³¼ì •ì„ ë‹´ê³  ìˆìŠµë‹ˆë‹¤.

### ğŸ¯ 3ëŒ€ ê²€ì¦ ê°€ì„¤ (Hypotheses)
1.  **Text Hypothesis**: "ê¸°ëŠ¥ì„± ë‹¨ì–´(ìŠ¤í…, ì§„ê³µ)ëŠ” ì˜¤íˆë ¤ ì €ë ´í•´ ë³´ì´ê³ , ì¶”ìƒì  ë‹¨ì–´(ì—ë””ì…˜, ì •í’ˆ)ëŠ” ë¹„ì‹¸ ë³´ì¸ë‹¤."
2.  **Structure Hypothesis**: "ë¸Œëœë“œì™€ ê°ì„± í‚¤ì›Œë“œê°€ ì œí’ˆ ìŠ¤í™(ìš©ëŸ‰)ë³´ë‹¤ ì•ì— ì˜¬ ë•Œ, ì†Œë¹„ìì˜ ì§€ë¶ˆ ìš©ì˜(WTP)ê°€ ë†’ì•„ì§„ë‹¤."
3.  **Visual Hypothesis**: "ì±„ë„ê°€ ë‚®ê³  ì°¨ë¶„í•œ(Pastel) ì´ë¯¸ì§€ê°€ ì›ìƒ‰(Vivid) ì´ë¯¸ì§€ë³´ë‹¤ ê³ ê¸‰ìŠ¤ëŸ¬ì›Œ ë³´ì¸ë‹¤."
---"""

# 2. Setup & Data Load
setup_code = """\
import pandas as pd
import numpy as np
import glob
import os
import re
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import Ridge
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_absolute_error, r2_score
import warnings

# ì„¤ì •
warnings.filterwarnings('ignore')
plt.rcParams['font.family'] = 'AppleGothic'
plt.rcParams['axes.unicode_minus'] = False
%matplotlib inline

# ë°ì´í„° ë¡œë“œ (Repo êµ¬ì¡°ì— ë§ì¶° ./data ê²½ë¡œ ì‚¬ìš©)
data_dir = "./data"
# ë¡œì»¬ í…ŒìŠ¤íŠ¸ìš© ê²½ë¡œ fallback
if not os.path.exists(data_dir):
    data_dir = "./naver_shopping_analysis/data"

csv_files = glob.glob(os.path.join(data_dir, "naver_shopping_*.csv"))
if not csv_files:
    # ê¹ƒí—ˆë¸Œìš© ê²½ë¡œ (ë¦¬í¬ì§€í† ë¦¬ ìµœìƒë‹¨ ê¸°ì¤€)
    csv_files = glob.glob(os.path.join(".", "*.csv"))

print(f"ğŸ“ ê°ì§€ëœ ë°ì´í„° íŒŒì¼: {len(csv_files)}ê°œ")

df_list = []
for f in csv_files:
    try:
        df_list.append(pd.read_csv(f, encoding='utf-8-sig'))
    except:
        pass

if df_list:
    df = pd.concat(df_list, ignore_index=True)
    
    # ì „ì²˜ë¦¬
    df = df.drop_duplicates(subset=['product_id']).copy()
    df['lprice'] = pd.to_numeric(df['lprice'], errors='coerce')
    df = df.dropna(subset=['lprice', 'title'])
    
    # ì•„ì›ƒë¼ì´ì–´ ì œê±° (ì•ˆì •ì  ë¶„ì„ì„ ìœ„í•´ ìƒí•˜ìœ„ 1% ì œì™¸)
    lower = df['lprice'].quantile(0.01)
    upper = df['lprice'].quantile(0.99)
    df_clean = df[(df['lprice'] >= lower) & (df['lprice'] <= upper)].copy()
    
    print(f"âœ… ë°ì´í„° ë¡œë“œ ë° ì •ì œ ì™„ë£Œ: {len(df_clean)}ê°œ ìƒ˜í”Œ")
    print(df_clean[['title', 'lprice', 'brand']].head())
else:
    print("âš ï¸ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê²½ë¡œë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")"""

# 3. Text Mining Section
text_analysis_md = """\
## 2. í…ìŠ¤íŠ¸ ë§ˆì´ë‹: "ê°€ì¹˜ì˜ ì¬ë°œê²¬"
TF-IDFì™€ Ridge Regression ëª¨ë¸ì„ í™œìš©í•˜ì—¬, ê° ë‹¨ì–´ê°€ ê°€ê²©(Price)ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ë ¥ì„ ìˆ˜ì¹˜í™”í–ˆìŠµë‹ˆë‹¤.
- **ë¶„ì„ ëª©í‘œ:** "ìŠ¤í…" vs "ì—ë””ì…˜" ì¤‘ ì–´ë–¤ ë‹¨ì–´ê°€ ë” ë¹„ì‹¼ê°€?"""

text_analysis_code = """\
# í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬ í•¨ìˆ˜
def clean_text(text):
    text = str(text).lower()
    text = re.sub(r'[^ê°€-í£a-z0-9\s]', ' ', text)
    return text

df_clean['clean_title'] = df_clean['title'].apply(clean_text)

# TF-IDF ë²¡í„°í™” (1-2 gram)
vectorizer = TfidfVectorizer(max_features=3000, ngram_range=(1, 2), min_df=3)
X = vectorizer.fit_transform(df_clean['clean_title'])
y = np.log1p(df_clean['lprice']) # ê°€ê²© ë¡œê·¸ ë³€í™˜

# Ridge Regression í•™ìŠµ
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
model = Ridge(alpha=1.0)
model.fit(X_train, y_train)

# ì„¤ëª…ë ¥ í™•ì¸
r2 = model.score(X_test, y_test)
print(f"ğŸ“Š ëª¨ë¸ ì„¤ëª…ë ¥ (R2 Score): {r2:.3f}")

# ì£¼ìš” í‚¤ì›Œë“œ ì¶”ì¶œ
feature_names = vectorizer.get_feature_names_out()
coefs = model.coef_
coef_df = pd.DataFrame({'keyword': feature_names, 'coefficient': coefs})
coef_df = coef_df.sort_values(by='coefficient', ascending=False)

# ì‹œê°í™”: High Value Keywords
plt.figure(figsize=(10, 6))
sns.barplot(data=coef_df.head(10), x='coefficient', y='keyword', palette='Reds_r')
plt.title('ê°€ê²©(Value)ì„ ìƒìŠ¹ì‹œí‚¤ëŠ” Top 10 í‚¤ì›Œë“œ')
plt.show()

# ì‹œê°í™”: Low Value Keywords
plt.figure(figsize=(10, 6))
sns.barplot(data=coef_df.tail(10).sort_values(by='coefficient'), x='coefficient', y='keyword', palette='Blues_r')
plt.title('ê°€ê²©(Value)ì„ í•˜ë½ì‹œí‚¤ëŠ” Top 10 í‚¤ì›Œë“œ')
plt.show()"""

# 4. A/B Test Simulation
ab_test_md = """\
## 3. A/B í…ŒìŠ¤íŠ¸ ì‹œë®¬ë ˆì´ì…˜: ê°€ì¹˜ ìƒìŠ¹ ì˜ˆì¸¡
ë„ì¶œëœ ì¸ì‚¬ì´íŠ¸(ê°€ì„¤)ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìƒí’ˆëª…ì„ ìµœì í™”(Optimization)í–ˆì„ ë•Œ, AI ëª¨ë¸ì´ ì˜ˆì¸¡í•˜ëŠ” ê°€ì¹˜ê°€ ì–¼ë§ˆë‚˜ ìƒìŠ¹í•˜ëŠ”ì§€ ì‹œë®¬ë ˆì´ì…˜í–ˆìŠµë‹ˆë‹¤.

### ğŸ§ª ì‹¤í—˜ ì„¤ê³„ (Experimental Design)
- **Control Group:** ê¸°ì¡´ ìƒí’ˆëª… ê·¸ëŒ€ë¡œ ì‚¬ìš©
- **Test Group:** ìµœì í™” ë¡œì§ ì ìš©
    1.  **Remove:** `ìŠ¤í…`, `ì´ì¤‘ì§„ê³µ`, `ê°€ì„±ë¹„` ë“± ì €ê°€í˜• ë‹¨ì–´ ì‚­ì œ
    2.  **Reorder:** `ìš©ëŸ‰(500ml)`ì€ ë’¤ë¡œ ë³´ë‚´ê³ , `ë¸Œëœë“œ/ê°ì„±` í‚¤ì›Œë“œëŠ” ì•ìœ¼ë¡œ ë°°ì¹˜"""

ab_test_code = """\
# ìµœì í™” ë¡œì§ ì •ì˜
def optimize_title(title):
    new_title = title
    # 1. ì €ê°€í˜• ë‹¨ì–´ ì œê±°
    removals = ['ìŠ¤í…', 'ìŠ¤í…Œì¸ë¦¬ìŠ¤', 'ì´ì¤‘ì§„ê³µ', 'ê°€ì„±ë¹„', 'ì‹¤ì†', 'ì €ë ´í•œ', 'íŠ¹ê°€']
    for r in removals:
        new_title = new_title.replace(r, '')
        
    # 2. ìš©ëŸ‰ í‘œê¸° í›„ë°© ë°°ì¹˜
    cap_pattern = r'(\d+ml|\d+\.\d+L|\d+L)'
    match = re.search(cap_pattern, new_title)
    capacity = ""
    if match:
        capacity = match.group(0)
        new_title = re.sub(cap_pattern, '', new_title)
        
    # 3. ë¸Œëœë”© ê°•í™” (ì‹œë®¬ë ˆì´ì…˜ìš© ì˜ˆì‹œ: ìœ ëª… ë¸Œëœë“œì— 'ì •í’ˆ' íƒœê·¸ ë¶€ì—¬)
    prefix = ""
    if "ìŠ¤íƒ ë¦¬" in new_title or "ìŠ¤íƒ€ë²…ìŠ¤" in new_title:
        if "ì •í’ˆ" not in new_title:
            prefix += " [ë³¸ì‚¬ì •í’ˆ]"
            
    final_title = f"{prefix} {new_title} {capacity}".strip()
    return re.sub(r'\s+', ' ', final_title)

# íƒ€ê²Ÿ ìƒ˜í”Œë§ (ë¸Œëœë“œ ì œí’ˆ ìœ„ì£¼ 100ê°œ)
target_brands = ['ìŠ¤íƒ ë¦¬', 'ìŠ¤íƒ€ë²…ìŠ¤', 'ì¨ëª¨ìŠ¤']
mask = df_clean['title'].apply(lambda x: any(b in x for b in target_brands))
sample_df = df_clean[mask].sample(100, random_state=42).copy()

# ì‹œë®¬ë ˆì´ì…˜ ì‹¤í–‰
sample_df['optimized_title'] = sample_df['title'].apply(optimize_title)

vec_orig = vectorizer.transform(sample_df['title'].apply(clean_text))
vec_opt = vectorizer.transform(sample_df['optimized_title'].apply(clean_text))

sample_df['pred_original'] = np.expm1(model.predict(vec_orig))
sample_df['pred_optimized'] = np.expm1(model.predict(vec_opt))
sample_df['lift'] = (sample_df['pred_optimized'] - sample_df['pred_original']) / sample_df['pred_original'] * 100

# ê²°ê³¼ ì‹œê°í™”
plt.figure(figsize=(10, 6))
sns.kdeplot(sample_df['pred_original'], fill=True, label='Original (Before)', color='gray')
sns.kdeplot(sample_df['pred_optimized'], fill=True, label='Optimized (After)', color='red')
plt.title('A/B Simulation: ìƒí’ˆëª… ìµœì í™” ì „í›„ ê°€ì¹˜ ë¶„í¬ ë³€í™”')
plt.xlabel('AI ì˜ˆì¸¡ ê°€ê²© (Predicted Price)')
plt.legend()
plt.show()

print(f"ğŸ’° í‰ê·  ê°€ì¹˜ ìƒìŠ¹ë¥  (Avg Lift): +{sample_df['lift'].mean():.2f}%")
print(f"ğŸš€ ìµœëŒ€ ê°€ì¹˜ ìƒìŠ¹ ì‚¬ë¡€: +{sample_df['lift'].max():.2f}%")"""

# 5. Image Analysis
image_md = """\
## 4. ì´ë¯¸ì§€ ë¶„ì„: "Visual Pricing Strategy"
60ê°œ ëŒ€í‘œ ìƒí’ˆì˜ ì¸ë„¤ì¼ ì´ë¯¸ì§€ë¥¼ ë‹¤ìš´ë¡œë“œí•˜ì—¬ **RGB/HSV í”½ì…€ ë¶„ì„**ì„ ìˆ˜í–‰í–ˆìŠµë‹ˆë‹¤.
(ë³¸ ë¶„ì„ì€ `Pillow`ì™€ `KMeans`ë¥¼ í™œìš©í•˜ì—¬ ì´ë¯¸ì§€ì˜ ì±„ë„ì™€ ë°ê¸°ë¥¼ ìˆ˜ì¹˜í™”í–ˆìŠµë‹ˆë‹¤.)"""

image_code = """\
# ì´ë¯¸ì§€ ë¶„ì„ ê²°ê³¼ ë¡œë“œ (ì‚¬ì „ ë¶„ì„ëœ ë°ì´í„° í™œìš©)
# (ë…¸íŠ¸ë¶ ì‹¤í–‰ ì†ë„ ë° ì¸í„°ë„· ì—°ê²° ì˜ì¡´ì„±ì„ ì¤„ì´ê¸° ìœ„í•´ CSV ê²°ê³¼ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤)
# ì‹¤ì œ ë¶„ì„ ì½”ë“œëŠ” ì•„ë˜ ì£¼ì„ì— í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤.

import requests
from io import BytesIO
from PIL import Image
# ... (Image Processing Code skipped for brevity, loading result csv)

img_result_path = "./data/image_analysis_result.csv"
if os.path.exists(img_result_path):
    img_df = pd.read_csv(img_result_path)
    
    # ì‹œê°í™”: ì±„ë„(Saturation) vs ê°€ê²©(Price)
    plt.figure(figsize=(10, 6))
    sns.scatterplot(x='saturation', y='lprice', data=img_df, hue='lprice', palette='coolwarm', s=100)
    plt.axvline(x=0.4, color='gray', linestyle='--')
    plt.text(0.1, img_df['lprice'].max(), 'Pastel Zone (Premium)', color='blue')
    plt.text(0.6, img_df['lprice'].max(), 'Vivid Zone (Mass)', color='red')
    plt.title('ì´ë¯¸ì§€ ì±„ë„(Saturation)ì™€ ê°€ê²©ì˜ ìƒê´€ê´€ê³„')
    plt.xlabel('Saturation (0: Gray/Pastel -> 1: Vivid)')
    plt.show()
    
    corr = img_df['saturation'].corr(img_df['lprice'])
    print(f"ğŸ“‰ ì±„ë„ì™€ ê°€ê²©ì˜ ìƒê´€ê³„ìˆ˜: {corr:.3f} (ìŒì˜ ìƒê´€ê´€ê³„ í™•ì¸)")
else:
    print("ì´ë¯¸ì§€ ë¶„ì„ ê²°ê³¼ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")"""

# 6. Conclusion
conclusion_md = """\
## 5. ê²°ë¡  ë° ì œì–¸ (Conclusion)
ë³¸ ë¶„ì„ì„ í†µí•´ **"ìŠ¤í™ì„ ê°ì¶”ê³ , ê°ì„±ì„ íŒ”ì•„ë¼"**ëŠ” ê°€ì„¤ì´ ë°ì´í„°ë¡œ ì…ì¦ë˜ì—ˆìŠµë‹ˆë‹¤.

### ğŸ“ Action Plan
1.  **Title:** `ìŠ¤í…`, `ì´ì¤‘ì§„ê³µ` ì‚­ì œ â†’ `[ë³¸ì‚¬ì •í’ˆ]`, `[ì»¬ë ‰ì…˜ëª…]` ì¶”ê°€
2.  **Image:** ì¸ë„¤ì¼ ì±„ë„ë¥¼ ë‚®ì¶°(Desaturation) ê³ ê¸‰ìŠ¤ëŸ¬ìš´ ë¬´ë“œ ì—°ì¶œ

---
*Created by Data Analyst Sebokoh*"""

# Append cells
nb.cells.append(nbf.v4.new_markdown_cell(intro_md))
nb.cells.append(nbf.v4.new_code_cell(setup_code))
nb.cells.append(nbf.v4.new_markdown_cell(text_analysis_md))
nb.cells.append(nbf.v4.new_code_cell(text_analysis_code))
nb.cells.append(nbf.v4.new_markdown_cell(ab_test_md))
nb.cells.append(nbf.v4.new_code_cell(ab_test_code))
nb.cells.append(nbf.v4.new_markdown_cell(image_md))
nb.cells.append(nbf.v4.new_code_cell(image_code))
nb.cells.append(nbf.v4.new_markdown_cell(conclusion_md))

# Save
with open('Naver_Shopping_Pricing_Strategy.ipynb', 'w', encoding='utf-8') as f:
    nbf.write(nb, f)

print("âœ… ë…¸íŠ¸ë¶ ë¦¬ë¹Œë“œ ì™„ë£Œ (Full Code Embedded)")
